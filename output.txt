E
s
s
e
n
t
i
a
l
s
o f
 
C o m p u t e r
A r c h i t e c t u r e
2
n
d
 
E
d
E s s e n t i a l s  o f  C o m p u t e r  A r c h i t e c t u r e  2 n d  E d
Douglas E. Comer
著
吉川邦夫
 翻訳
［第
２
版］
コ
ン
ピ
ュ
ータ
ア
ーキテ
ク
チャ
の
エ
ッ
セ
ン
ス
基
礎
知
識
こ
そ
プロ
グ
ラマに
とって
の
”銀
の
弾
丸
“だ
！
計
算
機
工
学
と
計
算
機
科
学
の
両
分
野
を
内
包
す
る
広
大
な
世
界
を
、
プ
ロ
セ
ッ
サ
、メ
モ
リ
、I
O
の
3
つ
の
入
り
口
か
ら
攻
略
し
、
ハ
ー
ド
ウ
ェ
ア
と
ソ
フ
ト
ウ
ェ
ア
の
知
見
を
有
す
る
プ
ロ
グ
ラ
マ
へ
と
進
化
せ
よ
基
礎
知
識
こ
そ
プロ
グ
ラマに
とって
の
”銀
の
弾
丸
“だ
！
計
算
機
工
学
と
計
算
機
科
学
の
両
分
野
を
内
包
す
る
広
大
な
世
界
を
、
プ
ロ
セ
ッ
サ
、メ
モ
リ
、I
O
の
3
つ
の
入
り
口
か
ら
攻
略
し
、
ハ
ー
ド
ウ
ェ
ア
と
ソ
フ
ト
ウ
ェ
ア
の
知
見
を
有
す
る
プ
ロ
グ
ラ
マ
へ
と
進
化
せ
よ
hi.0412.ko.2002@gmail.com
hi.0412.ko.2002@gmail.com
hi.0412.ko.2002@gmail.com
本書内容に関するお問い合わせについて
このたびは翔泳社の書籍をお買い上げいただき、誠にありがとうございます。弊社では、読者の皆様から
のお問い合わせに適切に対応させていただくため、以下のガイドラインへのご協力をお願いいたしており
ます。下記項目をお読みいただき、手順に従ってお問い合わせください。
●ご質問される前に
弊社Web サイトの「正誤表」をご参照ください。これまでに判明した正誤や追加情報を掲載しています。
正誤表
https://www.shoeisha.co.jp/book/errata/
●ご質問方法
弊社Web サイトの「刊行物Q ＆A」をご利用ください。
刊行物Q ＆A
https://www.shoeisha.co.jp/book/qa/
インターネットをご利用でない場合は、FAX または郵便にて、下記“翔泳社愛読者サービスセンター”ま
でお問い合わせください。
電話でのご質問は、お受けしておりません。
●回答について
回答は、ご質問いただいた手段によってご返事申し上げます。ご質問の内容によっては、回答に数日ない
しはそれ以上の期間を要する場合があります。
●ご質問に際してのご注意
本書の対象を越えるもの、記述個所を特定されないもの、また読者固有の環境に起因するご質問等にはお
答えできませんので、あらかじめご了承ください。
●郵便物送付先およびFAX 番号
送付先住所〒160-0006 東京都新宿区舟町5
FAX 番号03-5362-3818
宛先（株）翔泳社愛読者サービスセンター
※本書に記載されたURL 等は予告なく変更される場合があります。
※本書の出版にあたっては正確な記述につとめましたが、著者や出版社などのいずれも、本書の内容に対し
てなんらかの保証をするものではなく、内容やサンプルに基づくいかなる運用結果に関してもいっさいの
責任を負いません。
※本書に掲載されているサンプルプログラムやスクリプト、および実行結果を記した画面イメージなどは、
特定の設定に基づいた環境にて再現される一例です。
※本書に記載されている会社名、製品名はそれぞれ各社の商標および登録商標です。
※本書ではTM、Ⓡ、ⓒは割愛させていただいております。
Essentials of Computer Architecture, Second Edition
Authorised translation from the English language edition published by CRC Press, a member of the
Taylor & Francis Group LLC.
through Japan UNI Agency, Inc., TOKYO
All rights reserved.
Japanese-language edition copyright c
⃝2020 by Shoeisha Co., Ltd.
hi.0412.ko.2002@gmail.com
目　次
序文
· · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · xxi
著者について· · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · ·xxiii
第1 章
序論と概要
1
1.1
アーキテクチャの重要性· · · · · · · · · · · · · · · · · · · · · · · · ·
1
1.2
エッセンスを学ぶ
· · · · · · · · · · · · · · · · · · · · · · · · · · · ·
1
1.3
テキストの構成· · · · · · · · · · · · · · · · · · · · · · · · · · · · · ·
2
1.4
省略する事項· · · · · · · · · · · · · · · · · · · · · · · · · · · · · · ·
2
1.5
用語：アーキテクチャと設計· · · · · · · · · · · · · · · · · · · · · · ·
3
1.6
まとめ
· · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · ·
3
第1 部
基礎
5
第2 章
デジタル論理回路の基礎
7
2.1
はじめに· · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · ·
7
2.2
デジタル計算機· · · · · · · · · · · · · · · · · · · · · · · · · · · · · ·
7
2.3
用語：電圧と電流
· · · · · · · · · · · · · · · · · · · · · · · · · · · ·
8
2.4
トランジスタ· · · · · · · · · · · · · · · · · · · · · · · · · · · · · · ·
8
2.5
論理ゲート· · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · 10
2.6
トランジスタによるNAND 論理ゲートの実装· · · · · · · · · · · · · · 11
2.7
論理ゲートに使われる記号· · · · · · · · · · · · · · · · · · · · · · · · 13
2.8
ゲートの組み合わせを示す例· · · · · · · · · · · · · · · · · · · · · · · 13
2.9
バイナリ加算のデジタル回路· · · · · · · · · · · · · · · · · · · · · · · 16
2.10
複数のゲートを持つ集積回路· · · · · · · · · · · · · · · · · · · · · · 17
2.11
組み合わせ回路だけでは足りない· · · · · · · · · · · · · · · · · · · · 18
2.12
状態を維持する回路· · · · · · · · · · · · · · · · · · · · · · · · · · · 19
2.13
伝搬遅延
· · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · 19
2.14
ラッチを使ってメモリを作る· · · · · · · · · · · · · · · · · · · · · · 20
2.15
フリップフロップと状態遷移図· · · · · · · · · · · · · · · · · · · · · 21
2.16
バイナリカウンタ· · · · · · · · · · · · · · · · · · · · · · · · · · · · 23
hi.0412.ko.2002@gmail.com
iv
目　次　
2.17
クロックとシーケンス
· · · · · · · · · · · · · · · · · · · · · · · · · 24
2.18
フィードバックという重要な概念· · · · · · · · · · · · · · · · · · · · 27
2.19
シーケンスを始動する
· · · · · · · · · · · · · · · · · · · · · · · · · 28
2.20
ソフトウェアの反復とハードウェアの複製· · · · · · · · · · · · · · · 29
2.21
ゲートとチップの最小化
· · · · · · · · · · · · · · · · · · · · · · · · 30
2.22
余ったゲートの使い方
· · · · · · · · · · · · · · · · · · · · · · · · · 31
2.23
配電と放熱
· · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · 31
2.24
タイミングと複数のクロック領域· · · · · · · · · · · · · · · · · · · · 32
2.25
クロックレスロジック
· · · · · · · · · · · · · · · · · · · · · · · · · 33
2.26
回路の規模とムーアの法則· · · · · · · · · · · · · · · · · · · · · · · 34
2.27
回路基板と多層化· · · · · · · · · · · · · · · · · · · · · · · · · · · · 36
2.28
抽象レベル
· · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · 36
2.29
まとめ· · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · 37
練習問題· · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · 37
第3 章
データとプログラムの表現
39
3.1
はじめに· · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · 39
3.2
デジタル論理と重要な抽象· · · · · · · · · · · · · · · · · · · · · · · · 39
3.3
ビットとバイトの定義· · · · · · · · · · · · · · · · · · · · · · · · · · 40
3.4
バイトのサイズと値の範囲· · · · · · · · · · · · · · · · · · · · · · · · 40
3.5
2 進の位取り記数法
· · · · · · · · · · · · · · · · · · · · · · · · · · · 41
3.6
ビットの順序· · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · 43
3.7
16 進記法· · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · 43
3.8
16 進および2 進の定数記法· · · · · · · · · · · · · · · · · · · · · · · 44
3.9
文字集合· · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · 45
3.10
Unicode · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · 46
3.11
符号なし整数のオーバーフローとアンダーフロー
· · · · · · · · · · · 47
3.12
ビットとバイトの番号
· · · · · · · · · · · · · · · · · · · · · · · · · 47
3.13
2 進の符号付き整数· · · · · · · · · · · · · · · · · · · · · · · · · · · 49
3.14
2 の補数の例
· · · · · · · · · · · · · · · · · · · · · · · · · · · · · · 50
3.15
符号拡張
· · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · 51
3.16
浮動小数点
· · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · 51
hi.0412.ko.2002@gmail.com
　目　次
v
3.17
IEEE 浮動小数点値の範囲· · · · · · · · · · · · · · · · · · · · · · · · 53
3.18
特殊な値
· · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · 54
3.19
BCD 表現· · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · 54
3.20
BCD 表現の符号と小数とパック
· · · · · · · · · · · · · · · · · · · · 56
3.21
データの集まり· · · · · · · · · · · · · · · · · · · · · · · · · · · · · 56
3.22
プログラムの表現· · · · · · · · · · · · · · · · · · · · · · · · · · · · 57
3.23
まとめ· · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · 57
練習問題· · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · 57
第2 部
プロセッサ
61
第4 章
さまざまなプロセッサと計算エンジン
63
4.1
はじめに· · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · 63
4.2
アーキテクチャ：2 つの基本アプローチ· · · · · · · · · · · · · · · · · 63
4.3
ハーバードとノイマンのアーキテクチャ
· · · · · · · · · · · · · · · · 64
4.4
プロセッサの定義
· · · · · · · · · · · · · · · · · · · · · · · · · · · · 65
4.5
ロジックの柔軟性
· · · · · · · · · · · · · · · · · · · · · · · · · · · · 66
4.6
階層構造と計算エンジン· · · · · · · · · · · · · · · · · · · · · · · · · 67
4.7
一般的なプロセッサの構造· · · · · · · · · · · · · · · · · · · · · · · · 68
4.8
各種のプロセッサと、その役割
· · · · · · · · · · · · · · · · · · · · · 70
4.9
プロセッサ製造技術
· · · · · · · · · · · · · · · · · · · · · · · · · · · 71
4.10
プログラム内蔵方式· · · · · · · · · · · · · · · · · · · · · · · · · · · 71
4.11
フェッチ‒ 実行サイクル· · · · · · · · · · · · · · · · · · · · · · · · 72
4.12
プログラムの変換· · · · · · · · · · · · · · · · · · · · · · · · · · · · 73
4.13
クロック周期と命令実行速度· · · · · · · · · · · · · · · · · · · · · · 74
4.14
始動と停止の制御· · · · · · · · · · · · · · · · · · · · · · · · · · · · 74
4.15
フェッチ‒ 実行サイクルを開始する
· · · · · · · · · · · · · · · · · · 75
4.16
まとめ· · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · 76
練習問題· · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · 76
第5 章
プロセッサの種類と命令セット
79
5.1
はじめに· · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · 79
hi.0412.ko.2002@gmail.com
vi
目　次　
5.2
計算能力、利便性、コスト· · · · · · · · · · · · · · · · · · · · · · · · 79
5.3
命令セットのアーキテクチャ· · · · · · · · · · · · · · · · · · · · · · · 80
5.4
オペコード、オペランド、結果
· · · · · · · · · · · · · · · · · · · · · 81
5.5
典型的な命令のフォーマット· · · · · · · · · · · · · · · · · · · · · · · 81
5.6
可変長命令と固定長命令· · · · · · · · · · · · · · · · · · · · · · · · · 82
5.7
汎用レジスタ· · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · 83
5.8
浮動小数点レジスタとレジスタ番号· · · · · · · · · · · · · · · · · · · 83
5.9
レジスタを使うプログラミング
· · · · · · · · · · · · · · · · · · · · · 83
5.10
レジスタバンク· · · · · · · · · · · · · · · · · · · · · · · · · · · · · 84
5.11
CISC とRISC の命令セット· · · · · · · · · · · · · · · · · · · · · · · 86
5.12
RISC 設計と実行パイプライン
· · · · · · · · · · · · · · · · · · · · · 87
5.13
パイプラインと命令ストール· · · · · · · · · · · · · · · · · · · · · · 88
5.14
パイプラインがストールする他の原因
· · · · · · · · · · · · · · · · · 90
5.15
プログラマにおよぼす影響· · · · · · · · · · · · · · · · · · · · · · · 90
5.16
プログラミング、ストール、No-Op 命令· · · · · · · · · · · · · · · · 91
5.17
フォワーディング· · · · · · · · · · · · · · · · · · · · · · · · · · · · 92
5.18
演算の型
· · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · 92
5.19
プログラムカウンタ、フェッチ‒ 実行、分岐· · · · · · · · · · · · · · 92
5.20
サブルーチンコール、引数、レジスタウィンドウ
· · · · · · · · · · · 94
5.21
命令セットの例· · · · · · · · · · · · · · · · · · · · · · · · · · · · · 96
5.22
最小限の命令セット· · · · · · · · · · · · · · · · · · · · · · · · · · · 98
5.23
直交性の原則· · · · · · · · · · · · · · · · · · · · · · · · · · · · · · 99
5.24
条件コードと条件分岐
· · · · · · · · · · · · · · · · · · · · · · · · · 99
5.25
まとめ· · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · 100
練習問題· · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · 100
第6 章
データパスと命令実行
103
6.1
はじめに· · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · 103
6.2
データパス· · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · 103
6.3
サンプルの命令セット· · · · · · · · · · · · · · · · · · · · · · · · · · 104
6.4
メモリ内の命令· · · · · · · · · · · · · · · · · · · · · · · · · · · · · · 107
6.5
次の命令に進む· · · · · · · · · · · · · · · · · · · · · · · · · · · · · · 108
hi.0412.ko.2002@gmail.com
　目　次
vii
6.6
命令をフェッチする
· · · · · · · · · · · · · · · · · · · · · · · · · · · 110
6.7
命令をデコードする
· · · · · · · · · · · · · · · · · · · · · · · · · · · 111
6.8
レジスタユニットへの接続· · · · · · · · · · · · · · · · · · · · · · · · 112
6.9
制御と連携· · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · 112
6.10
算術演算とマルチプレクサの働き· · · · · · · · · · · · · · · · · · · · 113
6.11
メモリ上のデータに関わる演算· · · · · · · · · · · · · · · · · · · · · 115
6.12
実行シーケンスの例· · · · · · · · · · · · · · · · · · · · · · · · · · · 115
6.13
まとめ· · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · 117
練習問題· · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · 117
第7 章
オペランドのアドレッシングと命令表現
119
7.1
はじめに· · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · 119
7.2
0/1/2/3 アドレス設計
· · · · · · · · · · · · · · · · · · · · · · · · · · 119
7.3
0 オペランド命令· · · · · · · · · · · · · · · · · · · · · · · · · · · · · 120
7.4
1 オペランド命令· · · · · · · · · · · · · · · · · · · · · · · · · · · · · 121
7.5
2 オペランド命令· · · · · · · · · · · · · · · · · · · · · · · · · · · · · 121
7.6
3 オペランド命令· · · · · · · · · · · · · · · · · · · · · · · · · · · · · 122
7.7
オペランドのソースと即値· · · · · · · · · · · · · · · · · · · · · · · · 123
7.8
フォン・ノイマンのボトルネック
· · · · · · · · · · · · · · · · · · · · 124
7.9
明示的または暗黙のオペランド符号化· · · · · · · · · · · · · · · · · · 124
7.10
複数の値を組み合わせるオペランド
· · · · · · · · · · · · · · · · · · 125
7.11
オペランド選択のトレードオフ· · · · · · · · · · · · · · · · · · · · · 126
7.12
メモリ内の値と間接参照
· · · · · · · · · · · · · · · · · · · · · · · · 128
7.13
オペランドアドレッシングモードの図解· · · · · · · · · · · · · · · · 128
7.14
まとめ· · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · 129
練習問題· · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · 130
第8 章
CPU：マイクロコード、保護、プロセッサモード
133
8.1
はじめに· · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · 133
8.2
中央処理装置· · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · 133
8.3
CPU の複雑さ
· · · · · · · · · · · · · · · · · · · · · · · · · · · · · · 134
8.4
実行モード· · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · 135
hi.0412.ko.2002@gmail.com
viii
目　次　
8.5
後方互換性· · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · 136
8.6
モード切り替え· · · · · · · · · · · · · · · · · · · · · · · · · · · · · · 136
8.7
特権と保護· · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · 137
8.8
複数レベルのプロテクション· · · · · · · · · · · · · · · · · · · · · · · 137
8.9
マイクロコードで書かれた命令
· · · · · · · · · · · · · · · · · · · · · 138
8.10
各種のマイクロコード
· · · · · · · · · · · · · · · · · · · · · · · · · 140
8.11
マイクロコードの長所
· · · · · · · · · · · · · · · · · · · · · · · · · 141
8.12
FPGA と命令セット変更
· · · · · · · · · · · · · · · · · · · · · · · · 141
8.13
垂直型のマイクロコード
· · · · · · · · · · · · · · · · · · · · · · · · 142
8.14
水平型のマイクロコード
· · · · · · · · · · · · · · · · · · · · · · · · 143
8.15
水平マイクロコードの仕組み· · · · · · · · · · · · · · · · · · · · · · 144
8.16
水平マイクロコードのサンプル· · · · · · · · · · · · · · · · · · · · · 145
8.17
複数サイクルが必要な演算· · · · · · · · · · · · · · · · · · · · · · · 147
8.18
水平マイクロコードと並列処理· · · · · · · · · · · · · · · · · · · · · 147
8.19
先読みで実行を高速化する· · · · · · · · · · · · · · · · · · · · · · · 148
8.20
並列処理と実行順序· · · · · · · · · · · · · · · · · · · · · · · · · · · 149
8.21
命令のアウトオブオーダー実行· · · · · · · · · · · · · · · · · · · · · 150
8.22
条件分岐と分岐予測· · · · · · · · · · · · · · · · · · · · · · · · · · · 150
8.23
プログラマにおよぼす影響· · · · · · · · · · · · · · · · · · · · · · · 151
8.24
まとめ· · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · 151
練習問題· · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · 152
第9 章
アセンブリ言語とプログラミングパラダイム
155
9.1
はじめに· · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · 155
9.2
高水準プログラミング言語の性質
· · · · · · · · · · · · · · · · · · · · 155
9.3
低水準プログラミング言語の性質
· · · · · · · · · · · · · · · · · · · · 157
9.4
アセンブリ言語· · · · · · · · · · · · · · · · · · · · · · · · · · · · · · 158
9.5
アセンブリ言語の構文とオペコード· · · · · · · · · · · · · · · · · · · 158
9.6
オペランドの順序
· · · · · · · · · · · · · · · · · · · · · · · · · · · · 160
9.7
レジスタ名· · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · 162
9.8
オペランドの型· · · · · · · · · · · · · · · · · · · · · · · · · · · · · · 163
9.9
アセンブリ言語プログラミングのパラダイムとイディオム
· · · · · · · 163
hi.0412.ko.2002@gmail.com
　目　次
ix
9.10
if 文のアセンブリコード
· · · · · · · · · · · · · · · · · · · · · · · · 164
9.11
if-then-else のアセンブリコード
· · · · · · · · · · · · · · · · · · · · 165
9.12
for ループのアセンブリコード
· · · · · · · · · · · · · · · · · · · · · 165
9.13
while 文のアセンブリコード· · · · · · · · · · · · · · · · · · · · · · 166
9.14
サブルーチン呼び出しのアセンブリコード· · · · · · · · · · · · · · · 166
9.15
引数付きでサブルーチンを呼び出すアセンブリコード· · · · · · · · · 167
9.16
プログラマにおよぼす影響· · · · · · · · · · · · · · · · · · · · · · · 168
9.17
関数呼び出しのアセンブリコード· · · · · · · · · · · · · · · · · · · · 168
9.18
アセンブリ言語と高水準言語のやりとり· · · · · · · · · · · · · · · · 169
9.19
変数とストレージのアセンブリコード
· · · · · · · · · · · · · · · · · 170
9.20
アセンブリ言語のコーディング例· · · · · · · · · · · · · · · · · · · · 170
9.21
2 パスのアセンブラ· · · · · · · · · · · · · · · · · · · · · · · · · · · 176
9.22
アセンブリ言語のマクロ
· · · · · · · · · · · · · · · · · · · · · · · · 178
9.23
まとめ· · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · 181
練習問題· · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · 181
第3 部
メモリ
183
第10 章
メモリとストレージ
185
10.1
はじめに
· · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · 185
10.2
定義· · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · 185
10.3
メモリの主要な側面· · · · · · · · · · · · · · · · · · · · · · · · · · · 186
10.4
メモリテクノロジーの特徴· · · · · · · · · · · · · · · · · · · · · · · 186
10.5
記憶階層という重要な概念· · · · · · · · · · · · · · · · · · · · · · · 188
10.6
命令とデータのストア
· · · · · · · · · · · · · · · · · · · · · · · · · 189
10.7
フェッチとストアのパラダイム· · · · · · · · · · · · · · · · · · · · · 189
10.8
まとめ· · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · 190
練習問題· · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · 190
第11 章
物理メモリと物理アドレッシング
193
11.1
はじめに
· · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · 193
11.2
コンピュータにおけるメモリの性質
· · · · · · · · · · · · · · · · · · 193
hi.0412.ko.2002@gmail.com
x
目　次　
11.3
SRAM とDRAM の違い
· · · · · · · · · · · · · · · · · · · · · · · · 193
11.4
メモリテクノロジーの評価基準· · · · · · · · · · · · · · · · · · · · · 195
11.5
密度· · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · 195
11.6
リードとライトの性能を区別する· · · · · · · · · · · · · · · · · · · · 196
11.7
レイテンシとメモリコントローラ· · · · · · · · · · · · · · · · · · · · 196
11.8
同期とマルチデータレートの技術· · · · · · · · · · · · · · · · · · · · 197
11.9
メモリ構成
· · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · 199
11.10
メモリアクセスとメモリバス
· · · · · · · · · · · · · · · · · · · · · 199
11.11
ワード、物理アドレス、メモリ転送· · · · · · · · · · · · · · · · · · 200
11.12
演算と物理メモリ· · · · · · · · · · · · · · · · · · · · · · · · · · · 200
11.13
メモリのワードサイズとデータ型· · · · · · · · · · · · · · · · · · · 201
11.14
バイトアドレッシングとワードへのマッピング· · · · · · · · · · · · 201
11.15
2 の冪乗を使う
· · · · · · · · · · · · · · · · · · · · · · · · · · · · 203
11.16
アラインメントとプログラミング· · · · · · · · · · · · · · · · · · · 204
11.17
メモリ容量とアドレス空間
· · · · · · · · · · · · · · · · · · · · · · 204
11.18
ワードアドレッシング用のプログラミング
· · · · · · · · · · · · · · 205
11.19
メモリ容量と「2 の冪乗」· · · · · · · · · · · · · · · · · · · · · · · 206
11.20
ポインタとデータ構造· · · · · · · · · · · · · · · · · · · · · · · · · 206
11.21
メモリダンプ
· · · · · · · · · · · · · · · · · · · · · · · · · · · · · 207
11.22
間接参照と間接オペランド
· · · · · · · · · · · · · · · · · · · · · · 209
11.23
個別にコントローラを持つ複数のメモリ
· · · · · · · · · · · · · · · 209
11.24
メモリバンク
· · · · · · · · · · · · · · · · · · · · · · · · · · · · · 210
11.25
インターリーブ
· · · · · · · · · · · · · · · · · · · · · · · · · · · · 211
11.26
CAM · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · 212
11.27
3 値CAM · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · 213
11.28
まとめ· · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · 214
練習問題· · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · 214
第12 章
キャッシュとキャッシング
217
12.1
はじめに
· · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · 217
12.2
情報はストレージの階層を伝播する
· · · · · · · · · · · · · · · · · · 217
12.3
キャッシングの定義· · · · · · · · · · · · · · · · · · · · · · · · · · · 218
hi.0412.ko.2002@gmail.com
　目　次
xi
12.4
キャッシュの特徴· · · · · · · · · · · · · · · · · · · · · · · · · · · · 218
12.5
キャッシュの用語· · · · · · · · · · · · · · · · · · · · · · · · · · · · 219
12.6
ベストケースとワーストケースのキャッシュ性能
· · · · · · · · · · · 220
12.7
典型的なシーケンスにおけるキャッシュ性能· · · · · · · · · · · · · · 221
12.8
キャッシュの置換ポリシー· · · · · · · · · · · · · · · · · · · · · · · 221
12.9
LRU 置換· · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · 222
12.10
多段キャッシュの階層構造
· · · · · · · · · · · · · · · · · · · · · · 223
12.11
キャッシュをプリロードする
· · · · · · · · · · · · · · · · · · · · · 223
12.12
メモリシステムで使われるキャッシュ· · · · · · · · · · · · · · · · · 224
12.13
物理メモリのキャッシュ· · · · · · · · · · · · · · · · · · · · · · · · 225
12.14
ライトスルーとライトバック
· · · · · · · · · · · · · · · · · · · · · 225
12.15
キャッシュの一貫性· · · · · · · · · · · · · · · · · · · · · · · · · · 227
12.16
L1、L2、L3 のキャッシュ· · · · · · · · · · · · · · · · · · · · · · · 228
12.17
L1、L2、L3 のキャッシュ容量
· · · · · · · · · · · · · · · · · · · · 229
12.18
命令キャッシュとデータキャッシュ· · · · · · · · · · · · · · · · · · 229
12.19
変形ハーバードアーキテクチャ· · · · · · · · · · · · · · · · · · · · 230
12.20
メモリキャッシュの実装方法
· · · · · · · · · · · · · · · · · · · · · 231
12.21
ダイレクトマップ式メモリキャッシュ· · · · · · · · · · · · · · · · · 231
12.22
2 の冪乗による効率化· · · · · · · · · · · · · · · · · · · · · · · · · 233
12.23
ダイレクトマップ式キャッシュのハードウェア実装· · · · · · · · · · 234
12.24
セットアソシアティブ式メモリキャッシュ
· · · · · · · · · · · · · · 236
12.25
プログラマにおよぼす影響
· · · · · · · · · · · · · · · · · · · · · · 237
12.26
まとめ· · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · 237
練習問題· · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · 238
第13 章
仮想メモリ技術と仮想アドレッシング
241
13.1
はじめに
· · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · 241
13.2
仮想メモリの定義· · · · · · · · · · · · · · · · · · · · · · · · · · · · 241
13.3
MMU とアドレス空間· · · · · · · · · · · · · · · · · · · · · · · · · · 242
13.4
複数の物理メモリシステムに対するインターフェイス· · · · · · · · · 242
13.5
アドレスの変換あるいはマッピング
· · · · · · · · · · · · · · · · · · 243
13.6
算術演算を避ける· · · · · · · · · · · · · · · · · · · · · · · · · · · · 245
hi.0412.ko.2002@gmail.com
xii
目　次　
13.7
不連続なアドレス空間
· · · · · · · · · · · · · · · · · · · · · · · · · 245
13.8
仮想メモリを使う動機
· · · · · · · · · · · · · · · · · · · · · · · · · 247
13.9
複数の仮想空間とマルチプログラミング· · · · · · · · · · · · · · · · 248
13.10
仮想空間を動的に生成する
· · · · · · · · · · · · · · · · · · · · · · 249
13.11
ベースと境界のレジスタ· · · · · · · · · · · · · · · · · · · · · · · · 250
13.12
仮想空間を変更する· · · · · · · · · · · · · · · · · · · · · · · · · · 250
13.13
仮想メモリとプロテクション
· · · · · · · · · · · · · · · · · · · · · 251
13.14
セグメンテーション· · · · · · · · · · · · · · · · · · · · · · · · · · 251
13.15
デマンドページング· · · · · · · · · · · · · · · · · · · · · · · · · · 253
13.16
デマンドページング用のハードウェアとソフトウェア
· · · · · · · · 253
13.17
ページ置換· · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · 254
13.18
ページングの用語とデータ構造· · · · · · · · · · · · · · · · · · · · 255
13.19
ページングシステムにおけるアドレス変換
· · · · · · · · · · · · · · 255
13.20
2 の冪乗を使う
· · · · · · · · · · · · · · · · · · · · · · · · · · · · 257
13.21
「存在」と「利用」と「変更」のビット
· · · · · · · · · · · · · · · 258
13.22
ページテーブルのストレージ
· · · · · · · · · · · · · · · · · · · · · 259
13.23
ページングの効率とTLB
· · · · · · · · · · · · · · · · · · · · · · · 260
13.24
プログラマにおよぼす影響
· · · · · · · · · · · · · · · · · · · · · · 261
13.25
仮想メモリとキャッシングの関係· · · · · · · · · · · · · · · · · · · 262
13.26
仮想メモリのキャッシングとキャッシュフラッシュ· · · · · · · · · · 263
13.27
まとめ· · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · 264
練習問題· · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · 265
第4 部
入出力
267
第14 章
入出力の概念と用語
269
14.1
はじめに
· · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · 269
14.2
入出力機器
· · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · 269
14.3
外部機器の制御· · · · · · · · · · · · · · · · · · · · · · · · · · · · · 270
14.4
データ転送
· · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · 271
14.5
シリアルとパラレルのデータ転送· · · · · · · · · · · · · · · · · · · · 271
14.6
セルフクロッキング式のデータ· · · · · · · · · · · · · · · · · · · · · 272
hi.0412.ko.2002@gmail.com
　目　次
xiii
14.7
全二重と半二重の交信
· · · · · · · · · · · · · · · · · · · · · · · · · 273
14.8
インターフェイスのスループットとレイテンシ· · · · · · · · · · · · · 273
14.9
多重化の基礎· · · · · · · · · · · · · · · · · · · · · · · · · · · · · · 274
14.10
外部インターフェイス毎に複数の機器を繋ぐ· · · · · · · · · · · · · 275
14.11
プロセッサから見た入出力
· · · · · · · · · · · · · · · · · · · · · · 275
14.12
まとめ· · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · 276
練習問題· · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · 276
第15 章
バスとバスアーキテクチャ
279
15.1
はじめに
· · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · 279
15.2
バスの定義
· · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · 279
15.3
プロセッサとI/O デバイスとバス
· · · · · · · · · · · · · · · · · · · 280
15.4
物理的な接続· · · · · · · · · · · · · · · · · · · · · · · · · · · · · · 281
15.5
バスインターフェイス
· · · · · · · · · · · · · · · · · · · · · · · · · 282
15.6
制御線、アドレス線、データ線· · · · · · · · · · · · · · · · · · · · · 283
15.7
「フェッチとストア」のパラダイム
· · · · · · · · · · · · · · · · · · 284
15.8
「フェッチとストア」とバスのサイズ
· · · · · · · · · · · · · · · · · 284
15.9
多重化· · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · 285
15.10
バス幅とデータ項目のサイズ
· · · · · · · · · · · · · · · · · · · · · 286
15.11
バスアドレス空間· · · · · · · · · · · · · · · · · · · · · · · · · · · 287
15.12
エラーの可能性
· · · · · · · · · · · · · · · · · · · · · · · · · · · · 288
15.13
アドレス構成とソケット· · · · · · · · · · · · · · · · · · · · · · · · 289
15.14
複数バスの問題
· · · · · · · · · · · · · · · · · · · · · · · · · · · · 290
15.15
「フェッチとストア」をデバイスに使う
· · · · · · · · · · · · · · · 290
15.16
インターフェイスの演算· · · · · · · · · · · · · · · · · · · · · · · · 292
15.17
非対称な割り当てとバスエラー· · · · · · · · · · · · · · · · · · · · 292
15.18
メモリとデバイスの統一アドレッシング
· · · · · · · · · · · · · · · 292
15.19
バスアドレス空間の穴· · · · · · · · · · · · · · · · · · · · · · · · · 293
15.20
アドレスマップ
· · · · · · · · · · · · · · · · · · · · · · · · · · · · 294
15.21
バスへのプログラムインターフェイス· · · · · · · · · · · · · · · · · 295
15.22
2 つのバスを繋ぐブリッジ· · · · · · · · · · · · · · · · · · · · · · · 296
15.23
メインバスと補助バス· · · · · · · · · · · · · · · · · · · · · · · · · 296
hi.0412.ko.2002@gmail.com
xiv
目　次　
15.24
プログラマにおよぼす影響
· · · · · · · · · · · · · · · · · · · · · · 298
15.25
バスに代わるスイッチングファブリック
· · · · · · · · · · · · · · · 298
15.26
まとめ· · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · 299
練習問題· · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · 300
第16 章
プログラム駆動と割り込み駆動の入出力
303
16.1
はじめに
· · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · 303
16.2
入出力のパラダイム· · · · · · · · · · · · · · · · · · · · · · · · · · · 303
16.3
プログラム駆動の入出力
· · · · · · · · · · · · · · · · · · · · · · · · 304
16.4
同期· · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · 304
16.5
ポーリング
· · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · 305
16.6
ポーリングのコード· · · · · · · · · · · · · · · · · · · · · · · · · · · 305
16.7
CSR：コントロールとステータスのレジスタ· · · · · · · · · · · · · · 308
16.8
CSR を構造体で定義する· · · · · · · · · · · · · · · · · · · · · · · · 309
16.9
プロセッサの有効利用とポーリング
· · · · · · · · · · · · · · · · · · 310
16.10
割り込み駆動の入出力· · · · · · · · · · · · · · · · · · · · · · · · · 310
16.11
割り込み機構と「フェッチ‒ 実行」サイクル· · · · · · · · · · · · · 312
16.12
割り込み処理
· · · · · · · · · · · · · · · · · · · · · · · · · · · · · 312
16.13
割り込みベクトル· · · · · · · · · · · · · · · · · · · · · · · · · · · 313
16.14
割り込みの初期化と禁止· · · · · · · · · · · · · · · · · · · · · · · · 314
16.15
割り込みハンドラへの割り込み· · · · · · · · · · · · · · · · · · · · 315
16.16
割り込みの設定
· · · · · · · · · · · · · · · · · · · · · · · · · · · · 315
16.17
動的バス接続と挿抜可能なデバイス· · · · · · · · · · · · · · · · · · 316
16.18
割り込みと性能とスマートデバイス· · · · · · · · · · · · · · · · · · 316
16.19
DMA · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · 318
16.20
バッファの連鎖によるDMA の拡張· · · · · · · · · · · · · · · · · · 318
16.21
スキャッターリードとギャザーライト· · · · · · · · · · · · · · · · · 320
16.22
演算の連鎖· · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · 320
16.23
まとめ· · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · 321
練習問題· · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · 321
hi.0412.ko.2002@gmail.com
　目　次
xv
第17 章
デバイスと入出力とバッファのプログラミング
323
17.1
はじめに
· · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · 323
17.2
デバイスドライバの定義
· · · · · · · · · · · · · · · · · · · · · · · · 323
17.3
デバイスに依存しない：カプセル化と隠蔽· · · · · · · · · · · · · · · 324
17.4
デバイスドライバの構成
· · · · · · · · · · · · · · · · · · · · · · · · 325
17.5
デバイスの分類（キャラクタ指向とブロック指向）
· · · · · · · · · · 326
17.6
デバイスドライバにおける制御の流れ
· · · · · · · · · · · · · · · · · 326
17.7
キューを使う出力処理
· · · · · · · · · · · · · · · · · · · · · · · · · 328
17.8
デバイスに割り込みを強制する· · · · · · · · · · · · · · · · · · · · · 329
17.9
キューを使う入力処理
· · · · · · · · · · · · · · · · · · · · · · · · · 330
17.10
非同期デバイスドライバと排他制御· · · · · · · · · · · · · · · · · · 331
17.11
アプリケーションから見た入出力· · · · · · · · · · · · · · · · · · · 332
17.12
ライブラリとOS の分割· · · · · · · · · · · · · · · · · · · · · · · · 333
17.13
OS がサポートする入出力演算
· · · · · · · · · · · · · · · · · · · · 333
17.14
入出力演算のコスト· · · · · · · · · · · · · · · · · · · · · · · · · · 335
17.15
システムコールのオーバーヘッドを減らす
· · · · · · · · · · · · · · 335
17.16
バッファリングの重要性· · · · · · · · · · · · · · · · · · · · · · · · 336
17.17
バッファ付き出力の実装· · · · · · · · · · · · · · · · · · · · · · · · 337
17.18
バッファをフラッシュする
· · · · · · · · · · · · · · · · · · · · · · 338
17.19
入力のバッファリング· · · · · · · · · · · · · · · · · · · · · · · · · 339
17.20
バッファリングの効率· · · · · · · · · · · · · · · · · · · · · · · · · 339
17.21
キャッシングとの関係· · · · · · · · · · · · · · · · · · · · · · · · · 340
17.22
例：C 標準入出力ライブラリ
· · · · · · · · · · · · · · · · · · · · · 341
17.23
まとめ· · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · 341
練習問題· · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · 342
第5 部
高度な話題
343
第18 章
並列処理
345
18.1
はじめに
· · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · 345
18.2
並列とパイプラインのアーキテクチャ
· · · · · · · · · · · · · · · · · 345
18.3
並列処理の特徴· · · · · · · · · · · · · · · · · · · · · · · · · · · · · 346
hi.0412.ko.2002@gmail.com
xvi
目　次　
18.4
微視的／巨視的な並列性
· · · · · · · · · · · · · · · · · · · · · · · · 346
18.5
ミクロ（微視的）な並列処理の例· · · · · · · · · · · · · · · · · · · · 347
18.6
マクロ（巨視的）な並列処理の例· · · · · · · · · · · · · · · · · · · · 347
18.7
対称的／非対称的な並列性· · · · · · · · · · · · · · · · · · · · · · · 348
18.8
細粒度／粗粒度の並列性
· · · · · · · · · · · · · · · · · · · · · · · · 349
18.9
明示的／暗黙的な並列性
· · · · · · · · · · · · · · · · · · · · · · · · 349
18.10
並列アーキテクチャの種類（フリンの分類）· · · · · · · · · · · · · 349
18.11
SISD（単一命令、単一データ）· · · · · · · · · · · · · · · · · · · · 350
18.12
SIMD（単一命令、複数データ）
· · · · · · · · · · · · · · · · · · · 351
18.13
MIMD（複数命令、複数データ）· · · · · · · · · · · · · · · · · · · 352
18.14
通信、協調、競合· · · · · · · · · · · · · · · · · · · · · · · · · · · 355
18.15
マルチプロセッサの性能· · · · · · · · · · · · · · · · · · · · · · · · 356
18.16
プログラマにおよぼす影響
· · · · · · · · · · · · · · · · · · · · · · 358
18.17
冗長と並列のアーキテクチャ
· · · · · · · · · · · · · · · · · · · · · 361
18.18
コンピュータの分散とクラスタ· · · · · · · · · · · · · · · · · · · · 362
18.19
最近のスーパーコンピュータ
· · · · · · · · · · · · · · · · · · · · · 363
18.20
まとめ· · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · 363
練習問題· · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · 364
第19 章
パイプライン処理
367
19.1
はじめに
· · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · 367
19.2
パイプライン処理の概念
· · · · · · · · · · · · · · · · · · · · · · · · 367
19.3
ソフトウェアによるパイプライン· · · · · · · · · · · · · · · · · · · · 370
19.4
ソフトウェアパイプラインの性能とオーバーヘッド
· · · · · · · · · · 370
19.5
ハードウェアによるパイプライン· · · · · · · · · · · · · · · · · · · · 371
19.6
ハードウェアパイプラインで性能を向上させる方法
· · · · · · · · · · 372
19.7
パイプラインを使えるケース· · · · · · · · · · · · · · · · · · · · · · 374
19.8
処理分割のコンセプト
· · · · · · · · · · · · · · · · · · · · · · · · · 376
19.9
パイプラインアーキテクチャ· · · · · · · · · · · · · · · · · · · · · · 377
19.10
パイプラインのセットアップとストールとフラッシュのタイミング
· 377
19.11
スーパーパイプラインアーキテクチャの定義· · · · · · · · · · · · · 378
19.12
まとめ· · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · 378
hi.0412.ko.2002@gmail.com
　目　次
xvii
練習問題· · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · 379
第20 章
電力とエネルギー
381
20.1
はじめに
· · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · 381
20.2
電力の定義
· · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · 381
20.3
エネルギーの定義· · · · · · · · · · · · · · · · · · · · · · · · · · · · 382
20.4
デジタル回路が消費する電力· · · · · · · · · · · · · · · · · · · · · · 383
20.5
CMOS デジタル回路によるスイッチング電力の消費· · · · · · · · · · 384
20.6
冷却と電力密度と電力の壁· · · · · · · · · · · · · · · · · · · · · · · 385
20.7
エネルギーの利用· · · · · · · · · · · · · · · · · · · · · · · · · · · · 386
20.8
電力管理
· · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · 386
20.9
エネルギー利用のソフトウェア制御
· · · · · · · · · · · · · · · · · · 389
20.10
スリープとスリープ解除のタイミング· · · · · · · · · · · · · · · · · 390
20.11
スリープモードとネットワーク機器· · · · · · · · · · · · · · · · · · 392
20.12
まとめ· · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · 392
練習問題· · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · 393
第21 章
性能評価
395
21.1
はじめに
· · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · 395
21.2
計算能力と性能を測定する· · · · · · · · · · · · · · · · · · · · · · · 395
21.3
計算能力の測定方法· · · · · · · · · · · · · · · · · · · · · · · · · · · 396
21.4
特定アプリケーションの実行命令数
· · · · · · · · · · · · · · · · · · 397
21.5
命令ミックス· · · · · · · · · · · · · · · · · · · · · · · · · · · · · · 398
21.6
標準ベンチマーク· · · · · · · · · · · · · · · · · · · · · · · · · · · · 399
21.7
入出力とメモリのボトルネック· · · · · · · · · · · · · · · · · · · · · 400
21.8
ハードウェアとソフトウェアの境界をずらす· · · · · · · · · · · · · · 400
21.9
最適化する項目の選択：アムダールの法則· · · · · · · · · · · · · · · 401
21.10
アムダールの法則と並列システム· · · · · · · · · · · · · · · · · · · 402
21.11
まとめ· · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · 402
練習問題· · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · 403
hi.0412.ko.2002@gmail.com
xviii
目　次　
第22 章
アーキテクチャのサンプルと階層構造
405
22.1
はじめに
· · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · 405
22.2
アーキテクチャの3 つのレベル· · · · · · · · · · · · · · · · · · · · · 405
22.3
システムレベルのアーキテクチャ：PC · · · · · · · · · · · · · · · · · 406
22.4
バスの相互接続とブリッジ· · · · · · · · · · · · · · · · · · · · · · · 406
22.5
コントローラチップと物理アーキテクチャ· · · · · · · · · · · · · · · 407
22.6
仮想バス
· · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · 408
22.7
接続の速度
· · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · 410
22.8
ブリッジ機能と仮想バス
· · · · · · · · · · · · · · · · · · · · · · · · 411
22.9
ボードレベルのアーキテクチャ· · · · · · · · · · · · · · · · · · · · · 411
22.10
チップレベルのアーキテクチャ· · · · · · · · · · · · · · · · · · · · 413
22.11
オンチップ機能ユニットの構造· · · · · · · · · · · · · · · · · · · · 414
22.12
まとめ· · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · 415
練習問題· · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · 415
第23 章
ハードウェアのモジュール化
417
23.1
はじめに
· · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · 417
23.2
モジュールの需要· · · · · · · · · · · · · · · · · · · · · · · · · · · · 417
23.3
ソフトウェアのモジュール化· · · · · · · · · · · · · · · · · · · · · · 418
23.4
パラメータを持つサブプログラムの呼び出し· · · · · · · · · · · · · · 418
23.5
ハードウェアのスケーリングと並列性
· · · · · · · · · · · · · · · · · 419
23.6
基本ブロックの複製· · · · · · · · · · · · · · · · · · · · · · · · · · · 419
23.7
設計の例：リブータ· · · · · · · · · · · · · · · · · · · · · · · · · · · 419
23.8
高いレベルでのリブータ設計· · · · · · · · · · · · · · · · · · · · · · 420
23.9
広範囲な規模に対応できるビルディングブロック
· · · · · · · · · · · 421
23.10
並列的な相互接続· · · · · · · · · · · · · · · · · · · · · · · · · · · 421
23.11
相互接続の例
· · · · · · · · · · · · · · · · · · · · · · · · · · · · · 422
23.12
モジュール選択
· · · · · · · · · · · · · · · · · · · · · · · · · · · · 422
23.13
まとめ· · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · 423
練習問題· · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · 423
hi.0412.ko.2002@gmail.com
　目　次
xix
付録A
コンピュータアーキテクチャコースのラボ
425
A.1
はじめに· · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · 425
A.2
デジタルロジックの実験に必要なハードウェア· · · · · · · · · · · · · 425
A.3
ソルダーレスブレッドボードとは· · · · · · · · · · · · · · · · · · · · 426
A.4
ソルダーレスブレッドボードを使う· · · · · · · · · · · · · · · · · · · 426
A.5
電源とグランドの接続· · · · · · · · · · · · · · · · · · · · · · · · · · 428
A.6
回路を組んでテストする· · · · · · · · · · · · · · · · · · · · · · · · · 428
A.7
ラボの実験· · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · 428
付録B
ブール代数を単純化する規則
445
B.1
はじめに· · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · 445
B.2
使用する記法· · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · 445
B.3
ブール代数の規則
· · · · · · · · · · · · · · · · · · · · · · · · · · · · 445
付録C
x86 アセンブリ言語の基本
447
C.1
はじめに· · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · 447
C.2
x86 の汎用レジスタ· · · · · · · · · · · · · · · · · · · · · · · · · · · 448
C.3
許容されるオペランド· · · · · · · · · · · · · · · · · · · · · · · · · · 449
C.4
Intel 方式とAT&T 方式のx86 アセンブリ言語· · · · · · · · · · · · · 450
C.5
算術命令· · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · 452
C.6
論理演算· · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · 454
C.7
基本データ型· · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · 455
C.8
データブロックと配列と文字列
· · · · · · · · · · · · · · · · · · · · · 456
C.9
メモリ参照· · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · 457
C.10
データサイズの推定と明示的なサイズディレクティブ· · · · · · · · · 458
C.11
アドレス計算· · · · · · · · · · · · · · · · · · · · · · · · · · · · · · 459
C.12
スタック演算：プッシュとポップ
· · · · · · · · · · · · · · · · · · · 460
C.13
制御の流れと無条件分岐· · · · · · · · · · · · · · · · · · · · · · · · 461
C.14
条件分岐と条件コード
· · · · · · · · · · · · · · · · · · · · · · · · · 462
C.15
サブプログラムのコールとリターン
· · · · · · · · · · · · · · · · · · 463
C.16
C の呼び出し規約と引数渡し· · · · · · · · · · · · · · · · · · · · · · 464
C.17
関数コールと戻り値
· · · · · · · · · · · · · · · · · · · · · · · · · · 466
hi.0412.ko.2002@gmail.com
xx
目　次　
C.18
64 ビットへの拡張（x64）· · · · · · · · · · · · · · · · · · · · · · · 466
C.19
まとめ
· · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · 468
付録D
ARM のレジスタ定義とコーリングシーケンス
469
D.1
はじめに· · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · 469
D.2
ARM プロセッサのレジスタ· · · · · · · · · · · · · · · · · · · · · · · 469
D.3
ARM の呼び出し規約
· · · · · · · · · · · · · · · · · · · · · · · · · · 471
索　引· · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · 474
hi.0412.ko.2002@gmail.com
　序文
xxi
序文
ハードウェア技術者の仕事は、電子部品の組み立てから、プログラマブルなデバイスを使う
方向へとシフトしました。だからプログラミングが、以前よりはるかに重要になっています。
ハードウェアがどのように動作するのかを理解し、ハードウェアの基礎的な原理を知っている
プログラマは、より効率がよくエラーを起こしにくいソフトウェアシステムを構築できます。
コンピュータアーキテクチャの基礎知識を身につけたプログラマは、ソフトウェアとハード
ウェアの対応を重視した、より良いソフトウェア設計を選択できるのです。また、根底にある
ハードウェアを理解すればデバッグが容易になるという利点もあります。どこに問題があるの
か、素早く的確にポイントを指摘できるのです。
このテキストは1 学期の学部コースに適しています。コンピュータサイエンスの多くのプロ
グラムで、学生はプログラミングを学びますが、自分がプログラミングするコンピュータの構造
を説明できるような基本的コンセプトに触れるカリキュラムは、コンピュータアーキテクチャ
またはコンピュータの構成に関するコースだけです。しかも残念ながら、コンピュータアーキ
テクチャについて書かれたテキストの大半は、ハードウェア設計を学ぶ学生に向けてハード
ウェア技術者が書いたものです。このテキストは、それとは異なるアプローチを採用します。
ハードウェア設計とエンジニアリングの詳細に焦点を絞るのではなく、プログラマのためにプ
ログラマが知っているべきハードウェアの基本的側面を説明するのです。トピックをプログラ
マの視点から説明し、プログラマにおよぼす影響を重視しています。
このテキストは５部にわかれています。第1 部では、
デジタル回路の基礎であるゲート、
デー
タ経路、データ表現を扱います。根底にあるハードウェアについて、ざっと述べるだけなので、
ほとんどの学生に喜ばれるでしょう（テキストとラボで、細かいハードウェアの詳細を略して
います）
。第2 部から第4 部までは、アーキテクチャの主な側面であるプロセッサとメモリと
入出力のシステムを扱います。学生は、それぞれの章で、あまり詳細に立ち入ることなく、機
構がどう働くかを理解するのに十分な背景知識を獲得し、プログラマにおよぼす影響も知るこ
とができます。最後に第5 部では高度な話題として、並行処理、パイプライン、電力とエネル
ギー、性能について学びます。
付録A は、このコースの重要な側面のひとつを記述しています。つまり学生が実際にやっ
てみて学ぶ実地体験のラボです。ほとんどのラボプログラムはプログラミングに焦点を絞りま
す。学生は最初の２．３週間はラボにこもって、ブレッドボードでゲートを組んだりすべきで
すよ。実験装置は安価です（私たちが永続的な装置に費やした費用は、学生一人につき15 ド
ル未満、学生が自分用に買うチップセットは20 ドル未満です）
。
付録C では、x86 アセンブリ言語とx64 エクステンションを、手っ取り早く紹介します。多
くの先生がたがx86 を教えるので、ぜひ入れるようにと頼まれました。これらの素材は付録に
しておいたので、
（たとえばARM アーキテクチャの）RISC アセンブリ言語に焦点を絞りたい
先生にも、比較のために使っていただけるでしょう。
hi.0412.ko.2002@gmail.com
xxii
序文　
この第2 版では、新たに２つの章を追加するとともに、随所に変更と更新を加えました。第
3 章ではデータパスについて、コンピュータの構成部品を示し、それらのコンポーネントの間
で、命令実行につれてデータがどのように流れるかを記述しました。第2 章では、簡単な例を
入れて、第2 章のデジタル回路と、それに続く章で示すプロセッサに関する記述とのギャップ
を埋めました。第20 章は電力とエネルギーに関するものですが、詳細に立ち入らずに基本を押
さえています。デュアルコアのチップで、それぞれのコアを半分の速度で実行すると、全速で
実行するシングルコアのチップより消費電力が低くなるのは、なぜか。その理由を説明します。
原著には専用のWeb サイトがあります。
http://www.eca.cs.purdue.edu
テキストとラボの課題は、パデュー大学で使っているものです。どちらも学生たちから熱烈
な支持を得ています。テキストとコースについて感謝の言葉を受け取っています。多くの学生
にとって、このラボはハードウェアで実験する最初の経験となるもので、彼らには大きな刺激
になっています。
本書に貢献された多くの人々に厚く感謝します。Bernd Wolﬁnger からは、広範なレビュー
を提供していただき、トピックと方向性について、いくつも重要な提案を頂きました。先生が
た、それに学生たちが、第1 版のタイプミスを見つけてくれました。George Adams からは、
第2 版のために詳細なコメントと提案を頂きました。
最後に、妻のChris に感謝します。根気良く注意深い編集のおかげで、テキストが改善され、
きれいに仕上がりましたよ。
Douglas E. Comer
hi.0412.ko.2002@gmail.com
　著者について
xxiii
著者について
コンピュータシステムに関して該博な知識を持つDouglas E. Comer 博士
（PhD）
には、
ハー
ドウェアとソフトウェアの両方に業績がある。ソフトウェアでの仕事はシステムのほとんどの
側面におよび、コンパイラとオペレーティングシステムも含んでいる。彼は、プロセスマネー
ジャ、メモリマネージャ、シリアルインターフェイスとパラレルインターフェイスのデバイスド
ライバを含む、完全なOS を作成したのだ。Comer 博士は、ネットワークプロトコルのソフト
ウェアや、一般的なコンピュータとネットワークプロセッサのためのネットワークデバイスド
ライバも作っている。彼のOS（Xinu）もTCP/IP プロトコルスタックも商品で使われてきた。
ハードウェアについての彼の経験には、ディスクリートな部品を使う仕事も、ロジックゲー
トで回路を組む仕事も、基礎的なシリコン技術の経験もある。ネットワークプロセッサのアー
キテクチャに関して人気のある教科書を執筆しているし、Bell 研究所ではVLSI 設計を研究し
実際にVLSI チップを製作している。
Comer 博士は、パデュー大学（Purdue University）でコンピュータサイエンスの特別教授
（Distinguished Professor）として、コースの開発と教授を行いながら、コンピュータの構成、
オペレーティングシステム、ネットワーク、インターネットに関する研究に関わっている。コ
ンピュータのオペレーティングシステム、ネットワーク、TCP/IP、コンピュータテクノロジー
について、国際的に評判の高い技術書を書いているほか、革新的なラボを作り上げた。そこで
は学生たちが、OS やIP ルータのようなシステムを構築して計測できる。彼のコースは、どれ
もラボでの実地体験を含んでいる。
パデュー大学の休暇期間に、彼はCisco Systems で研究副部長に就任している。彼は現在も
世界中の大学、業界、カンファレンスで相談に応じ、レクチャーを提供している。
「Software:
Practice and Experience」誌の編集長を20 年も勤めた。ACM（Association for Computing
Machinery）フェローであり、Purdue Teaching Academy のフェローであり、USENIX の
Lifetime Achievement Award を含む数多くの賞を受けている。
その他の情報は以下のサイトを参照のこと1。
www.cs.purdue.edu/people/comer
1　訳注：ここに紹介されているComer 氏の著作で、日本語に翻訳された書籍には、本書『コンピュータ
アーキテクチャのエッセンス』の第1 版（翔泳社、2017 年）のほか、
『コンピュータネットワークとイン
ターネット』
（翔泳社）
、
『TCP/IP によるネットワーク構築』
（共立出版）
、
『Xinu オペレーティングシステム
デザイン』
（アスキードワンゴ）などがある。
hi.0412.ko.2002@gmail.com
hi.0412.ko.2002@gmail.com
第1 章
序論と概要
1.1 　アーキテクチャの重要性
コンピュータは、どこにでもある。スマートフォンにもゲーム機にも家電製品にもクルマに
も、プログラマブルな（プログラムを組むことができる）プロセッサが入っている。これらの
システムは、それぞれソフトウェアに依存している。そこで、こんな疑問が生じないだろうか。
「ソフトウェア開発に興味があるならコンピュータアーキテクチャを学ぶべきだ、と言われる
のは、なぜだろう」
。重要な問題だ。その答えは、ハードウェアを理解すると、より小さくて
高速でエラーを起こしにくいコードを書けるからだ。アーキテクチャの基本を知っているプロ
グラマは、処理の相対的なコストを（たとえば算術命令と入出力命令では必要な時間が違うこ
とを）理解しているから、プログラミングで判断を下すのが容易になる。そしてハードウェア
の仕組みを理解しているプログラマは、デバッグもうまい。ハードウェアを知っていれば、バ
グの根源を見つけるための手がかりを、より多く持つことになるからだ。要するにプログラマ
は、根底にあるハードウェアを理解すればするほど、ソフトウェアを上手に作成できる。
1.2 　エッセンスを学ぶ
どんなハード屋さんでも教えてくれると思うが、コンピュータシステムを構築するのに使わ
れるデジタルハードウェアは、信じられないほど複雑だ。コンピュータシステムは膨大な技術
の集積であり、それぞれの技術は錯綜する無数の電子部品の集合である。しかも技術者は、そ
れぞれの部品について、構築方法を決定する設計のルールと、それらを組み合わせてシステム
を形成する方法を、習得しなければならない。おまけに、これらの技術は進化を続け、より新
しくスマートで高速な部品が、どんどん現れてくる。
だが、ありがたいことに、低いレベルの技術的詳細を知らなくても、アーキテクチャの部品
（コンポーネント）を理解することは可能だ。本書はエッセンスに焦点を絞り、コンピュータ
hi.0412.ko.2002@gmail.com
2
第1 章
序論と概要　
アーキテクチャを包括的な概念の言葉で説明する。主なコンポーネントを、それぞれ説明して、
システム全体における役割を明らかにしていくが、それらの主題を理解するのに電子工学の背
景知識は不要である。
1.3 　テキストの構成
本書で扱う主なトピックは、何だろうか。テキストは次の5 部で構成される。
第1 部基礎：最初に学ぶ2 つのトピックは、本書の残りの部分を読むのに必要な「デジタル
論理回路」と「データ表現」である。どの話題にも、必ず「デジタル情報を表現し操作するた
めに電子的な機構を使う」という問題が関わっている。
第2 部プロセッサ：アーキテクチャの主な領域は3 つある。第1 の領域である「プロセッ
サ」の仕事は、計算（たとえば算術演算）と制御（たとえばシーケンスのステップ実行）の両
方だ。ここでは基本的な構成要素（ビルディングブロック）について学び、それらのブロック
が現代のCPU（Central Processing Unit）で、どのように使われているかを見ていく。
第3 部メモリ：アーキテクチャの主な領域の2 つめである「メモリ」システムは、デジタル
情報を保存（ストア）し、それをアクセスすることに重点を絞っている。物理的なメモリシス
テムと、仮想的なメモリシステムの両方を調べ、コンピュータの処理において最も重要なコン
セプトのひとつである「キャッシング」を理解する。
第4 部入出力：3 つめの「入出力」
（インプットとアウトプット）は、マイク、キーボード、
マウス、ディスプレイ、ディスク、ネットワークといったデバイス群とコンピュータとの接続
に関する、アーキテクチャの主要領域だ。ここではバステクノロジーについて学び、プロセッ
サがバスを使ってデバイスと通信する方法を知って、デバイスドライバというソフトウェアの
役割を理解する。
第5 部高度な話題：最後に学ぶ並列処理とパイプラインは、いろいろな形式で出現する重要
なコンセプトだ。ハードウェアの並列化やパイプライン化によって、システム全体の性能を向
上させる方法を学ぼう。
1.4 　省略する事項
トピックをエッセンスだけに絞るため、省略する事項を選ばなければならない。本書の場合
は、深さよりも広さを重視しているので、取捨選択で、詳細ではなくコンセプトに重点を絞る。
したがって本書はアーキテクチャの主要なトピックを網羅するが、あまり知られていない変種
や低いレベルの技術的詳細を省略している。たとえば基礎的なNAND ゲートの働きを示すの
に最もシンプルな記述を選び、実際の内部構造だとか、ゲートが電流をどのように消費するか
といった具体的な記述を略した。同様にプロセッサに関する議論では、ハードウェア技術者に
必要な性能の定量分析を避け、読者がハードウェアを構築できるようにするのではなく、全体
的な設計とプログラマに対する影響を理解できるように、高いレベルの視点を選んだ
hi.0412.ko.2002@gmail.com
　1.5
用語：アーキテクチャと設計
3
1.5 　用語：アーキテクチャと設計
本書を通じて、
「アーキテクチャ」という言葉を、コンピュータシステムの全体的な構成を意
味する用語として使う。コンピュータのアーキテクチャは、青写真（ブループリント）に例え
られる。アーキテクチャは、主な部品（コンポーネント）について接続方法を示す「仕様」と、
それぞれの全体的な「機能」とを定めるが、あまり詳細には立ち入らない。与えられたアーキ
テクチャを実装するデジタルシステムを構築するときに、全体的なアーキテクチャの仕様では
略されている詳細を明らかにするため、技術者は、仕様を具体的な「設計」に落とし込む必要が
ある。設計では、たとえばチップ上でコンポーネントをどのように編成するか、回路基板上で
チップをどのように配置するか、それぞれの基板に対してどのように給電するかを指定しなけ
ればならない。設計は、最後には実装する必要があるのだから、結果的には、システムの構築
に使う特定のハードウェアを選ぶことにもなる。設計は、所与のアーキテクチャを実現できる
方法のひとつを表現する。そして「実装」は、所与の設計を実現する方法のひとつを表現する。
1.6 　まとめ
本書は、コンピュータアーキテクチャのエッセンスであるデジタル論理回路、プロセッサ、
メモリ、入出力、そして高度な話題を扱う。テキストを読むのに、電子工学の背景知識は必要
ない。本書のトピックは、コンセプトに重点を置いて説明し、低いレベルの詳細を省き、プロ
グラマにとって重要な項目に集中する。
hi.0412.ko.2002@gmail.com
hi.0412.ko.2002@gmail.com
第1部
基礎
デジタル論理回路とデータ表現
コンピュータを組み立てる基本
hi.0412.ko.2002@gmail.com
hi.0412.ko.2002@gmail.com
第2 章
デジタル論理回路の基礎
2.1 　はじめに
この章ではデジタル回路の基礎を扱う。その目標は、読者が残りの章を理解するのに必要
かつ十分な背景知識を提供することだ。プログラマがソフトウェアへの影響を理解するには、
ハードウェアの基礎知識が必要だが、低いレベルの詳細の多くは関係ない。したがって、電子
工学的な詳細に立ち入ったり、根底にある物理を論じたり、ハードウェア技術者がデバイスを
組み合わせるのに必要な設計ルールを示したりはしない。代わりに、複雑なデジタルシステム
の仕組みを理解するための基礎を学んでいこう。
2.2 　デジタル計算機
われわれ技術者は、離散的な値を持つデータ項目に対して計算ステップのシーケンスを実行
する機器を、
「デジタルコンピュータ」という言葉で呼ぶ。これに対して「アナログコンピュー
タ」と呼ばれる機器は、時間の経過にしたがって継続的に変化する値を扱う。デジタル計算に
は、高精度という利点がある。いまのデジタルコンピュータは安価で、しかも非常に信頼性が
高いから、アナログコンピュータは数少ない特殊な分野にしか残されていない。
信頼性を求める需要が高いのは、計算が何十億ステップにもおよぶことがあるからだ。コン
ピュータが1 個の値の解釈を誤ったり、1 個の「セット」命令の実行に失敗するだけで、正し
い計算は不可能になる。だからコンピュータは、故障率が十億回に1 回どころか、はるかに少
ないように設計される。
高い信頼性と高性能を、どうすれば達成できるのだろうか。初期の計算機の1 つは「そろば
ん」であり、人間が玉を動かすことで合計を出していた。20 世紀初頭になると、機械的なギア
とレバーがキャッシュレジスタや加算機に使われた。1940 年代には、初期の電子計算機が真
空管で組み立てられた。それらは機械的なデバイスよりはるかに高速だったが、フィラメント
hi.0412.ko.2002@gmail.com
8
第2 章
デジタル論理回路の基礎　
を赤熱させる真空管は信頼性が低かった。つまり数百時間も使えばフィラメントが焼き切れて
しまう。
1947 年にトランジスタが発明されて、コンピュータは劇的に変化した。真空管と違ってト
ランジスタはフィラメントを必要とせず、さほど多くの電力を消費せず、大量の熱を発せず、
焼き切れることもない。しかもトランジスタは真空管より、ずっと低いコストで量産できた。
その結果、現代のデジタルコンピュータは、トランジスタを使う電子回路で構築されている。
2.3 　用語：電圧と電流
電子回路は、電荷の存在と流れに伴う物理現象に依存している。電荷の存在を検知し、その
流れを制御する方法が物理学者によって発見され、そういう機能を素早く実行できる機構が技
術者によって開発された。その機構が、現在のデジタルコンピュータの基礎になっている。
われわれは「電圧」と「電流」という用語で、電気の定量的な特性を表す。2 点間の電圧（単
位はボルト：V）が、潜在的なエネルギーの差異を表現し、電流（単位はアンペア：A）が、あ
るパス（リード線などの経路）に沿った電子の流れを表現する。水にたとえるとわかりやすい。
電圧は水圧にたとえられ、電流は、ある時間にパイプを通って流れる水の量にたとえられる。
タンクに穴が空いて、そこから水が流れ始めたら、水圧は低下する。同様に、もし電線を通じ
て電流が発生したら、電圧は低下する。
電圧について知っておくべきもっとも重要なポイントは、電圧は2 点間の差としてしか計測
できない（相対的な計測しかできない）ということだ。したがって、電圧を測る「電圧計」に
は、必ず2 本のプローブがあり、両方の電極が接続されるまで電圧計は電圧を示さない。計測
を簡略化するために、われわれは片方のプローブがゼロボルトを示すものと想定し、第2 のポ
イントでの電圧をゼロとの相対値で表現する。そしてゼロボルトとみなすポイントを「グラン
ド」と呼ぶ。本書で示すデジタル回路は、どれも2 本のリード線によって電力が供給されるこ
とが暗黙の前提である。1 本はグランド線（GND）であり、ゼロボルトと想定される。もう1
本は5 ボルトである。
さいわい、デジタル論理回路のエッセンスは、電圧と電流についての知識がこれだけあれば
理解できる。電流を制御する方法と、電子的にデジタル数値を表現する方法を理解すれば良い
のだ。
2.4 　トランジスタ
電流の制御に使われるのは、
「トランジスタ」と呼ばれる半導体の機構だ。最も低いレベルを
見れば、
すべてのデジタルシステムがトランジスタで構成されている。とくにデジタル回路で使
われるトランジスタは「MOSFET」と呼ばれる。MOS はMetal Oxide Semiconductor（金属
酸化物半導体）
、FET はField Eﬀect Transistor（電界効果トランジスタ）の略称だ。MOSFET
はシリコン（珪素）の結晶を土台として、P 型とN 型のシリコン層を重ね、酸化シリコンの絶
hi.0412.ko.2002@gmail.com
　2.4
トランジスタ
9
縁層（一種のガラス）を挟み、トランジスタを回路の他の部分に接続する電線には金属が使わ
れる。
デジタル回路で使われるトランジスタの機能は、一種のOn/Oﬀスイッチだが、機械的にで
はなく電子的に操作される。つまり、機械的スイッチは物理的な力で開閉するが、トランジス
タは電圧で開閉するのだ。トランジスタは、どれも3 つの端子を持つ。3 本のリード線で、回
路の他の部分と接続されるのだ。そのうち、
「ソース」と「ドレイン」という2 つの端子間の
チャネル（経路）で、電気抵抗を制御できる。もし抵抗が低ければ、電流はソースからドレイ
ンに向けて流れる。抵抗が高ければ、電流は流れない。第3 の端子は「ゲート」といって、こ
れが抵抗を制御する。次の節では、このスイッチングトランジスタを使って、デジタルシステ
ムで使われる複雑なコンポーネントの構築方法を見ていく。
MOSFET トランジスタには2 種類あって、どちらもデジタル論理回路で使われる。図2‒1
に、この2 種類を示すためにハードウェア技術者が使う図を示す1。
S
：
ソー
ス
S
：
ソー
ス
G
：
ゲー
ト
G
：
ゲー
ト
D
：
ド
レ
イ
ン
D
：
ド
レ
イ
ン
電流はGが正の
と
き
Sか
らDへ
と流れる
電流はGが負の
と
き
Sか
らDへ
と流れる
（a）
（b）
図2‒1：論理回路で使われる2 種類のトランジスタ（a）の型は、ゲートの電圧が正のときOn になる（b）
の型は、ゲートの電圧がゼロまたは負のときOn になる
この図で（a）のトランジスタは、ゲートの電圧が正であれば（最小限の閾値を超えていれ
ば）必ずOn になる。このゲート端子に適切な電圧をかけると、あと2 つの端子の間に大きな
電流を流すことができる。そしてゲートの電圧を落とせば、大電流は止まる。ゲートに小さな
丸印のある、
（b）のトランジスタは、それとは反対の働きをする。つまり、ソースからドレイ
ンに向けて大きな電流が流れるのは、ゲート電圧が閾値に満たないとき（つまり、ゼロに近い
とき）であり、ゲート電圧が上がると電流が止まる。この2 つは「相補型」と呼ばれ、その技
術全体を「CMOS」
（Complementary Metal Oxide Semiconductor）と称する。CMOS の主
な利点は、極度に消費電力の低い回路を作れることだ。
1　ここに図示する2 種類のMOSFET は、技術的にはチャネルの極性によりp 型とn 型として分類される。
hi.0412.ko.2002@gmail.com
10
第2 章
デジタル論理回路の基礎　
2.5 　論理ゲート
デジタル回路を、どうすれば組めるだろうか。トランジスタには2 つの状態がある。電流が
流れている状態と、流れていない状態だ。だから、
「ブール代数」と呼ばれる2 値の算術シス
テムを使って回路が設計される。ほとんどのプログラマは、
「AND」と「OR」と「NOT」とい
う3 つのブール演算（ブール関数）を知っているだろう。表2‒1 に、これらの関数で利用可能
な入力値と、その結果を示す。
表2‒1：ブール関数と、可能な入力の集合に対応する結果。0 という論理値は「偽」を表し、1 という論理値
は「真」を表す
a
b
a AND b
a
b
a OR b
a
NOT a
0
0
0
0
0
0
0
1
0
1
0
0
1
1
1
0
1
0
0
1
0
1
1
1
1
1
1
1
ブール関数は、デジタルハードウェアの基礎を提供する概念だ。より重要な点は、トランジ
スタを利用して、これらの関数を効率よく実装する回路を作ることが可能であるということだ。
たとえばブール関数「NOT」について考えてみよう。典型的な論理回路は、正の電圧によって
ブール値「1」を表し、0 の電圧によってブール値「0」を表す。0 の値を表現するのに0 ボル
トを使い、1 の値を表現するのに正の電圧を使うのだから、関数「NOT」は2 個のトランジス
タで構築できる。つまり、その回路は、1 本の線から入力を受け取って、もう1 本の線に出力
するが、その出力は、常に入力の反対となる。入力の電圧が正ならば出力は0 になり、入力電
圧が0 ならば、出力は正になる2。図2‒2 に、関数「NOT」を実装する回路を示す。
このような図を「回路図」と呼ぶ。回路図に引かれた線は、コンポーネントを繋ぐリード線
に対応する。黒丸は電子的な接続を示し、線の端にある小さな白丸は外部接続を示す。この回
路には入力と出力のほかに、正電圧とゼロ電圧への外部接続がある。
ブール関数を実装する電子回路がコンピュータプログラムと大きく違うのは、回路が自動的
かつ継続的に動作することだ。つまり、いったん電圧を供給すれば（図の＋電圧）
、トランジス
タは役割を果たして電力がOn である間ずっと働き続けるし、入力が変化したら出力を変化さ
せる。呼び出されたときにだけ結果を出すプログラムの関数と違って、回路の出力は常に存在
し、いつでも使用可能だ。
回路の動作を理解するため、
「トランジスタはソースとドレインの端子間に電子的な接続を
作るのだ」と考えよう。入力が正のとき、上側のトランジスタはOﬀになり、下側のトランジ
スタはOn になる。だから出力はゼロボルトに接続される。逆に入力電圧がゼロのときは、上
2　ある種のデジタル回路では5V を使うが、他の回路は3.3V を使う。具体的に電圧を示す代わりに、ハー
ドウェア技術者はVdd と書いて、所与の回路に適切な電圧を表現する。
hi.0412.ko.2002@gmail.com
　2.6
トランジスタによるNAND 論理ゲートの実装
11
dd
＋電圧
（V   ）
出力
入力
0ボル
ト
図2‒2：1 対の相補型トランジスタを使ってブール関数「NOT」を実装する
側のトランジスタがOn になり、下側のトランジスタがOﬀになる。したがって出力は正の電
圧に接続される。ゆえに出力の電圧は、常に入力電圧を論理的に反転したものになる。
ちょっとした詳細のため、ブール関数は、もう少し複雑になっている。電子回路の特性によ
り、それぞれの関数よりも、その論理の「逆」を表現する関数のほうが、より少ないトランジ
スタで組めるのだ。このため、ほとんどのデジタル回路は「論理OR の逆」と「論理AND の
逆」を実装している。つまり、
「NOT OR」を意味する「NOR」と、
「NOT AND」を意味する
「NAND」の論理だ。さらに、ある種の回路では排他的論理和を意味する「XOR」関数も使わ
れる。表2‒2 に、それぞれの関数で可能な入力と結果を示す3。
表2‒2：論理ゲートが提供する、NAND とNOR とXOR の関数
a
b
a NAND b
a
b
a NOR b
a
b
a XOR b
0
0
1
0
0
1
0
0
0
0
1
1
0
1
0
0
1
1
1
0
1
1
0
0
1
0
1
1
1
0
1
1
0
1
1
0
2.6 　トランジスタによるNAND 論理ゲートの実装
トランジスタの詳細と、その組み合わせは、本書の残りの部分にとって重要ではない。理解
する必要があるのは、前に述べた各種ブール関数を作るのにトランジスタを使えるということ、
そして、それらの関数を使えばコンピュータのデジタル回路を作れるということだ。けれども、
トランジスタの話題を離れる前に、1 つだけ例を見ておこう。トランジスタを使って「NAND」
3　後の節で説明するように、この図に使っている表には、
「真理値表」という名前がある。
hi.0412.ko.2002@gmail.com
12
第2 章
デジタル論理回路の基礎　
関数を実装する回路だ。図2‒3 に、その回路図を示す。前述したように、結果として作られる
回路には「論理ゲート」という用語を使う。実際に論理ゲートを構築するには、
「ダイオード」
、
「抵抗」などの部品も加わる。これらはトランジスタを静電気の放電や過電流から保護するた
めのものだ。ゲートの論理的な動作に影響を与えるわけではないので、そうした追加部品は図
から省いている。
入力 A
入力 B
出力
dd
＋電圧
（V   ）
0ボル
ト
図2‒3：4 個のトランジスタを組み合わせてNAND 論理ゲートの実装回路を作る
この回路の働きを理解するために、もし両方の入力が論理値1 なら、下側の2 個のトランジ
スタがOn になることに注目しよう。すると出力は0 ボルト（論理値0）に接続される。もし
そうでなければ、上側の2 個のトランジスタのうち、少なくとも1 個がOn になり、出力は正
の電圧（論理値1）に接続される。もちろん回路は、出力が正の電圧とゼロボルトの両方に接
続されることが決してないように注意深く設計する必要がある（そうしなければトランジスタ
が壊れてしまう）
。
図2‒3 では、
「2 本の線が交差しても、そこに黒丸がなければ電子的な接続を示すものではな
い」という一般的な規約を使っている。この規則は、グラフィックスで頂点と辺を描画する場
合に似ている（2 本の辺が交差しても、そこに丸を描かなければ、頂点の存在を意味しない）
。
回路図では、2 本の線が交差しても黒丸がない場合、物理的な接点が存在しないことを意味す
る。この場合は、ワイヤは空中配線されて、間に空気が挟まっている（接触していない）と考
えればよい。接点がないことを強調するために、交点に近いところに少しだけ空間を入れて線
を引いている。
hi.0412.ko.2002@gmail.com
　2.7
論理ゲートに使われる記号
13
以上でトランジスタからゲートを作れることを例示できた。今後は個々のトランジスタにつ
いて考慮する必要はない。この章の残りの部分では、内部機構に言及することなくゲートを解
説し、次章以降では、ゲートで構成される、もっと大きくて複雑な機構を論じる。
2.7 　論理ゲートに使われる記号
回路を設計する技術者が順列組み合わせを考えるのは、トランジスタではなく論理ゲートだ。
さまざまなゲートが、それぞれ記号（シンボル）によって表現され、それらの接続を示すよう
に回路図を描く。図2‒4 に、NAND、NOR、インバータ、AND、OR、XOR の、各ゲートの記
号を示す。この図では一般的な呼称にしたがい、ブールの「NOT」演算を実行するゲートを呼
ぶのに「インバータ」という用語を使っている。
NANDゲー
ト 
NORゲー
ト 
インバータ
ANDゲー
ト 
ORゲー
ト 
XORゲー
ト
図2‒4：よく使われるゲートの記号。それぞれのゲートの入力は左側に、出力は右側に置かれる
2.8 　ゲートの組み合わせを示す例
ゲートを実装する電子部品は「TTL」
（Transistor-Transistor Logic）と総称される。それは
ゲートが、出力トランジスタを他のゲートの入力トランジスタに直結できるように設計されて
いるからだ。実際、出力は複数の入力に繋ぐことができる4。たとえば、ディスクが回転してい
るときにユーザーが電源オフのボタンを押したら出力を真にする回路が必要だとしよう。論理
的に考えれば、その2 つの入力のブール関数「AND」が、その回路の出力となる。しかし前
述したように、ある種の設計では使えるゲートがNAND とNOR とインバータに限定される。
その場合でも関数「AND」は、NAND ゲートの出力をインバータの入力に直結すれば作れる。
図2‒5 に、その接続方法を示す。
4　このテクノロジーで1 個の出力に繋げられる入力の数には限度がある。ある出力から供給できる入力の
数を示すのに、
「ファンアウト」という用語を使う。
hi.0412.ko.2002@gmail.com
14
第2 章
デジタル論理回路の基礎　
電源ボタンからの入力
ディスクからの入力
出力
図2‒5：ゲートを組み合わせる例。ある論理ゲートの出力は、もう1 つのゲートの入力に直結できる
ゲートを組み合わせる例として、もう1 つ、3 つの入力を持つ図2‒6 の回路を見よう。
出力
X
Y
Z
A
B
C
図2‒6：3 つの入力（ラベルはX、Y、Z）を持つ回路の例。中間的な値を論じるために、内部の配線にもラ
ベルを付けている（A、B、C）
「この図の回路は、
どういう関数を実装しているのですか?」
という質問に答える方法は、
2 つ
ある。この回路に対応するブール式を判定するか、入力として可能な値の組み合わせ8 種類に
ついて、それぞれ出力に現れる値を列挙するか、どちらも可能だ。この2 つの方法を理解しや
すくするため、図では、それぞれの入力と出力だけでなく、回路内の接続にもラベルを付けた。
ブール式を明らかにするには、まず入力Y がインバータに直結されていることに注目しよう。
だからA の値はブール関数「NOT Y」に対応する。そしてNOR ゲートの入力は、
（インバー
タからの）
「NOT Y」とZ の2 つである。したがって、B の値は次のブール関数に対応する。
Z nor (not Y)
NAND ゲートと、
それに続くインバータの組み合わせにより、
2 つの入力のブール関数
「AND」
が作られる。その出力は、次の式に対応する。
X and (Z nor (not Y))
同じ論理を、次のようにも書ける。
X and not (Z or (not Y))
(2.1)
ここではブール式を「回路を理解する手段」として使ったが、ブール式は回路設計において
も重要だ。回路を設計する技術者は、回路に望まれる動作を記述するブール式を見つけること
hi.0412.ko.2002@gmail.com
　2.8
ゲートの組み合わせを示す例
15
から設計を開始できる。そういう式を書くことは、問題点や特殊なケースを認識する助けにも
なる。そうして正しい式を見つけたら、それと等価なハードウェアのゲートに変換できる。
回路を指定するのにブール式を使うことには大きな利点がある。ブール式を扱うさまざまな
ツールを利用できるのだ。式を分析するにも、最小化するにも5、ゲートの組み合わせに変換す
るにも、ツールを使える。とくに、必要なゲートの数を削減できる「自動的な最小化」は重要
だ。つまり、あるブール式を入力として受け取り、それと等価だが必要なゲート数が少ない式
を出力し、おまけにその出力を回路図に変換してくれるツールが存在するのだ。要旨をまとめ
ておこう。
あるブール式を入力として受け取り、その式を最適化した回路を出力するツールが存在
する。
既存の論理回路を理解する第2 の手段は、まず可能な入力をすべて列挙し、それから回路の
各点で、それらの値に対応する値を調べるという方法だ。たとえば図2‒6 の回路には3 つの入
力があるので、入力で可能な値の組み合わせは8 種類だ。列挙を表現するのに、われわれ技術
者は「真理値表」を使う。真理値表は、しばしば回路のデバッグでも使われる。表2‒3 にある
のは、図2‒6 の回路の真理値表だ。この表は、ワイヤX、Y、Z の入力として可能な値の、すべ
ての組み合わせを列挙するとともに、ワイヤA、B、C と出力に現れる結果の値を示している。
表2‒3：図2‒6 の回路の真理値表
X
Y
Z
A
B
C
出力
0
0
0
1
0
1
0
0
0
1
1
0
1
0
0
1
0
0
1
1
0
0
1
1
0
0
1
0
1
0
0
1
0
1
0
1
0
1
1
0
1
0
1
1
0
0
1
0
1
1
1
1
0
0
1
0
表2‒3 は、まず可能な入力をすべて書き出し、それから残りの列を順に記入して作っている。
この例で3 つある入力（X、Y、Z）は、それぞれ0 または1 になる可能性があるから、表の列
X、Y、Z には、それぞれ可能な組み合わせが8 個ある。そして、記入を終えた入力の列を使っ
て、また次の列を記入できる。たとえばこの回路の点A は、第1 のインバータの出力なので、
A の値は入力Y の逆だ。したがって列A は、列Y の値を反転することで記入できる。同様に、
列B は列A と列Z の「NOR」を表す。
真理値表は、ブール式の評価にも使える。入力で可能なすべての値について式を計算し、真
5　ブール式の最小化に使える規則のリストを、付録B に示す。
hi.0412.ko.2002@gmail.com
16
第2 章
デジタル論理回路の基礎　
理値表の値と比較すればよい。たとえば表2‒3 の真理値表を使って、
（2.1）で示したブール式
が次の式と等価かどうかを判定できる。
X and Y and (not Z))
評価を実行するには、X、Y、Z で可能なすべての値の組み合わせについて、ブール式の値を
計算する。そして、それぞれの組み合わせについて、式の値と真理値表の出力列の値とを比較
する。
2.9 　バイナリ加算のデジタル回路
論理回路で整数演算を実装する方法を見てみよう。ゲートを使って、たとえば2 進数2 つの
和（sum）を求めるのだ。それには、算数の授業で習った方法を使えばよい。2 つの数を、桁
を合わせて上下に並べる。そして、最下位の桁から最上位の桁に向けて順に加算する。もし桁
あふれ（オーバーフロー）が発生したら、結果の上位桁を次の桁に繰り上げて（carry）
、そこ
に加えるのだ。ただしコンピュータは整数を10 進数ではなく2 進数で表現する。たとえば図
2‒7 は、20 と29 の加算をバイナリ（2 進法）で表現している。
carry
carry
carry
図2‒7：carry ビットを使ったバイナリ加算の例
この加算を実行する回路には、それぞれの桁（つまり、2 つのオペランドの各ビット）につい
て1 個のモジュールが必要だ。下位ビット用のモジュールは、2 つの入力を受け取って、sum
ビットとcarry ビットという2 つの出力を生成する。その回路は「ハーフアダー」
（半加算器）
と呼ばれるもので、1 個の「AND」ゲートと1 個の「XOR」ゲートを含む。ゲートの接続方法
を図2‒8 に示す。
XORゲー
ト
ANDゲー
ト
sum
carry
入力ビッ
ト 1
入力ビッ
ト 2
図2‒8：2 つの入力ビットから和と繰り上げを計算するハーフアダー回路
hi.0412.ko.2002@gmail.com
　2.10
複数のゲートを持つ集積回路
17
ハーフアダー回路は和の下位ビットを計算するが、他のビットにはもっと複雑な回路が必要
になる。具体的に言うと、これに続く計算には、それぞれ3 つの入力がある。つまり、2 つの入
力ビットと、右の桁から繰り上がるcarry ビットだ。その計算に必要な回路は、
「フルアダー」
（全加算器）と呼ばれる（図2‒9）
。2 つの入力ビットに対称性があることに注目しよう。前の
ビットの回路のsum に、どちらの入力を繋げてもかまわないのだ。
sum
carry入力
carry出力
入力ビッ
ト 1
入力ビッ
ト 2
図2‒9：2 つの入力ビットに加えてcarry 入力も受け取る、フルアダー回路
図が示すように、フルアダー回路は2 つのハーフアダー回路と、1 個のゲート（OR ゲート）
とで構成される。そのOR ゲートは、2 つのハーフアダーから受け取ったcarry を結び付ける
もので、2 つのハーフアダーのうち、どちらか一方でもcarry を出していたら、carry を出力
する。
フルアダーが受け取る入力の組み合わせは全部で8 通りあるが、回路の正しさを確認するた
めに検討すべき組み合わせは6 つだけだ。その理由を知りたければ、フルアダーが「bit 1」と
「bit 2」を対象的にに扱うことを思い出そう。このため、考慮すべきケースは3 通りしかない。
両方の入力ビットが0 のときと、両方の入力ビットが1 のときと、入力ビットの片方が1 でも
う片方が0 のときだ。carry 入力が存在するので、可能性は2 倍の6 通りになる。このフルア
ダー回路を真理値表を使って検証すれば、実際、入力の組み合わせのそれぞれについて正しい
出力が得られることがわかる。練習として実際にやってみるとよい。
2.10 　複数のゲートを持つ集積回路
上に述べたような論理ゲートは多数のトランジスタを必要としないから、1 個の電子部品に
TTL のゲートを複数入れた集積回路を安価に製造できる。そのように複数の論理ゲートを実装
する一般的なTTL 部品（汎用ロジックIC）として、7400 ファミリーがある6。このファミリー
のパーツには、それぞれ「74」で始まる番号が割り当てられている。7400 ファミリーの多く
は、物理的なチップの形状が長方形パッケージで、長さ約2 センチ。部品を回路に繋ぐ線の数
6　7400 ファミリーには、この節で述べた論理ゲートの他に、より洗練された機構も含まれる。つまりフ
リップフロップや、カウンタや、デマルチプレクサなどだが、これらは後の章で紹介しよう。
hi.0412.ko.2002@gmail.com
18
第2 章
デジタル論理回路の基礎　
（いわゆるピン数）が14 本なので、14 ピンDIP（Dual In-line Package）と呼ばれている。同
じ7400 シリーズでも、より複雑なチップは、より多くのピンを必要とする（たとえば16 ピ
ンDIP 構成を使うものがある）
。
7400 シリーズのチップで、複数のゲートをどのように配置しているかを理解するために、例
を3 つ見ておこう。7400 というチップには4 個のNAND ゲートが含まれ、7402 には4 個の
NOR ゲートが含まれ、7404 には6 個のインバータが含まれている。それぞれのケースで個々
の論理ゲートの入出力が、どのピンと接続しているかを図2‒10 に示す。
 
14 13 12 11 10 
9 
8
 
1 
2 
3 
4 
5 
6 
7
gnd
+
7400 
7402 
7404
+
+
gnd
gnd
 
14 13 12 11 10 
9 
8
 
1 
2 
3 
4 
5 
6 
7
 
14 13 12 11 10 
9 
8
 
1 
2 
3 
4 
5 
6 
7
図2‒10：論理ゲートを実装する一般的な3 種類のIC について、ピン接続を示す
この図にはピンの7 番と14 番に接続されるゲートが見えないが、この2 つのピンはゲート
を駆動するのに必要な電源を供給するもので、実際には欠かすことができない。ラベルが示し
ているように、ピン14 は＋5V に接続され、ピン7 はグランド（0V）に接続される。
2.11 　組み合わせ回路だけでは足りない
これまで述べてきた回路のように、ブール論理ゲートを相互に接続したものは、
「組み合わ
せ回路」と呼ばれる。ブール演算によって入力値を組み合わせたものが出力になるからだ。組
み合わせ回路で出力が変化するのは、入力値が変化したときだけである。このような組み合わ
せ回路は不可欠な存在だが、それだけで十分ではない。コンピュータには、入力の変化を待た
ずに動作するような回路も必要だ。たとえばユーザーがボタンを押してコンピュータの電源を
入れたとき、ハードウェアは一連の処理を実行する必要があり、そのシーケンスはユーザーか
らの追加入力なしで進行させなければならない。実際、ユーザーは電源ボタンを、ずっと押し
続ける必要もない。起動シーケンスは、ユーザーがボタンから指を離した後も進行する。しか
も、同じボタンが再び押されたとき、ハードウェアはシャットダウンのシーケンスを開始する。
どうして同じ電源ボタンで、システムを起動するだけでなく、停止することもできるのか。
デジタル回路が、入力値の変化を待たずに一連の処理を実行できるのは、なぜなのか。入力が
元の状態に戻った後でも、デジタル回路が処理を続行できるのは、どうしてか。その答えは、
機構の追加に関わる。論理ゲートの洗練された配置によっても必要な機能の一部は提供される
が、それ以外の機能には、
「クロック」と呼ばれるハードウェア装置が必要だ。次節で洗練され
hi.0412.ko.2002@gmail.com
　2.12
状態を維持する回路
19
た回路の例を見た後でクロックを解説しよう。
2.12 　状態を維持する回路
電子部品は、基本的なブール論理ゲートを含むものだけではない。組み合わせによって「状
態」の維持を可能にするゲートを含むような部品もある。そういう論理回路の出力は、現在の
入力値だけの関数ではなく、それまでの入力シーケンスにあった値も含めて決定される関数だ。
このような論理回路は「順序回路」
（シーケンシャルサーキット）と呼ばれる。
もっとも基礎的な順序回路の1 つが「ラッチ」だ。そのアイデアは単純明快で、ラッチには
1 個のデータ入力と1 個の出力のほかに、
「イネーブル」という入力信号線が追加される。そ
のイネーブル信号が論理値1 のとき、ラッチは入力のコピーそのものを出力する。つまり、イ
ネーブルが1 である間に、もし入力が変化したら、出力も変化するわけだ。しかし、いったん
イネーブル信号が論理値0 に変わったら、出力はそのときの値で凍結され、もう変化しない。
したがってラッチは、イネーブル信号がセットされていたときの入力値を「記憶」し、出力を
その値で維持する。
では、どうすればラッチを作れるのだろうか。面白いことにブール論理ゲートの組み合わせ
で十分なのだ。図2‒11 に、4 個のNAND ゲートを使って1 個のラッチを作る回路を示す。そ
の考えは、こうだ。イネーブルが論理値0 のとき、右側にある2 個のNAND ゲートが、現在
の出力を記憶する。2 つのNAND ゲートの出力は、互いの入力にフィードバックされるので、
出力値は安定する。そしてイネーブルが論理値1 のときは、左側の2 個のゲートが、データ入
力の値（下側の線）と、その逆の値（上側の線）を、右側にあるゲートのペアに渡す。
データ入力
イネーブル
出力
図2‒11：1 ビットのラッチを実装するのに4 個のNAND ゲートを使う
2.13 　伝搬遅延
ラッチの動作を理解するには、それぞれのゲートに「伝搬遅延」があることを認識する必要
がある。つまり、入力が変化してから出力が変化するまでに遅延が発生するのだ。その伝搬遅
延の間、出力は前の値のままになる。もちろんトランジスタは遅延が最小限になるように設計
されているし、遅延といってもミリ秒より短いのだが、有限の遅延時間が存在する。回路に対
hi.0412.ko.2002@gmail.com
20
第2 章
デジタル論理回路の基礎　
して伝搬遅延が、どんな影響をおよぼすかを、図2‒12 の回路を見て考えよう。
出力
図2‒12：インバータの出力を、その入力に接続する
この図はインバータの出力を、その入力に戻している。こんな接続に意味があるとは思えな
いだろう。なぜならインバータの出力は、常にその入力の逆だからだ。この回路のブール式は、
出力= not(出力)
なのだから、論理の矛盾ではないか。
しかしこの回路の働きは伝搬遅延によって説明できる。いつでも、もし出力が0 ならば、イ
ンバータの入力は0 になるだろう。ある伝搬遅延時間の後、インバータは出力を1 に変える。
出力が1 になったら、また伝搬遅延が発生し、出力は再び0 に戻る。このサイクルが永遠に繰
り返され、回路は0 と1 との間で変化を繰り返す出力を生成する。だから回路は「発振」し、
出力は「矩形波」になる。この伝搬遅延の概念が、図2‒11 に示したラッチの動作を説明する。
ラッチの出力は、伝搬遅延が発生するまで同じままになるのだ。
2.14 　ラッチを使ってメモリを作る
後述するように、プロセッサでは「レジスタ」という内部記憶ユニットが一時的なストレー
ジの役割を果たす。レジスタに格納された値は計算に使われるのが典型的だ（たとえば2 つの
値を加算するために）
。1 個のレジスタに複数のビットが格納される。たいがいのコンピュータ
には、32 ビットまたは64 ビットのレジスタが、いくつも含まれる。レジスタの回路は、デジ
タルハードウェア設計における重要な原則を示す。
複数のビットを扱う回路は、1 ビットを扱う回路を物理的に複製して構成される。
この原則を理解するために、図2‒13 を見ていただきたい。これは、4 ビットのレジスタ回路
を4 個の1 ビットラッチから構築できることを示している7。この図では、4 個のラッチのイ
ネーブル線をすべて繋ぎ合わせたものが、レジスタのイネーブル入力になっている。このハー
ドウェアは4 個の独立した回路で構成されているが、イネーブル線を繋いだので、4 個のラッ
チの動作が一致する。イネーブル線に論理値1 がセットされると、レジスタは4 ビットの入力
を受け取り、それにしたがって4 ビットの出力をセットする。イネーブル線が0 になっても、
7　図2‒13 では4 ビットのレジスタしか示していないが、典型的なプロセッサで使われているレジスタに
は、32 ビットまたは64 ビットが格納される。
hi.0412.ko.2002@gmail.com
　2.15
フリップフロップと状態遷移図
21
それらの出力は、そのまま固定される。つまりレジスタには、その入力として存在した値が、何
であっても保存される。そして、その出力値は、次にイネーブル線が1 になるまで変化しない。
まとめると次のようになる。
プロセッサの主な構成要素の1 つであるレジスタは、一群のラッチによってデジタル値
を保存するハードウェア機構である。
レジスタのイネーブル信号線
レジスタ
レジスタの入力ビッ
ト群
レジスタの出力ビッ
ト群
1ビッ
トの
ラ
ッチ
1ビッ
トの
ラ
ッチ
1ビッ
トの
ラ
ッチ
1ビッ
トの
ラ
ッチ
図2‒13：1 個の4 ビットレジスタは、4 個の1 ビットラッチから作られている
2.15 　フリップフロップと状態遷移図
フリップフロップも、出力が現在の入力だけでなく以前の入力にも依存するタイプの回路だ。
これにはさまざまな形式があるが、その1 つはコンピュータの電源スイッチと、まったく同じ
ように動作する。最初に入力が1 になるとき、フリップフロップは出力をOn にする。そして
2 回目に入力が1 になるとき、フリップフロップは出力をOﬀにする。電源の制御に使われる
プッシュボタン式のスイッチと同じで、フリップフロップは連続的な入力に応答するのではな
い。1 の入力値によってフリップフロップの状態を変化させるには、まず入力を0 に戻す必要
がある。入力が0 から1 に遷移するとき、いつでもフリップフロップは出力を現在の状態から
その逆へと変化させるのだ。図2‒14 のシーケンスは、このフリップフロップの入力の変化と、
その結果である出力の変化を示している。
このように入力のシーケンスに応答するのだから、フリップフロップは単純な組み合わせ回
路ではない。フリップフロップを1 個のゲートから構築することはできない。けれどもフリッ
プフロップは、1 対のラッチから構築することができる。
フリップフロップの働きを理解するには、入力と出力を時間の関数としてグラフに描くとわ
かりやすい。このようにプロットしたものを、
「遷移図」と呼んでいる。ほとんどのデジタル回
路で、遷移はクロックによって調整され、必ず規則的な周期にしたがって発生する。図2‒15
hi.0412.ko.2002@gmail.com
22
第2 章
デジタル論理回路の基礎　
入力
：
 
０ 
０ 
１ 
０ 
１ 
１ 
０ 
０ 
０ 
０ 
１ 
０ 
１ 
０ 
１ 
０
出力
：
 
０ 
０ 
１ 
１ 
０ 
０ 
０ 
０ 
０ 
０ 
１ 
１ 
０ 
０ 
１ 
１
入力
フリ
ップ
フロ
ップ
出力
時間の経過
図2‒14：あるタイプのフリップフロップが、入力のシーケンスに、どう反応するかを示す。このフリップフ
ロップは、入力が0 から1 に（つまり0V から5V に）変化するとき、出力を変化させる
は、図2‒14 のフリップフロップ値を遷移図にしたものだ。図2‒15 で「クロック」というラ
ベルの付いた線は、どこでクロックのパルスが発生するかを示している。入力の遷移は、いず
れもクロックのパルスの1 つに束縛される。しかし、いまは一般的なコンセプトを理解できれ
ば十分だ。クロックについては、後の節で説明する。
入力: 
出力:
1
0
1
0
時間の経過
図2‒15：フリップフロップが、図2‒14 に示した入力シーケンスに、どう反応するかを示す遷移図。時間
はX 軸に沿って進行し、その刻みはクロックの「ティック」
（tick）に対応している
このフリップフロップは、1 のビットに遭遇するたびに出力を変化させる。この遷移図を見
ると、回路設計にとって重要なタイミングの詳細が明らかになる。遷移図は、このフリップフ
ロップがトリガされるのは入力が「立ち上がる」ときだけだということを示している。つまり
出力は、入力が0 から1 へと遷移するまで変化しない。これを技術者は、出力の遷移は入力の
変化のうち「立ち上がりエッジ」で発生する、と表現する。そして、入力が1 から0 に変化す
るとき遷移する回路の場合、その遷移は「立ち下がりエッジ」で発生すると言う。
実際のフリップフロップは、その他の詳細があるので、もっと複雑である。たとえば、ほとん
どのフリップフロップには「リセット」と呼ばれる追加入力があり、これが出力の状態を0 に
戻す。フリップフロップには、他にもいくつかの変種がある。たとえば、あるフリップフロッ
プは、メイン出力の逆となる第2 の出力を提供する（ある種の回路では、逆があればゲート数
hi.0412.ko.2002@gmail.com
　2.16
バイナリカウンタ
23
を削減できる）
。
2.16 　バイナリカウンタ
1 個のフリップフロップで可能な出力値は0 か1 かの2 種類しかない。けれども一連のフ
リップフロップを繋ぎ合わせれば、合計を数えるバイナリカウンタ（2 進計数器）を作成でき
る。
「カウンタ」の入力は、フリップフロップと同じく1 個だけだ。けれどもフリップフロップ
と違って、カウンタには複数の出力がある。その出力は、検出した入力パルスを数えた合計の
バイナリ表現だ8。この出力は0 から始まり、入力が0 から1 に遷移するたびに1 が加算され
る値だ。だから、3 本の出力線を持つカウンタは、0 から7 までの合計を数えることが可能であ
る。そういうカウンタと、入力の変化にしたがって出力が変化するようすを、図2‒16 に示す。
0 
000 
0
0 
000 
0
1 
001 
1
0 
001 
1
1 
010 
2
1 
010 
2
0 
010 
2
1 
011 
3
0 
011 
3
1 
100 
4
0 
100 
4
1 
101 
5
 
・
 
 
・
 
 
・
カウンタ
入力
出力
（a）
（b）
時間の
経過
入力
出力
10進数
図2‒16：（a）はバイナリカウンタ、
（b）は、その入力値のシーケンスと、対応する出力を示す。
「10 進
数」というラベルの列は、
「出力」と等価な10 進の値である
実際にバイナリカウンタを実装する電子パーツには、まだ他に追加すべき機能がある。たと
えばカウンタには、合計をゼロにリセットするための別の入力が必要だし、カウンタを一時的
に停止する（入力を無視して出力を固定する）ための入力が加わるかもしれない。もっと重要
なことに、どんなカウンタも出力ピン数が固定されている限り、それぞれ表現できる最大の値
が存在する。合計が最大値を超えるとき、カウンタは出力をリセットし、追加の出力線によっ
てオーバーフローの発生を示す。
8　2 進数によるデータ表現は、第3 章で詳しく見ることにしよう。いまは、この出力が、ある数を表現す
ることだけ理解すれば十分だ。
hi.0412.ko.2002@gmail.com
24
第2 章
デジタル論理回路の基礎　
2.17 　クロックとシーケンス
これまで「デジタル論理」の基本的な構成要素を見てきたが、もう1 つデジタルコンピュー
タには絶対に欠かせない機能がある。それは自動運転だ。つまりコンピュータは、入力の変化
がなくても一連の命令シーケンスを実行できなければいけない。これまで述べてきた論理回路
は、どれも入力のどれかが変化するのに応答するから、入力が変化するまで何の機能も実行で
きない。デジタル論理回路は、どうすれば一連のステップを実行できるのだろうか。
ハードウェアが入力の変化を待たずに動作するための機構は、
「クロック」である。実際、ほ
とんどのデジタル論理回路は、
「クロックで動く」と言われる。つまり、入力の変化ではなくク
ロック信号が、個々のコンポーネントや、その中の部品の動きを制御し同期させることによっ
て、意図した通りの協調した動作を確実に実行させるのだ（たとえば、ある段の処理が、それ
より前の段の伝搬遅延時間を必ず待つことが保証される）
。
クロックとは何だろう。
「時計」という一般的な意味とは違って、ハードウェア技術者がク
ロックという用語を使うときは、一定周期で発振する電子回路のことを言っている。その振動
は、交互に1 と0 を繰り返す「シーケンス」に変換される。クロックは、1 個のインバータに
よって作ることも可能だが（図2‒12 を参照）
、ほとんどのクロック回路は、自然に発振する
クォーツ（水晶）の結晶を使うことによって、ある精密な周期を持つ信号を提供する。クロッ
クの回路は、その信号を増幅し、正弦波（サイン波）を矩形波（方形波）に変換する。
したがってクロックとは、一定の周期で0 と1 を相互に繰り返すシーケンスを発するものと
考えられる。クロックの速さは、ヘルツ（Hz）で数えられる。それはクロック信号が1 になり、
それから0 になるサイクルが、1 秒間にいくつあるかを示す数だ。高速なデジタルコンピュー
タを動かすクロックの速さ（周波数）は、ほとんどが100MHz（1 億ヘルツ）から数GHz（数
十億ヘルツ）の範囲にある。たとえば現在、典型的なプロセッサで使われているクロックは、
およそ3GHz のスピードで動作するものだ。
それほど高い周波数で変化する回路を人間が想像することは困難だ。そこでコンセプトを明
らかにするため、1Hz という極端に遅い周波数で動作するクロックがあると考えよう。そうい
うクロックなら、人間とのインターフェイスに使えそうだ。たとえば、あるコンピュータに、
アクティブ状態を示すために点滅するLED があるとしたら、そのLED を制御するのに遅いク
ロックが必要だ。クロックのレートが1Hz だとしたら、1 サイクルを完結するのに1 秒かか
る。つまり、そのクロックは1/2 サイクルの間は論理値1 を発し、その後の1/2 サイクルの間
は論理値0 を発する。もし回路によって、クロックが論理値1 を発するとき常にLED を点灯
させるなら、そのLED は1/2 秒間は点灯し、その次の1/2 秒間は消灯する。
0 と1 の値を相互に繰り返すシーケンスが、どうしてデジタル回路をより強力にするのだろ
うか。それを理解するために、クロックで動く単純な回路を考えよう。あるコンピュータは、
起動時に下記のステップによる「シーケンス」を実行しなければならないと想定する。
hi.0412.ko.2002@gmail.com
　2.17
クロックとシーケンス
25
•
バッテリーをテストし、
•
電源をOn にしてメモリをテストし、
•
ディスクのスピン（回転）を開始し、
•
スクリーンの電源を投入し、
•
ディスクのブートセクタをメモリに読み込んで、
•
CPU を起動
説明を単純化するため、それぞれのステップは長くても1 秒間で完了し、それから次のス
テップを始動できるということにする。そこで期待されるのは、いったん始動されたら、それ
以降は入力が変化しなくても、6 段階のステップからなるシーケンスを1 ステップずつ1 秒間
隔で実行する回路だ。
いまは回路のエッセンスに焦点を絞り、
どうやって始めるかは後ほど考えよう。シーケンスに
ある6 つのステップを実行する仕事を扱う回路は、
3 つの構成要素から構築できる。それらはク
ロックと、バイナリカウンタと、
「デコーダ」あるいは「デマルチプレククサ」
（demultiplexor）
と呼ばれるデバイスで、後者はしばしば「demux」と略される。
カウンタについては、すでに考察した。そして、1 秒間にきっかり1 サイクルの周期でデジ
タル出力を生成するクロックも、使えるとしよう。最後のパーツであるデコーダ／デマルチプ
レクサは、1 個の集積回路であり、入力の2 進数を出力の集合にマップする。このデコード機
能を使って、出力を1 つ選択するのだ。つまり、デコーダは入力として1 個の2 進数を取り、
その値にしたがって1 個の出力を選択する。デコーダがOn にする出力は、いつでも必ず1 つ
だけで、それ以外の出力は全部Oﬀになる。入力が2 進数i を表すとしたら、デコーダはi 番
目の出力を選択する。図2‒17 に、そのコンセプトを示す。
デコーダとして使われるとき、このデバイスは、出力のうち1 つを選択するだけである。デ
マルチプレクサとして使われるとき、このデバイスは、もう1 つの追加入力を受け取り、それ
入力
出力
デコーダ
x
y
z
“000”
“001”
“010”
“011”
“100”
“101”
“110”
“111”
図2‒17：3 本の入力線と8 本の出力線を持つデコーダ。もし入力x、y、z の値が0、1、1 ならば、上から
4 本めの出力が選択される
hi.0412.ko.2002@gmail.com
26
第2 章
デジタル論理回路の基礎　
を選択した出力に渡す。デコーダ機能も、それより複雑なデマルチプレクサ機能も、ブール論
理ゲートで構築できる。
デコーダが、この単純なシーケンサ機構に必要な最後の機能を提供する。クロックとカウン
タとデコーダを組み合わせた結果の回路は、一連のステップを実行できるのだ。たとえば図
2‒18 に示す接続では、クロックの出力をバイナリカウンタの入力として使い、バイナリカウン
タの出力をデコーダの入力として使っている。
未使用
バッテリーをテス
ト
メモリをテス
ト
ディスクを始動
ディスプレイ電源投入
ブー
トブロ
ッ
クを読み出す
CPUを起動
未使用
クロ
ッ
ク
カウンタ
デコーダ
図2‒18：6 段階のステップをシーケンシャルに実行する回路にクロックを使う。カウンタからの出力線が、
デコーダの入力線に直結している
この回路の動作を理解するため、カウンタがゼロにリセットされたと考えよう。カウンタの
出力が000 なので、デコーダはもっとも上の出力線を選択するが、これは「未使用」
。つまり
何も接続されていない。クロックが論理値0 から論理値1 に変化するときに、動作が始まる。
カウンタは、それを1 と数えて、出力を001 に変える。デコーダは入力が変化したら第2 の出
力を選択する。それは「バッテリーをテスト」というラベルが付いた線だ。この第2 の出力線
が、必要なテストを実行する回路に接続される。第2 の出力線は、1 秒間選択される。その1
秒の間にクロック出力は、まず1/2 秒間は論理値1 のままとなり、それに続く1/2 秒間は論理
値0 に反転している。クロック出力が論理値1 に戻ると、カウンタの出力線は010 に変化す
る。そしてデコーダは第3 の出力を選択し、それはメモリをテストする回路に繋がっている。
もちろん詳細は重要だ。たとえば、ある種のデコーダチップは選択した出力を0 にするが、
他のは1 にする。電気的な詳細も無視できない。他のデバイスとの互換性を持つために、ク
ロックは論理値1 には5V を、論理値0 には0V を使う必要がある。また、ワイヤを直結する
のだから、バイナリカウンタの出力線には、デコーダの入力線と同じバイナリ表現を使う必要
がある。データ表現については、第3 章で論じよう。いまは、出力と入力の値に互換性がある
ものと想定する。
hi.0412.ko.2002@gmail.com
　2.18
フィードバックという重要な概念
27
2.18 　フィードバックという重要な概念
図2‒18 に示した単純な回路は、ある重要な機能が欠けている。演算を制御する方法がない
のだ（つまりシーケンスを開始し、あるいは停止する手段が存在しない）
。クロックは永遠に動
き続けるので、この図のカウンタはゼロから最大値までカウントしたら、またゼロに戻ってカ
ウントを始める。その結果、デコーダの出力は何度でも同じシーケンスを繰り返し、それぞれ
の出力は必ず1 秒で次に進む。
同じ一連のステップを繰り返し実行するだけのデジタル回路は少ない。6 つのステップを実
行し終えたらシーケンスを停止するには、
どうすればいいだろうか。その答えは
「フィードバッ
ク」という基礎的なコンセプトにある。フィードバックは複雑なデジタル回路の中枢になる。
なぜなら、処理の結果をフィードバックすることで、回路の振る舞いに影響を与えられるから
だ。コンピュータの起動シーケンスでは、それぞれのステップにフィードバックが必要だ。た
とえば、もしディスクを起動できなければ、ブートセクタをディスクから読み出すことができ
ない。
フィードバックは、すでに図2‒11 のラッチ回路でデータの値を保持するために使っている。
右側にある2 つのNAND ゲートで、それぞれの出力を、もう一方のゲートに入力としてフィー
ドバックしていたのだ。フィードバックのもう1 つの例として、デコーダの最後の出力（F と
呼ぼう）を使ってシーケンスを停止させられないか、検討してみよう。簡単な解決策として、F
の値によって、
クロックのパルスがカウンタに届くのを防ぐという方法がある。つまり、
クロッ
クの出力をカウンタの入力に直結せず、代わりに論理回路を間に挟むのだ。その回路のゲート
によって、F の値が0 のときだけ、カウンタの入力が続くのを許す。ブール演算を使うと、そ
のカウンタ入力を次の式で書ける。
CLOCK and (not F)
つまり、F が偽である間はカウンタ入力をクロックと等しくするが、F が真のときカウンタ
入力がゼロに変わる（その値が続く）
。2 個のインバータと1 個のNAND ゲートを使えば必要
な機能を実装できることを、図2‒19 に示す。
図2‒19 にフィードバックが存在することは明白だ。なにしろ最後の出力と入力側の組み合
わせ回路とを繋ぐ物理的な接続が、はっきり見えるのだから。また、フィードバック機構が
「フィードバックループ」9とも呼ばれる理由も、この図を見ればわかるだろう。
9　「フィードバックループ」は、フリップフロップの構築に使われるゲート間にも存在する。
hi.0412.ko.2002@gmail.com
28
第2 章
デジタル論理回路の基礎　
未使用
バッテリーをテス
ト
メモリをテス
ト
ディスクを始動
ディスプレイ電源投入
ブー
トブロ
ッ
クを読み出す
CPU起動
停止
デコーダ
クロ
ッ
ク
この2つのゲー
トが
ブール演算のANDを
実行する
カウンタ
フィー
ドバッ
ク
図2‒19：各出力を一巡したら処理を止めるため、図2‒18 の回路にフィードバックを加える
2.19 　シーケンスを始動する
フィードバックによってプロセスを停止できることは図2‒19 で示したが、この回路はまだ
完全ではない。シーケンスを始動するための機構が含まれていないからだ。さいわい、始動機
構を追加するのは簡単だ。カウンタには、カウントをゼロにリセットする別の入力線があるこ
とを思い出そう。だから回路を始動するのに必要なのは、カウンタの「リセット」に、もう1
本の（たとえばユーザーが押すボタンからの）入力を繋げることだけだ。
そのボタンをユーザーが押せば、カウンタはゼロにリセットされ、出力は000 になる。すべ
てがゼロの入力を受け取ったデコーダは、最初の出力をOn にし、最後の出力をOﬀにする。最
後の出力がOﬀになれば、NAND ゲートがクロックパルスを通すので、カウンタが動き始める。
これでシーケンスは始動するが、ユーザーにカウンタのリセットを許すと、問題が生じるか
もしれない。たとえば、スタートアップのシーケンスを実行中に短気なユーザーが待ちきれず、
またボタンを押すかもしれない。カウンタがリセットされたら、またシーケンスが最初から始
まってしまう。ある処理を2 度実行するのは、場合によっては単なる時間の浪費だが、別の場
合では処理の繰り返しによって問題が生じる（たとえば、ある種のディスクドライブは、ある
タイミングで1 個だけコマンドを発行することが要求される）
。したがって製品のシステムで
は複雑な組み合わせのロジックを使って、シーケンスが中断されたり完了前にリスタートされ
るのを防いでいる。
この例は、わずかなパーツしか含んでいないが、ある重要なコンセプトを示している。論理
的なステップのシーケンスを実行可能にするには、いくつかのブール論理ゲートと1 個のク
ロックがあれば十分なのだ。要点をまとめると次のようになる。
このサンプル回路は、
「始動されたら、ある論理的なステップのシーケンスを実行し、そ
れから停止する回路」を、一群のブール論理ゲートと1 個のクロックによって組めるこ
hi.0412.ko.2002@gmail.com
　2.20
ソフトウェアの反復とハードウェアの複製
29
とを示している。
汎用的なコンピュータを作るのに、あと1 つ必要なのは「プログラマビリティ」
、つまりプ
ログラムを組めるようにすることだ。ハードウェアに関するこの話の続きは、第6 章で展開さ
れる。そこでは、ここで述べた基本的なコンポーネントを使って、メモリ内のプログラムで処
理のシーケンスを決定する「プログラマブルなプロセッサ」を作る方法を示す。
2.20 　ソフトウェアの反復とハードウェアの複製
ハードウェアについての考察で、1 つ重要なポイントを覚えておこう。一群の要素に対して
同じ処理を行う必要があるとき、ソフトウェアとハードウェアでは使う手段が大きく異なるの
だ。ソフトウェアで、ある集合に属する複数の要素を扱う基本的なパラダイムは、
「反復」であ
る。プログラマは、ある集合から次の要素を見つけて処理するのを繰り返し実行するコードを
書く。根底にある処理システムが一度に1 個の要素にしか適用されないから、プログラマは要
素の個数（反復の回数）を指定する必要がある。反復は本当に重要なので、ほどんどのプログ
ラミング言語には、反復をより明快に表現できるステートメント（たとえばfor ループ）が用
意されている。
ハードウェアも、実行を繰り返すように組むことが可能だが、そうするのは難しく、結果は
不細工なハードウェアになる。複数の要素をハードウェアで扱うための基本的なパラダイムは、
反復でなく「複製」だ。ハードウェア技術者は、ある回路のコピーを複数作る。それぞれの回
路は1 個の要素を処理するだけだが、すべてのコピーが同時に実行される。たとえば1 対の
32 ビット値に対して、あるブール演算を行うとき、ハードウェア設計者は、まず1 対のビッ
トのための回路を組み、それから同じ回路を32 倍に複製する。したがって、2 つの32 ビッ
ト整数についてブール演算の「排他的論理和」を求めるのに、ハードウェア設計者は32 個の
「XOR」ゲートを使える。
複製の利点を認めるのは、プログラマにとっては難しいことだ。なにしろ複製は「良いプロ
グラミング」の原則に反する。プログラマはコードの複製を避けるように教育される。しかし
ハードウェアの世界において、複製には3 つの明瞭な利点がある。エレガンスと、スピードと、
正確さだ。複製によってエレガンスが現れるのは、個々の要素を選択し、それを別の場所に移
し、結果を元の場所に戻すのに必要となるハードウェアの追加を避けられるからだ。複製は、
値や結果を移動することで生じる遅延をなくすだけではない。複数の処理を同時に実行できる
から性能が向上する。たとえば32 個のインバータが同時に働けば、32 ビットを反転するのに、
1 個のインバータで1 ビットを反転するのと、まったく同じ時間しかかからない。このスピー
ドアップは、コンピュータが64 ビットを同時に処理できれば、まさに顕著となる。並列処理
という考えは、本書を通じて現れる。後の章では並列処理が、もっと大きなスケールにおいて、
どのように適用されるかを説明する。
複製の第3 の利点は、信頼性の高さだ。信頼性が向上するのは、ハードウェアの実証が複製
hi.0412.ko.2002@gmail.com
30
第2 章
デジタル論理回路の基礎　
によって容易になるからだ。たとえば32 ビットの処理が正しく動作することを実証するのに、
ハードウェア技術者が実証すべきものは、1 ビットの回路だけだ。同じ回路の複製だから、残
りのビットも同じように動作するはずだ。その結果、ハードウェアはソフトウェアより、ずっ
と信頼性が高い。実際に法律でもハードウェアにはソフトウェアより高い信頼性の基準が求め
られている。しばしば「as is」として無保証で売られるソフトウェアと違って、ハードウェア
（たとえば集積回路）の販売では、法的枠組みの範囲内で、意図した用途に適応することが要求
される。要点をまとめよう。
反復を使うソフトウェアと違って、ハードウェアは複製を利用する。複製の利点は、エ
レガントになり、速度が向上し、信頼性が高まることだ。
2.21 　ゲートとチップの最小化
これまでは、根底に存在する技術的詳細について多くを語らなかったが、たとえば全体的な
設計と使用すべき複製の量の選択を終えた技術者が次に求めるのは、必要となるハードウェア
の量を最小にする方法だ。それにはゲート数の最小化と、チップ数（IC の個数）の最小化とい
う、2 つの問題がある。第1 の問題には、ブール演算の一般則が関わる。たとえば次のブール
式を見よう。
not (not z)
この式を実装する回路は、2 つのインバータを繋ぐものだが、この式は全体を「z」で置換で
きる。2 つのNOT 演算を繋げば「恒等写像」になることを、われわれは知っている。直結さ
れた1 対のインバータを回路から省略しても、結果に影響はない。
ブール式を最適化する、もう1 つの例として、次の式も見ておこう。
x nor (not x)
「x」が1 の値を持つか、それとも「not x」が1 の値を持つかの、どちらかだ。したがって
NOR 関数は、いつでも同じ0 という論理値を作り出す。したがって式全体を0 という値で置
換できる。回路で言えば、この式をNOR ゲートとインバータを使って計算するのは愚かだ。
その2 つのゲートから得られる結果は、いつでも論理値0 になるのだから。このように、いっ
たんブール式を書いた技術者は、その式を分析して、結果を変えずに縮小あるいは削除できる
部分式を探すことができる。
さいわい、
技術者がゲートを最小化する作業には、
洗練された設計ツールの援助がある。ツー
ルに入力としてブール式を渡せば、ツールが式を分析して、それを最小のゲート数で実装する
回路を作ってくれる。設計ツールは、単にブール演算のAND とOR とNOT を使うわけでは
なく、利用できるゲート（たとえばNAND）を理解し、利用できる電子部品によって回路を定
義してくれる。
hi.0412.ko.2002@gmail.com
　2.22
余ったゲートの使い方
31
ブール式は数学的に最適化できるが、それ以上の最適化が必要となる。なぜなら全体的な目
標がチップ数の最小化だからだ。状況を理解するために、同じ型のゲートのコピーを複数含む
IC が多いことを思い出そう。だから、ブール演算の数を最小化しても、最小化によって必要
なゲートの型数が増えてしまったら、回路の最小化にならない。たとえば、あるブール式に4
個のNAND ゲートが必要だとしよう。これを最適化すれば、2 個のNAND ゲートと1 個の
NOR ゲートにでき、必要なゲート数を3 個に減らせる。ところが、最適化によってゲート数
が少なくなっても、必要なIC の数が増えてしまう。なぜかといえば、4 個のNAND ゲートな
ら1 個の7400 集積回路に含まれるのに、最適化の結果にNAND とNOR の両方のゲートが
含まれていたら、2 個のIC が必要となるからだ。
2.22 　余ったゲートの使い方
図2‒19 に示した回路10をもとに考察を続けよう。クロックとカウンタとデコーダに、それぞ
れ1 個のIC が必要だとして、あといくつのIC が必要だろうか。2 個というのが自明な答えだ
ろう。1 つはNAND ゲートに必要で（たとえば7400）
、もう1 つは2 個のインバータに必要
だ（たとえば7404）
。ところが驚くべきことに、この回路はIC を1 個追加するだけで実装でき
る。7400 には4 個のNAND ゲートが含まれるが、必要なのは、そのうち1 個だけだ。余った
ゲートを、どう使うか。1 と0 のNAND は1 になり、1 と1 のNAND は0 になる。だから、
1 nand x
というブール式は、
not x
に等しい。
1 個のNAND ゲートをインバータとして使うには、その入力の片方を論理値1（つまり5V）
に繋ぐだけでよい。余ったNAND ゲートはインバータとして使える。
2.23 　配電と放熱
われわれ技術者は、目標とする機能を正しく実行できるデジタル回路を計画し、それに使う
部品数を最小化するだけでなく、根本的な電力と冷却の要件にも取り組む必要がある11。たと
えばこの章の回路図ではゲートの論理的な入出力だけを示してきたが、どのゲートも電力を消
費する。1 個のIC が使う電力は些細な量だが、ハードウェア設計には反復よりも複製を使う
傾向があるから、複雑なデジタルシステムには大量の回路が含まれる。技術者は、必要とされ
る電力の総量を計算して、適切な「配電回路」を構築し、個々のチップに給電する追加配線を
10　これは動作停止のためにフィードバックを加えた回路だ。
11　電力については第20 章で、詳しく考察しよう。
hi.0412.ko.2002@gmail.com
32
第2 章
デジタル論理回路の基礎　
計画しなければならない。
電力を消費するデバイスは、物理の法則により、どれも熱を発する。そうして生成される熱
の量は消費電力に比例する。1 個のIC から生じる熱はわずかだが、小さな閉鎖空間で何百もの
回路を使うデジタルシステムで発せられる熱の総量は、ずいぶん大きくなる。放熱機構を講じ
なければ、おそらく高熱で回路が故障するだろう。小さなシステムの技術者は、シャシーに穴
を開けることで熱せられた空気を外に出し、もっと冷たい空気を周囲から取り入れて換気する。
中程度の規模のシステム、たとえばパーソナルコンピュータでは、周囲から取り込んだ空気を
システムに素早く行き渡らせるため、いくつかのファンを追加する。もっとも大規模なデジタ
ルシステムでは、冷えた空気では足りず、冷却液による本格的な冷却システムが必要だ（たと
えばスーパーコンピュータCray-2 の回路は、冷却材のタンクに直接浸された）
。
2.24 　タイミングと複数のクロック領域
デジタルロジックを巡る、この簡単な案内で、技術者が考慮すべき重要な側面を、もう1 つ
だけ見ておきたい。それは「タイミング」だ。ゲートは即座に動作するのではなく、
「セトリン
グ」に（つまり入力の変化に応じて変化する出力が安定するまでに）時間を要する。これまで
の例でタイミングを無視できたのは、1Hz などという、とてつもなく遅い周期のクロックに対
して、すべてのゲートのセトリングタイムが1 マイクロ秒より短いため、ゲートがクロックの
パルスに比べて、ずっと早く安定していたからだ。
しかし実際のデジタル回路は高速に動作するよう設計されるのだから、電子工学でタイミン
グの側面は極めて重要だ。回路が正しく動作することを保証するために技術者は、すべての
ゲートが安定するまでに必要な時間を計算しなければならない。
また、
信号がシステム全体に伝播するのに必要な時間も計算しなければならない。それは
「ク
ロックスキュー」のせいでシステムが誤動作しないことを保証するためだ。クロックスキュー
（クロック信号のタイミングのずれ）を理解するために、図2‒20 を見よう。この回路図のク
ロックは、システム内の3 個のIC を制御している。
この図に示す3 個のIC は、物理的に分散している（たぶん残りの空間は他のIC が占めてい
るのだろう）
。残念ながら、クロックからの信号が個々のIC に届くまでには、ある有限な時間
が必要であり、その時間は、クロックと所与の回路を繋ぐ配線の長さに比例する。その結果と
してクロック信号は、一部のIC に、ほかのIC に届くよりも早く到達する。目安として、信号
が1 フィート（約30 センチ）の配線を伝搬するのに、およそ1 ナノ秒かかる。だから、18 イ
ンチ（約46 センチ）幅のシステムで、クロック信号がクロックに近い場所に届くのは、クロッ
クからもっとも遠い場所に届くより1 ナノ秒ほど前になるだろう。システムにおいて、ある部
品が他の部品より前に動作する必要があるのなら、クロックスキューによって問題が生じるこ
とは明らかだ。回路を設計する技術者は、それぞれの経路の長さを計算し、クロックスキュー
の問題を回避できるレイアウトを考案しなければならない。
hi.0412.ko.2002@gmail.com
　2.25
クロックレスロジック
33
クロ
ッ
ク
IC1
IC2
IC3
図2‒20：このデジタルシステムには、1 個のクロックで制御されるIC が3 つある。クロックとIC を結ぶ
配線の長さによって、クロック信号が到達するタイミングが決まる。
クロックスキューがあるので、技術者がシステム全体に1 個のグローバルクロックを使うこ
とは、めったにない。その代わりに複数のクロックを使い、それぞれのクロックでシステムの
一部を制御する。しばしば物理的に最小な領域に、最高速で動くクロックが使われる。われわ
れは、所与のクロックが制御するゾーンを「クロック領域」12と呼んでいる。この考えは、物
理的に大きなシステムだけに限定されるものではない。たとえばCPU のように、複雑で大規
模な集積回路では、1 個のチップにおいて複数のクロック領域が使われるようになっている。
複数クロック領域を使うことでクロックスキューの問題は回避されるが、複数のクロックに
より「クロック同期」という新たな問題が現れる。クロック領域の境界にデジタルロジックを
置き、双方の調停を図らなければならない。通常そのような調停は、回路が遅くなることを意
味し、データの移動に複数のクロックサイクルを取られるだろう。
2.25 　クロックレスロジック
チップの規模と複雑さが増すのにしたがって、クロックスキューの問題と、システムを複数
クロック領域に分割することが、いよいよ重要になってきた。多くのシステムにおいて、ク
ロック領域の境界がボトルネックになる。あるクロック領域からの出力を、別のクロック領域
に転送するには、その境界に存在する論理回路で複数のクロックサイクルを待つ必要があるか
らだ。複数領域の同期という問題が深刻なので、代替となるアプローチが研究され、考案され
ている。それが「クロックレスロジック」だ。基本として、クロックレスシステムでは、ある
ブール値を表現するのに1 本ではなく2 本の配線を使う。2 本使うことによって、その出力は
クロックに依存することなく「ビットの終わり」を明確に示すことができる。表2‒4 に、2 本
の配線で可能な値の組み合わせ4 種類と、それぞれの意味を示す。
12　訳注：原文ではclock zone ですが、clock domain という用語も使われます（
「クロックドメインクロッ
シング」
（CDC）
、
「マルチクロックドメイン設計」など）
。
hi.0412.ko.2002@gmail.com
34
第2 章
デジタル論理回路の基礎　
表2‒4：あるチップから他のチップへビットを転送するのにクロックレスロジックを使うとき、2 本の配線
が表す意味
線1
線2
意味
0
0
新しいビットを始める前にリセット
0
1
0 のビットを転送
1
0
1 のビットを転送
1
1
未定義（使用しない）
このアイデアでは、ビットとビットの合間に、送り側が両方の線を0 ボルトにセットして、
受け側をリセットする。リセット後に、送り側が論理値0 または1 を転送する。受け側は、2
本の線のうち必ず片方だけがhigh（5V）になることで、ビットの到着を確実に察知する。
なぜクロックレスロジックを使うのだろうか。複数クロック領域の協調という問題を排除し、
より高速なチップ間データ転送を可能にするだけでなく、クロックレスのアプローチでは消費
電力も削減できる。クロックのある回路では、常にクロック信号を（たとえ回路にアクティブ
ではない部分があっても）継続的に伝搬しなければならない。クロックレスロジックでは、ク
ロック信号の伝搬というオーバーヘッドを回避できる。
クロックレスのアプローチは、実際に使えるのだろうか。答えはイエスだ。プロセッサ全体
でクロックレスロジックを使う設計により、ARM 社は、このアプローチが大規模で複雑な回路
にスケーリングすることを証明した。ゆえにクロックレスのアプローチには可能性があるが、
現在ほとんどのチップ設計者は、クロック同期式のアプローチを、いまだに使っている。
2.26 　回路の規模とムーアの法則
ほとんどのデジタル回路は「IC」
（集積回路：Integrated Circuit）から作られる。この技術
により、多数のトランジスタを1 個のシリコンチップに置いて相互に接続することが可能にな
る。だから、あるIC に存在するコンポーネントだけで有益な回路を形成できる。
IC の製造には、しばしば「CMOS」
（相補型金属酸化膜半導体）テクノロジーが使われる。
シリコン（珪素）に不純物を添加することで、負または正にイオン化する。その結果として作
られる物質を、N 型シリコン、P 型シリコンと呼ぶ。N 型とP 型のシリコン層を重ねることに
よって、トランジスタができる。
IC の製造工場では、IC を1 個ずつ作るわけではない。直径12 インチ（約30 センチ）から
18 インチ（約45 センチ）の円形のウェハーを作るが、そのなかに所与のIC 設計のコピーが
数多く入っている。ウェハーができたら個々のチップに切り分け、それぞれのチップをプラス
チックのケースに接続用のピンとともにパッケージングする。
IC の形状と規模はさまざまだ。小さいのは外部との接続端子（つまりピン）が8 本しかない
hi.0412.ko.2002@gmail.com
　2.26
回路の規模とムーアの法則
35
が、大きいのは何百本ものピンを持つ13。小規模なIC は数十のトランジスタを含むが、何百万
も含む大規模なIC もある。
チップ上に存在するトランジスタの数によって、IC は表2‒5 に示すような4 つのカテゴリー
に分類できる。
表2‒5：集積回路の規模によるクラス分け
名称
用例
SSI（小規模集積）
基本的なブール論理ゲート
MSI（中規模集積）
カウンタなど、中間的なロジック
LSI（大規模集積）
小さな埋め込み用のプロセッサ
VLSI（超大規模集積）
複雑なプロセッサ
たとえば、この章に記述のある7400、7402、7404 といったIC はSSI に分類される。バイ
ナリカウンタや、フリップフロップや、デマルチプレクサはMSI である。
VLSI の定義は、四角いチップに収納可能なトランジスタの密度を高める新しい方法を製造
業者が考案するたびに変わってきている。インテルの設立者の1 人であるゴードン・ムーア
（Gordon Moore）は、シリコン回路の密度（1 平方インチあたりのトランジスタの数）が、毎
年2 倍に増えるという予測を立てた。この「ムーアの法則」は、伸び率が弱まった1970 年に
「18 か月ごとに2 倍」と改訂された。
1 個のチップに積めるトランジスタの数が増えたのを利用して、ベンダー各社は次々に機能
を追加していった。いくつかのベンダーは1 個のチップに自社CPU（コア）の複数のコピー
を入れ、それらを接続することで「マルチコア」CPU を作った。ほかのベンダーは、
「SoC」
（System on Chip）というアプローチを採用した。これは1 個のチップにプロセッサ、メモリ、
入出力装置とのインターフェイスを入れ、それらすべてを接続し、完全なシステムとして提供
するものだ。そして最後にメモリ製造業者は、DRAM（Dynamic Ram）と呼ばれるメインメ
モリのチップ容量を、どんどん増加していった。
ベンダーが設計して販売する汎用のIC に加えて、個々の用途に専用のIC を作ることも可能
になった。
「ASIC」
（Application Speciﬁc Integrated Circuits）と呼ばれるIC を、個々の企業
が設計し、その設計をベンダーに送って製造させるのだ。ASIC の設計は高価で時間もかかるが
（およそ2 百万ドル、2 年近く）いったん設計が完了したら、そのASIC のコピーを安価に製
造できる。だから標準のチップでは要件を満たせない製品を大量に作ろうとする企業は、ASIC
の設計を選ぶ。
13　チップの各ピンの用途を記述する図を、
「ピン配置図」と呼ぶ。
hi.0412.ko.2002@gmail.com
36
第2 章
デジタル論理回路の基礎　
2.27 　回路基板と多層化
ほとんどのデジタルシステムは、
「プリント回路基板」
（PCB：Printed Circuit Board）を使っ
て作られる。PCB は、ファイバーグラスの板に薄い金属片を貼り、IC その他の部品を実装す
るための穴を開けたものだ。その金属片によって、基板上の部品に配線する。
配線の交差が必要なほど複雑な回路にも、プリント基板を使えないだろうか。その問題を解
決するために、技術者たちは「多層」のプリント基板を開発した。つまり、多層基板なら3 次
元の配線が可能になる。配線を交差させる必要があるときは、その線を上の層に通して、そこ
で交差し、また下の層に戻すのだ。
どんな回路でも2、3 層もあれば十分と思われるかもしれない。けれども大規模で複雑な回
路で何千もの配線が必要な場合は、さらなる多層化が必要になる。18 層におよぶ回路基板を設
計することも、まれではない。極度に多層化された基板は、24 層にも達する。
2.28 　抽象レベル
この章で示したように、
デジタル論理回路はさまざまな抽象レベルで見ることができる。もっ
とも低いレベルでは、トランジスタがシリコンから製造される。次のレベルでは、複数のトラ
ンジスタを抵抗やダイオードなど他の部品とともに使って、ゲートが作られる。その次のレベ
ルでは、複数のゲートを組み合わせて、フリップフロップのような中間規模のユニットが作ら
れる。そして今後の章では、それぞれ複数の中間規模ユニットから構築される、もっと複雑な
機構（プロセッサ、メモリシステム、入出力デバイスなど）について論じる。表2‒6 に、抽象
レベルのまとめを示す。
表2‒6：デジタルロジックにおける抽象レベルの例。あるレベルの項目は、1 つ下のレベルにある項目を使っ
て実装される
抽象
実際に使うもの
コンピュータ
回路基板
回路基板
プロセッサ、メモリ、バスアダプタのチップ
プロセッサ
VLSI チップ
VLSI チップ
数多くのゲート
ゲート
数多くのトランジスタ
トランジスタ
シリコンで実装される半導体
重要なポイントは、抽象レベルを上げるにつれて、より多くの詳細を隠すことができ、内部
の詳細に触れずに、ますます大きな構成要素について語れるということだ。たとえばプロセッ
サを記述するときは、ゲートあるいはトランジスタのレベルで内部構造を見ることなしに、プ
ロセッサの仕組みを考察できる。
抽象化は、アーキテクトやエンジニアがデジタルシステムを記述するのに使う図にも、重要
hi.0412.ko.2002@gmail.com
　2.29
まとめ
37
な影響をもたらす。これまで見てきたように、回路図はトランジスタ、抵抗、ダイオードを結
ぶ配線を表現できるだけでなく、ゲートの組み合わせを表現するのにも使える。今後の章では、
プロセッサとメモリシステムの繋がりを表現するのに、より高いレベルの図を使う。そのよう
な図では、小さな矩形のボックスがプロセッサやメモリを表すので、ゲート間の接続などは見
せない。アーキテクチャの図を見るときは、抽象化のレベルを理解しよう。高いレベルの図で
は1 個の要素でも、低いレベルでは多数の要素に対応するかもしれないのだ。
2.29 　まとめ
「デジタルロジック」は、コンピュータのようなデジタルシステムを構築するのに使うハー
ドウェア部品である。これまで見てきたように、デジタル回路設計ではブール演算が重要な道
具の1 つになる。ブール関数と、組み合わせて回路の実装に使うゲートには、直接的な関係が
存在する。また、ブール論理の値を真理値表で記述できることを見てきた。
クロックは、一定の周期でパルスを送り出す機構であり、それによって1 と0 の信号が相互
に作られる。クロックによってデジタル回路の出力は、入力の関数に加えて時間の関数にもな
る。クロックは、回路の複数のパーツに同期を提供するためにも使われる。
デジタル論理は数学的視点から考察できるが、実際に回路を組むには根底にあるハードウェ
アの詳細を理解する必要がある。技術者は基本的な正確さのほかに、電力の配給、熱の発散、
クロックスキューといった問題に対処しなければならない。
練習問題
2.1
Web を使ってVLSI チップにあるトランジスタの数と、チップの物理的なサイズを
調べましょう。仮にダイ（die）の全域が使われるとしたら、個々のトランジスタの大
きさは、どのくらいですか?
2.2
スマートフォンなど、バッテリーで動くデバイスのデジタル論理回路は、5V 駆動で
はありません。スマートフォンのバッテリーを見るか、Web でサーチして、何ボルト
が使われているのか調べましょう。
2.3
NAND とNOR とインバータのゲートを使って排他的論理和（XOR）関数を提供す
る回路を設計しましょう。ただし、これら全部の種類のゲートを、必ず使う必要はあ
りません。
2.4
図2‒9 にあるフルアダー回路の真理値表を書きましょう。
2.5
Web を使ってフリップフロップについての記事を読み、主な種類と性質を書き出し
ましょう。
2.6
NAND とNOR とインバータのゲートを使って、デコーダの回路を作りましょう。
2.7
以下の質問については、Wikipedia などWeb 上のリソースを参考にしてください。
チップメーカーが、7 ナノメートル（7nm）のテクノロジーを使っていると、誇らし
hi.0412.ko.2002@gmail.com
38
第2 章
デジタル論理回路の基礎　
げに書いているのは、どういう意味でしょうか?
2.8
あるカウンタのチップに16 本のピンがあるとしたら、そのカウンタの出力は最大で
何ビットですか?
ヒント：チップにはパワーとグランドの端子も必要です。
2.9
もしデコーダチップに5 本の入力ピンがあるとしたら（パワーとグランドは勘定に
入れません）
、出力ピンは何本でしょうか?
2.10
A、B、C の3 つの入力を受け取って3 つの出力を生成する回路を設計しましょ
う。ごく単純な回路で良いですが、必ず2 個のインバータを使うこと。他のチップ
（NAND、NOR、XOR）は任意に使って結構です。
2.11
ある回路に使っていないNOR ゲートが1 個あるとします。その入力の1 つを論理
値1 に（あるいは0 に）直結したら、何か役に立つ関数を作れるでしょうか。理由も
説明してください。
2.12
クロックレスロジックについての記事を読みましょう。どこで使われていますか?
hi.0412.ko.2002@gmail.com
第3 章
データとプログラムの表現
3.1 　はじめに
前章ではデジタル論理回路を紹介し、デジタルシステムの構築に使われる基本的な構成要素
としてのハードウェアを記述した。この章では基本的な議論の続きとして、デジタルシステム
がプログラムとデータを「エンコード」
（符号化）するのに、2 進表現をどう使うのかを説明し
よう。その表現はハードウェア技術者だけでなくプログラマにも重要だ。なぜならソフトウェ
アを書くには、根底にあるハードウェアで使われるフォーマットを理解する必要があり、ハー
ドウェアが（たとえば加算などの）演算を実行する速度はフォーマットに影響されるからだ。
3.2 　デジタル論理と重要な抽象
これまで見てきたように、デジタル論理回路には低いレベルの詳細が数多く含まれる。基本
的な演算を実行するために、回路はトランジスタを使うし電圧も使う。けれどもデジタル論理
でもっとも重要なポイントは「抽象」にある。だから根底にある詳細を隠し、可能な限り高い
レベルの抽象を使いたい。たとえば7400 シリーズのデジタル論理チップの入力も出力も、状
態には0V か5V かという2 つの可能性がある。しかしアーキテクトが論理ゲートを使ってコ
ンピュータを設計するとき、そんな詳細を考えたりはしない。彼らはブール代数の論理値、つ
まり0 と1 という抽象を使うのだ。メモリやプロセッサのように複雑なデジタルシステムを、
トランジスタや電圧を考慮することなく記述できるのも抽象化の働きだ。もっと重要なことに、
より低い電圧を使って電力の消費を抑えるスマートフォンのようなバッテリー駆動のデバイス
で同じ設計を再利用できるのも、抽象化のおかげなのだ。
プログラマにとってもっとも重要な抽象は、ソフトウェアから見える要素、すなわちデータ
やプログラムの表現だ。これから先の節ではデータ表現について考察し、それらがプログラム
からどう見えるのかを論じる。そして最後の節で、
「命令」がどう表現されるかを示す。
hi.0412.ko.2002@gmail.com
40
第3 章
データとプログラムの表現　
3.3 　ビットとバイトの定義
すべてのデータ表現はデジタル論理に基づく。われわれは、2 つの値のどちらかを持つデジ
タルな存在を表現するのに、
「2 進法の桁」を意味する「ビット」
（bit）という名前を使い、数
学的な0 と1 を、その2 つの値に割り当てる。
より複雑なデータ要素を表すには複数のビットを使う。たとえば、どのコンピュータシステ
ムでも、そのハードウェアが操作できる1 ビットより大きな最小のデータ要素として、
「バイ
ト」
（byte）が定義されている。
バイトは、どのくらい大きいのか? バイトのサイズに、すべてのコンピュータシステムに共
通する標準は存在しない。バイトのサイズは、コンピュータを設計するアーキテクトが選ぶも
のだ。初期のコンピュータ設計者は、実験的にさまざまなバイトサイズを使った。CDC が作っ
た初期のコンピュータは6 ビットのバイトを使い、BB&N が設計したコンピュータは10 ビッ
トのバイトを使っていた。特殊な用途を持つ一部のコンピュータでは、いまも特異なバイトサ
イズが使われるが、ほとんどのコンピュータシステムで「バイトは8 ビット」と定義されてい
る。このサイズが広く受け入れられているので、技術者は普通（とくに指定がなければ）
、バイ
トサイズは8 ビットに等しいと想定する。要点をまとめよう。
コンピュータにはさまざまなサイズのバイトが使われてきたが、現在のコンピュータ業
界では、1 バイトは8 ビットを含むという定義が慣例である。
3.4 　バイトのサイズと値の範囲
バイトあたりのビット数がプログラマにとって特に重要なのは、メモリがバイトのシーケン
スとして組織されるからだ。1 バイトに格納できる最大の数は、バイトサイズによって決まる。
k ビットを格納するバイト1 つで表現できる数値は、2k 通りある（1 と0 で構成される長さk
のユニークな2 進数は、2k 個存在する）
。だから6 ビットのバイトで表現できるのは64 個の
数であり、8 ビットのバイトで表現できるのは256 個の数である。一例として、3 ビットで表
現できる8 つの組み合わせを考えてみよう。図3‒1 に、それらの組み合わせを示す。
000 
010 
100 
110
001 
011 
101 
111
図3‒1：3 ビットに割り当てられる8 つのユニークな組み合わせ
ビットパターンが表現するのは何だろうか。ここで理解すべき重要なポイントは、
「ビット列
そのものに、内在的な意味はない」ということだ。値の解釈は、それらのビットをハードウェ
アとソフトウェアが、どう使うかによって決まる。アルファベットの文字1 つも、文字列も、
整数あるいは浮動小数点数も、オーディオ録音（楽曲など）も、ビデオも、コンピュータプロ
hi.0412.ko.2002@gmail.com
　3.5
2 進の位取り記数法
41
グラムも、ビット列によって表現される。
コンピュータのハードウェアでビット列が示すのは、プログラマなら誰でも知っている要素
だけではない。たとえば次のように、3 個のビットが3 個の周辺機器を表すように設計するこ
とも可能だ。
•
第1 ビットが1 ならば、キーボードが接続されている。
•
第2 ビットが1 ならば、カメラが接続されている。
•
第3 ビットが1 ならば、プリンタが接続されている。
あるいは、3 個のビットが3 個の押しボタンスイッチの現在の状態を表すようにハードウェ
アを設計することも可能だ。つまりi 番目のビットが1 ならば、いまユーザーがi 番目のスイッ
チを押している、という意味だ。まとめると次のようになる。
ビット列に固有の意味はない。すべての意味は、ビットをどう解釈するかによって付加
される。
3.5 　2 進の位取り記数法
ビットの組み合わせに意味を割り当てるのにもっともよく使われる抽象は、それらを数値と
して解釈するものだ。たとえば整数の解釈は数学の応用である。ビット列は、底を2 とする2
進（バイナリ）の「位取り記数法」の値だ。この解釈を理解するには、次のことを思い出そう。
底が10 ならば、1 つの桁に使える数字は0、1、2、3、4、5、6、7、8、9 のどれかで、それぞれ
の桁の位置が10 の「冪」
（べき）を表す。だから123 という数は、1 × 102 + 2 × 101 + 3 × 100
を意味する。2 進法で利用できる数字は0 と1 だけで、各ビットの位置は2 の冪を表す。つま
り各桁は順に、20、21、22、... という意味になる。図3‒2 に、2 進数の位取りを示す。
25 = 32
24 = 16
23 = 8
22 = 4
21 = 2
20 = 1
図3‒2：底を2 とする位取り記数法で、最初の6 つのビット位置に割り当てられる値
一例として、次の2 進数について考えよう。
0 1 0 1 0 1
この値は、上の図にしたがって、次のように解釈される。
0 1 0 1 0 1 = 0 × 25 + 1 × 24 + 0 × 23 + 1 × 22 + 0 × 21 + 1 × 20 = 21
整数表現の細部（負の数など）は後の章で論じよう。いまは、慣例的な位取り表記がもたら
hi.0412.ko.2002@gmail.com
42
第3 章
データとプログラムの表現　
す重要な結果に触れておくだけで十分だ。つまり、k ビットで表現できる2 進数は、1 ではな
く0 から始まる。ゆえに、図3‒2 の位取り表記でいえば、3 個のビットで表現できる2 進数は
0 から7 まで、8 ビットで表現できる2 進数は、0 から255 までの範囲である。要約すると次
のようになる。
k 個のビットは、1 個の2 進整数を表すものとして解釈できる。
慣例的な位取り記法を使えば、k ビットで表現できる値の範囲は0 から2k −1 まで。
これはソフトウェアの設計にもハードウェアの設計にも欠かせない基本中の基本なので、こ
れらの分野で働く人は誰でも知っていなければならない。表3‒1 に示す2 進数と10 進数の対
応など、ハードウェアおよびソフトウェアの設計者ならば当然の知識だ。この表には、232 と
264 の項も含まれている（しかし驚くほど大きな数だ）
。表中の、比較的小さな値は暗記すべき
だが、ハードウェアとソフトウェアの設計者が知っておくべきことは、こういった大きな項が
「何桁あるか」である。さいわい、232 に10 進の10 桁が含まれ、264 に20 桁が含まれること
は記憶しやすい。
表3‒1：一般に使われる2 の冪乗と、その10 進値
2 の冪乗
10 進の値
10 進の桁数
0
1
1
1
2
1
2
4
1
3
8
1
4
16
2
5
32
2
6
64
2
7
128
3
8
256
3
9
512
3
10
1024
4
11
2048
4
12
4096
4
15
16384
5
16
32768
5
20
1048576
7
30
1073741824
10
32
4294967296
10
64
18446744073709551616
20
hi.0412.ko.2002@gmail.com
　3.6
ビットの順序
43
3.6 　ビットの順序
図3‒2 の位取り表記を見て、そんなのは当然でしょう、と思われたかもしれない。たしかに
10 進数を書くとき、われわれは常に、最下位の桁を右端に置き、最上位の桁を左端に置く。だ
から2 進数を書くときも、
「最下位ビット」
（LSB：Least Signiﬁcant Bit）を右端に置き、
「最
上位ビット」
（MSB：Most Signiﬁcant Bit）を左端に置くのが理に適っている。けれども、整
数値を保存するのにデジタル論理回路を使うときは、右とか左とかいう概念は無意味だ。コン
ピュータアーキテクトは、何ビットを保存するのか、そのちどれが最下位で、どれが最上位な
のかを、はっきり指定する必要がある。
ビットの順序が特に重要なのは、ある場所から別の場所へビット群を転送するときだ。たと
えば、ある数値をレジスタからメモリに移動するときは、ビットの順序を保存しなければなら
ない。同じように、ネットワークを超えてデータを送信するときは、送り側と受け側でビット
の順序が一致していなければならない。つまりLSB とMSB の、どちらを先に送るのかについ
て、同意が必要だ。
3.7 　16 進記法
2 進数は、それと等価な10 進数に変換できる。しかしプログラマや技術者でも、等価な10
進数がわかりにくい場合がある。たとえばプログラマは、右から5 番目のビットをテストする
必要があれば、バイナリ定数の「010000」を使うほうが、それと等価な10 進定数「16」を使
うよりも、定数値とビットとの対応が、はるかに明快だ。
しかし残念ながら長いビット列は、それと等価な10 進数と比べて扱いにくく、わかりにく
い。たとえば次の2 進数で16 番目のビットがセットされているかどうか判断するのに、人間
はビットを1 個ずつ数えなければならない。
1 1 0 1 1 1 1 0 1 1 0 0 1 0 0 1 0 0 0 0 1 0 0 1 0 1 0 0 1 0 0 1
2 進法よりわかりやすい表現として、より大きな底を使うという妥協案が生まれた。底が2
の冪乗ならば、2 進法への変換は、きわめて容易である。8 進法も使われたが、一般に使われ
るようになったのは16 進法だ。
16 進には、2 つの利点がある。まず、表現が2 進よりずっとコンパクトなので、値を表す数
字の列が短くなる。第2 に、16 は2 の冪乗なので、2 進と16 進の変換は単純明快で、複雑な
計算を行う必要がない（計算機などの道具を使わなくても、容易に素早く変換できる）
。
16 進表記では、4 ビットのグループを、0 から15 までの値を持つ「1 桁の16 進数」に、そ
れぞれ変換する1。表3‒2 に、16 個の16 進数と、それぞれに対応する2 進数と10 進数を示
1　プログラマは、16 進を意味するhexadecimal を略したhex という言葉を使う。訳注：ヘキサとも言
う。数字の後にH またはh と書く場合もある。
hi.0412.ko.2002@gmail.com
44
第3 章
データとプログラムの表現　
す。今後の図と例では、A からF までの大文字によって、9 より大きな16 進数を表す。一部
のプログラマと一部のプログラミング言語は、代わりにa からf までの小文字を使うが、重要
な違いではない。プログラマなら、どちらでも使えるようにしよう。
表3‒2：16 進1 桁の数字と、それぞれに等しい2 進数および10 進数。1 桁の16 進数は、バイナリの4
ビットをエンコードしたもの
16 進
2 進
10 進
0
0000
0
1
0001
1
2
0010
2
3
0011
3
4
0100
4
5
0101
5
6
0110
6
7
0111
7
8
1000
8
9
1001
9
A
1010
10
B
1011
11
C
1100
12
D
1101
13
E
1110
14
F
1111
15
16 進にエンコードする例として、図3‒3 は、ある2 進数を、それと等価な16 進数に変換し
ている。
1 1 0 1 1 1 1 0 1 1 0 0 1 1 0 1 0 0 0 0 1 0 0 1 0 1 0 0 1 0 0 1
D 
E 
C 
9 
0 
9 
4 
9
図3‒3：2 進数と16 進数の対応。1 桁の16 進数が5 ビットを表す
3.8 　16 進および2 進の定数記法
2 進法、10 進法、16 進法の表記は、使う数字に重なりがあるので定数が多義的になる恐れ
がある。その曖昧さを解決するために、それぞれ異なる表記が必要だ。数学書や、ある種の教
科書は、底が10 以外であることを下付き文字で表す（たとえば13516 などと書いて、この定
数が16 進数であることを示す）
。コンピュータアーキテクトやプログラマは、プログラミング
言語の記法にしたがうことが多い。つまり数の前に、16 進の定数ならば「0x」というプリフィ
クス（接頭辞）を付け、2 進の定数ならば「0b」というプリフィクスを付けるのだ。したがっ
て、13516 を表すのに、プログラマは0x135 と書く。同様に、図3‒3 にあった32 ビットの定
hi.0412.ko.2002@gmail.com
　3.9
文字集合
45
数は、次のように書く。
0xDEC90949
3.9 　文字集合
前述したように、ビット列そのものに固有の意味はない。それぞれのビットが何を意味する
かは、ハードウェアかソフトウェアが決める。さらに重要なポイントとして、複数の解釈が可
能である。一群のビットを、ある解釈によって作成し利用し、その後で、また別の解釈をする
ことも、あり得るのだ。
一例として文字データには、数値としての解釈と、シンボルとしての解釈がある。どのコン
ピュータシステムにも、
「文字集合」が定義されている2。そのコンピュータと外部入出力デバ
イスとの間で、ある一群のシンボルを「文字」として使うという了解があるわけだ。典型的な
文字集合にはアルファベットの大文字と小文字、数字、句読点などの記号が含まれる。もっと
重要なポイントとして、コンピュータアーキテクトは、1 文字が1 バイトに収まる文字集合を
選ぶことが多い（1 バイトで表現できるビットパターンのそれぞれに1 文字を割り当てる）
。こ
のため、8 ビットのバイトを使うコンピュータの文字集合には、256（28）個の文字が含まれ
る。6 ビットのバイトを使うコンピュータなら、64（26）文字だ。実際、多くのプログラミン
グ言語でバイトデータを「キャラクタ」と呼んでいるくらい、バイトサイズと文字集合には非
常に密接な関係がある。
それぞれの文字をエンコードするのに、どんなビット値が使われるのだろうか。それはコン
ピュータアーキテクトが決めることだ。たとえば1960 年代にIBM 社は、EBCDIC（Extended
Binary Coded Decimal Interchange Code）というコード体系を、IBM のコンピュータで使う
という選択をした。そしてCDC 社は、自社のコンピュータに6 ビットの文字集合を使うこと
に決めた。この2 つの文字集合には、まったく互換性がなかった。
実際問題として、コンピュータシステムにはキーボード、プリンタ、モデムといった機器が
接続されるが、そういった機器は、しばしば別の会社によって作られる。互換性を維持するた
めに、周辺機器とコンピュータシステムには、どのビットパターンが所与の文字や記号に対
応するのかの合意が必要だ。ベンダーが互換性のある装置を作れるように、ANSI（American
National Standards Institute：米国国家規格協会）が、ASCII（American Standard Code for
Information Interchange）と呼ばれる文字集合を定義した。ASCII は、通常の大文字、小文
字、数字、句読点などを含む、128 個の文字表現を指定するので、8 ビットのバイトでは、残
りの128 文字に特殊記号を割り当てることが可能だ。この標準規格は、広く受け入れられた3。
2　文字集合の呼び名には、たとえば（英語の会話では「エブシディク」などと発音される）EBCDIC や、
「アスキー」
（ASCII）がある。
3　訳注：日本ではASCII をもとに「JIS 符号」が定められた。国際的にも、やはりASCII をもとにISO
符号が定められた。
hi.0412.ko.2002@gmail.com
46
第3 章
データとプログラムの表現　
表3‒3 に、文字のASCII 表現を、それぞれの16 進数と、それに対応するシンボルによって
示す。もちろん16 進表記は、2 進数を短く表記する手段にすぎない。たとえば小文字の「a」
は0x61 という16 進の値を持つが、それは2 進数の0b01100001 という値に対応する。
表3‒3：ASCII 文字集合。それぞれのエントリで、16 進の値と、印字可能な文字ならばシンボル表現を、そ
れ以外のキャラクタ（制御文字）には意味を示す
00
nul
01
soh
02
stx
03
etx
04
eot
05
enq
06
ack
07
bel
08
bs
09
ht
0A
lf
0B
vt
0C
np
0D
cr
0E
so
0F
si
10
dle
11
dc1
12
dc2
13
dc3
14
dc4
15
nak
16
syn
17
etb
18
can
19
em
1A
sub
1B
esc
1C
fs
1D
gs
1e
rs
1F
us
20
sp
21
!
22
”
23
#
24
$
25
%
26
&
27
’
28
(
29
)
2A
*
2B
+
2C
,
2D
-
2E
.
2F
/
30
0
31
1
32
2
33
3
34
4
35
5
36
6
37
7
38
8
39
9
3A
:
3B
;
3C
<
3D
=
3E
>
3F
?
40
@
41
A
42
B
43
C
44
D
45
E
46
F
47
G
48
H
49
I
4A
J
4B
K
4C
L
4D
M
4E
N
4F
O
50
P
51
Q
52
R
53
S
54
T
55
U
56
V
57
W
58
X
59
Y
5A
Z
5B
[
5C
5D
]
5E
̂
5F
60
’
61
a
62
b
63
c
64
d
65
e
66
f
67
g
68
h
69
i
6A
j
6B
k
6C
l
6D
m
6E
n
6F
o
70
p
71
q
72
r
73
s
74
t
75
u
76
v
77
w
78
x
79
y
7A
z
7B
{
7C
̶
7D
}
7E
̃
7F
del
前述したように、一般的なコンピュータは8 ビットのバイトを使う。そしてASCII が定義し
たのは128 個のキャラクタ（7 ビットの文字集合）である。したがって、一般的なコンピュー
タでASCII を使うと、1 バイトが取り得る値の半分（10 進で128 から255 までの値）は、未
定義となる。それらの値は、どう使われたのか。ある場合には、使われなかった（キャラクタ
を受け取ったり送ったりする周辺機器は、バイトの8 ビットめを、単に無視した）
。その他の
場合では、コンピュータアーキテクトまたはプログラマが、この文字集合を拡張した（たとえ
ば英語以外の言語のために記号を追加した）
。
3.10 　Unicode
7 ビットの文字集合を持つ「7 ビットのバイト」でも、英語と一部の欧州言語には十分だが、
すべての言語には不十分だ。漢字のシンボルは何千もある。そのような言語に対応するために、
拡張案や代替案が提案された。
拡張文字集合の1 つとして、広く受け入れられたのが、Unicode（ユニコード）だ。Unicode
はASCII を拡張したものだが、極東を含む全世界の言語に対応することを意図している。もと
hi.0412.ko.2002@gmail.com
　3.11
符号なし整数のオーバーフローとアンダーフロー
47
もとは16 ビットの文字集合として設計されたが、その後のバージョンでは、より大きな表現
を受け入れるために拡大されている。今後のコンピュータや入出力デバイスは、Unicode に基
づいた文字集合を使うようになっていくのだろう。
3.11 　符号なし整数のオーバーフローとアンダーフロー
図3‒2 で示した2 進数の位取り記数法で作られるのは、
いわゆる
「符号なし整数」
（unsigned
integer）である。つまり、ビットの2k 通りの組み合わせに、それぞれ正の（マイナスではな
い）数値を割り当てる。コンピュータで使われる符号なし整数は有限なので、足し算や引き算
のような演算から、予期せぬ結果が生じる場合がある。たとえば、k ビットの符号なし整数を、
もっと小さなk ビットの符号なし整数から差し引くと、負の（符号が必要な）結果が生じるは
ずだ。同様に、k ビットの符号なし整数を2 つ足し合わせたら、k ビットでは表現できないほ
ど大きな値が生じるかもしれない。
この問題を、符号なしで2 進の算術演算を行うハードウェアが扱う方法は興味深い。第1 に
ハードウェアは、
「ラップアラウンド」を使って結果を求める（つまりハードウェアは、k ビッ
トの整数を2 つ加算した結果から、下位k ビットだけを取る）
。第2 にハードウェアは、
「オー
バーフロー」または「アンダーフロー」の状態を示すビットによって、結果がk ビットを超過
したか、あるいは負になったことを示す4。たとえばオーバーフローを示すビットの値は、k ＋
1 番目のビットに現れるはずの値に対応する（そのビット値は、普通「キャリー」と呼ばれる）
。
図3‒4 に、結果としてキャリーが立つような3 ビット演算による加算を示す。
1 0 0
1 1 0
1 0 1 0
オーバーフロー
結果
図3‒4：オーバーフローを起こす符号なし整数の加算。ラップアラウンドの発生を示すオーバーフローのビッ
トは、キャリーに等しい
3.12 　ビットとバイトの番号
ビットの集合に、どういう順序で番号を振るべきだろうか。ビット列だと思えば、左端から
振るのが理屈に合っている。2 進数だと思えば、右端から（数値的には最下位ビットから）振
るのが理屈に合っている。番号付けが特に重要なのは、データをネットワーク越しに転送する
4　アンダーフローという用語は、値が表現可能な範囲より小さいことを示す。符号なし整数の演算で負の
結果が生じた場合、負の値は表現できないので、アンダーフロー状態になる。
hi.0412.ko.2002@gmail.com
48
第3 章
データとプログラムの表現　
ときだ。受信側と送信側のコンピュータ間には、最初に最下位ビットを送るのか、それとも最
上位ビットを送るのかについて、合意が必要だ。
複数バイトにまたがるデータ項目を考えると、番号付けは、もっと複雑になる。たとえば32
ビットで構成される整数を考えてみよう。もしコンピュータが8 ビットのバイトを使っている
のなら、4 バイトにまたがる整数は、最下位バイトからでも、最上位バイトからでも、転送で
きるだろう。
複数バイトにおよぶ整数を最下位から最上位の順で格納し転送するシステムを「リトルエン
ディアン」と呼び、最上位から最下位の順で格納し転送するシステムを「ビッグエンディアン」
と呼んでいる。同様に、1 バイトの転送を最下位ビットから始めるシステムを「ビットリトル
エンディアン」と呼び、最上位ビットから始めるシステムを「ビットビッグエンディアン」と呼
んでいる。整数を構成する複数のバイトが「配列」に格納されると思えば、エンディアンは、そ
のメモリ内の向きを決めるものと考えられる。図3‒5 は、4 バイトの整数が、リトルエンディ
アンとビッグエンディアンの両方で、どのように表現されるのかを示す（各バイトのメモリ内
の位置を相対アドレスで示す）
。
０
０
０
１
１
１
０
１ 
１
０
１
０
０
０
１
０ 
０
０
１
１
１
０
１
１ 
０
１
１
０
０
１1１
（a）
 整数497,171,303を、
バイ
トに分けた2進数で表現
（b）
 リ
トルエンディアンの順序で整数を格納
（c）
 ビッ
グエンディアンの順序で整数を格納
loc.i 
loc.i+1 
loc.i+2 
loc.i+3
loc.i 
loc.i+1 
loc.i+2 
loc.i+3
０
０
０
１
１
１
０
１ 
１
０
１
０
０
０
１
０ 
０
０
１
１
１
０
１
１ 
０
１
１
０
０
１1１
０
１
１00１1１ 
00１
１1０
１1 
10100010 
０00１
１
１0１
図3‒5：（a）497,171,303 という整数を、32 ビットの2 進数で表現したもの。8 ビットごとに空白を入
れて、バイトの区分を示す（b）その整数をリトルエンディアンの順序で、連続するメモリに格納する場合
（c）同じ整数をビッグエンディアンの順序で、連続するメモリに格納する場合
これを見るとビッグエンディアンのほうが、人間が数字を書く順番と同じなのでわかりやす
いと思われるかもしれない。ところがコンピュータの処理ではリトルエンディアンに、いくつ
かのメリットがある。リトルエンディアンなら、たとえばプログラマは4 バイト整数の全体を
参照する場合も、下位2 バイトを参照する場合も、最下位バイトだけ参照する場合も、同じ1
個のメモリアドレスを使える。
hi.0412.ko.2002@gmail.com
　3.13
2 進の符号付き整数
49
3.13 　2 進の符号付き整数
「3.5 　2 進の位取り記数法」で述べた位取り記数法は、負の数への配慮がなかった。負の
数を受け入れるには別の方法が必要だが、それには次の3 種類の解釈が使われてきた。
•
サインと絶対値
これは正負の符号と絶対値による表現だ。整数は、1 個のサインビット（整数が負な
らば1、そうでなければ0）と、整数の絶対値を表すビット集合で構成される。絶対
値のフィールドは、図3‒2 に示した位取り記法にしたがう。
•
1 の補数
これはビット集合を1 個のフィールドとして解釈する。正の整数には、図3‒2 に示し
た位取り記数法を使うが、k ビットの整数で表現できる正の値の上限は、2k−1 にな
る。ある数の負の値を作るには、すべてのビットを反転する（0 を1 に、1 を0 に変
える）
。最上位ビットをサインと解釈すれば、その整数の正負がわかる（負の整数なら
1 であり、そうでなければ0 である）
。
•
2 の補数
これもビット集合を1 個のフィールドとして解釈し、正の整数に図3‒2 の位取り記数
法を使う。k ビットの整数で表現できる正の値の上限は、2k−1 −1 になるが、その表
現は、1 の補数と同じである。負の数を作るには、正の数から1 を引いてから、すべ
てのビットを反転する。1 の補数と同じく、最上位ビットをサインと解釈すれば、そ
の整数の正負がわかる（負の整数なら1、そうでなければ0）
。
いずれの解釈にも、奇妙な癖がある。たとえばサインと絶対値による表現では、
「負のゼロ」
を作ることが可能だが、その考えは数学の有効な概念に対応しない。1 の補数による解釈では、
ゼロに2 種類の値がある。つまり、全部のビットが0 のときと、その補数、つまり全部のビッ
トが1 のときがあるのだ。最後に、2 の補数による解釈では、正の値よりも負の値の方が1 つ
だけ多い（ゼロが1 つだから）
。
どれが最良の解釈だろうか。どの解釈にも、うまく使えるケースが存在するから、この問題
についてプログラマは討論できる。けれどもプログラマには選択権がない。どれにするかを決
断するのはハードウェアアーキテクトであり、その決断にしたがってハードウェアが構築され
るからだ。3 つの解釈のどれもが、少なくとも1 個のコンピュータで使われてきた。しかし、
多くのハードウェアアーキテクチャは、2 の補数の体系を使っている。それには2 つの理由が
ある。第1 に、2 の補数ならば、算術演算を実行するハードウェアが、ローコストで高速にな
る。第2 に、次節で説明するが、2 の補数で計算するハードウェアは符号なし整数の計算も扱
うことができるのだ。
hi.0412.ko.2002@gmail.com
50
第3 章
データとプログラムの表現　
3.14 　2 の補数の例
前述したように、k 個のビットで表現可能な組み合わせは2k 個ある。符号なし表現の組み
合わせは、0 から始まる整数の連続的な集合に対応するが、2 の補数は、その組み合わせを半
分に分ける。その片方（ゼロから2k−1 −1 まで）の組み合わせには、符号なし表現と同じ値
が割り当てられる。もう片方（最上位ビットが1 に等しい部分）の組み合わせは、負の整数に
対応する。したがって、可能な組み合わせを順に並べると、ちょうど半分のところで、値は表
現可能な最大の整数から、最大の絶対値を持つ負の整数に変わる。
2 の補数の割り当てを、例をあげて明示しておこう。例を小さくするために、4 ビットの整
数を考える。表3‒4 に、4 個のビットで表現可能な16 個の組み合わせと、それらを符号なし、
符号と絶対値、1 の補数、2 の補数の表現を使ったときの値（10 進表記）で示す。
表3‒4：4 ビットの組み合わせ（2 進数）と、符号なし、符号と絶対値、1 の補数、2 の補数の解釈によって
割り当てられる値（10 進数）
2 進数
符号なしの解釈
符号と絶対値の解釈
1 の補数による解釈
2 の補数による解釈
0000
0
0
0
0
0001
1
1
1
1
0010
2
2
2
2
0011
3
3
3
3
0100
4
4
4
4
0101
5
5
5
5
0110
6
6
6
6
0111
7
7
7
7
1000
8
-0
-7
-8
1001
9
-1
-6
-7
1010
10
-2
-5
-6
1011
11
-3
-4
-5
1100
12
-4
-3
-4
1101
13
-5
-2
-3
1110
14
-6
-1
-2
1111
15
-7
-0
-1
前述したように、符号なし表現と2 の補数については、オーバーフローを除けば同じハード
ウェアの演算が両方の表現に使えるという利点がある。たとえば1001 という2 進の値に1 を
加えれば1010 になる。符号なし表現では、9 に1 を足して10 になる。2 の補数では、−7 に
1 を足して−6 になる。
要点をまとめよう。
コンピュータは、同じ1 つのハードウェア回路を使って、符号なしと2 の補数の、両方
の整数演算を提供できる。そのコンピュータで実行されるソフトウェアは、それぞれ整
数に使うべき解釈を選択できる。
hi.0412.ko.2002@gmail.com
　3.15
符号拡張
51
3.15 　符号拡張
表3‒4 で示したのは4 ビットの2 進数だったが、この考えは任意のビット数に拡張できる。
たいがいのコンピュータのハードウェアは、複数の整数サイズをサポートしているので（たと
えば1 つのコンピュータで、16 ビット、32 ビット、64 ビットの表現を利用できる）
、プログ
ラマは個々の整数データ項目に、どれか1 つのサイズを選択できる。
もしコンピュータに複数サイズの整数があれば、ある値を小さいサイズの整数から、より大
きなサイズの整数にコピーする状況が生じるかもしれない。たとえば16 ビット整数を32 ビッ
ト整数にコピーする場合を考えよう。残りのビットには何を置けば良いだろうか。2 の補数で
は、下位のビットをそのままコピーして、符号ビットを拡張することになる。元の値が正であ
れば、最上位ビットを拡張すると、大きな整数の上位ビットがゼロで補充される。元の数が負
であれば、最上位ビットの拡張で、大きな整数の上位ビットは1 で補充される。どちらにして
も、より多くのビットを持つ整数も、少ないビットを持つ整数と同じ数値を持つと解釈される5。
まとめよう。
符号拡張　2 の補数の計算によって、k ビットの整数Q を、k よりビット数の多い整数
にコピーするとき、上位に追加されるビットは、どれもQ の最上位ビットと等しい。符
号ビットを拡張することによって2 つの整数は（どちらも2 の補数として解釈すれば）
同じ値となる。
2 の補数型のハードウェアでは、符号なしの整数値に算術演算を行うと正しい値を得られる
ので、すべての符号なし演算にハードウェアのサポートが得られると思われるかもしれない。
けれども符号拡張によってルールに例外が生じる。つまりハードウェアが必ず符号拡張を行う
ことによって予想外の結果が生じる場合がある。たとえば、もし最上位ビットが1 である符号
なし整数を、より大きな符号なし整数にコピーしたら、そのコピーは同じ値にならないのだ。
つまり、要点は次のようになる。
2 の補数型のハードウェアは符号拡張を行うので、符号なし整数を、より大きな整数に
コピーすると、値が変わってしまうことがある。
3.16 　浮動小数点
汎用のコンピュータは、符号付きと符号なしの整数演算を実行するハードウェアだけでなく、
「浮動小数点」
（ﬂoating point）の数値で演算を実行するハードウェアも提供している。コン
ピュータで使われる浮動小数点表現では、値が「仮数」と「指数」で表される。この指数表記
5　2 の冪乗による除算と乗算はシフト演算によって実装できる。右シフト演算では符号拡張が生じて、結
果は正しい値になる。したがって整数−14 を右に1 ビットだけシフトした結果は−7 になり、整数14 を
右に1 ビットだけシフトした結果は7 になる。
hi.0412.ko.2002@gmail.com
52
第3 章
データとプログラムの表現　
は、
「科学的表記法」から派生したものだ。科学的表記法では、たとえば−12345 という値を、
−1.2345 × 104 と書く。同様に、たとえば化学者がアボガドロ定数を書くときは、次のように
書くだろう6。
6.023 × 1023
基数を10 とする伝統的な科学的表記法と違って、コンピュータが使う浮動小数点記法は2
進法に基づいている。ビット列で構成される1 個の浮動小数点値は、符号を格納するサイン
ビット、仮数部を格納するビット群、指数部を格納するビット群という3 つのフィールドにわ
かれ、すべてが「2 の冪乗」を基にしている。仮数部には2 進法で値を格納するし、指数は（10
ではなく）2 の何乗かを指定する整数である。科学的表記法の指数は、10 進法の小数点を何桁
シフトするかの指定と考えられるが、浮動小数点表記の指数は、2 進法の小数点を何ビットシ
フトするかの指定である。
空間を最大限に利用するため、多くの浮動小数点表記には、次のような最適化も含まれる。
•
値が正規化される。
•
仮数部では、最上位ビットを明示しない。
•
指数部では、絶対値による比較を容易にするため、バイアスを加えて正の数にする。
このうち、最初の2 つの最適化には関連がある。浮動小数点数を「正規化」するには、仮数
から「先行ゼロ」をなくすように指数を調節する。たとえば10 進数なら、0.003 × 104 を正規
化して、3 × 101 にできる。注目すべきことに、2 進の浮動小数点値を正規化すると、必ず1
個の1 が先行する（数がゼロという特殊ケースを除く）
。そこで、仮数部の有効ビットを増や
して精度を高めるため、浮動小数点表現では、仮数の値をメモリに格納するとき、その最上位
ビットを保存する必要がない。代わりに、浮動小数点演算が必要になったとき、ハードウェア
が仮数部の値に1 のビットを連結する。
この考えは、例を見れば明らかになるだろう。ここで使う例は、IEEE 標準754 で、コン
ピュータ業界では広く使われている7。この標準が、単精度と倍精度の数を定義している。その
標準によれば、単精度の値は32 ビットを占め、倍精度の値は64 ビットを占める。図3‒6 に、
このIEEE 標準で浮動小数点数が、どのように3 つのフィールドに分割されるかを示す。
この図における「ビット番号」は、IEEE 標準にしたがって最下位ビットに0 という番号を
割り当てている。たとえば単精度では、仮数部が入る下位23 ビットに、0 から22 までの番号
が振られている。その次の、指数部が入る8 ビットには、23 から30 までの番号があり、最上
6　訳注：これは近似値の1 つ。ほかに6.02 × 1023、6.022 × 1023、6.022141527 × 1023 などとも書か
れる。これらの表記で、6.02、6.022、6.023 などが仮数部である。
7　IEEE は、Institute of Electrical and Electronics Engineers の略称。この組織が、電子的デジタルシス
テムの標準規格を作っている。
hi.0412.ko.2002@gmail.com
　3.17
IEEE 浮動小数点値の範囲
53
（a）
（b）
S
指数部
仮数部 
（ビッ
ト0から22）
S
指数部
仮数部 
（ビッ
ト0から51）
31 30 
23 22 
0
63 62 
52 51 
0
図3‒6：IEEE 標準754 による浮動小数点数。S は符号を表す。
（a）は単精度、
（b）は倍精度で、各フィー
ルドのビット番号を示す
位のサイン（S）ビットの番号は31 だ。倍精度の場合、仮数部が52 ビットを占め、指数部が
11 ビットを占める。
3.17 　IEEE 浮動小数点値の範囲
単精度浮動小数点のIEEE 標準では、正規化された指数の範囲が−126 から127 までとな
る。したがって、表現できる値は、およそ次の範囲である。
2−126から2127まで
これを10 進で書くと、およそ次の範囲である。
10−38から1038まで
倍精度浮動小数点のIEEE 標準は、指数の範囲が単精度よりも、はるかに広い。
2−1022から21023まで
10 進で書くと、およそ次の範囲である。
10−308から10308まで
絶対値を高速に比較できるよう、IEEE 標準は指数部に、
（2 の何乗かを示す）
「冪指数」に
「バイアス定数」を足した値を格納するよう指定している。単精度で使われるバイアス定数は
127、倍精度で使われるバイアス定数は1023 だ8。たとえば単精度で2 の3 乗を表現する指数
の場合、指数部には130 という値が格納され、2 の−5 乗を表現する指数なら、指数部に122
が格納される。
浮動小数点の例として、6.5 という値が、どのように表現されるかを見ておこう。6 は2 進
8　バイアス定数は、常に2k−1 −1 である（k は、指数部のビット数）
。訳注：このようにバイアスを加え
ることを、日本語では「ゲタをはかせる」とも言う。
hi.0412.ko.2002@gmail.com
54
第3 章
データとプログラムの表現　
法で110、.5 は2 進法の小数点に続く1 ビットだから、110.1 になる（2 進法で）
。2 進法の
科学的表記法を使い、値を正規化すれば、6.5 は、次のように表現できる。
1.101 × 22
同じ値をIEEE の単精度浮動小数点値として表すなら、サインビットは0、指数部はバイア
スの127 を足して129 になる。129 の2 進数は、
10000001
仮数部の値を理解するには、先行する1 が格納されないことを思い出そう。だから1101 の
後にゼロの列が続くのではなく、仮数部は次のように格納される。
10100000000000000000000
これらを組み合わせた、6.5 のIEEE 単精度浮動小数点表現を、図3‒7 に示す。
S 指数部
（ビッ
ト23から30）
 
仮数部
（ビッ
ト0から22）
0 
1 0 0 0 0 0 0 1 
1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
図3‒7：10 進の6.5 という値を、IEEE 単精度浮動小数点定数として表現
3.18 　特殊な値
たいていの浮動小数点数表現と同じく、IEEE 標準でも最初のビットは暗示されるだけだ。つ
まり先行するはずの
「暗黙の1 ビット」
が、仮数部に格納されない。もちろん、先行する1 ビッ
トの想定を厳密に強制する表現は使えない。その表現ではゼロの値を格納できないからだ。ゼ
ロを扱うために、IEEE 標準は特例を設けている。すべてのビットがゼロならば、暗黙の想定は
無視され、格納された値はゼロとみなされるのだ。
IEEE 標準には、ほかにも正の無限大と負の無限大のために、2 つの特殊な値が予約されてい
る。それらは、指数部のビットがすべて1、仮数部のビットがすべて0 の値だ。なぜ無限大の
値が重要かといえば、ある種のデジタルシステムには「算術オーバーフロー」のようなエラー
を処理する機能がないので、そのようなシステムでもソフトウェアが浮動小数点演算の失敗を
検知できるように、値を予約しておくことが重要なのだ。
3.19 　BCD 表現
ほとんどのコンピュータは整数と浮動小数点数を2 進法で表現している。根底にあるハード
ウェアがデジタル論理を使っているから、バイナリの0 と1 がハードウェアに直接対応する。
その結果、ハードウェアが行う2 進演算の効率は高く、ビットのすべての組み合わせが有効で
ある。ただし、2 進法の表現を使うことには不都合な点も2 つある。第1 に、値の範囲が10 の
hi.0412.ko.2002@gmail.com
　3.19
BCD 表現
55
冪乗ではなく2 の冪乗である（たとえば符号なし32bit 整数の範囲はゼロから4,294,967,295
まで）
。第2 に、浮動小数点値を丸めた値は、10 進ではなく2 進の分数になる。
2 進の分数を使うと、いくつか意図しない結果が生じてしまうし、あらゆる計算に使えるも
のではない。たとえばドルとセントを格納する銀行口座を考えてみよう。普通は、1 セントを
1 ドルの100 分の1 として表現する。だから、5.23 と書けば、5 ドルと23 セントを意味する。
ところが驚くべきことに、100 分の1（つまり1 セント）を2 進の浮動小数点数で正確に表現
することは不可能で、2 進法では循環小数が生じる。したがって、もし金額の計算に2 進の浮
動小数点演算を使ったら、1 セントが丸められて、正確な額が出なくなる。科学的な感覚で言
えば、その誤差は、ある領域内に限定されている。しかし人間は、銀行が正確な記録を取り続
けることを要求する。銀行預金で、ほとんどの桁が維持されても、何セントか失われれば、人
間は立腹するのだ。
銀行など、10 進の計算が必要なケースには、
「BCD」
（Binary Coded Decimal：2 進化10
進数）の表現が使われる。ある種のコンピュータ（有名なのはIBM のメインフレーム）には、
BCD 演算をサポートするためのハードウェアがある。他のコンピュータでは、BCD 値に対す
る演算を、すべてソフトウェアが実行する。
BCD でもさまざまなフォーマットが使われてきたが、本質は常に同じで、値は10 進の桁を
並べて表現される。もっとも単純な形式は、
「文字列」によるもので、個々のバイトに「1 桁の
数字を表す1 文字」が含まれる。けれども文字列では計算の効率が悪く、不要な空間を取られ
る。一例として、もしコンピュータがASCII の文字集合を使うとしたら、123456 という1 個
の整数が、次の値を持つ6 バイトに格納される9。
0x31 0x32 0x33 0x34 0x35 0x36
文字形式を使うとしたら、それぞれの文字（たとえば0x31）を、等価な2 進の値（たとえば
0x01）に変換しなければ算術演算を行えない。そればかりか、いったん演算を実行したら、結
果を2 進から文字形式の各桁に変換する必要がある。だから計算効率を高めるために、現行の
BCD システムでは各桁の数字を文字ではなく2 進数で表現する。つまり、123456 は次のよう
に表現できる。
0x01 0x02 0x03 0x04 0x05 0x06
表現を2 進化すれば、
計算が高速になるという長所が得られるが、
短所もある。BCD の値は、
いったん文字に変換してからでなければ表示も印字もできないのだ。しかし一般に、算術演算
のほうが入出力より頻繁に行われるので、2 進化によって全体の性能が向上すると考えられる。
9　この例ではASCII を使っているが、とくにBCD を扱うIBM 社のコンピュータは、EBCDIC 文字集合
を使う。
hi.0412.ko.2002@gmail.com
56
第3 章
データとプログラムの表現　
3.20 　BCD 表現の符号と小数とパック
前節で述べたBCD の説明は、商用システムに見られる詳細の多くを略していた。たとえば
実装によってBCD の値の大きさに制限がかかるかもしれない。小数を扱うBCD 表現は、明
示的な小数点を含むか、あるいは小数点の位置を指定しなければならない。それだけでなく、
符号付きの演算を扱うために、BCD 表現には符号も含めなければならない。興味深いことに、
もっとも広く使われているBCD 規約の1 つは、符号バイトをBCD 文字列の右端に置くこと
を定めている。だから−123456 は、次のシーケンスで表現されるかもしれない。
0x01 0x02 0x03 0x04 0x05 0x06 0x2D
ここで0x2D は、マイナス記号を表す値である。符号を右に置くフォーマットには、演算を
実行するときにスキャンを省略できるというメリットがある。そのシーケンスでは、最後のバ
イトを除く全部のバイトが、それぞれ10 進の桁に対応する。
BCD のエンコードで使われる最後の詳細は、各桁に1 バイト使うのでは効率が不十分だとい
う指摘から生まれたものだ。各桁に4 ビットしか必要ないのだから、8 ビットのバイトに、そ
れぞれ1 桁を入れるのでは、それぞれのバイトの半分が無駄になる。BCD に必要なストレー
ジ空間を節約するために、各桁が1 個の「ニブル」
（4 ビット）を占めるように圧縮された表現
が使われる。BCD の圧縮バージョンでは、整数−123456 を4 バイトで表現できる。
0x01 0x23 0x45 0x6D
ここでは、最後のニブルに入ってる0xD という値が、負の数であることを示している10。
3.21 　データの集まり
これまでは、話題を文字、整数、浮動小数点数などといった個々のデータ項目に限って、それ
らの表現を見てきた。しかし、ほとんどのプログラミング言語でプログラマは、配列、レコー
ド、構造体などを指定できる。つまり、複数のデータ項目を含む「集合体」としてのデータ構造
を使えるのだ。そういう値は、どう格納されるのだろう。一般に、集合体の値は連続するバイ
ト並びを占める。だから8 ビットのバイトを使うコンピュータでは、3 個の16 ビット整数で
構成されるデータ集合体が、図3‒8 に示すように、6 個の連続するバイトを占めることになる。
後述するように、ある種のメモリシステムは、任意のデータ型が連続するのを容認しない。
だからデータ集合体については、メモリアーキテクチャを論じるときに再考しよう。
10　BCD 演算を援助するために、x86 アーキテクチャには、4 ビットの加算がオーバーフローするかどうか
を示す条件コードのビットがある。
hi.0412.ko.2002@gmail.com
　3.22
プログラムの表現
57
整数 #1 
整数 #2 
整数 #3
0 
1 
2 
3 
4 
5
図3‒8：3 個の16 ビット整数で構成されるデータ集合体が、メモリでは0 から5 の番号を持つ連続した6
バイトに置かれる
3.22 　プログラムの表現
現代のコンピュータは、データだけでなくプログラムもメモリに置くので、
「ストアドプログ
ラム型」に分類される。プログラムの表現とストレージについては次の章で論じよう。それに
はコンピュータが理解する命令の構造や、それをメモリに保存する方法も含まれる。いまは、
どのコンピュータにも特有な一群の演算と、それを保存するフォーマットが定義されているこ
とを知っていれば十分だ。たとえば、ある種のコンピュータでは、どの命令も同じサイズだが、
他のコンピュータでは命令のサイズが統一されていない。後述するが、典型的なコンピュータ
では1 個の命令が複数バイトを占めるのだ。したがって、コンピュータがデータの値に使う
ビットとバイトの番号付けが、命令にも適用される。
3.23 　まとめ
コンピュータの根底にあるデジタルハードウェアが表現できる値は、論理値0 と論理値1 の
2 つだけだ。われわれは、この2 つの値がビットを定義すると考えて、データとプログラムを
表現するのにビットを利用する。どのコンピュータでもバイトのサイズが定義される。現在の
システムは、ほとんどが1 バイトに8 ビットを使っている。
1 群のビットによって、コンピュータの文字集合にある1 文字も、符号なし整数も、単精度
または倍精度の浮動小数点値も、そしてプログラムも、表現することが可能だ。コストを抑え
ながら、ハードウェアの柔軟性と速度を最大化するため、表現方法が注意深く選択される。符
号付き整数で2 の補数表現が一般的なのは、2 の補数を使う整数も符号なし整数も、どちらで
も演算できるようなハードウェアを構築できるからだ。10 進の計算が必要なケースで、コン
ピュータはBCD の値を使う。この表現では、10 進の個々の桁をビット列で指定する。
ANSI やIEEE のような団体が作ってきた標準により、別の会社で製造されたハードウェア
が相手でも、データの相互運用と交換が可能になっている。
練習問題
3.1
k ビットの組み合わせで2k 種類の値を表現できることを、数学的に証明しましょう。
ヒント：ビット数k に関する帰納法を使います。
hi.0412.ko.2002@gmail.com
58
第3 章
データとプログラムの表現　
3.2
次に示す2 進数の並びは、16 進では何の値ですか?
1101 1110 1010 1101 1011 1110 1110 1111
3.3
実行に使われるコンピュータが、整数の表現にビッグエンディアンを使うのか、リト
ルエンディアンを使うのかを判定するコンピュータプログラムを書きましょう。
3.4
ある整数のビット並びを0 と1 で表示するコンピュータプログラムを書きましょう。
各ビットの間に1 個の空白を入れ、さらに4 ビットごとに1 個の空白を加えます。
3.5
実行に使われるコンピュータが、符号付き整数の表現に1 の補数を使うのか、2 の補
数を使うのか、あるいは（もしあれば）他の表現を使うのかを判定するコンピュータ
プログラムを書きましょう。
3.6
実行に使われるコンピュータが、文字集合にASCII を使うのか、それともEBCDIC
を使うのかを判定するコンピュータプログラムを書きましょう。
3.7
一群の整数を入力として受け取り、それぞれの整数について、
「1 の補数」と「2 の
補数」と「サインと絶対値」による3 種類の表現を表示するコンピュータプログラム
を書きましょう。
3.8
8 ビットで可能な2 進数のすべてと、それぞれの「2 の補数」表現を表示する、C の
プログラムを書きましょう。
3.9
最大の正の整数に1 を足し、その結果を使って、コンピュータが2 の補数による演
算を実装しているかどうかを判定する、コンピュータプログラムを書きましょう。
3.10
1 バイトの値を16 進表記で表示するコンピュータプログラムを書き、そのプログ
ラムをバイトの配列に適用してみましょう。ただし出力を読みやすくするため、4 バ
イトごとに空白を加えること。
3.11
前項で作った16 進ダンプのプログラムを拡張して、印字可能なキャラクタについ
ては文字表現も表示するようにしましょう。印字可能な表現を持たないキャラクタに
ついては、代わりに1 個のピリオドを出すようにしてください。
3.12
2 つの32 ビット符号なし整数の和を、プログラマが計算した結果が、どちらか一
方の値よりも小さくなってしまいました。なぜでしょうか?
3.13
仮に、32 ビットの演算しか実行できないハードウェアを持つコンピュータを与えら
れ、64 ビットの和算と減算を行う関数を作るように頼まれたと仮定します。32 ビッ
トのハードウェアで、64 ビットの計算を行うことは、どうすれば可能でしょうか（問
題を簡略化するため、答えを符号なし演算に限定します）
。
3.14
プログラミング言語C では、プログラマが定数を指定するのに、10 進数だけでな
く、2 進数も、16 進数も、8 進数も使えます。それを利用して定数0、5、65、128、
−1、−256 を、10 進、2 進、16 進、8 進で宣言し、printf() を使って値が正しい
ことを確認するプログラムを書きましょう。もっとも容易に表現できるのは、どれで
すか?
3.15
本文で解説したのと同様なBCD の書式を作成し、その書式を使って任意の長さの
hi.0412.ko.2002@gmail.com
　3.23
まとめ
59
整数2 つを加算するコンピュータプログラムを書きましょう。
3.16
前項のプログラムを、乗算を含むように拡張しましょう。
3.17
金融業界では「銀行丸めアルゴリズム」
（”bankers” rounding algorithm）を使い
ます。まず、このアルゴリズムについて調べ、次に10 進の演算によって、2 つの10
進数の和を計算するプログラムを実装しましょう。
「銀行丸め」と「四捨五入」の両方
を使ってみてください11。
11　訳注：ヒント　英文Wikipedia の項目”Rounding”で、
「銀行丸め」
（bankers’ rounding）という呼び名
は、”Round half to even”という項目に書かれている。ちなみに、C++にはround() とnearbyint() が
あり、C#ではRound() メソッドでmode パラメータを指定できる。
hi.0412.ko.2002@gmail.com
hi.0412.ko.2002@gmail.com
第2部
プロセッサ
計算を駆動するエンジン
hi.0412.ko.2002@gmail.com
hi.0412.ko.2002@gmail.com
第4 章
さまざまなプロセッサと計算エンジン
4.1 　はじめに
これまでの章で述べたのは、コンピュータシステムの構築に使う基本的な構成要素としての
デジタル論理回路と、文字、整数、浮動小数点数といったデータ型の表現だった。この章から
は、どのコンピュータシステムにもある3 つの主要な要素の1 つ、
「プロセッサ」を、詳しく
見ていこう。この章では全般的な概念を紹介し、さまざまなプロセッサを記述し、クロック周
期と処理速度との関係を論じる。次章では基本的な記述の続きとして、命令セット、アドレシ
ングモード、汎用CPU の機能を説明しよう。
4.2 　アーキテクチャ：2 つの基本アプローチ
コンピュータの歴史の初期に、新しい設計を実験するアーキテクトたちはハードウェアの構
成方法を考えていた。そこから2 つの基本アプローチが生まれ、それぞれ提案したグループを
示す名前が付いた。
•
ハーバード・アーキテクチャ
•
フォン・ノイマン・アーキテクチャ
この2 つは、ほとんど同じアイデアだが、プログラムとデータを保存しアクセスする方法に
違いがある。
hi.0412.ko.2002@gmail.com
64
第4 章
さまざまなプロセッサと計算エンジン　
4.3 　ハーバードとノイマンのアーキテクチャ
「ハーバード・アーキテクチャ」という用語は、プロセッサ、命令メモリ、データメモリ、
入出力機構という、4 つの主要コンポンツによるコンピュータ構成を意味する1。その構成を、
図4‒1 に示す。
コンピュータ
プロセッサ
命令メモリ
データメモリ
入出力機構
図4‒1：ハーバード・アーキテクチャは2 つのメモリを使い、片方にはプログラムを、もう片方にはデータ
を格納する
「フォン・ノイマン・アーキテクチャ」も、同じ基本コンポーネントを含むのだが、1 つの
メモリにプログラムとデータの両方を格納する2。図4‒2 に、そのアプローチを示す。
コンピュータ
プロセッサ
メモリ
入出力機構
図4‒2：フォン・ノイマン・アーキテクチャでは、プログラムとデータの両方を同じメモリに格納できる
1　このアプローチは、リレー式計算機のHarvard Mark I で最初に使われたので、この名前が付けられた。
2　このアークテクチャを最初に提案した数学者、John von Neumann の名を採った。
訳注：日本語Wikipedia の項目名は「ノイマン型」
。
hi.0412.ko.2002@gmail.com
　4.4
プロセッサの定義
65
ハーバード・アーキテクチャには、あるメモリユニットをプログラム格納用に最適化しつつ、
もう1 つのメモリユニットをデータ格納用に最適化できるという長所がある。そして主な短所
は、融通性の欠如に由来する。コンピュータを買うときには、命令メモリとデータメモリのサ
イズを、それぞれ選ばなければならない。いったんコンピュータを買った後で、命令メモリの
一部をデータ格納用に使ったり、データメモリの一部を命令格納に使ったりすることはできな
い。だから汎用コンピュータには好ましくないという評価が下ったが、いまでもハーバード・
アーキテクチャは、小規模な埋め込みシステムや、その他の特殊な設計には、ときどき使われ
ている。
ハーバード・アーキテクチャと違ってフォン・ノイマン・アーキテクチャは完全な融通性を提
供する。コンピュータの所有者は、どれだけのメモリを命令とデータに分配するかを、いつで
も変更できる。このアプローチの価値は非常に高いと実証され、広く採用されることになった。
プログラムとデータの両方に1 つのメモリを使う、
柔軟性の高いフォン・ノイマン・アー
キテクチャは、広く普及した。ほとんどすべてのコンピュータが、フォン・ノイマンの
アプローチにしたがっている。
フォン・ノイマン・アーキテクチャにしたがうコンピュータは、いわゆる「プログラム内蔵
式」
のアプローチを採用している。つまりプログラムがメモリに格納されるのだ。さらに、
より
多くの重要なプログラムを、他のデータ項目と同じように、メモリにロードすることも可能だ。
本書の残りのテキストでは、特記しない限り暗黙のうちにフォン・ノイマン・アーキテクチャ
を前提とする。主な例外は第6 章と第12 章にある。データ経路を説明する第6 章では、例と
して単純なハーバード・アーキテクチャを使う。キャッシングについて説明する第12 章では、
命令とデータに別々のキャッシュを使う理由を論じる。
4.4 　プロセッサの定義
今後この章では、ハーバードとフォン・ノイマンの、どちらのアーキテクチャにも存在する
「プロセッサ」という要素について考察する。まず用語の定義とプロセッサの分類を行ってか
ら、複雑なプロセッサを構成するコンポーネントを見ていこう。
プログラマは、一般的なコンピュータのことを考えて、
「プロセッサ」という用語を「CPU」
（Central Processing Unit）と同じ意味で使いがちだが、この言葉をコンピュータアーキテク
トが使うときは、もっと広い意味を持たせる。自動車のエンジンを制御するのに使われるプロ
セッサも、手に持って操作するリモコン装置に入っているプロセッサも、グラフィックス機器
で使われる専用のビデオプロセッサも、それに含まれるのだ。アーキテクトにとって「プロ
セッサ」とは、複数のステップからなる計算処理を実行できるデジタル機器のことだ。個々の
プロセッサは、完全なコンピュータではなくて、アーキテクトがコンピュータシステムの構築
に使うパーツの1 つにすぎない。だからプロセッサは、第2 章で見たようなブール論理回路の
hi.0412.ko.2002@gmail.com
66
第4 章
さまざまなプロセッサと計算エンジン　
組み合わせよりは計算能力が高いだろうが、大規模だったり高速だったりする必要はない。プ
ロセッサには、典型的なPC に入っている汎用CPU と比べたら、ずいぶん非力なものもある。
次の章では、もっと定義を明らかにするため、さまざまなプロセッサの性質を調べ、どのよう
に利用できるかを説明する。
4.5 　ロジックの柔軟性
プロセッサの機能は広範囲におよび、数多くのバリエーションが存在するから、ただ1 つの
記述によってプロセッサが持つ全部の属性をうまく捉えることはできない。むしろ多くの設計
を評価できるように、プロセッサを機能と目的によって、いくつかのカテゴリーに分類する必
要がある。たとえば次に示す4 つのカテゴリーはプロセッサを、新たな計算に対応させること
ができるかによって評価するものだ。柔軟性の低いものから順番に並べている。
•
固定ロジック
•
選択可能なロジック
•
パラメータ化されたロジック
•
プログラマブルなロジック
もっとも柔軟性が低い「固定ロジックのプロセッサ」は、ただ1 つのタスクを実行するもの
だ。重要なポイントとして、その処理を実行するのに必要な機能のすべてがプロセッサの作成
時に組み込まれ、根底にあるハードウェアを取り替えない限り機能を変更できない3。固定ロ
ジックのプロセッサは、たとえばsine(x) のような関数を計算するように設計したり、あるい
はビデオゲームに必要なグラフィック演算の1 つを実行できるように設計することが可能だ。
「選択可能なロジックのプロセッサ」は、固定ロジックのプロセッサよりも、少し柔軟性が高
い。ロジックが選択可能というのは、いくつもの関数について、実行に必要な機能がプロセッ
サに含まれているという意味だ。どの関数を実行させるかは、プロセッサの起動時に指定する。
ロジックを選択できるプロセッサは、たとえばsine(x) またはcosine(x) を計算するように
設計できるだろう。
「パラメータ化されたロジックのプロセッサ」は、さらに柔軟性が高い。これも決められた
1 個の関数を計算するだけだが、その計算を制御する一群のパラメータをプロセッサが受け取
る。たとえばハッシュ関数のh(x) を計算するパラメータ付きプロセッサを考えてみよう。こ
のハッシュ関数は、p とq という2 つの定数を受け取り、x にp を掛けてq で割った余り（剰
余）を計算することによって、x のハッシュを計算する。たとえば、もしp が167 で、q が163
3　根底にあるワイヤリング（配線）を変えない限り機能を変更できないハードウェアを、エンジニアは
「ハードワイヤド」
（hardwired）と形容する。
hi.0412.ko.2002@gmail.com
　4.6
階層構造と計算エンジン
67
ならば、h(26729) は、4463743 を163 で割った剰余、すなわち151 になる4。ハッシュ関数
用にパラメータを加えたプロセッサでは、起動するたびに定数p とq を変更できる。つまり入
力であるx の他に、プロセッサは演算を制御する2 つのパラメータ、p とq も受け取るのだ。
「プログラミングできるロジックのプロセッサ」は、もっとも柔軟性が高い。このプロセッサ
は、実行するステップのシーケンスを、起動するたびに変更できる。こういうプロセッサには、
実行すべきプログラムを渡すことが可能であり、そのプログラムはメモリに置くのが典型的だ。
4.6 　階層構造と計算エンジン
大規模なプロセッサ、たとえば最近の汎用CPU は、あまりにも複雑なので、
「1 個のユニッ
トとしてのプロセッサ全体」を理解できる人など、1 人もいない。この複雑さを解決するため、
コンピュータアーキテクトは階層的なアプローチを使う。つまりプロセッサを区分けした各部
を、それぞれ独立させ設計しテストした後で、結合して最終的な設計とするのだ。
大規模なプロセッサの独立した部分には、あまりに洗練されているので、それ自身が「プロ
セッサの定義」に適合するものがある。その部分だけでも複数のステップからなる計算を実行
できるのだ。たとえば、もしsine とcosine のための命令を持つ汎用CPU を構築するとした
ら、まず三角関数プロセッサを構築し、テストする。それから三角関数プロセッサを他の部分
と結合して、最終的なCPU にするのだ。
大規模で複雑なプロセッサの一部でありながら、独立して動作し計算を実行するような部分
を、どう呼べばよいだろうか。エンジニアは「計算エンジン」と呼ぶことが多い。この場合の
エンジンという言葉は、
「ユニット全体ほど強力ではないが、ある特定の役割を果たすには十分
な部品」という意味を持つのだ。たとえば図4‒3 は、いくつかのエンジンを含むCPU の例を
示している。
この図のCPU には、特殊用途の「グラフィックスエンジン」が含まれている。
「グラフィッ
クスアクセラレータ」とも呼ばれるこのエンジンが一般的な存在となったのは、ビデオゲーム
のソフトウェアが普及して、多くのコンピュータにグラフィックスを高速で駆動し表示するた
めのグラフィックスエンジンが必要になったからだ。グラフィックスエンジンには、表示した
図形を（たとえばジョイスティックの動きに対応して）動かすときに、その図形の表面を再描
画する機能などが含まれる。
図4‒3 に示したCPU には、他に「クエリーエンジン」も含まれている。クエリー（問い合わ
せ）エンジンと、それと密接な関係のある「パターンエンジン」は、どちらもデータベース用プ
ロセッサで使われる。クエリーエンジンは、高速でデータベースに含まれるレコードを調べ、
そのレコードがクエリーを満足させるかどうかを判断する。パターンエンジンはビット列を見
4　ハッシュは、しばしば文字列に適用される。この例で言えば、26729 という数は、文字列”hi”にある2
文字を1 個の符号なしの短い整数型（unsigned short integer）として扱うときの10 進値である。
hi.0412.ko.2002@gmail.com
68
第4 章
さまざまなプロセッサと計算エンジン　
CPU
三角関数
エンジン
グラフィ
ッ
クス
エンジン
その他の
コンポーネン
ト
クエリー
エンジン
算術
エンジン
図4‒3：複数のコンポーネントを含むCPU の例。図の中央にある双方向の矢印は、それらのコンポーネン
トを連携させる中心的な相互接続の機構を示す
て、それが指定のパターンとマッチするかを調べる（たとえば、ドキュメントに特定のワード
が含まれているかどうかをテストするために）
。どのタスクでも十分にこなせるだけの処理能
力をCPU 自身が持っているのだが、専用プロセッサなら同じタスクを、ずっと高速に実行で
きるのだ。
4.7 　一般的なプロセッサの構造
前節の記述にあった架空のCPU は多くのエンジンを含んでいたが、ほとんどのプロセッサ
は、そうではない。そこで2 つの疑問が生じるだろう。第1 に、普通のプロセッサには、どん
なエンジンが入っているのだろうか。そして第2 に、それらのエンジンは、どのように相互接
続されるのだろうか。この節では、以上の質問に広い意味で答え、後の節で詳細を加えよう。
実際のプロセッサは、多くのコンポーネントを含んでいて相互接続は複雑だが、概念的には、
プロセッサは次の5 つのユニットを持つと考えられる。
•
コントローラ
•
ALU（算術論理演算装置）
•
データのローカルストレージ：レジスタ
•
内部の相互接続
•
外部インターフェイス：入出力バス
図4‒4 に、そのコンセプトを示す。
hi.0412.ko.2002@gmail.com
　4.7
一般的なプロセッサの構造
69
内部の相互接続
ALU
コン
トローラ
ローカル
ス
トレージ
外部インターフェイス
外部との接続
図4‒4：一般的なプロセッサに見られる5 つの主要なユニット。外部インターフェイスは、そのコンピュー
タシステムの残りの部分に接続される
「コントローラ」は、プロセッサの中心的な存在だ。コントローラのハードウェアは、プロ
グラムの実行に全体的な責任を持つ。つまり、コントローラはプログラムをステップごとに実
行して、他のすべてのハードウェアユニットの動作を協調しながら、指定の処理を行っていく。
「算術論理演算装置」とも呼ばれる「ALU」
（Arithmetic Logic Unit）は、プロセッサの主
な計算エンジンと考えることができる。このユニットは、整数の算術演算や、ビット列に対す
る演算（左シフト、右シフトなど）
、論理演算（ブール演算のAND、OR、XOR、NOT など）
、
その他すべての計算処理を実行する。ただしALU は、複数のステップを実行することも、動
作を始めることもしない。ALU は1 度に1 個の演算を実行するだけであり、オペランドの値
で実際どんな演算を行うかを指定する役割は、コントローラに任せている。
「データのローカルストレージ」は、一般にハードウェアによる「レジスタ」の形をとる。プ
ロセッサには、少なくとも何らかのローカルなストレージ（保存装置）が必要で、そこに算術
演算のオペランドや結果といったデータの値を入れる。後述するように、値はレジスタにロー
ドしなければ計算に使うことができない。
プロセッサには、内部のハードウェアユニット間で値を受け渡すためのハードウェア機構と
して、
「内部の相互接続」が必要だ。たとえばレジスタからALU にデータを渡すにも、ALU か
らレジスタに結果を渡すにも、内部相互接続が使われる。アーキテクトは、内部相互接続の記
述に「データパス」という用語を使うことがある。
「外部インターフェイス」は、プロセッサと、そのコンピュータシステムの残りの部分との
間で行われるコミュニケーションのすべてを扱うユニットだ。具体的に外部インターフェイス
が管理するのは、プロセッサと、外部メモリやI/O デバイスとの間の通信である。
hi.0412.ko.2002@gmail.com
70
第4 章
さまざまなプロセッサと計算エンジン　
4.8 　各種のプロセッサと、その役割
プロセッサの守備範囲を理解することは、ハードウェア設計と無縁な人にとって、特に難し
いことだろう。プロセッサは、実にさまざまな役割に使われるからだ。けれども、各種のハー
ドウェア機器でプロセッサがどのように使われ、それぞれの役割でプロセッサがどんな機能を
果たすのかを考えれば、わかりやすくなるだろう。次に示す4 つの例を見ていく。
•
コプロセッサ
•
マイクロコントローラ
•
埋め込みシステムのプロセッサ
•
汎用プロセッサ
「コプロセッサ」は、他のプロセッサと共同して、その制御のもとで動く。通常コプロセッサ
と呼ばれるのは、あるタスクを高速で実行する特殊用途のプロセッサである。たとえば一部の
プロセッサには、
「数値演算コプロセッサ」とか「浮動小数点演算アクセラレータ」などと呼ば
れるコプロセッサを使って算術演算を加速するものがある。浮動小数点の計算が発生すると、
CPU が自動的に必要な値をコプロセッサに渡し、結果を受け取ってから実行を続けるのだ。実
行中のプログラムのなかで、どこにCPU によって直接実行される処理があり、どこにコプロ
セッサによって実行される処理があるのか、プログラム自身が知らないようなアーキテクチャ
ならば、コプロセッサの処理はソフトウェアから見て「トランスペアレント」
（透明）である。
典型的なコプロセッサは、固定あるいは選択可能なロジックを使う。つまり、コプロセッサが
実行できる機能は、そのコプロセッサの設計時に決まる。
「マイクロコントローラ」は、ある物理的なシステムの制御だけを行う、プログラマブルなプ
ロセッサだ。マイクロコントローラは、たとえば現代の自動車エンジン、飛行機の着陸装置、食
料品店の自動ドアなどといった物理的なシステムを動かす。多くの場合、マイクロコントロー
ラが実行するのは、あまり多くの計算を必要としない単純な機能である。つまりマイクロコン
トローラの仕事は、センサーの出力をチェックしてデバイスに制御信号を送ったりする程度の
ことなのだ。リスト4‒1 に、典型的なマイクロコントローラが実行するようにプログラミング
される処理ステップの例を示す。
リスト4‒1：マイクロコントローラが実行するステップの例。ほとんどの場合、マイクロコントローラは、
単純な制御の仕事に専念する
永遠に繰り返す{
センサーの作動を待つ
ドア用モーターの電源を入れる
ドアが開いたことを示す信号を待つ
センサーのリセットを待つ
10 秒の遅延を入れる
hi.0412.ko.2002@gmail.com
　4.9
プロセッサ製造技術
71
ドア用モーターの電源を切る
}
「埋め込みシステム」のプロセッサは、無線ルータやスマートフォンのような洗練された電
子機器を動かす。埋め込みシステムに使われるプロセッサは、マイクロプロセッサとして使わ
れるプロセッサより強力なのが普通であり、しばしば通信プロトコルスタックを実行する。た
だし、そのプロセッサは、より汎用性の高いCPU に見られる機能を、すべて含んではいない
かもしれない。
「汎用プロセッサ」は、おなじみなものだから、あまり説明をする必要がないだろう。たと
えばPC で使われているCPU は、汎用プロセッサである。
4.9 　プロセッサ製造技術
プロセッサは、どうやって作るのだろうか。1960 年代にはプロセッサをデジタル論理回路か
ら作っていた。個々のゲートを回路基板上で接続し、そのボードをシャシーに差し込んで、コ
ンピュータを作っていたのだ。1970 年代には大規模集積回路のテクノロジーが到来して、もっ
とも小さく能力も弱い（マイクロコントローラで使われるような）プロセッサを、1 個の集積
回路上に実装することができた。それからさらに集積回路のテクノロジーが進化し、チップに
載せられるトランジスタの数が増えたので、1 個のチップに、より強力なプロセッサを搭載す
ることが可能になった。現在では、もっとも強力な汎用プロセッサの多くが、ただ1 つの集積
回路で構成されている。
4.10 　プログラム内蔵方式
プロセッサは、複数のステップにわたる計算を実行すると述べた。一部のプロセッサでは一
連のステップがハードウェアに組み込まれるが、ほとんどのプロセッサでは、ステップが組み
込みではなく、
「プログラマブル」であって、要するに「プログラミング」という機構に頼るの
だ。プロセッサからアクセスできる場所に、実行すべきステップのシーケンスを書いたプログ
ラムを置いておく。プロセッサは、そのプログラムをアクセスして、指定されているステップ
にしたがう。
プログラマが親しんでいる一般的なコンピュータシステムでは、プログラムの置き場所とし
てメインメモリが使われる。プログラムは、
ユーザーがアプリケーションを実行するたびに、
メ
モリにロードされる。プログラムをメインメモリに置くことの主な利点は、プログラムを変更
できることにある。変更後にユーザーがプログラムを走らせるときには、更新されたバージョ
ンが使われる。
このような、われわれにとって親しみのあるプログラミングの概念は、汎用プロセッサには
適切だが、他の種類のプロセッサが使っている機構では変更が容易ではない。たとえばマイク
hi.0412.ko.2002@gmail.com
72
第4 章
さまざまなプロセッサと計算エンジン　
ロコントローラのプログラムは、たいがいROM と呼ばれるハードウェアの中にある。ROM は
「Read Only Memory」
（読み出し専用メモリ）の略称だ5。実際、プログラムを含むROM は、
そのプログラムを実行するマイクロプロセッサと同じ集積回路の中にあるかもしれない。たと
えば自動車で使われるマイクロコントローラは、そのマイクロコントローラが実行するプログ
ラムとともに、1 個の集積回路に置かれるかもしれない。
プログラミングという言葉の意味は広い。
コンピュータアーキテクトが、あるプロセッサを「プログラマブル」として分類するの
は、そのプロセッサと、実行されるプログラムとが、たとえ詳細なレベルでも分離して
いる場合だ。しかしユーザーから見れば、そのプログラムとプロセッサは一体化されて
いて、プロセッサを置き換えない限りプログラムを変更することは不可能かもしれない。
4.11 　フェッチ‒ 実行サイクル
プログラマブルなプロセッサでは、どうやってプログラムをアクセスし、そのステップを実
行するのだろうか。基本的なアイデアは、第6 章で解説する「データパス」
（データの経路）で
ある。詳細はプロセッサによって異なるが、プログラミング可能なプロセッサは、どれも同じ
基本的なパラダイムにしたがっている。その根底にある機構は、
「フェッチ‒ 実行サイクル」
（fetch-execute cycle）と呼ばれるものだ6。
フェッチ‒ 実行サイクルを実装するために、プロセッサは「命令ポインタ」を持っている。
このポインタは、ステップを順に実行するために、メモリ内のプログラムを自動的に辿って行
く。これによってプログラマブルなプロセッサは、
「フェッチ」と「実行」という2 つの機能を
繰り返し実行するのだ。アルゴリズム4‒1 に、この2 つの基本的なステップを示す7。
アルゴリズム4‒1：フェッチ‒ 実行サイクルの、2 つの基本ステップ
永遠に繰り返す{
フェッチ：プログラムの次のステップを、プログラムが置かれている場所から読み出す
実行：プログラムの、そのステップを実行する
}
重要なポイントを指摘しておきたい。
プログラマブルなプロセッサは、どれも何らかのレベルで、フェッチ‒ 実行サイクルを
実装している。
5　メモリについては後の章で詳しく述べよう。
6　訳注：この場合は、プロセッサがプログラムのステップを1 つメモリから取ってくるのがフェッチだ。
7　ここで示すアルゴリズムは単純化されている。アルゴリズムを拡張してデバイス割り込みを扱えるよう
にする方法は、入出力を論じるときに見よう。
hi.0412.ko.2002@gmail.com
　4.12
プログラムの変換
73
ここで、いくつも疑問が出てくる。プログラムは、メモリ上でどのように表現されるのか。
その表現は、どうやって作られるのか。プロセッサは、プログラムの次のステップを、どうやっ
て識別するのか。フェッチ‒ 実行サイクルの実行段階で、いったい何の演算を実行できるのか。
プロセッサは、それぞれの演算を、どのように実行するのか。しかし、これらの質問に対する答
えは次の章で詳しく述べることにして、この章の残りの部分では、次の3 つの質問に話を絞り
たい。プロセッサは、どのくらい速く動作するのか。プロセッサはプログラムの最初のステッ
プを、どうやって始めるのか。プロセッサがプログラムの終わりに到達したら何が起きるのか。
4.12 　プログラムの変換
プログラマにとって大切な疑問の1 つは、プログラムをプロセッサが期待する形式に変換す
る方法だ。プログラマは、コンピュータプログラムを作るのに「高水準言語」を使う。それに
よってプログラマは「ソースコード」を書く。プログラマは、ツールを使って、ソースコード
をプロセッサが期待する表現に変換する。
プログラマが呼び出すツールは1 個だが（たとえばgcc）
、変換の実行には複数のステップを
要する。まず「プリプロセッサ」が、前処理としてマクロを展開し、ソースプログラムの変更
版を作る。前処理を終えたソースコードが、
「コンパイラ」の入力になり、コンパイラは、その
プログラムをアセンブリ言語に変換する。それでプロセッサが必要とする形式に近づくが、ア
センブリ言語は、まだ人間が読めるものだ。
「アセンブラ」がアセンブリ言語のプログラムを、
リロケータブルな（再配置可能な）オブジェクトプログラムに変換する。そのプログラムは、
バイナリコードと外部ライブラリ関数への参照で構成される。
「リンカ」が、そのリロケータブ
ルオブジェクトコードを処理して、外部関数の参照を、その関数のコードで置き換える。その
ためにリンカは、関数名を抽出し、その関数のバイナリコードをライブラリから探す。図4‒5
ソースコー
ド
プリプロセッサ
前処理済みの
ソースコー
ド
コンパイラ
アセンブリ
コー
ド
アセンブラ
リロケータブルな
オブジェク
トコー
ド
リンカ
実行可能な
オブジェク
トコー
ド
ライブラリ関数の
オブジェク
トコー
ド
図4‒5：ソースプログラムを、プロセッサが使うバイナリ表現のオブジェクトコードに変換するステップ
hi.0412.ko.2002@gmail.com
74
第4 章
さまざまなプロセッサと計算エンジン　
に、この変換のステップと、各ステップを実行するツールを示す。
4.13 　クロック周期と命令実行速度
プロセッサについての主な疑問の1 つは、スピードに関するものだ。フェッチ‒ 実行サイク
ルは、どれほど速く動作するのか。その答えは、プロセッサと、プログラムをストアするテク
ノロジーと、個々の命令を実行するのに必要な時間とに依存する。物理的な装置（たとえば電
動のドア）を動かすためにマイクロコントローラとして使われるプロセッサなら、比較的低速
でかまわない。1/10 秒に満たない応答速度であれば人間には高速と感じられるからだ。その一
方で、最高速のコンピュータに使われるプロセッサでは性能の最大化が目標となるから、可能
な限り速くしなければならない。
第2 章「デジタル論理回路の基礎」で見たように、ほとんどのプロセッサは、根底にあるデ
ジタルロジックを動作させる周期の制御にクロックを使う。コンピュータを購入した経験のあ
る人なら誰でも知っているように、セールス担当者は顧客にクロックの速い製品を売りつける
ため、クロック周期が高ければ性能も高いのだという論法を使う。たしかにクロックが速けれ
ば処理速度も速いのが普通だが、重要なポイントとして、クロックの周期がフェッチ‒ 命令サ
イクルが進行する周期になるわけではない。具体的に言うと、ほとんどのシステムで、サイク
ルの実行に必要な時間は、実行される命令に依存する。後で見るように、メモリアクセスや入
出力を伴う演算には、そうではない演算よりも、ずっと多くの時間が（つまり、より多くのク
ロック周期が）必要だ。必要な時間の違いは、基本的な算術演算にもある。整数の乗算や除算
は、整数の加算や減算よりも時間がかかる。浮動小数点数の計算は、とくにコストが高い。浮
動小数点演算には、同様な整数演算よりも多くのクロックサイクルが必要なのが普通だ。とく
に浮動小数点値の乗算や除算はコストが高い。浮動小数点数の除算は、整数の加算と比べて、
必要なクロックサイクル数が桁違いに多いかもしれない。
いまのところは、次の原則を覚えておけば十分だ。
フェッチ‒ 実行サイクルは、一定のレートで進行しないかもしれない。なぜなら、命令
の実行にかかる時間が、実行する処理の内容に依存するからだ。乗算のような処理は、
加算のような処理よりも、多くの時間が必要だ。
4.14 　始動と停止の制御
これまでフェッチ‒ 実行サイクルを実行するプロセッサについて詳細に触れずに論じてきた
が、ここで2 つの基本的な質問に答えよう。つまり、どうすればプロセッサはフェッチ‒ 実行
サイクルを開始するのか。そして、プロセッサがプログラムの最後のステップを実行した後は、
どうなるのか。
プログラム終了の問題は、わかりやすい。プロセッサは停止するように設計されていない。
hi.0412.ko.2002@gmail.com
　4.15
フェッチ‒ 実行サイクルを開始する
75
フェッチ‒ 実行サイクルは無限に続くのだ。もちろんプロセッサを永続的に止めることは可能
だが、そのためのシーケンスは、コンピュータの電源を落とす目的でしか使われない。通常運
転では、プロセッサは命令を1 つずつ次々に実行し続ける。
場合によって、プログラムが遅延のためにループを使うことはある。たとえばマイクロコン
トローラは、プログラムを進行させる前に満たすべき外部条件をセンサーが示すのを待つ必要
があるかもしれない。その場合もプロセッサは、センサーを待つ間ただ停止するのではなく、
プログラムに含まれているループのなかで、センサーを繰り返しチェックする。だからハード
ウェアの視点から見れば、フェッチ‒ 実行サイクルは継続する。
フェッチ‒ 実行サイクルが無限に続くという認識は、プログラミングに直接的な影響を与え
る。ソフトウェアは、プロセッサが次に実行すべきステップを常に準備しなければならない。
物理的な装置を制御するマイクロコントローラのような専用システムの場合、プログラムは永
久ループを構成する。つまりプログラムの最後のステップを終えたら、プロセッサは最初のス
テップから実行を再開する。汎用プロセッサの場合は、必ずオペレーティングシステム（OS）
が存在する。OS が、まずアプリケーションをメモリにロードし、それからプロセッサに、そ
のアプリケーションを実行させる。フェッチ‒ 実行サイクルを継続させるため、OS は、アプ
リケーションが終了したときに制御を取り戻す必要がある。ほかのアプリケーションが実行さ
れないとき、OS はループに入って、
（タッチスクリーン、キーボード、マウスなどからの）入
力を待つ。
プロセッサはフェッチ‒ 実行サイクルを無限に実行するので、次に実行すべきステップ
が必ず存在するようにシステムを設計する必要がある。専用システムの場合、同じプロ
グラムを繰り返し実行する。汎用システムの場合、アプリケーションを実行しないとき
はOS を走らせる。
4.15 　フェッチ‒ 実行サイクルを開始する
プロセッサのフェッチ‒ 実行サイクルは、どうすれば始まるのだろうか。その答えは、根底
にあるハードウェアに依存するので単純ではない。たとえば一部のプロセッサにはハードウェ
アリセットがある。そういうプロセッサでは、すべてのシステムコンポーネントの実行準備が
整うまでリセット線に電圧をかけておくように、エンジニアが回路を組んでおくだろう。リ
セット線の電圧が開放されると、プロセッサは、ある固定の位置からプログラムの実行を開始
する。ある種のプロセッサは、リセットされたら、メモリのゼロ番地からプログラムの実行を
開始する。そういうシステムでは、プロセッサが実行を開始する前に有効なプログラムがゼロ
番地に置かれることを、設計者が保証しなければならない。
プロセッサを始動するステップは「ブートストラップ」と呼ばれる。埋め込み環境では、実
行すべきプログラムが「ROM」にある。一般的なコンピュータでは、ハードウェアが（あるい
はブートストラップローダが）ディスクなどの入出力装置からOS のコピーを読み込み、その
hi.0412.ko.2002@gmail.com
76
第4 章
さまざまなプロセッサと計算エンジン　
コピーをメモリに置いてからプロセッサを走らせる。どちらにしても、ブートストラップには
ハードウェアの援助が必要で、その理由はプロセッサにフェッチ‒ 実行サイクルの開始信号を
渡さなければならないからだ。
多くの装置には「ソフトパワースイッチ」がある。その場合、パワースイッチが実際に電源
のON/OFF を行うのではない。代わりに、スイッチはセンサーのような役割を持ち、プロセッ
サがスイッチの状態を調べて、現在の位置を判定する。しかしソフトスイッチを持つ装置の
ブートも、他の装置のブートと違わない。電源が最初に与えられるとき（たとえばバッテリー
を入れたとき）
、プロセッサは初期状態へとブートする。初期状態は、ソフトパワースイッチ
をチェックするループで構成される。いったんユーザーがソフトパワースイッチを押したら、
ハードウェアはブートストラップ処理を完了する。
4.16 　まとめ
プロセッサは複数のステップにわたる計算を実行できるデジタルデバイスだ。プロセッサの
ロジックは、固定される場合も、選択可能な場合も、パラメータ化される場合も、プログラマ
ブルな場合もある。
「エンジン」という言葉は、より複雑なプロセッサの一部であるプロセッサ
を意味する。
プロセッサはさまざまな役割に使われる。その種類は、コプロセッサ、マイクロコントロー
ラ、埋め込みプロセッサ、汎用プロセッサなどだ。初期のプロセッサは、ばらばらな部品を集め
たディスクリートロジックで作られたが、現在のプロセッサは1 個のVLSI として実装される。
プロセッサのハードウェアと、
そのプロセッサが実行するステップのシーケンスが、
何らかの
レベルでわかれていれば、そのプロセッサはプログラマブルと分類される。しかしエンドユー
ザーから見ると、プロセッサを交換することなくプログラムを変更することは不可能かもしれ
ない。プログラマブルなプロセッサは、どれもフェッチ‒ 実行サイクルにしたがう。1 サイク
ルに要する時間は、実行される演算の処理に依存する。フェッチ‒ 実行のサイクルは無限に続
くので、設計者はプログラムを、プロセッサが常に実行すべき命令を持つように構築しなけれ
ばならない。
プログラマが書くソースプログラムを、プロセッサが必要とするバイナリ表現に変換するた
めに、一群のソフトウェアプログラムが使われる。それにはプリプロセッサ、コンパイラ、ア
センブラ、リンカが含まれる。
練習問題
4.1
図4‒1 でも、図4‒2 でも、主なコンポーネントにストレージ（データ保存装置）が
含まれていません。フラッシュやディスクのようなストレージは、図のどこに該当す
るのでしょうか?
4.2
第2 章で記述した「SoC」のアプローチを考えてみましょう。プロセッサ、メモリ、
hi.0412.ko.2002@gmail.com
　4.16
まとめ
77
入出力機構のほかに、SoC に必要なのは何でしょうか。
4.3
初期のコンピュータについて、Wikipedia で調べましょう。Harvard Mark I コン
ピュータには、どれくらいのメモリがあり、何年に作られましたか? IBM の360/20
というコンピュータには、どれだけのメモリがあって、何年に作られたのですか?。
4.4
CPU の製造業者は、チップに搭載しているグラフィックスアクセラレータを誇らし
げに宣伝していますが、
一部のビデオゲームデザイナーは、
グラフィックスハードウェ
アをプロセッサと分離させる方法を選ぶそうです。そのように分離する動機を考え、
そのわけを説明してみましょう。
4.5
あるスマートフォンが、ハーバード・アーキテクチャを採用していると想像してくだ
さい。そのスマートフォンを買ったら、普通は設定しない何かを設定する必要がある
そうです。それは何でしょうか。
4.6
フォン・ノイマン・アーキテクチャが、ハーバード・アーキテクチャよりもハッカー
の攻撃に弱いといいますが、どんなところが弱いのでしょうか?
4.7
gcc をアクセスできますか? できれば、そのマニュアルページ（man）でコマンド行
引数の解説を読み、プリプロセッサだけを実行して、前処理を終えたプログラムを、
読むことのできるファイルに保存してみましょう。ソースプログラムの、何が変更さ
れるのでしょうか。
4.8
前項の課題を拡張して、コンパイラから出力されるアセンブリ言語を、読むことので
きるファイルに保存してみましょう。
4.9
整数の除算と浮動小数点数の除算とで、実行時間を比較するプログラムを書きましょ
う。そのプログラムをテストするには、それぞれの処理を10 万回ずつ実行して、実
行にかかった時間の差を見ます。
hi.0412.ko.2002@gmail.com
hi.0412.ko.2002@gmail.com
第5 章
プロセッサの種類と命令セット
5.1 　はじめに
前章で各種のプロセッサを紹介し、プログラマブルなプロセッサが使うフェッチ‒ 実行サイ
クルを説明した。この章ではプロセッサが実行できる演算の集合に話題を絞る。コンピュータ
アーキテクトたちが選んできた多彩なアプローチを説明し、それらの長所と短所を論じていこ
う。そして次章では、さらに話を進めて、プロセッサがオペランドをアクセスする各種の方法
を記述する。
5.2 　計算能力、利便性、コスト
プロセッサは、どのような演算集合を提供すべきだろうか。数学的な視点から言えば、実に
さまざまな計算モデルによって同等な計算能力を提供できる。そして理論的は、ある小さな基
本演算集合を備えているプロセッサであれば、計算可能な関数なら何でも計算するのに十分な
能力を持つ1。
プログラマは、たとえ本当に必要なのが最小限の演算集合だとしても、最小限では便利でも
実用的でもないことを知っている。だから演算集合は、単に機能を増やすためではなく利便性
を求めて設計される。たとえば割り算の商を求めるのに、引き算を繰り返して計算することは
可能だ。けれども減算の繰り返しを使って商を求めるプログラムは実行が遅い。だから、ほと
んどのプロセッサには、加算、減算、乗算、除算という基本演算を行うためのハードウェアが
含まれている。
コンピュータアーキテクトにとって、プロセッサが実行すべき演算集合には、その選択にト
1　数理的な意味で、計算可能な関数を何でも計算するには、
「1 を足す」と、
「1 を引く」と、
「値がゼロな
ら分岐する」という、たった3 種類の演算が必要なだけだ。
hi.0412.ko.2002@gmail.com
80
第5 章
プロセッサの種類と命令セット　
レードオフが存在する。たとえば乗算や除算などの算術演算を追加することで、一方ではプロ
グラマに利便性が提供される。しかし、その一方で、演算の種類を増やすたびにハードウェア
が追加され、プロセッサの設計が、さらに難しくなる。ハードウェアを追加すれば、チップサ
イズ、電力消費、放熱など、製造技術に関して考慮すべき事項も増える。このため、バッテリー
の電力を持たせるように設計されるスマートフォンのプロセッサは、強力なメインフレームコ
ンピュータで使われるプロセッサより、組み込まれる演算の数が少ないのが典型的である。
要するに、プロセッサの演算集合を検討するときは、その選択が複雑なトレードオフを反映
していることを、忘れてはいけない。
プロセッサが提供する演算集合には、ハードウェアのコスト、プログラマにとっての利
便性、電力消費など技術的な考慮事項のトレードオフが表れる。
5.3 　命令セットのアーキテクチャ
プログラマブルなプロセッサを設計するとき、アーキテクトは次の2 つについて決定的な判
断を下さなければならない。
•
命令セット：プロセッサが提供する演算の集合
•
命令の表現：個々の演算を表すフォーマット
われわれは「命令セット」という用語を、ハードウェアが認識する演算の集合という意味で
使い、それぞれの演算を「命令」と呼ぶ。そしてプロセッサは、フェッチ‒ 実行サイクルを繰
り返すたびに1 個の命令を「実行する」ものとする。
命令セットの定義は、命令群に関するすべての詳細を指定する。それには、プロセッサが命
令を実行するときに行う動作の正確な仕様が含まれる。だから命令セットでは、それぞれの命
令が演算に使う値と生成する結果が定義される。また、許容される値（たとえば除算命令では
除数がゼロではないことが要求される）や、エラーの状況（たとえば、もし加算の結果オーバー
フローが発生したら何が起きるか）も定義される。
「命令表現」あるいは「命令フォーマット」というのは、ハードウェアで命令に使われるバ
イナリ表現のことだ。命令のフォーマット（形式）が重要なのは、それによって決定的なイン
ターフェイスが定義されるからだ。それは、命令を生成してメモリに置くソフトウェアと、そ
の命令を実行するハードウェアとのインターフェイスである。ソフトウェア（コンパイラ、リ
ンカ、ローダ）は、プロセッサのハードウェアが期待する形式と正確に一致した命令フォーマッ
トを使って、メモリ上のイメージ（命令表現）を作成しなければならない。
命令セットと、それに対応する表現を定義するのが「命令セットアーキテクチャ」
、いわゆる
「ISA」
（Instruction Set Architecture）だ。つまりISA は、命令セットの構文的側面と意味的
側面の両方を定義する。このアプローチの先駆として、1960 年代にIBM 社はSystem/360 コ
hi.0412.ko.2002@gmail.com
　5.4
オペコード、オペランド、結果
81
ンピュータのためにISA を開発した。わずかな例外を除いて、そのシリーズに属するすべての
コンピュータが共通の基本命令セットを持っていたが、個々のモデルは、メモリの大きさもプ
ロセッサの速度もコストも、大きく（およそ1:30 の比率で）異なっていた。
5.4 　オペコード、オペランド、結果
基本的に、個々の命令は3 つの部分で構成される。それぞれの役割は、実行すべき演算の精
密な指定、演算に使用すべき値、そして結果を置くべき場所である（値や結果は、複数かもし
れない）
。以下の段落で、この考えを、もっと詳しく定義しよう。
オペコード
operation code（演算コード）を略したopcode（オペコード）2は、実行すべき演算を精密
に指し示す数だ。命令セットを設計するとき、それぞれの演算にユニークなオペコードを割り
当てる必要がある（たとえば整数の加算に5 というコードを割り当て、整数の減算に12 とい
うコードを割り当てる）
。
オペランド
演算の実行に必要な値を、
「オペランド」と呼ぶ。命令セットの定義では、個々の演算につい
て、オペランドの数と、それぞれに許される値が、精密に指定される（たとえば「この加算に
は2 個の符号付き整数が必要」
）
。
結果
アーキテクチャによって、プロセッサが命令の実行結果（たとえば算術演算の結果）をどこ
に置くべきかを、1 つ以上のオペランドで指定するものがある。その他のアーキテクチャでは、
結果の置き場所が自動的に決定される。
5.5 　典型的な命令のフォーマット
個々の命令はビット列で表現される。ほとんどのプロセッサで、
命令はオペコード
（演算コー
ド）を含むフィールドで始まり、その後にオペランドを含むフィールドが続く。図5‒1 に、そ
のフォーマットの凡例を示す。
オペコー
ド 
オペラン
ド 1 
オペラン
ド 2
図5‒1：多くのプロセッサが使う命令フォーマットの凡例。命令の先頭に置かれるオペコードによって、そ
の後に続くオペランドが厳密に決定される
2　訳注：英語ではopcode と書き、
「オプコード」と発音する。
「命令コード」とも呼ばれる。
hi.0412.ko.2002@gmail.com
82
第5 章
プロセッサの種類と命令セット　
5.6 　可変長命令と固定長命令
ここで問われるのは、どの命令も同じサイズに（つまり同じバイト数を占めるように）すべ
きか、それともオペランドの数と種類によって長さを変えるべきか、という問題だ。たとえば
整数の算術演算について考えてみよう。加算や減算では演算に使う値が2 つあるが、正負の反
転演算に使うのは1 個の値だけだ。そればかりか、プロセッサは複数のサイズを持つオペラン
ドをサポートできる（たとえば、あるプロセッサには、16 ビット整数のペアを加算する命令の
ほかに、32 ビット整数のペアを加算する命令があるかもしれない）
。ある命令を、他の命令よ
りも短くしてよいだろうか?
複数の命令サイズを含む命令セットを、われわれは「可変長」と形容する。そして、どの命
令も同じサイズである命令セットを「固定長」と形容する。プログラマが可変長命令を期待す
るのは、ソフトウェアでは各オブジェクトのサイズにしたがって空間を割り当てるのが普通だ
からだ（もしプログラムの中に「Hello」と「bye」という文字列があれば、コンパイラはそれ
ぞれに5 バイトと3 バイトを割り当てるのではないか?）
。しかしハードウェアの視点から見
ると、可変長命令には、フェッチとデコードに、より複雑なハードウェアが必要だ。反対に、
固定長命令ならば、それほど複雑なハードウェアは必要ない。固定長命令のプロセッサなら、
ハードウェアが高速に動作する。それはハードウェアが次の命令が置かれている位置を、容易
に計算できるからだ。このため、多くのプロセッサは、たとえ一部の命令を他の命令よりも少
ないビット数で表現できても、すべての命令を強制的に同じサイズにしている。要するに、
プログラマには効率が悪いと思われるかもしれないが、
固定長命令を使う方が、
プロセッ
サのハードウェアを、より単純かつ高速にできる。
固定長命令を使うプロセッサは、すべてのオペランドを必要としない命令を、どう扱うのだ
ろうか。たとえば固定長の命令セットで、加算と正負の逆転の両方を、どう両立させるのか。
それは簡単で、演算に不要なフィールドを無視するようにハードウェアが設計されるのだ。だ
から命令セットでは、ある種の命令について、
「これらのビットは使っていない」と指定するこ
とがある3。
固定長命令セットを採用するとき、一部の命令には、ハードウェアによって無視される
余分なビットが含まれる。使っていないフィールドは、ハードウェア最適化の一部と考
えるべきであり、粗雑な設計の徴候ではない。
3　「使っていないビット」がゼロであることを要求するハードウェアもある。
hi.0412.ko.2002@gmail.com
　5.7
汎用レジスタ
83
5.7 　汎用レジスタ
前に述べたように、
「レジスタ」というハードウェアデバイスは、プロセッサに入っている小
規模で高速なストレージ（データ保存装置）である。レジスタは固定サイズで（たとえば32
ビットや64 ビット）
、フェッチとストアという2 つの基本的な動作をサポートする。後に見る
ようにレジスタはさまざまな役割を果たし、そのなかには「命令ポインタ」あるいは「プログ
ラムカウンタ」といって、次に実行すべき命令のアドレスを示すものもある。しかしいまは、
プログラマによく知られている単純なケースだけに注意を集中しよう。それは、一時的なスト
レージとして使われる「汎用レジスタ」だ。プロセッサは普通、あまり多くない数の汎用レジ
スタを持ち（たとえば32 個）
、それぞれのレジスタは整数1 個のサイズであることが多い。た
とえば32 ビット算術演算を提供するプロセッサでは、それぞれの汎用レジスタが32 ビットの
大きさになる。その結果汎用レジスタは、算術命令に必要なオペランドや、その命令の結果を
収納できる。
多くのアーキテクチャにおいて、汎用レジスタには0 からN‒1 までの番号が振られる。そ
のプロセッサには、特定のレジスタに値をストアする命令や、レジスタから値をフェッチする
命令が含まれる。汎用レジスタには、メモリと同じ用語が使われる。
「フェッチ」が返す値は、
その前の「ストア」で指定された値である。そしてストアは、レジスタの内容を新しい値で置
き換える。
5.8 　浮動小数点レジスタとレジスタ番号
浮動小数点演算をサポートするプロセッサは、浮動小数点値を格納するのに別のレジスタ集
合を使うことが多い。どのレジスタを使うかは命令によって定まるが、汎用レジスタにも浮動
小数点レジスタにも普通は0 から始まる番号を振るから、話がややこしくなりやすい。たとえ
ば、もしレジスタの3 番と6 番が、ある整数型命令のオペランドに指定されていれば、プロ
セッサは、それらの汎用レジスタからオペランドを取り出す。けれども、もしレジスタの3 番
と6 番が、ある浮動小数点型命令のオペランドに指定されていれば、浮動小数点レジスタが使
われるのだ。
5.9 　レジスタを使うプログラミング
多くのプロセッサでは、命令を実行する前にオペランドを汎用レジスタに置く必要がある。
また、命令の結果を汎用レジスタに置くプロセッサもある。そういうプロセッサで変数X と変
数Y にある2 つの整数を加算して、結果を変数Z に置くとしたら、プログラマは、対応するレ
ジスタに変数の値を移す一連の命令を書かなければならない。たとえば、もし汎用レジスタの
3 と6 と7 を利用できるなら、そのプログラムには、次のステップを実行する4 つの命令が含
まれるかもしれない。
hi.0412.ko.2002@gmail.com
84
第5 章
プロセッサの種類と命令セット　
•
メモリから変数X のコピーをレジスタ3 にロードする。
•
メモリから変数Y のコピーをレジスタ6 にロードする。
•
レジスタ3 の値をレジスタ6 の値に足して、その結果をレジスタ7 に置く。
•
レジスタ7 の値のコピーを、メモリの変数Z にストアする。
後述するように、メモリとレジスタの間で値を移動するのは比較的コストが高いので、もし
同じ値をまた使うのなら、その値をレジスタに残しておくことで性能の最適化が計られる。プ
ロセッサが持つレジスタの数は少ないので、いつでもプログラマは（あるいはコンパイラは）
、
一群のレジスタに残す値を決めなければならない。その他の値はメモリに入れておくのだ。ど
の値をレジスタに入れるかを選択するプロセスを「レジスタ割り当て」と呼ぶ4。
レジスタ割り当ては、いくつもの詳細によって複雑になる。よくある問題の1 つは、命令の
実行結果として、より大きな値が生成される「拡張値」だ。たとえば整数の乗算は、オペラン
ドの2 倍のビット数を含む結果を出すことがある。プロセッサによっては「倍精度」演算の機
能を提供するものもある（もし通常の整数が32bit ならば、倍精度整数は64bit を占める）
。
拡張値に対処するため、ハードウェアは複数のレジスタを連続したものとして扱う。そうい
うプロセッサでは、たとえば倍精度整数をレジスタ4 にロードする命令は、その整数の半分を
レジスタ4 に置き、あと半分をレジスタ5 に置く（つまり、命令に明示的な言及がなくても、
レジスタ5 の値が変わってしまう）
。使用するレジスタを選ぶとき、プログラマは、拡張値を
連続するレジスタに置く命令についても、考慮しなければならない。
5.10 　レジスタバンク
レジスタ割り当てを複雑にするハードウェアの詳細が、もう1 つある。一部のアーキテク
チャはレジスタ群を複数の「バンク」に分け、命令のオペランドを、それぞれ別のバンクから取
ることを要求する。たとえば2 つのレジスタバンクを使うプロセッサでは、整数の「add」命
令について、2 つのオペランドを別々のバンクから取るように求められるかもしれない。
レジスタバンクを理解するためには、根底にあるハードウェアを見る必要がある。本質的に、
レジスタバンクは、そのハードウェアの処理速度を向上させるものだ。個々のバンクに別々の
物理アクセス機構があって、それらの機構が同時に動作するように作られている。このため、
レジスタ内の2 つのオペランドをアクセスする命令をプロセッサが実行するとき、両方のオペ
ランドが同時に取得される。図5‒2 に、このコンセプトを示す。
レジスタバンクは興味深い影響をプログラマにおよぼす。データの値をレジスタに置いてお
くことが不可能になるかもしれないのだ。その理由を理解するには、一般的なプログラミング
4　ちなみに、新しい値をレジスタに入れられるようレジスタの値をメモリに戻すことを、
「レジスタスピ
ル」と呼ぶ。
hi.0412.ko.2002@gmail.com
　5.10
レジスタバンク
85
0
1
2
3
4
5
6
7
バンクA
バンクB
2つのレジスタバンクの
アクセスに、
別々のハー
ドウェア
ユニッ
トを使う
プロセッサ
図5‒2：8 個のレジスタが2 つのバンクにわかれている。このハードウェアによってプロセッサは両方のバ
ンクを同時にアクセスできる
言語で使われるような次の代入文について考えてみるとよい。図5‒2 で示した2 つのレジスタ
バンクを持つプロセッサで、これらのステートメントを実装する場合を考えよう。
R ←X + Y
S ←Z −X
T ←Y + Z
最初の加算を実行するには、X とY が別々のレジスタバンクになければならない。そこで、
X にはバンクA、Y にはバンクB のレジスタを割り当てる。次の減算のZ は、X とは違うレジ
スタバンクになければならない。したがって、バンクB のレジスタでなければならない。第3
の代入では、Y とZ が別のバンクになければならない。しかし残念ながら、最初の2 つの代入
で、Y とZ を同じバンクに置くことになっている。したがって、これら3 つの命令に通用する
ようなX、Y、Z のレジスタ割り当ては不可能なのだ。この状態を、
「レジスタコンフリクト」が
発生したと言う。
レジスタのコンフリクト（衝突）には、どう対処すればよいだろうか。プログラマは、レジ
スタの再割り当てを行うか、値をコピーする命令を挿入する必要がある。たとえば、最後の加
算を実行する前に、Z の値をバンクA のレジスタにコピーする命令を追加できる。
hi.0412.ko.2002@gmail.com
86
第5 章
プロセッサの種類と命令セット　
5.11 　CISC とRISC の命令セット
コンピュータアーキテクトは、命令セットを大きく2 つのカテゴリーに分け、どちらを使う
かによってプロセッサを2 つのクラスに分類する5。
•
CISC（Complex Instruction Set Computer）
：複雑な命令セットのコンピュータ
•
RISC（Reduced Instruction Set Computer）
：縮小命令セットのコンピュータ
「CISC プロセッサ」には、数多くの命令が含まれ（何百もあるのが典型的だ）
、それぞれの
命令で任意の複雑さを持つ計算を行うことができる。インテルのx86 命令セットがCISC に分
類されるのは、1 個のプロセッサが何百もの命令を提供し、実行に長時間を要する複雑な命令
も含まれるからだ。ある命令はメモリ上のグラフィックスを操作するし、サイン関数やコサイ
ン関数を計算する命令もある6。
CISC と対照的に、
「RISC プロセッサ」には制約がある。RISC の設計は、命令の自由度で
はなく、すべての計算に必要十分な最小限の命令セット（たとえば32 種類の命令）を追求す
る。1 個の命令で任意の演算を実行できるようにはせず、個々の命令は基本的な計算だけを行
う。可能な限り高速を達成するために、RISC 設計は命令を固定サイズに制約する。そして最
後に、次の節で説明するように、RISC プロセッサは1 命令を1 クロックサイクルで実行する
ように設計される7。ARM とMIPS は、制約された命令を1 クロックサイクルで実行できる
RISC アーキテクチャを、それぞれ作った。とくにARM の設計は、スマートフォンや、消費電
力の小さな機器で、広く使われている。
要点をまとめよう。
プロセッサの命令セットに、長時間を要するかもしれない複雑な計算を実行する命令が
含まれるなら、そのプロセッサはCISC に分類される。RISC に分類されるのは、含まれ
るのが少数の命令だけで、どれも1 クロックサイクルで実行できるプロセッサである。
5　ほとんどの技術者は、長いフルネームの代わりに頭字語を使い、
「シスク」
「リスク」と発音する。
6　訳注：x86 にグラフィックス操作専用命令はないが、movs 命令は自動的な繰り返しによってメモリか
らメモリへと連続的にデータを転送するから画像データの操作に使える。また、コプロセッサ用にfsin、
fcos などの命令がある。
7　第2 章「デジタル論理回路の基礎」で述べたように、デジタルロジックはクロックの定周期パルスに
よって制御される。
hi.0412.ko.2002@gmail.com
　5.12
RISC 設計と実行パイプライン
87
5.12 　RISC 設計と実行パイプライン
RISC プロセッサは1 クロックサイクルに1 命令を実行すると書いたが、より正確に書くと、
RISC プロセッサは、
それぞれのクロックサイクルで1 命令を
「完結」
できるように設計される。
この微妙な違いを理解するには、ハードウェアの仕組みを理解することが重要だ。プロセッサ
のフェッチ‒ 実行サイクルは、前にも述べたように、まず命令をフェッチしてから、その命令
を実行するのだが、そのフェッチ‒ 実行サイクルが、いくつものステップに分割されるのだ。
典型的なのものを次にあげる。
•
次の命令をフェッチする
•
その命令をデコードし、オペランドをレジスタからフェッチする
•
オペコードで指定された算術演算を実行する
•
必要ならばメモリの読み出しや書き込みを行う
•
結果をレジスタに書き戻す
高速化を実現するため、RISC プロセッサは、それぞれ上記のステップの1 つを並列的に実
行する複数のハードウェアユニットを含み、それらのハードウェアが多段階の「パイプライン」
に配置される8。つまり、あるハードウェアユニットの結果が、次のハードウェアユニットに渡
されるのだ。図5‒3 にパイプラインの一例を示す。
ステージ 1 
ステージ 2 
ステージ 3 
ステージ 4 
ステージ 5
次の命令を
フェ
ッチ
デコー
ドして
オペラン
ドを
フェ
ッチ
算術演算を
実行
メモリの
読み出し/
書き込み
結果をス
トア
図5‒3：フェッチ‒ 実行サイクルの実行に使われるパイプライン。この例には5 段のハードウェアステージ
がある
この図で、命令はパイプラインの左から右に進む（最初のステージで命令をフェッチし、次
のステージでオペコードを調べる、など）
。クロックのパルスが来るたびに、すべてのステージ
が一斉に、命令を右に渡す。こうして命令は、組み立てラインの流れ作業のようにパイプライ
ンを通って行く。パイプラインにはいつでも5 個の命令が入っている。
パイプラインのスピードが上がるのは、すべてのステージが並行処理されるからだ。第4 の
ステージが命令を実行している間、第3 ステージは次の命令のためにオペランドをフェッチす
8　フェッチ‒ 実行サイクルで使われる多段階のパイプラインは、
「命令パイプライン」とも「実行パイプラ
イン」とも呼ばれるが、どちらも同じ意味だ。
hi.0412.ko.2002@gmail.com
88
第5 章
プロセッサの種類と命令セット　
る。クロックサイクルごとに命令が準備されるのだから、どのステージも待つ必要がない。図
5‒4 に、5 段のパイプラインを一群の命令が通っていく過程を示す。
クロ
ッ
ク 
ステージ 1 
ステージ 2 
ステージ 3 
ステージ 4 
ステージ 5
 1 
命令 1 
- 
- 
- 
-
 2 
命令 2 
命令 1 
- 
- 
-
 3 
命令 3 
命令 2 
命令 1 
- 
-
 4 
命令 4 
命令 3 
命令 2 
命令 1 
-
 5 
命令 5 
命令 4 
命令 3 
命令 2 
命令 1
 6 
命令 6 
命令 5 
命令 4 
命令 3 
命令 2
 7 
命令 7 
命令 6 
命令 5 
命令 4 
命令 3
 8 
命令 8 
命令 7 
命令 6 
命令 5 
命令 4
時間
図5‒4：5 段のパイプラインを命令が通る過程。いったんパイプラインが満たされたら、どのステージも、
すべてのクロックサイクルでビジーになる
この図を見れば明らかなように、RISC プロセッサは、1 個の命令をフェッチして実行するの
に必要な全部のステップを、1 クロックサイクルの間に実行できなくても、並行して動作する
ハードウェアのおかげで、1 クロック毎に1 個の命令を完了することが可能なのだ。要約する
と次のようになる。
RISC プロセッサはフェッチ‒ 実行サイクルの全部のステップを1 クロックサイクルで
実行できないが、
並行処理を行う命令パイプラインで、
ほぼ同等な性能を得られる。いっ
たんパイプラインが満たされれば、クロックサイクル毎に1 個の命令が完了するからだ。
5.13 　パイプラインと命令ストール
命令パイプラインが、プログラマにとって「トランスペアレント」だと言われるのは、命令
セットにパイプラインを明示的に参照する命令が含まれていないからだ。つまりハードウェア
は、パイプラインがあってもなくてもプログラムの実行結果が同じになるように構築されてい
る。この透明性は利点にもなるが欠点にもなる。パイプラインを理解していないプログラマが、
そうとは知らずに効率を悪くすることがあるのだ。
プログラミング上の選択がパイプラインにおよぼす影響を理解するために、次のプログラム
を考えてみよう。そのなかで、add とsubtract という2 つの連続する命令で加算と減算を行
う。そのオペランドと結果に使うレジスタには、A、B、C、D、E というラベルを付けてある。
命令K :
C
←add A B
命令K+1 :
D
←subtract E C
命令K は、パイプラインの最初から最後まで無事に進行できるが、命令K+1 は、途中で問
題にぶつかる。そのとき、まだオペランドC を使えないのだ。このためハードウェアは、命令
hi.0412.ko.2002@gmail.com
　5.13
パイプラインと命令ストール
89
K+1 のオペランドをフェッチする前に、命令K が終わるのを待たなければならない。パイプ
ライン内のステージがオペランドが得られるまで待つことを「ストール」と呼ぶ。図5‒5 に、
パイプラインがストールすると何が起きるかを示す。
 1 
命令 K 
命令 K－1 
命令 K－2 
命令 K－3 
命令 K－4
 2 
命令 K+1 
命令 K 
命令 K－1 
命令 K－2 
命令 K－3
 3 
命令 K+2 
(命令 K+1) 
命令 K 
命令 K－1 
命令 K－2
 4 
(命令 K+2) 
(命令 K+1) 
- 
命令 K 
命令 K－1
 5 
(命令 K+2) 
(命令 K+1) 
- 
- 
命令 K
 6 
(命令 K+2) 
命令 K+1 
- 
- 
-
 7 
命令 K+3 
命令 K+2 
命令 K+1 
- 
-
 8 
命令 K+4 
命令 K+3 
命令 K+2 
命令 K+1 
-
 9 
命令 K+5 
命令 K+4 
命令 K+3 
命令 K+2 
命令 K+1
 10 
命令 K+6 
命令 K+5 
命令 K+4 
命令 K+3 
命令 K+2
時間
ステージ 1 
ステージ 2 
ステージ 3 
ステージ 4 
ステージ 5
クロ
ッ
ク
命令を
フェ
ッチ
オペラン
ドを
フェ
ッチ
ALUの
演算
メモリを
アクセス
結果を
書く
図5‒5：パイプラインのストール。命令K+1 は、命令K からオペランドを得るまで進行できない
この図のパイプラインは、クロックサイクル3 で命令K+1 がステージ2 に届くまでは通常
運転をしている。ステージ2 では、オペランドをレジスタからフェッチするが、この例では命
令K+1 のオペランドの1 つが利用できない。それは命令K が結果をレジスタに書くまで使え
ないのだから、命令K の完了までパイプラインはストールせざるを得ない。上記のコードで言
えばC の値が、まだ計算されていないので、ステージ2 はC の値をフェッチできない。このた
めステージ1 とステージ2 は、クロックサイクル4 と5 の間、ストールしたままになる。ク
ロックサイクル6 で、ステージ2 はオペランドをフェッチでき、パイプライン処理が進行する。
図5‒5 の右端の列を見れば、ストールが性能に与える悪影響は明らかだ。これはパイプライ
ンの最終ステージだが、クロックサイクル6、7、8 の間、何の結果も出していない。もしス
トールが起きなければ、命令K+1 はクロックサイクル6 で完了していたはずだが、ストール
したので、その命令はクロックサイクル9 になるまで完了していない。
ストールの原因が生じてから出力が止まる時間までの遅れを表現するのに、われわれは、パ
イプラインを「バブル」
（気泡）が通る、と表現する。もちろんバブルの存在はパイプラインの
性能を監視している人にしかわからない。なぜならバブルは、正確さに影響を与えるわけでは
ないからだ。命令は、あるステージが完了したら即座に次のステージへと直接渡されるので、
すべての命令は指定されたままの順序で実行される。
hi.0412.ko.2002@gmail.com
90
第5 章
プロセッサの種類と命令セット　
5.14 　パイプラインがストールする他の原因
プロセッサが命令を実行するときにパイプラインがストールして、プロセッサの処理を遅ら
せたり通常の流れを乱したりする原因は、オペランド待ちの他にもある。ストールは、たとえ
ばプロセッサが下記の処理を行うときに発生するかもしれない。
•
外部ストレージをアクセスするとき
•
コプロセッサを呼び出すとき
•
新しい場所に分岐するとき
•
サブルーチンをコールするとき
最も洗練されたプロセッサには、ストールを避けるためのハードウェアが追加されている。
たとえば、いくつかのプロセッサにはパイプラインのコピーが2 つある。そういうプロセッ
サは、ある分岐が行われたときに実行されるはずの命令のデコードを始めながら、その分岐が
行われなければ実行されるはずの命令もデコードできる。2 つのコピーは、分岐命令の実行が
可能になるまで、それぞれの動作を続けるが、そのときハードウェアは、パイプラインのどち
らのコピーにしたがうべきかを知って、もう片方のコピーを無視する。その他のプロセッサに
は、結果のコピーをパイプラインの前段に渡す特例的なショートカット（あるいはバイパス）
のハードウェアが含まれている。
5.15 　プログラマにおよぼす影響
RISC アーキテクチャで最大の速度を達成するためには、命令パイプラインに適したプログ
ラムを書く必要がある。たとえばプログラムは不要な分岐命令が入らないように書くべきだ。
同様に、結果を入れたレジスタを、その直後の命令で参照するよりも、参照を遅らせるのが良
い。表5‒1 は、実行が速くなるようにコードの編成を改めた例を示している。
表5‒1：パイプラインのストールを減らすことで高速になる
元の命令リスト
パイプラインでの実行が速くなるように並べ替えた命令リスト
C ←add
A B
C ←add
A B
D ←subtract
E C
F ←add
G H
F ←add
G H
M ←add
K L
J ←subtract
I F
D ←subtract
E C
M ←add
K L
J ←subtract
I F
P ←subtract
M N
P ←subtract
M N
この表で、最適化したプログラムは参照と計算が分離されている。たとえば元のプログラム
では第2 の命令（減算）でC の値を参照しているが、それは直前の命令で作られた値だ。その
hi.0412.ko.2002@gmail.com
　5.16
プログラミング、ストール、No-Op 命令
91
せいで、第1 の命令と第2 の命令の間でストールが発生する。その減算を、それより後の段階
に移せば、プロセッサはストールせずにプログラムの実行を続けられる。
もちろんプログラマは、パイプラインを「プログラミングの重荷」と考えるかわりに「自動
的な最適化」とみなすことも可能だ。さいわいなことに、ほどんどのプログラマは、手作業で
パイプライン最適化を行う必要がない。代わりに高水準言語のコンパイラが、その最適化を自
動的に行ってくれるのだ。
コードのシーケンスを再編成することで、ハードウェアが命令パイプラインを使うとき
の処理速度を向上させることが可能だ。その再編成は、
プログラマの立場から見れば
「正
確さに影響を与えずに速度を上げることのできる最適化」である。
5.16 　プログラミング、ストール、No-Op 命令
場合によっては、プログラムの命令をストール防止のために再編成するのが不可能かもしれ
ない。その場合、プログラマは、そのコードを読む人がストールの発生を理解するように、ス
トールを文書化できる。そのようなドキュメントは、とくにプログラムの更新時に役立つ。そ
のプログラムを書き換えるプログラマなら、状況を再検討して、ストールを防止するように命
令を再編成できるかもしれない。
プログラマは、どうすればストールを文書化できるのだろう。当然ながら、ストールの原因
を説明するコメントを入れることも、そういうテクニックの1 つだ。けれども、ほとんどの
コードはコンパイラによって生成されるのだし、それを人間が読むのは、問題が発生したとき
か、特殊な最適化が必要になったときだけだ。この場合には、コードでストールが発生する場
所に余分な命令を入れておくという、もう1 つの技を使える。その余分な命令は「パイプライ
ンに影響を与えることなく要素を追加できる場所」を示すのだ。もちろん、余分な命令は無害
でなければならない。その命令はレジスタの値を変えるなど、プログラムに影響を与えること
は、何もしてはいけない。たいがいのハードウェアには「No-Op」
（no operation）という命
令が提供されている9。これは、ある時間を占めるだけで、まったく何もしない命令だ。
ほとんどのプロセッサには、No-Op 命令がある。これはデータの値を参照せず、結果の
計算もせず、その他コンピュータの状態に影響を与えることは何もしない命令だ。no-op
命令は、ストールが発生する場所に、一種のドキュメントとして挿入できる。
9　訳注：3 文字を基本とするニーモニックでは、nop という名前の命令になる。
hi.0412.ko.2002@gmail.com
92
第5 章
プロセッサの種類と命令セット　
5.17 　フォワーディング
前に述べたように、一部のハードウェアには、命令パイプラインの性能を改善する特殊な機
能がある。たとえばALU は、
「フォワーディング」と呼ばれる技法を使って、連続する演算命
令に結果を渡すという問題を解決している。
フォワーディングの仕組みを理解するために、次の2 つの命令について考えてみよう。ここ
でオペランドのA、B、C、D、E は、どれもレジスタに入れる。
命令K :
C
←add A B
命令K+1 :
D
←subtract E C
このようなシーケンスが、パイプラインを持つプロセッサでストールを起こすことは、前に
述べた通りだ。けれどもフォワーディングを実装するプロセッサでは、ストールを回避するた
めに、こういう依存関係を自動的に検出してC の値を命令K から命令K+1 へと直接渡すよ
うに、特別なハードウェアが編成されている。つまり、命令K でALU から出力される値のコ
ピーが直接送られて、命令K+1 でALU の入力になる。その結果、命令はパイプラインを満た
し続け、ストールは発生しない。
5.18 　演算の型
コンピュータアーキテクトが命令セットを論じるときは、いくつかの基本的なカテゴリーに
命令を分類する。次に、考えられる分類の例を示す。
•
整数の算術命令
•
浮動小数点の算術命令
•
論理命令（ブール演算の命令）
•
データのアクセスと転送の命令
•
条件分岐と無条件分岐の命令
•
プロセッサ制御命令
•
グラフィックス命令
5.19 　プログラムカウンタ、フェッチ‒ 実行、分岐
第4 章で述べたように、どのプロセッサも基本的なフェッチ‒ 実行サイクルを実装する。そ
のサイクルの間に、プロセッサの制御装置は自動的に次の命令へと進む。つまり、ある命令の
実行を終えたプロセッサは、次の命令をフェッチする前に、メモリ上の位置を現在の命令を超
えた所まで進める。フェッチ‒ 実行サイクルと次の命令への移動を実装するのに、プロセッサ
hi.0412.ko.2002@gmail.com
　5.19
プログラムカウンタ、フェッチ‒ 実行、分岐
93
は「命令ポインタ」または「プログラムカウンタ」と呼ばれる内部レジスタを使う10。
フェッチ‒ 実行サイクルを始めるとき、プログラムカウンタには、これから実行する命令の
アドレスが入っている。その命令をフェッチした後、プログラムカウンタは、次の命令のアド
レスに更新される。それぞれのフェッチ‒ 実行サイクルの間にプログラムカウンタが更新さ
れるから、プロセッサはメモリ上で連続する命令のなかを自動的に進んで行く。アルゴリズム
5‒1 に、連続する命令をフェッチ‒ 実行サイクルが消費する過程を示す。
アルゴリズム5‒1：フェッチ‒ 実行サイクル
プログラムカウンタにプログラムの開始アドレスを代入
永遠に繰り返す{
フェッチ: プログラムカウンタが指す位置から、プログラムの次のステップをアクセスする
内部のアドレスレジスタA に、いまフェッチした命令を超えた場所のアドレスを設定
実行: プログラムのステップを実行する
アドレスレジスタA の内容をプログラムカウンタにコピーする
}
このアルゴリズムによって、分岐命令の仕組みも理解できる。分岐には絶対と相対の2 種類
がある。
「絶対分岐」で指定されるメモリアドレスは、次に実行すべき命令が置かれている位置
のアドレスだ。絶対分岐命令は「jump」と呼ばれるのが典型的である。その実行ステップで、
ジャンプ命令は指定されたアドレスの値を、アルゴリズム5‒1 で指定したのと同じ内部レジス
タA にロードする。フェッチ‒ 実行サイクルの終わりに、ハードウェアが、その値をプログ
ラムカウンタにコピーする。つまり、そのアドレスが次の命令をフェッチするのに使われるの
だ。たとえば、次の絶対分岐命令、
jump 0x05DE
これをプロセッサが実行すると、内部アドレスレジスタに0x05DE がロードされ、次の命令
をフェッチする前に、その値がプログラムカウンタにコピーされる。言い換えると、次の命令
フェッチは、0x05DE というメモリ位置で発生する。
絶対分岐命令と違って、
「相対分岐命令」は、メモリアドレスそのものを指定しない。代わり
に相対分岐命令は、プログラムカウンタに正または負の差分を加える。たとえば次の命令、
br +8
これは、現在位置（プログラムカウンタの現在の値）から数えて8 バイト先の位置に分岐さ
せる。
相対分岐を実装するために、プロセッサは分岐命令のオペランドをプログラムカウンタに加
10　この2 つの用語は等価である。
hi.0412.ko.2002@gmail.com
94
第5 章
プロセッサの種類と命令セット　
算し、その結果を内部アドレスレジスタA に置く。もし相対分岐が−12 を計算するなら、次
に実行すべき命令は、現在の命令の位置から12 を引いたアドレスにある。コンパイラは相対
分岐を、短い「while ループ」の末尾で使えるだろう。
ほとんどのプロセッサは、サブルーチンを呼び出すための命令も提供する。典型的な呼び名
の1 つは「jsr」
（jump subroutine）だ。フェッチ‒ 実行サイクルに関して言えば、jsr 命令
も分岐命令に似ているが、1 つ大きな違いがある。分岐が発生する前に、jsr 命令はアドレスレ
ジスタA の値を保存するのだ11。実行が終わるとサブルーチンは呼び出し側に戻る。サブルー
チンは、そのために保存されたアドレスへの絶対分岐を実行する。ゆえにサブルーチンが完了
すると、フェッチ‒ 実行サイクルはjsr の直後にある命令から再開される。
5.20 　サブルーチンコール、引数、レジスタウィンドウ
高水準言語は、jsr のようなサブルーチンコールの命令を使って、プロシージャ（手続き）
あるいは関数の呼び出しを実装する。呼び出し側のプログラムは、サブルーチンが計算に使う
「引数」
（argument）を提供する。たとえばcos(3.14159) という関数呼び出しは、引数とし
て浮動小数点定数の3.14159 を渡す。
さまざまなプロセッサの主な相違点の1 つは、根底にあるハードウェアによってサブルー
チンに引数を渡す方法が異なることだ。いくつかのアーキテクチャは、メモリを使う。つまり
呼び出しの前に引数がメモリ内のスタックに格納され、サブルーチンは引数を参照するときス
タックから値を取り出す。別のアーキテクチャのプロセッサは、汎用または専用のレジスタを
使って引数を渡す。
専用にせよ、汎用にせよ、レジスタを使って引数を渡すほうがメモリ内のスタックを使うよ
り、ずっと高速である。なぜならレジスタはプロセッサの内部に含まれるローカルストレージ
の一部だからだ。引数渡しのために専用のレジスタを提供するプロセッサは少ないので、典型
的に使われるのは汎用レジスタだ。しかし残念ながら、汎用レジスタを引数だけに使うことは
できない。それらは他の計算にも（たとえば算術演算のオペランドを格納する目的で）必要と
されるからだ。したがってプログラマは、トレードオフに直面する。引数渡しに汎用レジスタ
を使えばサブルーチンコールが高速になるが、データの値を格納するためにレジスタを使えば
計算が全般的に速くなる。だからプログラマは、どの引数をレジスタに入れ、どの引数をメモ
リに格納するかを選ばなければならない12。
プロセッサによっては、引数渡しを最適化するために「レジスタウィンドウ」を持つものがあ
11　訳注：アドレスの値を、どこに保存するかという問題がある。一定の場所に保存すると、サブルーチン
からサブルーチンを呼び出したら先に保存した値が上書きされて、元のプログラムに戻れなくなる。何らか
の対策が必要だが、そのあたりは読み進むにつれて、明らかになってくる。
12　付録C に、x86 アーキテクチャで使われるコーリングシーケンスを記述する。そして付録D では、ARM
アーキテクチャで、どのようにして引数の一部をレジスタで渡し、その他をメモリで渡すのかを説明する。
hi.0412.ko.2002@gmail.com
　5.20
サブルーチンコール、引数、レジスタウィンドウ
95
る。そういうプロセッサは汎用レジスタの大きな集合を持っているが、レジスタのハードウェ
アが一度に見せてくれるのは、レジスタの部分集合にすぎない。その部分集合が、
「ウィンド
ウ」と呼ばれるのだ。ウィンドウはサブルーチンが呼び出されるたびに自動的にスライドし、
サブルーチンがリターンするたびに戻る。重要なポイントとして、プログラムとサブルーチン
から利用できるウィンドウには重複がある。つまり、呼び出し側から見えるレジスタの一部は、
サブルーチンからも見えるのだ。呼び出し側は、サブルーチンを呼び出す前に、重複するレジ
スタに引数を置き、サブルーチンは、それらのレジスタから値を取り出す。図5‒6 に、レジス
タウィンドウのコンセプトを示す。
サブルーチン呼び出し前の
レジスタ0－7の値
他のレジスタは利用できない
利用できない
利用できない
サブルーチン実行中の
レジスタ0－7の値
x1 
x2 
x3 
x4 
A 
B 
C 
D
x1 
x2 
x3 
x4 
A 
B 
C 
D 
l1 
l2 
l3 
l4
（a）
（b）
図5‒6：レジスタウィンドウ：
（a）はサブルーチンコールの前。
（b）はコール中。値A、B、C、D は、渡さ
れる引数に対応する
図のハードウェアには16 個のレジスタがあるけれど、同時に見えるのは8 個だけで、他の
レジスタは利用できない。プログラムは可視のレジスタ群を、常に0 から「ウィンドウサイズ
−1」までの値で参照する（この例では0 から7 まで）
。サブルーチンが呼び出されると、ハー
ドウェアはウィンドウをスライドさせて、可視のレジスタ集合を変更する。この例では、呼び
出しの前は番号が4 から7 までだったレジスタ群が、呼び出し後は0 から3 までの番号にな
る。このため、呼び出し側のプログラムはA からD までの引数をレジスタ4 から7 に置くが、
サブルーチンは、それらの引数をレジスタ0 から3 で受け取る。xi の値を持つレジスタは、呼
び出し側しか使えない。レジスタウィンドウを使うアプローチには、いまウィンドウに入って
いないレジスタ群に、値がそのまま残っているというメリットがある。だから、呼び出された
サブルーチンがリターンするときにウィンドウが元の位置に戻されると、x のレジスタには、呼
び出し前とまったく同じ値が入っている。
図5‒6 の例では図を簡略化するために、レジスタ8 個分という小さなウィンドウサイズを
使っているが、実際にレジスタウィンドウを使うプロセッサには、もっと大きなウィンドウを
持たせるのが典型的だ。たとえばSPARC アーキテクチャは、128 または144 個の物理レジス
hi.0412.ko.2002@gmail.com
96
第5 章
プロセッサの種類と命令セット　
タを持ち、ウィンドウサイズはレジスタ32 個の大きさである。ただし、ウィンドウで重複す
るレジスタの数は8 個だけだ（つまり、引数渡しにはレジスタを8 個までしか使えない）
。
5.21 　命令セットの例
命令セットの例を見ると、これから述べるコンセプトがわかりやすくなる。例としてMIPS
プロセッサを選ぶのに2 つの理由がある。第1 に、MIPS プロセッサは組み込みシステムで、
よく使われる。第2 に、MIPS の命令セットは、RISC プロセッサによって提供される命令セッ
トの、古典的な例である13。表5‒2 に、MIPS 命令セットに含まれる命令を要約したリストを
示す。
MIPS プロセッサには、32 個の汎用レジスタが含まれ、ほとんどの命令はオペランドと結果
をレジスタに入れることが要求される。たとえばadd 命令では、3 つのオペランドをレジスタ
で指定する。この命令は、最初の1 対のレジスタを見て、その内容を加算し、結果を第3 のレ
ジスタに置く。
表5‒2 のリストにあげた整数命令のほか、MIPS アーキテクチャは、一群の浮動小数点命令
も、単精度（32bit）と倍精度（64bit）の両方で定義している。そしてハードウェアは32 個の
浮動小数点レジスタを提供する。これらの浮動小数点レジスタも0 から31 までの番号を持つ
が、汎用レジスタとはまったく独立している。
倍精度の値を扱うために、浮動小数点レジスタはペアで動作する。倍精度の値を格納するた
め、浮動小数点ポイントレジスタのうち奇数番のレジスタだけが、浮動小数点命令のオペラン
ドまたはターゲットとなる。そしてハードウェアは、指定された奇数番レジスタと、その次の
偶数番レジスタを組み合わせて、1 個のストレージ単位にする。表5‒3 に、MIPS の浮動小数
点命令セットを要約する。
13　訳注：MIPS アーキテクチャを使う教科書は多い。パターソン&ヘネシー『コンピュータの構成と設計』
（日経BP 社）
、ヘネシー&パターソン『コンピュータアーキテクチャ定量的アプローチ』
（翔泳社）のほか、
ハリス&ハリス『ディジタル回路設計とコンピュータアーキテクチャ』
（翔泳社）でも例として使われている。
hi.0412.ko.2002@gmail.com
　5.21
命令セットの例
97
表5‒2：命令セットの例として、ここではMIPS プロセッサが提供する命令を示す14
命令
意味
算術演算
add
整数加算
subtract
整数減算
add immediate
整数加算（レジスタ＋定数）
add unsigned
unsigned で整数加算
subtract unsigned
unsigned で整数減算
add immediate unsigned
unsigned で整数に定数を加算
move from coprocessor
コプロセッサをアクセス
multiply
整数乗算
multiply unsigned
unsigned で整数乗算
divide
整数除算
divide unsigned
unsigned で整数除算
move from Hi
上位レジスタをアクセスする
move from Lo
下位レジスタをアクセスする
論理演算（ブール代数）
and
レジスタ2 つの論理積
or
レジスタ2 つの論理和
and immediate
レジスタと定数の論理積
or immediate
レジスタと定数の論理和
shift left logical
レジスタをN ビット左シフト
shift right logical
レジスタをN ビット右シフト
データ転送
load word
メモリからレジスタにロード
store word
レジスタからメモリにストア
load upper immediate
定数をレジスタの上位16 ビットに入れる
move from coproc. register
コプロセッサのレジスタから値を取得
条件分岐
branch equal
レジスタ2 つが等しければ分岐
branch not equal
レジスタ2 つが等しくなければ分岐
set on less than
レジスタ2 つを比較
set less than immediate
レジスタと定数を比較
set less than unsigned
unsigned でレジスタ2 つを比較
set less than immediate
unsigned でレジスタと定数を比較
無条件分岐
jump
ターゲットアドレスに飛ぶ
jump register
レジスタのアドレスに飛ぶ
jump and link
プロシージャコール
14　訳注：この表のunsigned は、結果がオーバーフローしてもトラップが発生しない計算という意味
hi.0412.ko.2002@gmail.com
98
第5 章
プロセッサの種類と命令セット　
表5‒3：MIPS アーキテクチャで定義されている浮動小数点命令
命令
意味
算術命令
FP add
浮動小数点加算
FP subtract
浮動小数点減算
FP multiply
浮動小数点乗算
FP divide
浮動小数点除算
FP add double
倍精度FP 加算
FP subtract double
倍精度FP 減算
FP multiply double
倍精度FP 乗算
FP divide double
倍精度FP 除算
データ転送
load word coprocessor
値をFP レジスタにロード
store word coprocessor
FP レジスタからメモリにストア
条件分岐
branch FP true
FP 条件が真なら分岐
branch FP false
FP 条件が偽なら分岐
FP compare single
FP レジスタ2 つを比較
FP compare double
2 つの倍精度値を比較
5.22 　最小限の命令セット
「表5‒2 にある命令では不足だろう、もっと命令が必要では」と思われるかもしれない。た
とえばMIPS アーキテクチャには、あるレジスタの内容を別のレジスタにコピーする命令がな
いし、メモリの内容をレジスタの内容に加算するような命令も含まれていない。このような選
択は、スピードとミニマリズム（最小限を追求する思想）という2 つの原則をMIPS 命令がサ
ポートしている結果である。第1 に、この基本的な命令セットは、確実に高速が得られるよう
に注意深く選択されたものだ（このアーキテクチャの特徴として、パイプラインを使うときに
は、1 クロックサイクルごとに1 個の命令が完了する）
。第2 に、この命令セットは「最小限」
を目標として、可能な限り少ない数の標準的な計算を扱う命令だけを含んでいる。このように
命令の数を制限することは、この設計の鍵となっている。32 個に命令を絞ることで、オペコー
ドは5 ビットになり、ビットの組み合わせには、まったく無駄がない。
MIPS アーキテクチャには、ゼロという値を高速にアクセスできる性質があり、最小限という
目標の達成に役立っている。この性質は他のRISC プロセッサでも使われているが、MIPS の
場合はレジスタ0 が、その機構を提供している。レジスタ0 は、常にゼロという値を含むよう
に予約されているのだ。
したがって、あるレジスタの中身がゼロか否かをテストするときは、その値をレジスタ0 と
比較できる。レジスタ0 は、どの命令にも同じように使える。たとえば、あるレジスタから他
のレジスタへと値をコピーすにはadd 命令を使い、2 つのオペランドの片方をレジスタ0 に
する。
hi.0412.ko.2002@gmail.com
　5.23
直交性の原則
99
5.23 　直交性の原則
命令セットの技術的側面だけでなく、アーキテクトはデザインの美的側面も考慮しなければ
ならない。とくにアーキテクトが追求するのは「エレガンス」である。エレガンスは人間の感
覚に関係する。つまり、命令セットはプログラマからどう見えるか。どのように命令を組み合
わせたら一般的なプログラミングのタスクを扱えるのか。命令のバランスはとれているか（右
シフトがあるなら、左シフトもあるだろうか）
。もちろんエレガンスは主観的な判断を求めが
ちだ。けれども、いくつかの命令セットで経験を積めば、技術者もプログラマも、エレガンス
を認識して受け入れやすくなるだろう。
エレガンスのうち、
「直交性」と呼ばれる性質に関しては、命令から不要な重複を排除する
ことに重点を置く。命令セットが「直交的」だと言えるのは。それぞれの命令が1 個のユニー
クなタスクを実行する場合だ。直交的な命令セットには、プログラマにとって重要な長所があ
る。命令が直交的であれば理解が容易になり、プログラマは、同じ仕事を行う複数の命令から
1 つを選ぶ必要がなくなる。直交性は、プロセッサ設計の一般原則になっているくらい重要だ。
要点をまとめよう。
直交性の原則は、それぞれの命令が1 個のユニークなタスクを実行し、他の命令と機能
が重複しないことを求める。
5.24 　条件コードと条件分岐
多くのプロセッサでは、命令を実行した結果が「ステータス」
（状態）となって、プロセッ
サ内部のハードウェア機構に格納される。その後の命令でステータスを調べると、どのように
処理を続けるかを判断できる。たとえば算術演算命令を実行した場合、ALU は「条件コード」
と呼ばれる内部レジスタをセットする。これには計算の結果が正か負かゼロかを記録するビッ
トや、オーバーフローの発生を示すビットなどが含まれる。算術命令に続く「条件分岐」命令
は、条件コードのビットをチェックすることにより、分岐するかしないかを結果によって判断
できる。
条件コード機構の使い方は、例を見れば明らかになる15。2 つの値が等しいか否かを調べる
プログラムを考えてみよう。これは単純な例で、レジスタ4 の値がレジスタ5 の内容と等しく
なければレジスタ3 にゼロを入れるだけだ。リスト5‒1 に、コードの例を示す。
15　第9 章で条件コードを使うプログラミングを説明し、もっと多くの例を示す。
hi.0412.ko.2002@gmail.com
100
第5 章
プロセッサの種類と命令セット　
リスト5‒1：条件コードを使うコーディング例。まずALU 演算によって条件コードがセットされる。その
後の条件分岐命令で条件コードをテストする
cmp
r4, r5
# レジスタ4 と5 を比較して条件コードをセット
be
lab1
# 条件コードが等値を示していればlab1 に分岐
mov
r3, 0
# レジスタ3 にゼロを格納
lab1:
... ここからプログラムを続行
5.25 　まとめ
それぞれのプロセッサに、そのプロセッサがサポートする演算を集めた命令セットが定義さ
れるが、
その選択は、
プログラマの便宜とハードウェアの効率との妥協の産物である。一部のプ
ロセッサでは、どの命令も同じサイズに統一されるが、命令によってサイズが異なるプロセッ
サもある。
ほとんどのプロセッサには、高速なストレージ機構である汎用レジスタの小さな集合が内蔵
されている。レジスタを使うプログラミングでは、メモリから値をレジスタにロードし、計算
を実行して、その結果をレジスタからメモリにストアする。性能を最適化するため、プログラ
マは、また後で使う値をレジスタに残しておく。アーキテクチャによっては、レジスタが複数
のバンクに分割されるので、各命令で必ず異なるバンクをオペランドに選ぶよう配慮しなけれ
ばならない。
プロセッサは、大きく分けてCISC とRISC に分類できる。これは、プロセッサが複雑な命
令を数多く含むか、それとも最小限の命令を含むかの違いだ。RISC アーキテクチャでは、1 ク
ロックサイクルで必ず1 命令が完了するように、命令パイプラインが使われる。プログラマは
パイプラインのストールを回避するようにコードを並び替えることで、性能を最適化できる。
条件実行（if-then-else など）を実装するため、多くのプロセッサが条件コードの機構を
利用する。ALU 命令が条件コードをセットし、その後の命令（条件分岐）で、その条件コード
をチェックする。
練習問題
5.1
プログラムをデバッグしているとき、プログラマは便利なツールを使って、メモリの
内容を調査できます。そのツールを使って、メモリで命令を含む場所を調べたら、3
つの16 進数が次のようにラベル付きで表示されました。
OC=0x43 OP1=0xff00 OP2=0x0324
これらのラベルは何を意味する略語でしょうか?
5.2
あるコンピュータでは、算術演算のハードウェアによって、オペランドが個別のバン
クにあることが要求されます。その場合、次の計算を行うには、どういう命令シーケ
hi.0412.ko.2002@gmail.com
　5.25
まとめ
101
ンスが必要でしょうか?
A ←B −C
Q ←A ∗C
W ←Q + A
Z ←W −Q
5.3
ブール演算の論理積（AND）
、論理和（OR）
、否定（NOT）
、排他的論理和（XOR）を
実行する命令セットを、あなたが設計していると想定しましょう。それぞれの命令に
オペコードを割り当てて、各命令のオペランド数も書き出してみましょう。命令をメ
モリに入れるとき、オペコードには何ビットが必要でしょうか?
5.4
あるコンピュータが、16bit 整数、32bit 整数、32bit 浮動小数点値、64bit 浮動小数
点値について、加算、減算、乗算、減算を実行できるとしたら、ユニークなオペコー
ドがいくつ必要でしょうか?
ヒント：演算ごと、データサイズごとに、1 個のオペコードがあると想定します。
5.5
あるコンピュータアーキテクトが、どの命令もきっかり32bit を占めるようにコ
ンピュータを設計できたと誇らしげに語っています。そのような設計の利点は何で
しょう?
5.6
ARM Limited が所有するARM アーキテクチャ、Oracle Corpolation が所有する
SPARC アーキテクチャ、
Inrel Corporation が所有するIntel アーキテクチャを、
CISC
かRISC かで分類してください。
5.7
N 段のパイプラインで、ステージi にはti の時間が必要だとします。ステージ間の
遅延はないものとして、このパイプラインで1 個の命令を扱うのに、開始から終了ま
でに要する合計時間を求めてください。
5.8
次のコードに、nop を挿入して、パイプラインがストールする場所を指摘しましょう
（図5‒5 に示したパイプラインを想定します）
。
loadi
r7, 10
# レジスタ7 に値10 をロード
loadi
r8, 15
# レジスタ8 に値15 をロード
loadi
r9, 20
# レジスタ5 に値20 をロード
addrr
r10, r7, r8
# レジスタの7 と8 を加算し、結果をレジスタ10 に格納
movr
r12, r9
# レジスタ9 をレジスタ12 にコピー
movr
r11, r7
# レジスタ7 をレジスタ11 にコピー
addri
r14, r11, 27
# レジスタ11 に値27 を加算し、結果をレジスタ14 に格納
addrr
r13, r12, r11
# レジスタの11 と12 を加算し、結果をレジスタ13 に格納
hi.0412.ko.2002@gmail.com
hi.0412.ko.2002@gmail.com
第6 章
データパスと命令実行
6.1 　はじめに
「第2 章　デジタル論理回路の基礎」ではデジタルロジックを紹介し、デジタルシステムの
作成に使われる基本的なハードウェア構成要素（ビルディングブロック）について述べ、その
基本となるゲートがトランジスタで作られることを示した。また、クロックという重要なコン
セプトを紹介し、デジタル回路の一連の動作がクロックによって可能になることを示した。そ
れに続く章では、データをバイナリ（2 進法）で表現する方法を示し、プロセッサおよび命令
セットについて論じた。
この章では、デジタルロジックの組み合わせでコンピュータを構築できることを示し、その
方法を解説する。ALU やメモリなど特定の機能を持つユニットを概説し、それらがどのよう
に接続されるかを示す。そして最後に、それらの相互作用によって、どのように計算が実行さ
れるかを説明する。今後の章では、これらの概説をもとに、プロセッサとメモリシステムを、
もっと詳しく調べていく。
6.2 　データパス
プログラマブルなコンピュータを作るためにハードウェアをどう構成するかは、複雑な話で
ある。そこでアーキテクトは、大規模な設計のあらゆる詳細を見るのではなく、主要なハード
ウェアコンポーネントと、それらの相互接続を記述するところから始める。高いレベルで、わ
れわれの関心は、命令がどのようにメモリから読み出され実行されるかに限定される。高いレ
ベルの記述は多くの詳細を無視し、命令の実行にしたがってデータ項目が移動して行く相互接
続の経路だけを示すことになる。たとえば加算を考えるときは、2 つのオペランドがALU に
到達するまでに辿る経路と、もう1 つのユニットに計算の結果を渡すデータの経路に注目す
る。そうすれば、電源とグランドの接続や制御線の接続などといった詳細が図に現れることは
hi.0412.ko.2002@gmail.com
104
第6 章
データパスと命令実行　
ない。コンピュータアーキテクトは、これらのデータ経路を記述するのに「データパス」とい
う用語を使い、
「データパス図」と呼ばれる図を描く。
データパスの説明をわかりやすくするために、単純化されたコンピュータをサンプルとする。
その単純化は、次の想定を含む。
•
命令セットに含まれるのは4 つの命令だけ
•
すでにプログラムがメモリにロードされている
•
スタートアップを無視し、プロセッサが実行中である
•
データ項目と命令は、どれも厳密に32 ビットを占める
•
整数演算だけを考慮する
•
算術オーバーフローなど、すべてのエラー条件は、まったく無視する
このサンプルのコンピュータは極度に単純だが、その基本となるハードウェアは一般的なコ
ンピュータと、まったく同じものだ。したがって、こんな例でも主なハードウェア部品を示す
のには十分であり、それらの相互接続もデータパスの設計方法を示すのに十分である。
6.3 　サンプルの命令セット
前章で述べたように、新たなコンピュータの設計は命令セットの設計から始めなければなら
ない。命令の詳細な仕様が決まったら、コンピュータアーキテクトは、それぞれの命令を実行
するハードウェアを設計できる。具体的なハードウェア構成として、次の属性を持つ架空のコ
ンピュータを考えることにしよう。
•
「汎用レジスタ」16 個の集合1
•
命令群（1 本のプログラム）を格納するメモリ
•
それとは別の、データ項目を格納するメモリ
どのレジスタも、32 ビットの整数値を格納できる。命令メモリには、実行すべき命令のシー
ケンスが格納される。前述したようにスタートアップは無視し、すでにプログラムが命令メモ
リに置かれていると想定する。そしてデータメモリには、データの値を格納する。このコン
ピュータのメモリは、どちらもバイトアクセスが可能と想定するので、メモリ上のバイトは、
独自のアドレスを持つ。
表6‒1 に、その架空のコンピュータが実装する4 つの基本命令を示す。
1　ハードウェアエンジニアは、レジスタの集合を実装するハードウェアユニットを「register ﬁle」
（レジ
スタファイル）と呼ぶ。
hi.0412.ko.2002@gmail.com
　6.3
サンプルの命令セット
105
表6‒1：サンプルの4 つの命令とその意味
命令
意味
add
2 つのレジスタにある整数を加算し、その結果を第3 のレ
ジスタに置く
load
データメモリから整数をレジスタにロードする
store
レジスタに入っている整数をデータメモリにストアする
jump
命令メモリの新しい場所にジャンプする
最もわかりやすいのがadd 命令だ。この命令は2 個のレジスタから整数値を取得して足し合
わせ、その結果を第3 のレジスタに入れる。たとえば、あるadd 命令は、レジスタ2 と3 の内
容を加算して結果をレジスタ4 に置く。もしレジスタ2 に50 が含まれ、レジスタ3 に60 が
含まれていたら、そのadd 命令はレジスタ4 に、110（レジスタ2 と3 の整数の和）を置く。
アセンブリ言語で、そのような命令を指定するには、命令名（ニーモニック）のあとにオペ
ランドを並べる。たとえば、先ほど述べたadd 命令をプログラマがコーディングするときは、
次のように書く。
add
r4, r2, r3
ここではレジスタX を指定するためにrX という表記を使っている。最初のオペランドが「デ
スティネーションレジスタ」で、そのレジスタに結果が置かれる。第2、第3 のオペランドは
「ソースレジスタ群」で、add 命令はその2 つのレジスタから、加算すべき2 つの値を得る。
load とstore の命令は、データメモリとレジスタの間で値を移す。一般的なプロセッサと
同じく、われわれの架空のプロセッサも、add 命令の両方のオペランドがレジスタにあること
を要求する。そして一般のコンピュータと同じく、この架空のプロセッサも大きなデータメモ
リを持つがレジスタの数は少ない。その結果として、メモリに存在する2 つの整数を加算する
には、それらの値を2 つのレジスタにロードする必要がある。load 命令は、メモリ内の整数を
1 つコピーして、そのコピーをレジスタに入れる。store 命令は、その反対方向にデータを移
す。つまり、現在レジスタにある値のコピーを作り、そのコピーをメモリ上に整数として置く。
load やstore のオペランドの1 つは、ロードまたはストアするレジスタを指定するだけだ
が、もう1 つのオペランドは、より興味深い。これも一般的なプロセッサで見られる機能だが、
1 個のオペランドで2 つの値を組み合わせてメモリアドレスを指定する。つまりアドレスを指
定するメモリオペランドに、2 つの部分が含まれるのだ。その片方でレジスタを指定し、もう
片方では「オフセット」と呼ばれる定数を指定する。その命令が実行されるとき、プロセッサ
は指定されたレジスタから現在の値を読み、それにオフセットを加算した結果をメモリアドレ
スとして使う。
hi.0412.ko.2002@gmail.com
106
第6 章
データパスと命令実行　
例を見たほうがわかりやすい。値をメモリからレジスタ1 にロードするload 命令は、次の
ように書ける。
load
r1, 20(r3)
最初のオペランドは、値をレジスタ1 にロードせよという指定だ。そして第2 のオペランド
は、レジスタ3 の現在の内容にオフセット20 を加えてメモリアドレスを計算せよ、という指
定である。
レジスタにオフセットを加えるオペランド指定を持つようにプロセッサが設計される理由は
何だろうか。この形式を使うと、配列の巡回処理が容易になり、効率も良くなる。最初の要素
のアドレスをレジスタに入れておけば、オペランドの定数部を使って、要素の何バイトめをア
クセスするかを指定できる。配列の次の要素に進むには、レジスタを要素のサイズだけインク
リメントする（値を増やす）
。だが、いまは、このようなオペランドが使われることだけを理解
して、それを実装できるハードウェア設計を考えることにする。
たとえば、レジスタ3 に10000 という値が入っているときに、上記のload 命令で20 とい
うオフセットが指定されたとしよう。この命令を実行するとき、ハードウェアは10000 に20
を加え、その結果をメモリアドレスとして扱い、10020 番地にある整数をレジスタ1 にロード
する。
第4 の命令、jump は、命令メモリのアドレスをプロセッサに与えることで実行の流れを制御
する。この架空のプロセッサは、普通は一般のプロセッサと同じく、ある命令を実行したらメ
モリで次の位置にある命令へと自動的に進む。けれどもjump 命令に遭遇したとき、プロセッ
サは次の命令に進む代わりに、そのjump 命令のオペランドを使ってメモリアドレスを計算し、
そのアドレスから実行を始める。
load とstore の命令と同じく、このjump 命令でも、オペランドにレジスタとオフセット
の両方を指定できる。たとえば次の命令、
jump
60(r11)
で、プロセッサはレジスタ11 の内容を取得し、それに60 を足し、その結果を命令メモリの
アドレスとして扱うので、そのアドレスが次の命令を実行すべき場所となる。なぜプロセッサ
にjump 命令があるのかは、いまのところ重要ではない。理解しておく必要があるのは、プロ
グラムの新しい場所への移動を、どうやってハードウェアが処理するかである。
hi.0412.ko.2002@gmail.com
　6.4
メモリ内の命令
107
6.4 　メモリ内の命令
前述したように、この架空のコンピュータではプロセッサが実行すべき命令群が命令メモリ
にあって、それぞれの命令が32 ビットを占めている。コンピュータの設計者は、それぞれの命
令で各ビットが何を意味するのかを決める命令のフォーマットを厳密に指定する。図6‒1 に、
このコンピュータの命令フォーマットを示す。
演算 
reg A 
reg B 
dst reg 
未使用
演算 
reg A 
未使用 
dst reg 
オフセッ
ト
演算 
reg A 
reg B 
未使用 
オフセッ
ト
演算 
reg A 
未使用 
未使用 
オフセッ
ト
add
load
store
jump
0 0 0 0 1
0 0 0 1 0
0 0 0 1 1
0 0 1 0 0
図6‒1：表6‒1 で示した4 つの命令のバイナリ表現。どの命令も長さは32 ビット2
各命令に使われているフィールドを観察しよう。一部のフィールドは命令によっては不要だ
が、
それにもかかわらず、
どの命令も完全に同じフォーマットである。このように均一なフォー
マットにすれば、命令からフィールドを抽出するハードウェアを設計しやすくなる。
命令の演算フィールドは、opcode フィールドとも呼ばれる。ここには、演算を指定する値
が含まれる。この例で、add 命令の演算フィールドは1、load 命令の演算フィールドは2 の値
に設定されている（以下同様）
。命令をフェッチしたハードウェアは、この演算フィールドを
使って、実行すべき演算を判定する。
名前に「reg」がある3 種類のフィールドで3 つのレジスタを指定できるが、3 つのレジス
タ全部を必要とするのはadd 命令だけだ。その他の命令では、1 つか2 つのレジスタフィール
ドが、使われていない。ハードウェアは、add 以外の命令を実行するとき、未使用フィールド
を無視する。
上記のコードで、各命令におけるオペランドの順序は、予想に反して一貫性がないように思
われるかもしれない。たとえばadd 命令を書くときは、デスティネーション（結果を入れる
レジスタ）を左側に書き、加算すべき2 つのレジスタを右側に書く。ところが命令フォーマッ
トを見ると、加算すべき2 つのレジスタを指定するフィールドが、デスティネーション指定の
フィールドより前にある。プログラマが書くステートメントと、メモリ内のビット列に変換さ
2　訳注：reg はレジスタの略。dst はデスティネーションの略。
hi.0412.ko.2002@gmail.com
108
第6 章
データパスと命令実行　
れた命令を、図6‒2 に示す。要点をまとめると次のようになる。
アセンブリ言語プログラムにおけるオペランドの順序は、プログラマにとって便利なよ
うに選択される。メモリ内の命令におけるオペランドの順序は、ハードウェアの効率が
良くなるように選択される。
add          r4,  r2,  r3
(a)
演算 
reg A 
reg B 
dst reg 
oﬀset
0 0 0 0 1 0 0 1 0 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
(b)
図6‒2：（a）プログラマから見たadd 命令の例と、
（b）その命令をメモリに格納したもの
この図を見ると、reg A というラベルのフィールドにある数値2 で、レジスタ2 を指定し、
reg B というラベルのフィールドにある数値3 で、レジスタ3 を指定している。そして、dst
reg というラベルのフィールドに数値4 があるのは、結果をレジスタ4 に入れるという指定で
ある。
ハードウェアを調べると、命令で使われるビット表現が、ハードウェア設計をシンプルにす
るため慎重に選択されたフォーマットなのだと納得できる。たとえば、もし命令の中にメモリ
アドレスを指定するオペランドがあれば、そのオペランドのレジスタには、常にreg A という
ラベルのフィールドが割り当てられる。したがって、もしハードウェアがレジスタにオフセッ
トを追加する必要があれば、そのレジスタは必ずreg A フィールドで判明する。同様に、もし
レジスタに値を書く必要があれば、そのレジスタはdst reg フィールドで判明する。
6.5 　次の命令に進む
複数ステップの固定シーケンスがあるとき、クロックでタイミングを制御する方法は第2 章
で示した。しかしコンピュータを作るには、もう一工夫が必要だ。ただ固定されたシーケンス
で複数のステップを実行するのではなく、コンピュータはプログラミングが可能である。つま
りコンピュータには、どの命令でも実行できるハードウェアが存在するが、実行すべき命令の
シーケンスは、あらかじめ固定されていない。命令シーケンスは、プログラマがメモリにプロ
グラムとしてストアし、そのメモリをプロセッサが読み進めながら、連続する命令を1 つずつ
読み出しては実行する。今後の節では、そのようなプログラミングを可能にするために、デジ
タル論理回路を配置する方法を示す。
メモリの命令を読んで実行するのに必要なハードウェアは、何だろうか。主な要素の1 つは、
「命令ポインタ」だ。命令ポインタを構成するのは、次に実行すべき命令のメモリアドレスを格
hi.0412.ko.2002@gmail.com
　6.5
次の命令に進む
109
納する、プロセッサ内のレジスタだ（これはラッチの集合である）
。たとえば、32 ビットのメモ
リアドレスを持つコンピュータを想定すると、命令ポインタは32 ビットの値を格納すること
になる。命令のシーケンスを実行するために、ハードウェアは次の3 つのステップを繰り返す。
•
命令ポインタをメモリアドレスとして、その場所から命令をフェッチする
•
命令のビット列を使って、演算を実行するハードウェアを制御する
•
命令ポインタを、次の命令へと進める
命令を実行できるプロセッサで、もっとも重要な側面の1 つは、次の命令へと進める機構に
関するものだ。命令メモリから命令を取り出したら、次にプロセッサは、その直後にある命令
のメモリアドレスを計算しなければならない。だから所与の命令を実行したプロセッサは、そ
の次に続く命令を実行する準備ができている。
このコンピュータでは、どの命令もメモリで32 ビットを占める。けれどもメモリはバイト
単位でアドレッシング可能なのだから、命令を実行し終えたハードウェアは次の命令に進むた
めに、命令ポインタを4 バイト（32 ビット）インクリメントする必要がある。要するにプロ
セッサは、命令ポインタに4 を加えた結果を命令ポインタに書き戻す必要がある。その計算を
実行するため、定数4 と命令ポインタの現在の値が、32 ビットの「加算器」
（adder）に渡さ
れる。図6‒3 は、命令ポインタをインクリメントするための基本的なコンポーネントと、それ
らの接続方法を示している。
32bit
pgm. ctr.
32bit
adder
4
プログラムカウンタの値は
他のコンポーネン
トで使われる
図6‒3：プログラムカウンタをインクリメントするハードウェア。pgm. ctr. はプログラムカウンタ（命令ポ
インタと同じ意味）
この図の回路は、ひたすらプログラムカウンタをインクリメントし続ける無限ループに見え
るかもしれない。回路が暴走せずに正しく動作する仕組みを理解するには、デジタル回路の制
御と同期にクロックが使われることを思い出す必要がある。このプログラムカウンタは、ク
ロックによって、命令を実行した後にだけインクリメントが発生するようにしている。図には
クロックを示していないが、回路のコンポーネントは、どれもクロックに繋がれている。そし
hi.0412.ko.2002@gmail.com
110
第6 章
データパスと命令実行　
て、コンポーネントはクロックにしたがって動作することが前提になる。加算器は新しい値を
即座に計算するが、プログラムカウンタはクロックのパルスが来るまで更新されない。この議
論を通じて、クロックのパルスが1 命令ごとに1 回発生することを前提とする。
図に引かれている線は、どれもパラレルな複数のワイヤで構成される「データパス」を表現
している。この図のデータパスは、どれも32 ビット幅である。したがって加算器が受け取る
2 つの入力は、どちらも32 ビットだ。そのうち命令ポインタからの値は、命令ポインタが32
ビットだから当然だ。もう1 つの、4 というラベルがある入力は、4 という数値を持つ32 ビッ
ト定数を表現する。つまり、32 本のワイヤのうち、3 番目を除くすべてのワイヤがゼロなのだ。
加算器が、その和を計算して、32 ビットの結果を作る。
6.6 　命令をフェッチする
コンピュータを作るための次のステップは、メモリから命令をフェッチすることだ。このシ
ンプルな例では、実行すべきプログラムが専用の「命令メモリ」に格納され、メモリのハード
ウェアユニットが、入力として受け取るアドレスで指定されたメモリの場所から、32 ビットの
データ値を取り出すことが前提となる。メモリはバイトの配列で、パラレルな入力線と出力線
を備えている。入力線に値が置かれると、メモリは、その値をデコーダの入力として該当する
4 バイトを選び、その場所に置かれている値を出力線にセットする。図6‒4 は、命令メモリの
アドレスとして、プログラムカウンタの値を使う方法を示している。
32bit
pgm. ctr.
32bit
adder
4
命令メモリ
addr.
in
data
out
メモリからの命令
図6‒4：命令フェッチのときに使われるデータパス。プログラムカウンタの値がメモリアドレスとして使わ
れる。addr. はアドレス
hi.0412.ko.2002@gmail.com
　6.7
命令をデコードする
111
6.7 　命令をデコードする
メモリからフェッチした命令は32 ビットで構成される。命令実行における次の段階は、
「命
令デコーディング」
だ。つまりハードウェアは、
「演算」
、
「レジスタ」
、
「オフセット」
の各フィー
ルドを命令から切り分ける。命令のビット構成は図6‒1 で示した。それぞれの構成要素に別々
のビットフィールドを使っているので、命令のデコードは簡単だ。ハードウェアは、
「演算」
フィールド、3 個の「レジスタ」フィールド、そして「オフセット」フィールドの、それぞれの
ビット群を運ぶワイヤを分離するだけでよい。図6‒5 に、命令メモリからの出力を命令デコー
ダに供給する方法を示す。
32bit
pgm. ctr.
32bit
adder
4
命令メモリ
addr.
in
data
out
命令デコーダ
src reg A
src reg B
dst reg
oﬀset
operation
図6‒5：命令デコーダが、命令メモリの出力に接続されている
この図で、命令デコーダからの個々の出力に32 ビットすべてがあるわけではない。
「演算」
operation は5 ビット、3 つのreg は、それぞれ4 ビットで構成される。
「オフセット」の出
力は15 ビットだ。このように、データパス図に引かれている線は1 ビット以上のデータと考
えられる。
デコーダの出力が、命令を切り分けたフィールド群で構成される。これを理解するのが重要
なことだ。たとえばoffset というラベルのパスは、命令から切り分けた15 ビットのオフセッ
トを含んでいる。同様に、reg A というラベルの付いたデータパスは、命令のreg A フィール
ドにあった4 ビットだけを含んでいる。重要なポイントとして、reg A のデータは、どのレジ
スタを使うかを指定するだけで、現在レジスタに存在する値を運ぶのではない。
サンプルの命令デコーダは命令からビットフィールドを取り出すだけで、フィールドの
解釈は行わない。
われわれの架空のコンピュータと違って、現実のプロセッサには複数の命令フォーマットが
hi.0412.ko.2002@gmail.com
112
第6 章
データパスと命令実行　
あるかもしれない。たとえば算術命令のフィールドは、メモリをアクセスする命令のフィール
ドとは違う場所にあるかもしれない。さらに、現実のプロセッサには可変長の命令があるかも
しれない。その結果、命令デコーダは「演算」フィールドを調べないと、フィールドの位置を
決められないかもしれない。けれども原則は同じだ。デコーダは命令からフィールドを抽出し
て、それらのフィールドをデータパスに渡す。
6.8 　レジスタユニットへの接続
命令の「レジスタ」フィールドは、その命令で使うレジスタの選択に利用される。この例で、
jump 命令は1 個、load とstore の命令は2 個、add 命令は3 個のレジスタを使う。したがっ
て、図6‒6 に示すように、最大で3 つある「レジスタ」フィールドのそれぞれを、1 個のレジ
スタユニットに接続する必要がある。
32bit
pgm. ctr. 
32bit
adder
4
命令メモリ
addr.
in
data
out
レジスタ
ユニッ
ト
data in
命令デコーダ
reg A
reg B
dst reg
ソースレジスタAの内容
ソースレジスタBの内容
oﬀset
operation
図6‒6：レジスタユニットを命令デコーダに接続する
6.9 　制御と連携
3 つの「レジスタ」フィールドは、どれもレジスタユニットに接続されるが、レジスタユニッ
トがいつでも3 つのレジスタを全部使うわけではない。レジスタユニットには、与えられた命
令が、レジスタに存在する値を読み出すか否か、レジスタの1 つにデータを書くか否かを判定
するロジックが含まれている。load とadd の命令は、それぞれ1 個の結果をレジスタに書く
が、jump とstore の命令は、それを行わない。
それならいっそ、命令の「演算」フィールドをレジスタユニットに渡して、どうすればよいか
ユニットに知らせれば良いと思われるかもしれない。しかし図を見ると、命令の残りのフィー
hi.0412.ko.2002@gmail.com
　6.10
算術演算とマルチプレクサの働き
113
ルドはレジスタユニットに接続されていない。その理由を理解するには、図で見ているのが
データパス（データを流すことのできるハードウェア経路）だけだということを思い出そう。
実際のコンピュータでは、図に示したユニットのそれぞれに、制御信号を送る配線が追加され
る。たとえば、どのユニットも連携して正しいタイミングで動作できるように（たとえば正し
いアドレスが計算されるまでは、決してデータメモリに値が格納されないように）クロックシ
グナルを受け取る必要がある。
実際は、ほとんどのコンピュータに「コントローラ」と呼ばれるハードウェアユニットが加わ
り、それによって全体的なデータの動きや個々の機能ユニットを連携させている。コントロー
ラは、他のユニットに対して、それぞれ1 本以上の接続を持っている。命令を実行するのに各
ユニットがどのように動作すべきかを、コントローラは命令の「演算」フィールドから決定し
なければならない。たとえば、この図で言えばコントローラとレジスタユニットを繋ぐ接続を
使って、レジスタユニットが1 個または2 個のレジスタから値をフェッチするのか、また、ユ
ニットはレジスタに書くべきデータを受け取るべきかを、指定する必要がある。いまは、すべ
てのユニットの動作を連係させるコントローラが存在することを前提としている。
6.10 　算術演算とマルチプレクサの働き
サンプルの命令セットは、
ある重要な原則を示している。それは、
ハードウェアは機能ユニッ
トを再利用するように設計されるということだ。たとえば算術について言えば、明示的に算術
演算を実行する命令はadd だけである。実際のプロセッサならば、いくつか算術命令や論理命
令を持ち（たとえば除算、シフト、論理積など）
、命令の「演算」フィールドを使って、ALU で
実行すべき処理を決めることになるだろう。
この命令セットには暗黙的な算術演算が存在し、それはload、store、jump の命令で使わ
れる。これらの命令では、命令の実行時に加算が要求される。具体的に言うと、プロセッサは
命令そのものに含まれているオフセット値をレジスタの内容に加算しなければならない。そう
して計算した結果が、メモリアドレスとして扱われる。
そこで疑問が生じる。プロセッサは、アドレス計算に必要なハードウェアユニットを別に持
つべきか、それとも1 個のALU を、一般的な算術とアドレス計算の両方に使うべきなのか。こ
のような疑問が、プロセッサ設計における主な判断の基礎となる。別々の機能ユニットを持つ
ことには、性能と設計の容易さという利点がある。複数の目的に機能ユニットを再利用するこ
とには、消費電力が少ないという利点がある。
われわれの設計は再利用の例を示している。多くのプロセッサと同じく、われわれの設計に
も、すべての算術演算を実行する3、1 個の「ALU」が含まれている。サンプルの命令セットで、
ALU の入力となるソースには、2 つのケースがある。レジスタのペアから来る場合と、レジス
3　プログラムカウンタのインクリメントも、その特別なケースだ。
hi.0412.ko.2002@gmail.com
114
第6 章
データパスと命令実行　
タ1 個と命令内の「オフセット」フィールドから来る場合だ。ハードウェアユニットは複数の
入力ソースを、どうやって選択するのだろうか。2 つ以上の入力からの選択を調整する機構は、
「マルチプレクサ」と呼ばれる。基本的なアイデアは、こうだ。マルチプレクサにはK 個のデー
タ入力と、1 個のデータ出力と、どの入力を出力に送るかを指定する一群の制御線がある。マ
ルチプレクサの使い方を理解するために、図6‒7 を見よう。レジスタユニットとALU の間に
マルチプレクサがある。この図の線が、どれも32 ビットのデータパスだということを忘れて
はいけない。したがって、このマルチプレクサの入力と出力は、いずれも32 ビットを含んで
いる。マルチプレクサは、2 つの入力の片方から、その32 ビットすべてを選択し、それらを出
力に送る。
32bit
pgm. ctr. 
32bit
adder
4
命令メモリ
addr.
in
data
out
レジスタ
ユニッ
ト
data in
命令デコーダ
マルチプレクサ
ALU
ALU output
reg A
reg B
dst reg
oﬀset
operation
図6‒7：ALU の入力を選択するためにマルチプレクサを使う
この図でマルチプレクサの入力は、レジスタユニットと、命令の「オフセット」フィールド
から来ている。マルチプレクサは、どちらの入力を渡すかを、どうやって決めるのだろうか。
図がデータパスだけを示していることを思い出そう。そのほかに、プロセッサにはコントロー
ラが存在し、すべてのユニットはコントローラに接続されている。プロセッサがadd 命令を実
行するとき、コントローラはマルチプレクサに対する信号で、レジスタからの入力を選択する
ように知らせる。プロセッサが他の命令を実行するとき、コントローラはマルチプレクサに、
命令の「オフセット」フィールドから来る入力を選択するように知らせる。
命令の「演算」フィールドもALU に渡されることに注目しよう。これによってALU は、
どの演算を行うべきかを決める。算術命令または論理命令（add、subtract、right shift、
logical and など）の場合、ALU は、その「演算」を使って適切な処理を選ぶ。他の命令の
場合、ALU は加算を実行する。
hi.0412.ko.2002@gmail.com
　6.11
メモリ上のデータに関わる演算
115
6.11 　メモリ上のデータに関わる演算
load またはstore の演算を実行するとき、コンピュータはデータメモリ上の項目を参照し
なければならない。これらの演算では、ALU を使ってレジスタの内容に命令内のオフセットを
加算し、その結果をメモリアドレスとして使う。われわれの単純化された設計では、データ格
納用のメモリが、命令格納用のメモリから分離されている。図6‒8 に、データメモリへの接続
に使われるデータパスを示す。
M1
M3
32bit
pgm. ctr.
32bit
adder
4
命令メモリ
addr.
in
data
out
レジスタ
ユニッ
ト
data in
命令デコーダ
データメモリ
ALU
reg A
reg B
dst reg
M2
oﬀset
operation
addr.
in
data
in
data
out
図6‒8：データメモリを含むデータパス4
6.12 　実行シーケンスの例
どのように計算が進行するのかを理解するために、それぞれの命令で使われるデータパスを
考えてみよう。以下の段落で各命令のシーケンスを説明するが、どの命令でも、プログラムカ
ウンタが命令のアドレスを与え、それが命令メモリに渡される。命令メモリは、メモリから
フェッチした値のビット列を命令デコーダに渡す。デコーダは命令をフィールドに分けて、そ
れらを別のユニットに渡す。その後の演算は、命令によって異なる。
add（加算命令）
add 命令の場合、レジスタユニットに3 つのレジスタ番号が渡される。それらは図中でreg
A、reg B、dst reg のラベルが付いたパスを通って来る。レジスタユニットは、最初の2 つの
4　訳注：M1、M2、M3 はマルチプレクサ
hi.0412.ko.2002@gmail.com
116
第6 章
データパスと命令実行　
レジスタから値をフェッチしてALU に渡す。そしてレジスタユニットは、第3 のレジスタに
書き込む準備をする。ALU は演算コードによって、加算が要求されていると判断する。レジス
タユニットからのreg B 出力をALU に渡すため、
（図に示していない）コントローラが、レジ
スタユニットのB の値を渡し、デコーダからのオフセット値は無視するように、マルチプレク
サM2 を設定しなければならない。そしてコントローラは、ALU からの出力をレジスタユニッ
トのdata input に渡すようにマルチプレクサM3 を設定する一方で、マルチプレクサM1 を、
ALU からの出力を無視するように設定する必要がある。ALU からの出力がレジスタユニット
の入力に届いたら、レジスタユニットは、その値を、dst reg というラベルのパスで指定され
たレジスタにストアする。それで演算は完了する。
store（ストア命令）
store 命令がメモリからフェッチされ、デコードされたら、レジスタユニットがレジスタA
とB の値をフェッチし、それらを出力線に置く。マルチプレクサM2 は、
「オフセット」フィー
ルドをALU に渡し、レジスタB の値は無視するように設定される。コントローラがALU に加
算の実行を指示し、ALU はオフセットとレジスタA の内容を加算する。その結果の和が、アド
レスとしてデータメモリに渡される。それと同時に、レジスタB の値（レジスタユニットから
の第2 の出力）が、データとしてデータメモリに渡される。コントローラがデータメモリに対
して「write」演算の実行を指示するので、データメモリはレジスタB の値を、アドレス線の
値で指定された場所に書く。それで演算は完了する。
load（ロード命令）
load 命令がメモリからフェッチされ、デコードされたら、ALU がレジスタA の内容と命令
の「オフセット」フィールドを受け取るように、コントローラがマルチプレクサM2 を設定す
る。store と同様に、コントローラがALU に加算の実行を指示し、その結果がアドレスとして
データメモリに渡される。コントローラはデータメモリに対してフェッチ演算の実行を指示す
る。これによって、データメモリの出力は、アドレス入力で与えられた場所の値となる。コン
トローラはマルチプレクサM3 を、ALU からの出力を無視し、データメモリからの出力をレジ
スタユニットのdata in パスに渡すように設定する。コントローラはレジスタユニットに信
号を送って、その入力値をdst reg として指定されたレジスタに格納するよう指示する。レ
ジスタユニットが値を格納したら、命令の実行は完了する。
jump（ジャンプ命令）
jump 命令がメモリからフェッチされ、デコードされたら、コントローラがマルチプレクサ
M2 の設定により、命令の「オフセット」フィールドを渡して、ALU に加算の実行を指示する。
ALU は、そのオフセットをレジスタA の内容に加算する。その結果をアドレスとして使うた
め、コントローラは、ALU からの出力を渡し、データメモリからの出力は無視するようにマル
チプレクサM3 を設定する。最後にコントローラは、マルチプレクサM1 を設定して、ALU か
らの値をプログラムカウンタに渡す。これによってALU が出した結果が、32bit プログラムカ
hi.0412.ko.2002@gmail.com
　6.13
まとめ
117
ウンタの入力になる。プログラムカウンタが、その値を受け取って格納すると、命令は完了す
る。プログラムカウンタは、次の命令をフェッチすべきメモリアドレスを常に指定する。した
がって、次に命令を実行するときは、前の命令で計算したアドレスから命令が取り出される。
つまりプログラムは新しい場所にジャンプする。
6.13 　まとめ
コンピュータシステムが「プログラマブル」
（プログラミング可能）だというのは、演算シー
ケンスの全体がデジタル論理回路にハードワイヤリング（固定配線）されるのではなく、コン
ピュータがメモリから読み出した命令を実行するということだ。プログラマビリティ（プログ
ラムを組めること）は、とても大きな計算能力と柔軟性を与えてくれる。新しいプログラムを
メモリにロードすることによって、コンピュータの機能を変更できるのだ。命令を実行するコ
ンピュータ全体の設計は複雑だが、基本的なコンポーネントは理解し難いものではない。
コンピュータは複数のコンポーネントで構成される。それらは、プログラムカウンタ、メ
モリ、レジスタユニット、ALU などだ。コンポーネントを接続することで、コンピュータの
「データパス」が作られる。この章では、基本的な命令を実行するのに十分なコンポーネントを
調べ、命令のフェッチとデコードと実行のステップに関わるハードウェアを検討した（それに
はレジスタとデータのアクセスも含まれる）
。命令の符号化では、ハードウェア設計が容易に
なる方式が選択される。つまり命令から各フィールドを抽出して、それぞれのハードウェアユ
ニットに渡せるような設計である。
それぞれのハードウェアユニットには、データパスだけでなく、コントローラとの接続もあ
る。マルチプレクサは、ハードウェア間のデータ経路をコントローラが選べるようにする重要
な機構だ。基本的に、それぞれのマルチプレクサがスイッチの役割を果たして、いくつか存在
するソースの1 つを選び、そのデータが所与の出力に送られるようにする。命令が実行される
とき、コントローラは命令のフィールドを使って、その命令のためにマルチプレクサをどう設
定するかを決める。マルチプレクサのおかげで、1 個のALU を、アドレスオフセットの計算に
も、算術命令の計算にも使うことができる。
この章では、基本的な命令の実行を検討し、コンピュータのデータパスに注目して、所与の
ハードウェアユニットにどの値を渡すかを、マルチプレクサで制御する方法を見てきた。たと
えばマルチプレクサは、プログラムカウンタの値に4 を足して次の命令に進むのか、それとも
ALU の出力値で値を置き換えてジャンプを実行するのかを、選択する。
練習問題
6.1
サンプルのシステムは、フォン・ノイマン・アーキテクチャにしたがっていますか?
理由も述べなさい。
6.2
図6‒2 を参考にして、次の命令がメモリに格納されているとき、個々のビットがど
hi.0412.ko.2002@gmail.com
118
第6 章
データパスと命令実行　
うなるかを示しなさい。
add
r1, r14, r9
6.3
図6‒1、6‒2 を参考にして、次の命令がメモリに格納されているとき、個々のビット
がどうなるかを示しなさい。
load
r7, 43(r15)
6.4
次の命令が無効になるのは、なぜですか?
ヒント：この命令をメモリに格納するという点を考慮します。
jump
40000(r15)
6.5
この章で示したサンプルは、4 つの命令を使っています。図6‒1 のバイナリ表現で、
最大いくつの命令を作成できますか?
6.6
図6‒4 の回路は、なぜ単なる無限ループとして暴走しないのでしょうか。説明して
ください。
6.7
jump 命令を実行するときに、ALU が実行する演算は何ですか?
6.8
データパス図（たとえば図6‒8）では、多くの詳細が隠されています。もしサンプル
を変更して、どの命令も64bit 長にしたら、この図にどれほどの変更が必要になりま
すか?
6.9
さらに、すべての命令を表にして、それぞれの命令実行時の個々のマルチプレクサの
設定を記入してください。
6.10
サンプルシステムを更新して、右シフトと減算の命令を加えましょう。
6.11
図6‒8 で、add 命令のときにマルチプレクサM1 が出力に選ぶのは、どの入力で
すか?
6.12
図6‒8 で、
マルチプレクサM3 がALU からの入力を選択するのは、
どの命令ですか?
6.13
図6‒8 のコンピュータシステムを、相対分岐命令を含むように再設計しましょう。
「オフセット」フィールドに符号付きの値が含まれることにします。その値を現在のプ
ログラムカウンタに加算してプログラムカウンタの次の値を作るようにしましょう。
6.14
図6‒8 のシステムは、乗算を処理できますか? 理由も述べなさい。
hi.0412.ko.2002@gmail.com
第7 章
オペランドのアドレッシングと命令表現
7.1 　はじめに
これまでの章で、プロセッサの種類を論じ、命令セットを考察した。この章では命令に関す
る2 つの詳細に焦点を当てる。1 つは命令をメモリでどう表現するか。もう1 つは、どうやっ
てオペランドを指定するかだ。プログラマにとって、とくにオペランドの形式が重要なことが、
それで判明するだろう。また、命令の表現によって、利用可能なオペランド形式がどのように
定まるのかを理解できるだろう。
次の章でもプロセッサの議論を続け、CPU がどのように動作するかを説明する。これまで論
じてきた多くの機能が、CPU という大規模な、一体化されたシステムに、どうやって統合され
るのかを見ることになる。
7.2 　0/1/2/3 アドレス設計
前述したように、命令は普通、オペコードと、それに続く0 個以上の「オペランド」として
格納される。オペランドは、いくつ必要だろうか。
「第5 章　プロセッサの種類と命令セット」
の議論では、オペランドの数は実行される演算によって決まるのが前提だった。add 命令が少
なくとも2 つのオペランドを必要とするのは、加算に少なくとも2 つの数量が関わるからだ。
同様に、ブール演算のNOT 命令は1 個のオペランドを必要とする。論理の否定に関わる数量は
1 個だけだ。しかし、第5 章であげたサンプルのMIPS 命令セットでは、結果の場所を指定す
るオペランドも、それぞれの命令に加わっていた。だからサンプルの命令セットでもadd 命令
に3 個のオペランドが必要で、2 つは加算する値を指定し、第3 のオペランドは結果の置き場
所を指定していた。
それぞれの命令で任意の数のオペランドを持つプロセッサという考えには、感覚的に頷ける
ものがあるけれど、多くのプロセッサは、この案に同意していない。その理由を理解するには、
hi.0412.ko.2002@gmail.com
120
第7 章
オペランドのアドレッシングと命令表現　
根底にあるハードウェアを考慮する必要がある。第1 に、任意の数のオペランドは可変長命令
を意味するから、命令のフェッチとデコードは、固定長命令より効率が悪い。第2 に、任意の
数のオペランドをフェッチするには時間がかかるから、そういうプロセッサはオペランド数が
固定されたプロセッサよりも実行が遅い。
効率の悪さは、部分的には並列的なハードウェアで解決できると思われるかもしれない。た
とえば並列するハードウェアユニットが、それぞれ命令のオペランドを1 つずつフェッチす
ると想像しよう。もし命令にオペランドが2 つあれば、2 つのユニットが同時に動作する。命
令にオペランドが4 つあれば、4 つのユニットが同時に動く。けれども、並列的なハードウェ
アはチップ上に占める空間が大きく、電力も余計に消費する。さらに、チップのピン数によっ
て、チップから並列アクセス可能な外部データの量も制限される。したがって、並列的なハー
ドウェアは、多くの場合（たとえばバッテリー電源で動作する携帯電話機などのプロセッサで
は）魅力的なオプションではない。
そもそも任意の個数のオペランドを許さずに命令セットを設計できるものだろうか。もし可
能なら、
一般的な計算で実用になる最小限のオペランドは、
いくつだろうか。初期のコンピュー
タは、どの命令にも1 個のオペランドしか持たせないという案を使うことで、その質問に答え
ている。その後のコンピュータでは、それぞれの命令につきオペランドを2 個に制限した命令
セットが現れた。驚くべきことに、命令自身には1 つもオペランドを持たせないコンピュータ
も存在する。そして前章で見たように、一部のプロセッサでは命令のオペランドが3 個に限定
される。
7.3 　0 オペランド命令
命令がオペランドを持たないアーキテクチャは、
「0 アドレス」アーキテクチャと呼ばれる。
どんなアーキテクチャが、オペランドを指定しない命令を実現できるのだろうか。それにはオ
ペランドが暗黙的でなければならない。つまり、オペランドの場所が、あらかじめ判明してい
る必要がある。
「スタックアーキテクチャ」とも呼ばれる0 アドレスアーキテクチャでは、オ
ペランドを実行時のスタックに置く。たとえばadd 命令は2 つの値をスタックの一番上から
取り出して足し合わせ、その結果をスタックに積み戻す。もちろん、いくつか例外もあり、ス
タックコンピュータでも命令の一部ではプログラマがオペランドを指定できる。たとえば、ほ
とんどの0 アドレスアーキテクチャには、新しい値をスタックの一番上に積むpush 命令があ
り、スタックから一番上の値を取り出すpop 命令は、その値を指定されたメモリに置く。した
がって、このスタックマシンで変数X に7 を足すには、図7‒1 のような命令シーケンスを使う
ことができる。
スタックアーキテクチャの主な欠点は、
メモリの使い方に起因する。オペランドを、
プロセッ
サのレジスタからではなく、メモリからフェッチすると、ずっと時間がかかるのだ。この概念
は、後の節で論じるとして、いまのところは、コンピュータ業界がスタックアーキテクチャか
hi.0412.ko.2002@gmail.com
　7.4
1 オペランド命令
121
ら遠ざかっている理由を理解すれば十分だ。
push X
push 7
add
pop X
図7‒1：スタックコンピュータで変数X に7 を足す命令シーケンスの例。このアーキテクチャが「0 アドレ
ス」アーキテクチャと呼ばれるのは、add のような命令のオペランドが、スタックで見つかるからだ
7.4 　1 オペランド命令
個々の命令のオペランドを1 個に限定するアーキテクチャは、
「1 アドレス」設計に分類され
る。基本的に「1 アドレス」設計では、それぞれの命令が1 個の暗黙的オペランドに依存する。
それは「アキュミュレータ」と呼ばれる特別なレジスタだ1。オペランドの1 つは命令の中に
あって、プロセッサはアキュミュレータの値を第2 のオペランドとして使う。いったん演算を
実行したら、プロセッサは結果をアキュミュレータに書き戻す。それを、われわれは「アキュ
ミュレータの値に対する演算」を行う命令と考える。算術演算を例にしよう。次の加算命令に
はX というオペランドがある。
add X
この命令に遭遇すると、プロセッサは次の演算を行う。
accumulator ←accumulator + X
「1 アドレス」プロセッサの命令セットには、定数値またはメモリのどこかに存在する値を
アキュミュレータにロードする命令も、アキュミュレータの現在の値をメモリ上のどこかにス
トアする命令も、含まれる。
7.5 　2 オペランド命令
「1 アドレス」設計は、算術や論理の演算には使えるが、1 個の命令のなかで2 つの値を指
定することが許されない。たとえば、メモリ上のある場所から別の場所へと値をコピーする場
合を考えてみよう。
「1 アドレス」設計では、値をアキュミュレータにロードする命令と、その
1　「第5 章　プロセッサの種類と命令セット」で論じた汎用レジスタ群は、もともとあったアキュミュ
レータの概念を拡大したものと考えられるだろう。
hi.0412.ko.2002@gmail.com
122
第7 章
オペランドのアドレッシングと命令表現　
値を新しい場所にストアする命令の、2 つが必要だ。この設計は、ディスプレイのメモリでグ
ラフックスオブジェクトを動かすようなシステムでは、とくに効率が悪い。
「1 アドレス」システムの制限を打破するために、設計者たちは、それぞれの命令に2 個の
アドレスを持たせるプロセッサを開発した。このアプローチは「2 アドレス」アーキテクチャ
と呼ばれる。
「2 アドレス」プロセッサでは演算の対象がアキュミュレータに限定されず、指定
の値に演算を適用できる。
「2 アドレス」プロセッサで、次の命令は、
add X Y
X の値をY の現在の値に加える。
Y ←Y + X
命令で2 個のオペランドを指定できる「2 アドレス」プロセッサは、2 つのオペランドをソー
スおよびデスティネーションとして扱うデータ転送命令を提供できる。たとえば「2 アドレス」
命令は、場所Q のデータを場所R へと、直接コピーすることができる2。
move Q R
7.6 　3 オペランド命令
「2 アドレス」設計でもデータ転送を扱えるが、とくに複数の汎用レジスタを持つプロセッ
サでは、個々の命令で3 個のオペランドを指定することで、さらなる最適化が可能だ。
「2 アド
レス」設計の場合と違って、
「3 アドレス」アーキテクチャが選択される主な動機は、3 個の入
力値が必要な演算があるからではなく、第3 のオペランドでデスティネーションを指定できる
からだ。これは重要なポイントだ。たとえば和を求める演算では、加算に使う2 つの値だけで
なく、結果を格納するデスティネーションも指定できる。
add X Y Z
上の命令は、次の代入を指定している。
Z ←X + Y
2　ある種のアーキテクチャでは、
「2 アドレス」という言葉が、両方のオペランドでメモリの場所を指定す
る命令に限って使われ、片方のオペランドがメモリで、もう片方のオペランドがレジスタならば、
「1 1
2 アド
レス」という言葉が使われる。
hi.0412.ko.2002@gmail.com
　7.7
オペランドのソースと即値
123
7.7 　オペランドのソースと即値
上記の議論では、
それぞれの命令が持てるオペランドの数に焦点を当てていて、
オペランドの
具体的な詳細には触れなかった。命令がオペランド毎に1 つのビットフィールドを持つことは、
すでに紹介したが、フィールドのビット列がどう解釈されるのかという疑問が残されている。
各種のオペランドは命令の中で、それぞれどのように表現されるのか。すべてのオペランドに
同じ表現方法を使うのか。表現には、どのような意味（セマンティクス）が与えられるのか。
この問題を理解するために、まずはオペランドとして使われるデータ値が、さまざまな方法
で取得されるという点に注目しよう。図7‒2 に、
「3 アドレス」プロセッサにおけるオペラン
ドの可能性を例示する3。
ソースとして使われるオペランド（演算で使う項目）
命令内の符号付き定数
命令内の符号なし定数
1 個の汎用レジスタの内容
メモリにある場所の内容
デスティネーションとして使われるオペランド（結果の置き場所）
1 個の汎用レジスタ
連続する1 対の汎用レジスタ
メモリにある場所
図7‒2：「3 アドレス」プロセッサでオペランドが参照できる項目の例。ソースオペランドは値を指定し、
デスティネーションオペランドは場所を指定する
この図が示しているように、ほとんどのアーキテクチャでは、オペランドを定数にすること
が許されている。オペランドのフィールドは小さいが、明示的な定数を使えるのは重要だ。な
ぜならプログラムでは、小さな定数を頻繁に使うからだ（たとえばループのインデックスを1
だけインクリメントするために）
。定数は命令の中にエンコード（符号化）するほうが高速にな
るし、使うレジスタの数も少なくなる。
われわれは、定数オペランドを「即値」
（イミディエート値）と呼ぶ。アーキテクチャによっ
て、即値を符号付きと解釈するものと、符号なしと解釈するものと、符号付きか符号なしかを
プログラマが指定できるものがある。
3　性能を向上させるため、現在の「3 アドレス」アーキテクチャではオペランドに制限を加えて、命令の
うち最大1 個のオペランドしかメモリ内の場所を参照できないようにしている（他の2 つのオペランドはレ
ジスタを指定しなければならない）
。
hi.0412.ko.2002@gmail.com
124
第7 章
オペランドのアドレッシングと命令表現　
7.8 　フォン・ノイマンのボトルネック
前述したように、プログラムとデータの両方をメモリに格納する一般的なコンピュータは、
「フォン・ノイマン・アーキテクチャ」にしたがうものと分類される。オペランドのアドレッシ
ングを考えると、フォン・ノイマン・アーキテクチャの重要な弱点が明らかになる。それは、
メモリアクセスがボトルネックになるかもしれないということだ。命令はメモリに格納される
のだから、プロセッサは命令毎に少なくとも一度はメモリを参照する必要がある。もしオペラ
ンドの1 つ以上がメモリ内の要素を指定していたら、値をフェッチまたはストアするために、
プロセッサは、さらにメモリをアクセスしなければならない。性能を最適化し、ボトルネック
を避けるために、オペランドはメモリではなくレジスタから取る必要がある。
フォン・ノイマン・アーキテクチャのコンピュータでは、メモリアクセスに費やされる
時間が、全体的な性能の制限になるかもしれない。アーキテクトは、この状況を記述す
るのに「フォン・ノイマンのボトルネック」という言葉を使い、オペランドがレジスタ
で見つかるような設計を選ぶことで、そのボトルネックを回避する。
7.9 　明示的または暗黙のオペランド符号化
オペランドを命令の中で、どう表現すべきだろうか。命令には、それぞれのオペランドのた
めのビットフィールドがあるが、それらのビットが意味するものを、アーキテクトは正確に指
定しなければいけない（たとえば即値を含むのか、レジスタの番号か、メモリアドレスか）
。コ
ンピュータアーキテクトはオペランドに対して、
「暗黙」と「明示」の2 種類の解釈を使ってき
た。以下に、この2 つのアプローチを記述する。
7.9.1
暗黙のオペランド符号化
「暗黙のオペランド符号化」のほうが、理解しやすい。暗黙の符号化を使うプロセッサでは、
オペコードでオペランドの型を指定するから、1 種類の演算に複数のオペコードが存在する。
それぞれのオペコードは、オペランドの可能な組み合わせの1 つに対応する。たとえば表7‒1
に示すのは、暗黙のオペランド符号化を使うプロセッサが加算のために提供しそうな3 つの命
令である。
この表が示すように、全部のオペランドを同様に解釈する必要はない。たとえばAdd
immediate signed という命令を考えてみよう。この命令は2 つのオペランドを取るが、
第1 オペランドはレジスタ番号として解釈され、第2 オペランドは符号付き整数として解釈さ
れる。
hi.0412.ko.2002@gmail.com
　7.10
複数の値を組み合わせるオペランド
125
表7‒1：暗黙的オペランド符号化を使う「2 アドレス」プロセッサで使う加算命令の例。オペランドの可能
な組み合わせのそれぞれに、別々のオペコードが使われる
オペコード
オペランド
意味
Add register
R1 R2
R1 ←R1 + R2
Add immediate signed
R1 I
R1 ←R1 + I
Add immediate unsigned
R1 UI
R1 ←R1 + UI
Add memory
R1 M
R1 ←R1 + memory[M]
注）R1、R2 はレジスタ番号、I は符号付き整数、UI は符号なし整数、M はメモリアドレスを意味
7.9.2
明示的なオペランド符号化
暗黙的な符号化の欠点は、表7‒1 で明らかになったように、1 種類の演算に複数のオペコー
ドが必要なことだ。実際、オペランドの組み合わせの数だけ、別々のオペコードが必要になる。
もしプロセッサが使うオペランドの種類が多ければ、オペコードの集合は極端に大きくなるか
もしれない。そこで、代案となる「明示的なオペランド符号化」では、型情報を各オペランド
に結び付ける。図7‒3 に示すのは、明示的オペランド符号化を使うアーキテクチャのための、
2 つのadd 命令のフォーマットだ。
図のように、オペランドフィールドが2 つのサブフィールドに分割され、片方はオペランド
の型を、もう片方は値を指定する。たとえばレジスタを参照するオペランドならば、最初にあ
る型フィールドによって、残りのビット列をレジスタ番号として解釈せよ、と指定される。
オペコー
ド 
オペラン
ド 1 
オペラン
ド 2
add 
レジスタ 
1 
レジスタ 
2
オペコー
ド 
オペラン
ド 1 
オペラン
ド 2
add 
レジスタ 
1
符号付き
整数
－93
図7‒3：明示的符号化を使うアーキテクチャにおけるオペランドの例。それぞれのオペランドで、型と値を
指定する
7.10 　複数の値を組み合わせるオペランド
これまでの議論によれば、それぞれのオペランドは、レジスタかメモリか命令自身から抽出
される1 個の値で構成されるはずだ。実際に、ある種のプロセッサでは個々のオペランドが持
つ値が1 個に制限される。けれども、その他のプロセッサは、複数のソースから抽出した値を
組み合わせてオペランドの値を計算できるハードウェアを提供している。ハードウェアは、値
の和を計算するのが典型的だ。
hi.0412.ko.2002@gmail.com
126
第7 章
オペランドのアドレッシングと命令表現　
複数の値で構成されるオペランドをハードウェアがどのように扱うかは、例を見ると理解し
やすいだろう。アプローチの1 つは、
「レジスタ＋オフセット」機構という単純明快なアイデ
アだ。2 つのサブフィールドで型と値を指定する代わりに、個々のオペランドが3 つのフィー
ルドで構成され、それらは「レジスタ＋オフセット型」
、
「レジスタ」
、
「オフセット」を指定す
る。プロセッサはオペランドをフェッチするとき、指定されたレジスタの内容に「オフセット」
フィールドの値を加えた結果を、オペランドとして使う。図7‒4 に、
「レジスタ＋オフセット」
オペランドを持つadd 命令の例を示す。
add 
2 
－17 
4 
76
オペコー
ド 
オペラン
ド 1 
オペラン
ド 2
レジスタ
オフセッ
ト
レジスタ
オフセッ
ト
図7‒4：このサンプルのadd 命令では、個々のオペランドがレジスタ＋オフセットで構成される。オペラン
ドをフェッチするとき、ハードウェアが、指定されたレジスタの値にオフセットを加算して、オペランドの
値を取得する
この図では、第1 オペランドとしてレジスタ2 の内容から定数17 を差し引いた値を指定し、
第2 オペランドとしてレジスタ4 の内容に定数76 を足した値を指定している。メモリを論じ
るときに明らかになるが、オペランドで「レジスタ＋オフセット」を指定できると、とくにC
言語の構造体のようなデータの集合体を参照するのに便利である。構造体を指すポインタをレ
ジスタに入れておき、オフセットを使って個々の要素を参照できるからだ。
7.11 　オペランド選択のトレードオフ
これで終わりだろうか。可能性のある設計が数多く列挙されたが、どのアプローチが採用さ
れてきたのかを、まだ論じていないではないか。しかし実を言うと、最良の選択なるものは存
在しない。これまで論じてきたオペランドのスタイルは、どれも実際に使われたことがある。
そのなかで唯一最適なスタイルが現れなかったのは、なぜか。その答えは単純で、どのスタイ
ルにも長所と短所があるからだ。それらは、プログラミングの容易さ、コードサイズ、処理速
度、ハードウェアの複雑さに関するトレードオフである。以下の段落では、いくつか設計目標
の例をあげて、オペランド選択との関連を説明しよう。
プログラミングしやすくする
オペランドの形式を複雑にすると、プログラミングが楽になる。たとえば前述したように、
オペランドでレジスタ＋オフセットを指定できれば、データ集合体の参照が単純明快になる。
同様に、
「3 アドレス」のアプローチでターゲットを明示的に指定できれば、計算結果をデス
ティネーションにコピーする命令をプログラマが追加する必要がなくなる。もちろんプログラ
ミングの容易さを最適化するには、他の側面とのトレードオフがあり、アーキテクトは、それ
らを考えなければならない。
hi.0412.ko.2002@gmail.com
　7.11
オペランド選択のトレードオフ
127
命令数を少なくする
オペランドの表現力を上げれば、プログラムの命令数が減る。たとえばオペランドでレジス
タとオフセットの両方を指定できるのなら、レジスタにオフセットを加算する命令をプログラ
ムに追加する必要がなくなる。また、
命令ごとのアドレス数を増やすことでも、
命令の数は減る
（たとえば「3 アドレス」プロセッサなら、
「2 アドレス」プロセッサより、必要な命令数が少な
くなる）
。しかし残念ながらトレードオフとして、命令数を減らすと個々の命令が大きくなる。
命令のサイズを小さくする
オペランドの数や、オペランド型の集合や、オペランドの最大サイズを制限すれば、オペラ
ンド型の識別やオペランド値の表現に必要なビット数が少なくなるから、個々の命令サイズが
小さくなる。レジスタだけを指定するオペランドは、レジスタとオフセットを指定するオペラ
ンドよりも小さくなる。だから、もっとも小さく能力の低いプロセッサは、オペランドをレジ
スタだけに制限している。load とstore の演算は別として、プログラムで使う値はどれも、
レジスタから持ってくる必要がある。けれども命令のサイズを小さくすることで表現力が弱ま
るから、必要な命令の数が増えてしまう。
即値の範囲を広くする
k ビットのフィールドには、2k 通りの値を格納できる（これは第3 章で述べた）
。オペラン
ドで指定できる即値の範囲は、割り当てるビット数によって決まる。即値の範囲を広げれば、
命令が大きくなる。
オペランドのフェッチとデコードを速くする
オペランドの数と、個々のオペランドで使える型を減らせば、ハードウェアの動作が速くな
る。たとえばスピードを最高にしたいアーキテクトは、
「レジスタ＋オフセット」設計を避け
る。ハードウェアの動作は、レジスタ＋オフセットからオペランド値を計算するより、レジス
タからオペランドをフェッチするほうが、ずっと高速にできるからだ。
ハードウェアのサイズと複雑さを減らす
集積回路で利用できる空間には制限がある。アーキテクトは、その空間をどう使うかを決め
なければならない。複雑な形式のオペランドをデコードするには、単純な形式をデコードする
より多くのハードウェアが必要だ。したがって、
オペランドの型と複雑さを制限すれば、
必要と
なる回路のサイズは小さくなる。もちろん、その選択の結果として、プログラムが大きくなっ
てしまうというトレードオフがある。
要点をまとめると、次のようになる。
プロセッサのアーキテクトたちは、さまざまな型のオペランドを作ってきた。すべての
プロセッサに唯一最適な型は、存在しない。その選択では、機能、プログラムサイズ、
値をフェッチするのに必要なハードウェアの複雑さ、性能、プログラミングの容易さを
めぐって妥協することになる。
hi.0412.ko.2002@gmail.com
128
第7 章
オペランドのアドレッシングと命令表現　
7.12 　メモリ内の値と間接参照
プロセッサは、メモリ内の値をアクセスする方法を提供しなければならない。だから少なく
とも1 個の命令に、ハードウェアがメモリアドレスとして解釈するオペランドが必要だ4。メ
モリ内の値をアクセスするのは、レジスタの値をアクセスするより、ずっと高価である。プロ
グラミングは容易になるだろうが、どの命令もメモリを参照するような設計では、性能が落ち
るのが普通だ。たいがいのプログラマはコードの構成を工夫して、よく使う値をレジスタに入
れておき、メモリ参照は必要なときにだけ行うようにしている。
さまざまな種類の「間接参照」を可能にして、メモリ参照を拡張しているプロセッサもある。
たとえばレジスタ6 経由の間接参照を指定するオペランドにより、プロセッサは次の2 ステッ
プを実行する。
•
レジスタ6 から現在の値A を取得する。
•
A をメモリアドレスと解釈し、そのメモリからオペランドをフェッチする。
極端な形として、オペランドの「二重間接参照」
、つまり、参照したメモリを経由した間接参
照を行うプロセッサもある。その場合、オペランドをメモリアドレスM と解釈するが、アドレ
スM の値を直接ロードないしストアするのではなく、値を含むメモリのアドレスがM に入って
いるとみなすのだ。この場合、プロセッサは次のステップを実行する。
•
オペランドの値、M を取得する。
•
M をメモリアドレスとして解釈し、そのメモリから値A をフェッチする。
•
A を、もう1 つのメモリアドレスとして解釈し、そのメモリからオペランドをフェッ
チする。
ある場所のメモリを介して別の場所のメモリを参照する二重間接参照は、プログラムでメモ
リ内の「連結リスト」を追う必要があるときに便利だろう。しかし、そのオーバーヘッドは極
度に大きい（1 個の命令を実行するだけで、複数のメモリ参照を引き起こす）
。
7.13 　オペランドアドレッシングモードの図解
プロセッサには普通、
「命令レジスタ」と呼ばれる特殊な内部レジスタが含まれている。命令
をデコードしている間は、命令そのものが、このレジスタに入っている。さまざまな型のオペ
ランドアドレッシングを検討し、それぞれのコストを見積もるには、オペランドの場所と、値
4　メモリとメモリアドレッシングについては、本書の第3 部で述べる。
hi.0412.ko.2002@gmail.com
　7.14
まとめ
129
をフェッチするのに必要な参照の数を見れば良い。もっともコストが低いのは、即値である。
なぜなら、その値は「命令レジスタ」に（つまり命令そのものに）入っているからだ。汎用レ
ジスタを参照するのは、即値よりもわずかながらコストが高い。そのレジスタ参照よりも、メ
モリ参照のほうが、コストが高い。そして最後に、2 回のメモリ参照が必要な二重間接参照は、
もっともコストが高い。図7‒5 に、これらの選択肢と、それぞれの解決に関わるハードウェア
ユニットを図解する。
CPU
メモリ
命令レジスタ
メモリ内の場所
汎用レジスタ
即値
（命令に入っている）
レジスタを直接参照
メモリを直接参照
レジスタ経由の間接参照
メモリ間の間接参照
図7‒5：さまざまな「アドレッシングモード」でオペランドをフェッチするときアクセスされるハードウェ
アユニットの図解。間接参照には直接参照よりも長い時間がかかる
この図を見ると、③（モード3）と⑤（モード5）では、命令にメモリアドレスを入れる必要
がある。これらのモードは古いコンピュータでは利用できたが、命令が大きくなりすぎるので
使われなくなった。
7.14 　まとめ
アーキテクトはプロセッサを設計するとき、個々の命令で使えるオペランドの数と型とを選
択する。オペランドを効率よく扱うために、多くのプロセッサでは、命令ごとのオペランド数
の上限を、3 個か、それより少ない数に制限している。
即値のオペランドは定数を指定する。その他の選択肢として、レジスタの内容またはメモリ
hi.0412.ko.2002@gmail.com
130
第7 章
オペランドのアドレッシングと命令表現　
内の値を使ってオペランド指定を行うものがある。間接参照では、オペランドのメモリアドレ
スをレジスタに入れることができる。二重間接参照では、オペランドが指定するメモリアドレ
スで参照される値が、オペランド値を格納している他の場所のメモリを参照するポインタにな
る。オペランドの型は、暗黙のうちに（オペコードの値に）エンコードすることも、明示的に
指定することもできる。
数多くのバリエーションが存在するのは、オペランドの数と型の選択に、機能と、プログラ
ミングの容易さと、処理速度などの技術的詳細に関わるトレードオフがあるからだ。
練習問題
7.1
あるコンピュータアーキテクトが、極度に遅いメモリを持つコンピュータのために、
プロセッサを設計しています。そのアーキテクトは「0 アドレス」アーキテクチャを
選ぶでしょうか? その理由は?
7.2
あるアーキテクチャでは即値オペランドに大きな数値を使えますが、命令がメモリ
内で、より多くの空間を占めることになります。その理由は何でしょうか?
7.3
メモリ内のスタックを管理するスタックマシンで、変数p がメモリに格納されると
します。p を7 だけ増やすには、何回のメモリアクセスが必要でしょうか。
7.4
x とy という2 つの整数がメモリに格納されているとき、x+y の和をz に入れる命
令について考えましょう。
「2 アドレス」アーキテクチャでは、何回のメモリアクセス
が必要でしょうか?
ヒント：命令のフェッチも回数に含まれます。
7.5
「3 アドレス」アーキテクチャでadd 演算を実行するのに、どのオペランドもメモ
リを間接参照するとしたら、何回のメモリアクセスが必要でしょうか。
7.6
プログラマが、最大の即値オペランドより大きな値で変数をインクリメントしよう
としたら、ある最適化コンパイラは2 つの命令を生成します。たとえば127 以下の
即値しか許さないコンピュータで、変数x を140 だけインクリメントしようとした
ら、コンパイル結果は次のコードシーケンスになりました。
load r7, x
add immediate r7, 127
add immediate t7, 13
store r7, x
なぜコンパイラは、いったん140 をメモリに格納してから、その値をレジスタ7 に加
算しないのでしょうか。
7.7
1 回のメモリ参照には、レジスタ参照の12 倍の時間がかかると想定します。また、
プログラムが「2 アドレス」アーキテクチャでN 個の命令を実行すると想定します。
すべてのオペランドがレジスタに入っている場合と、すべてのオペランドがメモリに
hi.0412.ko.2002@gmail.com
　7.14
まとめ
131
入っている場合とで、それぞれの実行時間を比較しましょう。
ヒント：命令のフェッチには1 回のメモリ演算が必要です。
7.8
図7‒4 に示した、それぞれの型のオペランドについて、そのオペランドを表現する
のに必要なビット数を表す式を含む表を作りましょう。
ヒント：0 からN までの値を表現するビットの数は、次の式で求められます。
log2N
7.9
1 個の命令で使えるアドレスの数が多いと、どんなメリットがあるのでしょうか。1
つ教えてください。
7.10
暗黙のオペランドを使う「2 アドレス」コンピュータを想定します。2 つのオペラ
ンドのうち、片方は図7‒5 であげた5 種類のオペランド型の、どれでも使えます。も
う片方のオペランドには、即値を使えませんが、他の型は、どれでも使えます。この
コンピュータに必要な、全部のadd 命令のリストを作りましょう。
7.11
ほとんどのコンパイラには、頻繁に使われる変数を、いちいちメモリに書き戻すよ
り、レジスタに入れたままにしておくことを選ぶ最適化モジュールが含まれています。
その最適化モジュールが回避している問題の性質には、どんな名前がありますか?
hi.0412.ko.2002@gmail.com
hi.0412.ko.2002@gmail.com
第8 章
CPU：
マイクロコード、保護、プロセッサモード
8.1 　はじめに
プロセッサの主な側面である命令セットとオペランドを検討した第6 章と第7 章では、どの
ようなアプローチがあるかを説明し、それぞれのアプローチの長所と短所を論じた。この章で
は汎用プロセッサという広範なクラスを考察し、これまでの章で述べたコンセプトが、どれほ
ど適用されるかを示そう。次章では、プロセッサで使われる低いレベルのプログラミング言語
について考える。
8.2 　中央処理装置
コンピュータの歴史では、初期に「集中」という考えが生まれ、アーキテクチャの重要なア
プローチになった。できるだけ多くの機能を1 個のプロセッサに集めようとしたのだ。その中
心となるプロセッサは、CPU（中央処理装置）と呼ばれ、計算処理と入出力の両方を含むコン
ピュータ全体を制御した。
初期の設計とは対照的に、現在のコンピュータシステムは「分散」アプローチにしたがって
いる。システムは複数のプロセッサを含んでいて、その多くは特定の機能またはハードウェア
サブシステム専用である。たとえばディスクのような入出力装置には、ディスクの転送処理専
用のプロセッサを入れることができる。
このようにパラダイムはシフトしたが、CPU という言葉は生き残っている。その理由は1 個
のチップの中に、ほとんどすべての計算を実行し、他のプロセッサ群を協調・制御するハード
ウェアが入っているからだ。CPU は、コンピュータシステム全体を管理し、他のプロセッサに
対して、いつ始動するか、いつ停止するか、何を実行するかを指示する。CPU が周辺の機器や
プロセッサを制御する方法は、入出力（I/O）を論じるときに見ることにしよう。
hi.0412.ko.2002@gmail.com
134
第8 章　CPU：マイクロコード、保護、プロセッサモード　
8.3 　CPU の複雑さ
制御と処理の多様なタスクをこなす必要があるので、現在のCPU は極めて複雑だ。たとえ
ばインテルは、25 億個ものトランジスタを含むCPU チップを作っている1。CPU が、そんな
に複雑なのは、なぜだろう。それほどまで大量のトランジスタが、なぜ必要なのか。
マルチコア
最近のCPU チップは、実際にはプロセッサを1 個だけ含むのではなく、
「コア」と呼ばれる
プロセッサを複数搭載している。全部のコアが並列に機能するので、複数の計算を同時に進め
ることができる。高性能化のためにマルチコア設計が必要なのは、シングルコアでもクロック
を上げればいくらでも高速になるわけではないからである。
複数の役割
CPU が複雑化する理由の1 つは、大きな仕事を数多くこなす必要があるからだ。CPU はア
プリケーションプログラムを走らせ、OS を走らせ、外部入出力装置を扱い、コンピュータの
起動と停止を行い、メモリを管理する。これらすべての役割に最適な命令セットは存在しない
から、CPU は複数の命令セットを含むことが多い。
保護と特権
ほとんどのコンピュータシステムには「保護」のシステムがあり、それによって一部のサブ
システムに、他よりも高い「特権」が与えられる。たとえばアプリケーションが入出力装置と
直接やりとりするのを防ぐのも、OS のコードが不注意または故意に書き換えられるのを防ぐ
のも、ハードウェアによる特権と保護の働きによる。
ハードウェア優先度
CPU は「優先度」の体系を使って、一部の処理に他の処理より高い優先順位を与える。たと
えば後述するように、I/O デバイス（入出力装置）はアプリケーションよりも高い優先順位で
処理される。CPU がアプリケーションプログラムを実行している最中に、I/O デバイスをサー
ビスする必要が生じたら、CPU はアプリケーションの実行を中断して、そのデバイスに対処し
なければならない。
一般性
CPU は、広い範囲のアプリケーションをサポートするように設計される。その結果、CPU
の命令セットは、多様なアプリケーションで使われる命令を含むことが多い（つまりCISC 設
計だ）
。
1　訳注：2014 年のIntel Core i7 5960X が、
すでに26 億個だった。英文Wikipedia の”Transistor Count”
という項目に詳しい記述がある。
hi.0412.ko.2002@gmail.com
　8.4
実行モード
135
データサイズ
処理速度を確保するため、CPU は大きなデータ値を扱えるように設計される。第2 章で述
べたように、デジタル論理ゲートは、それぞれ1 ビットのデータを扱うから、整数を扱うには
ゲートの複製が必要になる。64 ビットで演算を行うには、CPU のどのデジタル回路でも、各
種のゲートに64 個ずつのコピーが必要になる。
高速CPU の複雑さを生む最後の、おそらく最大の要因は、速度の追求から生じる。前に述
べた重要なコンセプトを思い出そう。
並行処理は、高速なハードウェアを作るための基礎的なテクニックだ。
ゆえに、最高の性能を達成するには、CPU の「機能ユニット」を複製せざるを得ない。それ
らのユニットを同時に機能させる設計も不可欠だ。最新のCPU を最高速で動かすには、並行処
理のハードウェアが大量に必要だから、結局CPU には大量のトランジスタが必要になる。こ
の件については、この章で、また説明を加えよう。
8.4 　実行モード
上にあげた項目の実装は、組み合わせても、個別にも対処できる。たとえば、あるコアに、
メモリの他の部分へのアクセスを許可するときに、高い優先順位を与える場合も、そうしない
場合もある。CPU は、いったいどうすれば、これらすべての機能を、プログラマが理解して混
乱することなく使えるような方法で、まとめられるのだろうか。
この複雑な動作の制御に対処するため、ほとんどのCPU はハードウェアに、複数のパラメー
タ集合を持たせている。つまり、そういうハードウェアは複数の「実行モード」を持つのだ。
どんなときも、CPU の動作は、そのときの実行モードによって決定される。次に、CPU の実
行モードに割り当てられることの多い項目をあげる。
•
命令セットの有効な部分集合
•
データ項目のサイズ
•
アクセス可能なメモリの領域
•
利用できる機能ユニット群
•
特権レベル
これらはCPU の実行モードによって制御される典型的な要素である。モードが変わると、
CPU の性質が劇的に変化することがある。
hi.0412.ko.2002@gmail.com
136
第8 章　CPU：マイクロコード、保護、プロセッサモード　
8.5 　後方互換性
実行モードで、どれほどのバリエーションを実現できるのだろうか。原則として、CPU で利
用できる数々のモードに、多くの共通点を持たせる必要はない。極端な例として、あるCPU に
は、その前のモデルとの「後方互換性」を提供するモードがある。それによってベンダーは、
新しい機能を持つCPU を売り出すときも、顧客が古いソフトウェアを、そのCPU で実行でき
るようにしている。
後方互換性を、どう使えるかを示す例が、インテルの一連のプロセッサだ（8086、186、286
など）
。インテルが32bit で整数演算を行うCPU を最初に世に出したとき、そのCPU には同
社が従来のCPU で使っていた16bit の命令セットを実装する後方互換モードが含まれていた。
使う整数のサイズが異なるだけでなく、この2 つのアーキテクチャではレジスタの数が異なり、
含まれる命令の種類も違っていた。両者の違いが、あまりにも大きかったので、2 つをCPU に
含まれる別々なハードウェア部品とみなし、実行モードによって、どちらを使うかを、いつで
も決められるようにするというのがもっとも容易な設計だった。
実行モードの意味を、まとめておこう。
CPU は、そのとき行う処理のさまざまな性質を決めるのに「実行モード」を使う。一
部のCPU では各モードの性質が、あまりにも大きく異なるので、CPU に別々のハード
ウェアサブシステムが入っていて、いまどちらのハードウェアを使うのかを実行モード
によって決める、と考えることが可能だ。
8.6 　モード切り替え
CPU の動作モードは、どのように切り替えるのか。それには2 つの方法がある。
•
自動式（ハードウェアが切り替えを行う）
•
手動式（プログラムの制御で切り替える）
自動的なモード切り替え
CPU のモードは外部のハードウェアで切り替えられる。たとえば、もしI/O デバイスがサー
ビスを要求したら、ハードウェアがCPU に信号を送る。そのデバイスをサービスする前に、
CPU は自動的にモードを切り替える（そしてOS のコードにジャンプする）
。詳しくは、I/O の
仕組みを考えるときに述べよう。
手動のモード切り替え
手動による切り替えは、実行中のプログラムの制御下で行われる。そのプログラムは、たい
がいOS であり、アプリケーションを実行する前にモードを切り替える。ただし、一部のCPU
hi.0412.ko.2002@gmail.com
　8.7
特権と保護
137
はアプリケーションが利用できる複数のモードを提供し、それらのモードをアプリケーション
が選択できるようにしている。
モード切り替えに使う機構は何だろうか。3 つのアプローチが使われてきた。もっとも単純
なケースでは、CPU に現在のモードを設定する命令が含まれる。その他のケースでは、モード
制御専用の特殊な「モードレジスタ」がCPU に含まれる。プログラムがモードを変更するに
は、そのモードレジスタに値をストアするのだ。といっても、モードレジスタは一般的な意味
でのストレージユニットではない。それを構成するハードウェア回路は、
「ストア」コマンドへ
の応答として、動作モードを切り替えるのだ。最後にモード切り替えは、別の命令の副作用と
して発生することもある。たとえば、ほとんどのCPU の命令セットには、アプリケーション
がOS を呼び出すシステムコールに使う命令が含まれていて、その命令が実行されると、必ず
自動的にモード切り替えが発生する。
モードの大規模な変更を行うには、新しいモードを迎える準備のために他の機構が必要かも
しれない。たとえば2 つの実行モードが汎用レジスタを共有しないとしよう（たとえば、ある
モードではレジスタ群が16bit だが、もう1 つのモードでは、どれも32bit になる）
。その場
合、モードを切り替えて新しいレジスタ群を使う前に、前の値をコピーしておく必要があるか
もしれない。その場合は、モードを切り替える前にソフトウェアで値を作成あるいは更新でき
るように、CPU が特別な命令を提供する。
8.7 　特権と保護
実行モードと連携するのが、CPU 機構としての「特権」と「保護」だ。つまり、現在のモー
ドの一部として、CPU の特権レベルが指定される。たとえばCPU は、I/O デバイスをサービ
スするとき、OS のソフトウェアである「デバイスドライバ」は、デバイスとの相互作用で制御
機能を実行しなければならない。けれども、任意のアプリケーションプログラムが、間違って
も故意にでも、ハードウェアに対してコマンドを発行したり制御機能を実行したりすることは、
絶対に阻止しなければならない。だからOS は、アプリケーションプログラムを実行する前に、
実行モードを変更して特権のレベルを下げる。低い特権レベルで実行しているときのCPU は、
I/O デバイスの直接制御する命令を許さない（特権が必要な演算を、無効な命令のように扱う）
。
8.8 　複数レベルのプロテクション
保護のレベルは、いくつ必要だろうか。それぞれのレベルで、どのような演算を許可すべき
だろうか。この問題は、ハードウェアアーキテクトとOS 設計者の間で長年にわたって議論さ
れてきた。まったく保護を提供しないCPU もあったし、強弱8 段階の特権を持たせるCPU も
作られた。プロテクション（保護機構）とは、常に必要最小限の特権しか持たせないことで、
この問題を回避しようとするアイデアだ。要約すると次のようになる。
hi.0412.ko.2002@gmail.com
138
第8 章　CPU：マイクロコード、保護、プロセッサモード　
許可する演算をプロテクションで制限するCPU は、権限のない演算を実行しようとす
る試みを検出できる。
図8‒1 は、2 段階の特権レベルを示している。
OS
app1 
app 2 
app N
低い特権
高い特権
図8‒1：2 段階の特権レベルを提供するCPU。OS は最高レベルの特権で実行され、アプリケーションプロ
グラムは最低レベルの特権で実行される
すべてのCPU を満足させる保護機構は存在しないが、設計者たちは、アプリケーションを
走らせるCPU には最小で2 段階のプロテクションが必要だという考えに、おおむね同意して
いる。
アプリケーションを実行するCPU には、少なくとも2 段階の保護レベルが必要だ。OS
は最大の特権で実行する必要があるが、アプリケーションは特権を制限して実行できる。
プロテクションはメモリアクセスと密接な関わりがあるが、それはメモリを論じるときに検
討しよう。重要なのは、CPU モードの一部であるメモリアクセス機構も、ある種の保護を提供
するということだ。
8.9 　マイクロコードで書かれた命令
複雑なCPU を、どのように実装すべきだろうか。おもしろいことに、複雑な命令セットを
構築する主要な抽象化の1 つは、ソフトウェアから生まれる。なんと、複雑な命令はプログラ
ミングされるのだ! つまり、命令セットをデジタル回路によって直接的に実装するのではなく、
CPU を2 つに分けて構築する。まずハードウェアアーキテクトが、
「マイクロコントローラ」
と呼ばれる高速だが小さなプロセッサを作る2。次に、CPU の命令セットである「マクロ命令
セット」を実装するために、アーキテクトがマイクロコントローラのソフトウェアを書く。マ
イクロコントローラで実行されるソフトウェアは、
「マイクロコード」と呼ばれる。この2 段
階の構成と、それぞれの実装方法を図8‒2 に示す。
2　小規模なプロセッサも「マイクロプロセッサ」と呼ばれるが、この用語は誤解を招きそうだ。
hi.0412.ko.2002@gmail.com
　8.9
マイクロコードで書かれた命令
139
CPU
マクロ命令セッ
ト
（マイクロコー
ドによる実装）
マイクロ命令セッ
ト
（デジタルロジッ
クによる実装）
プログラマから見える
（外部命令）
隠される
（内部命令）
マイクロコン
トローラ
図8‒2：マイクロコントローラによって実装されたCPU。このCPU が提供する「マクロ命令セット」は、
マイクロコードによって実装される
マイクロコードについて考察するには、CPU のマクロ命令を1 つずつ実装する関数の集合を
想像するのが、もっとも簡単な方法だ。CPU が、命令実行中に、そのマイクロコードを呼び出
す。つまり、マクロ命令を取得してデコードしたCPU が、その命令に対応するマイクロコー
ドのプロシージャを呼び出すわけだ。
マクロとマイクロでは、アーキテクチャが違うかもしれない。たとえば、CPU が32 ビット
のデータ項目を処理するように設計され、マクロ命令セットには整数加算用の「add32」命令
が含まれていると考えよう。さらに、マイクロコントローラは16 ビット演算しか提供しない
ものとしよう。32 ビット加算を実装するために、マイクロコードは一度に16 ビットずつの加
算を行い、低位ビット列からのキャリー（桁あふれ）ビットを、高位ビット列に加算しなけれ
ばならない。それに必要なマイクロコードのステップを、リスト8‒1 に示す。
リスト8‒1：16 ビットの算術演算しか持たないマイクロコントローラで、32 ビット加算のマクロ命令を実
装するのに必要なステップ。マクロとマイクロでは、アーキテクチャが違うかもしれない!
/* 下記のステップの前提：32 ビットのオペランドが、
* R5 およびR6 のレジスタにあること。
* マイクロコードは、16 ビットレジスタの
* r0 からr3 までを使って結果を計算すること。
*/
add32:
R5 の下位16 ビットをr2 に移す
R6 の下位16 ビットをr3 に移す
r2 とr3 を加算し、結果をr1 に置く
このときのキャリーを示す値を保存する
R5 の上位16 ビットをr2 に移す
R6 の上位16 ビットをr3 に移す
r2 とr3 を加算し、結果をr0 に置く
r0 の値をr2 にコピーする
hi.0412.ko.2002@gmail.com
140
第8 章　CPU：マイクロコード、保護、プロセッサモード　
r2 とキャリーを加算し、結果をr0 に置く
オーバーフローをチェックし、条件コードをセットする
r0 とr1 にある32 ビットの結果を、指定のデスティネーションに移す
実装の詳細は重要ではない。このリストが示しているのは、マイクロコントローラのアーキ
テクチャが、マクロ命令セットと、これほど違っている場合があるということだ。また、それ
ぞれのマクロ命令をマイクロコードのプログラムで実装するから、マクロ命令は任意の処理を
実行できる。この点も重要だ。たとえば1 個のマクロ命令で、サインやコサインのような三角
関数を実装することも可能だし、大きなブロックをメモリ内で転送することも可能だ。もちろ
んアーキテクトは、高い性能を実現するために、所与の命令に対応するマイクロコードの量を
制限することもできる。
8.10 　各種のマイクロコード
マイクロコードの基本的な形式を基にして、コンピュータ設計者はさまざまなバリエーショ
ンを作ってきた。たとえば、CPU のフェッチ‒ 実行サイクルを実装するハードウェアが、命令
ごとにマイクロコードのプロシージャを呼び出すというのが前述の方法だが、CPU によっては
マイクロコードがフェッチ‒ 実行サイクル全体を実装する場合もある。つまり、マイクロコー
ドがオペコードを解釈し、オペランドをフェッチして、指定の演算を実行する。利点は、柔軟
性が大きいことにあり、マイクロコードがマクロシステムの全部の側面を定義する。それには
マクロ命令のフォーマットや、各オペランドの形式とエンコード方式も含まれる。逆に、主な
弱点は性能の低さだ。そのCPU は、命令パイプラインをハードウェアで実装することができ
ないのだから。
もう1 つのバリエーションとして、マイクロコードを単なる拡張として利用する形でCPU
を設計することも可能だ。つまり、まずCPU には、デジタル回路で直接実装された完全なマク
ロ命令セットがある。それに加えて、そのCPU には、マイクロコードで実装された、追加オ
ペコードの小さな集合もある。そうすればCPU ベンダーは、基本となるCPU の小規模なバリ
エーション（たとえばセキュリティソフトウェアを実装したい顧客のために特別な暗号化命令
を持たせたバージョンだとか、テキスト処理のソフトウェアを実装したい顧客のために特別な
パターンマッチング命令を持たせたバージョンなど）を製造できる。CPU の、ある特定のバー
ジョンでは、そういう追加命令の一部または全部が使われないとしたら、ベンダーは、それら
を未定義とするマイクロコードを挿入できる（つまり、未定義命令を実行したらマイクロコー
ドがエラーを出すのだ）
。
hi.0412.ko.2002@gmail.com
　8.11
マイクロコードの長所
141
8.11 　マイクロコードの長所
なぜマイクロコードが使われるのだろう。動機は3 つある。第1 に、マイクロコードは高い
レベルの抽象を提供するので、ハードウェアで回路を組むよりマイクロコードを組む方が、間
違いを起こしにくい。第2 に、回路を組む代わりにマイクロコードを組めば時間を短縮できる。
そして第3 に、ハードウェア回路の変更よりもマイクロコードの変更のほうが簡単なので、新
しいバージョンのCPU を早く作れる。
マイクロコードを使う設計のほうが、マイクロコードを使わない設計よりも、エラーが
少なく更新が速やかである。
もちろんマイクロコードには、長所と差し引きされる短所も、いくつかある。
•
マイクロコードは、ハードウェア実装よりもオーバーヘッドが大きい。
•
マイクロコントローラは、マクロ命令1 個について複数のマイクロ命令を実行するの
だから、CPU よりも、ずっと高速に実行しなければならない。
•
マクロ命令のコストは、マイクロ命令セットによって異なる。
8.12 　FPGA と命令セット変更
マイクロコントローラは設計者を援助するための内部機構なので、そのマイクロ命令セット
は、最終的な設計では隠されるのが普通だ。マイクロコントローラとマイクロコードは、CPU
の他の部分とともに集積回路に置かれるのが典型的で、それらは内部でしか使われない。プロ
グラマが利用できるのはマクロ命令セットだけである。しかし興味深いことに、ある種のCPU
は、マイクロコードが動的で、CPU を購入した顧客がアクセスできるように設計されている。
つまりCPU の根底にあるハードウェアをチップ製造後に変更できるような機構が組み込まれ
ているのだ。
なぜ顧客はCPU を変更したがるのだろうか。その動機は、柔軟性と性能だ。顧客がCPU の
命令に若干の変更を加えられるのなら、マクロ命令セットに関する決断を遅らせることができ、
CPU の所有者が特別な用途のために命令をカスタマイズすることも可能になる。たとえばビデ
オゲームを販売する会社なら、グラフィックスの画像操作用にマクロ命令を追加するかもしれ
ない。ネットワーク機器を作る会社なら、パケットのヘッダを処理するマクロ命令を作るかも
しれない。そして、根底にあるハードウェアを（マイクロコードを介して）直接変更できれば、
より高い性能を得られるかもしれない。
変更が許されるテクノロジーのなかで、
とりわけ一般化したのが、
「FPGA」
（Field Programmable
Gate Array ）である。このテクノロジーでは、チップを製造した後にゲートを変更できるの
だ。ただしFPGA の再構成は時間のかかるプロセスなので、FPGA を1 度だけ再構成し、その
hi.0412.ko.2002@gmail.com
142
第8 章　CPU：マイクロコード、保護、プロセッサモード　
結果のチップを使うのが一般的なアイデアだ。FPGA にCPU 全体を入れることも可能だし、少
数の追加命令だけを入れて増補として使うこともできる。
動的なマイクロコードとFPGA のようなテクノロジーによって、CPU を購入した後で
も、そのCPU の命令セットを変更あるいは拡張することが可能になった。柔軟性と、よ
り高い性能を求めることが、その動機である。
8.13 　垂直型のマイクロコード
マイクロコントローラには、どんなアーキテクチャを使うべきだろうか。あるいは、マイク
ロコードを書く立場で言えば、マイクロコントローラは、どんな命令を提供すべきだろうか。
これまでマイクロコードについては、マイクロコントローラも一般的なプロセッサ（一般的な
アーキテクチャにしたがうプロセッサ）と同じ構成とみなして記述してきたが、それとは異な
る設計も可能である。
実際、マイクロコントローラは一般のプロセッサと、まったく同じようには作れない。CPU
の内部にあるハードウェアユニットとの対話処理が必要なので、マイクロコントローラには、
いくつか特殊なハードウェア機構が必要だ。たとえばマイクロコントローラはALU をアクセ
スして、その結果を、マクロ命令セットで使える汎用レジスタに格納できるようにする必要が
ある。同様に、マイクロコントローラはオペランド参照をデコードして値をフェッチすること
も、できなければならない。そして最後に、マイクロコントローラは、メモリを含む他のハー
ドウェアと連携できなければならない。
このように特殊な要件はあるが、マイクロコントローラは、全般的には従来のプロセッサに
使われてきたのと同じアプローチにしたがって作られてきた。つまり、マイクロコントローラ
の命令セットには、
「load」
、
「store」
、
「add」
、
「subtract」
、
「branch」などといった、従来の
命令が含まれている。たとえばCISC プロセッサで使われるマイクロコントローラで、小さく
て高速なRISC プロセッサを使うことも可能だ。われわれは、このようなマイクロコントロー
ラは「垂直アーキテクチャ」を持っていると称し、そのマイクロコントローラで実行されるソ
フトウェアを「垂直マイクロコード」という用語で表現する。
プログラマにとって垂直マイクロコードは親しみやすい。なぜならプログラミングのイン
ターフェイスが馴染み深いものだからだ。もっとも重要なのは、垂直マイクロコードのセマン
ティクス（意味）が、プログラマが期待する「一度に1 個のマイクロ命令が実行される」動作
と、正確に一致することだ。次の節では、垂直マイクロコードに代わる別の選択肢について述
べよう。
hi.0412.ko.2002@gmail.com
　8.14
水平型のマイクロコード
143
8.14 　水平型のマイクロコード
ハードウェアから見ると、垂直型マイクロコードには、いささか不満がある。短所の1 つは、
性能上の要件から生じるものだ。ほとんどのマクロ命令は、複数のマイクロ命令を必要とする。
すなわち、マクロ命令を毎秒K 個の割合で実行するためには、マイクロコントローラがマイク
ロ命令を、毎秒N×K 個の割合で実行しなければならない（ここでN は、マクロ命令1 個あ
たりに必要とされるマイクロ命令数の平均値だ）
。ゆえに、マイクロコントローラに関連する
ハードウェアは、非常に速い速度で動作しなければならない（たとえばマイクロコードの格納
に使われるメモリは、マイクロ命令を高周期で送り出す必要がある）
。
垂直マイクロコードの第2 の短所は、
根底にあるハードウェアの並列性を、
垂直テクノロジー
では活用できないという問題から生じる。コンピュータ技術者は、垂直マイクロコードの短所
を、いくつか克服できるように、
「水平マイクロコード」と呼ばれる代替策を発明した。水平マ
イクロコードには、ハードウェアとの協調性が高いという長所があるが、プログラマにとって
親しみのあるインターフェイスを提供してくれない。
水平マイクロコードならハードウェアの実行速度を上げられるが、プログラミングは難
しくなる。
水平マイクロコードを理解するために、第6 章で取り上げた「データパス」を思い出そう。
CPU は複数の機能ユニットで構成され、それらのユニットはデータパスで接続されている。こ
れらのユニットの動作を制御する必要があり、個々のユニットは独立して制御される。それば
かりか、ある機能ユニットから別の機能ユニットにデータを送るためには、その2 つのユニッ
トを明示的に制御する必要がある。片方のユニットには、あるデータパスに向けてデータを送
出するように命じ、もう片方のユニットには、データを受信するように命じなければならない。
コンセプトは、例を見ると明らかになる。話をわかりやすくするために前提を単純化し、機
能ユニットの数を制限しよう。図8‒3 に、6 個の機能ユニットを相互接続する方法を示す。
ALU
結果1
結果2
マクロな
（算術論理ユニッ
ト）
汎用レジスタ群
オペラン
ド1
オペラン
ド2
レジスタ
インターフェイス
データ転送機構
図8‒3：CPU の内部構造を示す例。矢印のある線は、データ移動が可能なハードウェア経路を示す
hi.0412.ko.2002@gmail.com
144
第8 章　CPU：マイクロコード、保護、プロセッサモード　
この図の主なユニットは、加算、減算、ビットシフトなどの演算を実行する「ALU」だ。残
りの機能ユニットは、システムの他の部分とALU との間にインターフェイス機構を提供する。
たとえば「オペランド1」
、
「オペランド2」とラベルの付いたハードウェアユニットは、オペラ
ンド用のストレージユニット（内部のハードウェアレジスタ）である。ALU は、演算を実行す
る前に、これらのストレージユニットにオペランドが置かれることを前提として、演算の結果
を「結果1」
、
「結果2」というラベルの付いた2 つのハードウェアユニット3に格納する。最後
に「レジスタインターフェイス」ユニットは、汎用レジスタ群へのハードウェアインターフェ
イスを提供する。
この図の矢印は、ある機能ユニットから別のユニットへとデータが送られる経路を示してい
る。どの矢印も、複数のビット（たとえば32 ビット）をパラレルに処理する「データパス」で
ある。ほとんどの矢印が接続されている「データ転送機構」は、機能ユニットを結び付ける配
管設備の役割を担う。ここで示したデータ転送機構は「バス」と呼ばれるものだが、それにつ
いては後の章で説明しよう。
8.15 　水平マイクロコードの仕組み
それぞれの機能ユニットは、
「コマンド」
（つまりハードウェアがコマンドとして解釈する2
進数の値）を運ぶ信号線によって制御される。図8‒3 ではその線を示していないが、機能ユ
ニットに繋がれるコマンド線の本数は、そのユニットの型に依存する。たとえば「結果1」と
いうユニットは1 本のコマンド線しか必要としない。それは、このユニットが1 ビットの値で
制御できるからだ。もし0 ならば、このユニットは他のユニットとの通信を停止するが、もし
1 ならば、ユニットの現在の内容（結果）を、データ転送機構に送り出す。この例で、それぞ
れの機能ユニットに渡される可能性がある制御信号線の値（バイナリ）と、それぞれの意味を
表8‒1 にまとめた。
表8‒1 に示したように、
「レジスタインターフェイス」ユニットは特別で、コマンドが2 つ
の部分で構成される。最初の2 ビットは演算を指定し、残りの4 ビットは、その演算で使うレ
ジスタを指定する。したがって、010011 というコマンドは、レジスタ3 の値をデータ転送機
構に送れ、という意味である。
これでハードウェア構成がわかったから、水平マイクロコードの仕組みを解明できる。マイ
クロコードの命令は、
それぞれ機能ユニットへのコマンドで構成される。命令の実行時に、
ハー
ドウェアが命令のコマンド（ビット列）を機能ユニットに送るのだ。図8‒4 に、この例のコマ
ンドに対応するマイクロコードのビットを示す。
3　前に述べたように算術演算では（たとえば乗算を行うと）結果がオペランドの2 倍の大きさになること
がある。
hi.0412.ko.2002@gmail.com
　8.16
水平マイクロコードのサンプル
145
表8‒1：図8‒3 で例示した機能ユニットで使われるコマンド値と、その意味を示す。コマンドはパラレルな
線で運ばれる
ユニット
コマンド
意味
0 0 0
演算なし
0 0 1
加算
0 1 0
減算
ALU
0 1 1
乗算
1 0 0
除算
1 0 1
左シフト
1 1 0
右シフト
1 1 1
前の演算を続ける
オペランド
0
演算なし
1
1
データ転送機構から値をロードする
オペランド
0
演算なし
2
1
データ転送機構から値をロードする
結果
0
演算なし
1
1
データ転送機構に値を送る
結果
0
演算なし
2
1
データ転送機構に値を送る
0 0 x x x x
演算なし
レジスタ
0 1 x x x x
レジスタxxxx をデータ転送機構に送る
インターフェイス
1 0 x x x x
データ転送機構からレジスタxxxx に送る
1 1 x x x x
演算なし
ALU
オペラン
ド1
オペラン
ド2
結果1
結果2
レジスタインターフェイス
図8‒4：水平マイクロコード命令のうち、13 ビットが、6 個の機能ユニットへのコマンドに対応する
8.16 　水平マイクロコードのサンプル
水平マイクロコードを、どう使えば演算シーケンスを実行できるのだろう。基本的にプログ
ラマは、そのときアクティブにすべき機能ユニットを選択して、その情報をマイクロコードの
ビット列にエンコードする。たとえばプログラマが、汎用レジスタ4 の値を、汎用レジスタ13
の値に加算して、その結果を汎用レジスタ4 に置く必要があるとしよう。図8‒5 に、そのとき
実行する必要のある演算のリストを示す。
サンプルのシステムでは、どのステップも1 個のマイクロ命令で表現できる。命令に含まれ
るビットパターンで、その命令を実行するときに動かすべき機能ユニットを指定する（複数か
hi.0412.ko.2002@gmail.com
146
第8 章　CPU：マイクロコード、保護、プロセッサモード　
も知れない）
。たとえば図8‒6 に示すマイクロコードプログラムは、図8‒5 の4 ステップに対
応するものだ。
•
レジスタ4 の値を、
「オペランド1」のハードウェアユニットに送る。
•
レジスタ13 の値を、
「オペランド2」のハードウェアユニットに送る。
•
ALU に加算を実行させる。
•
「結果2」
（結果の下位ビット列）のハードウェアユニットから、値をレジスタ4 に
送る。
図8‒5：サンプル：汎用レジスタ4 と13 の値を加算した結果を汎用レジスタ4 に置くために、機能ユニッ
トが実行する必要のあるステップのシーケンス
この図では、それぞれの行が1 命令に対応する。命令は、それぞれ1 個の機能ユニットに対
応するフィールドに分けられる。命令の実行時に、コマンドを含むフィールドが、その機能ユ
ニットに送られる。それによって、それぞれのステップで稼働すべき機能ユニットが決まる。
1 
0 
0 
0 
1 
0 
0 
0 
0 
1 
0 
1 
0 
0
2 
0 
0 
0 
0 
1 
0 
0 
0 
1 
1 
1 
0 
1
3 
0 
0 
1 
0 
0 
0 
0 
0 
0 
0 
0 
0 
0
4 
0 
0 
0 
0 
0 
0 
1 
1 
0 
0 
1 
0 
0
命令 
ALU 
結果1 結果2 
レジスタインターフェイス
オペ
ラン
ド
1
オペ
ラン
ド
2
図8‒6：水平マイクロコードのプログラム。このサンプルは4 個の命令で構成され、それぞれの命令は13
ビットで構成される。個々の命令が、図8‒5 の各ステップに対応する
図のコードを調べよう。最初の命令は、ただ2 つのハードウェアユニット（オペランド1 と、
レジスタインターフェイス）に演算を指定している。他の4 つのユニットに対応するフィール
ドは、どれも0 なので、これらのユニットは最初の命令が実行されるとき何もしない。また、
最初の命令でデータ転送機構も使われ4、レジスタインターフェイスからオペランド1 に、転送
機構を介してデータが送られる。つまり、命令のフィールドにしたがって、レジスタインター
フェイスから転送機構経由で送られた値をオペランド1 が受け取る。
4　この単純化されたサンプルのデータ転送機構は、常に動作するので何の制御も必要ないということにす
る。
hi.0412.ko.2002@gmail.com
　8.17
複数サイクルが必要な演算
147
8.17 　複数サイクルが必要な演算
水平マイクロコードでもっとも重要な側面の1 つがタイミングだ。ある種のハードウェアユ
ニットは、他のユニットよりも演算に時間がかかる。たとえば乗算は加算よりも長時間を要す
るだろう。ある機能ユニットにコマンドが与えられたとき、その結果が即座に現れないとした
ら、その機能ユニットからの出力を利用したいプログラムは、それをアクセスする前に遅延を
入れなければならない。
水平マイクロコードを書くプログラマは、それぞれのハードウェアユニットに、仕事の完了
までに要する時間を正確に与えなければならない。図8‒6 のコードは、どのステップもマイク
ロ命令の1 サイクルで完了することを前提としていた。けれども一部のハードウェアユニット
は、1 マイクロサイクルで仕事を終えることが不可能かもしれない。たとえばALU は、加算
を完了させるまでにマイクロ命令で2 サイクルが必要かもしれない。もっと長くかかかる計算
を行うためには、図の3 つめの命令の後に、余分な命令を挿入できるだろう。その余分な命令
は、ALU に前の演算を続行させるだけで、他のユニットには影響を与えない。図8‒7 は、必要
な遅延を作るために挿入できる余分なマイクロコード命令を示している。
1 
1 
1 
0 
0 
0 
0 
0 
0 
0 
0 
0 
1
ALU 
結果1 結果2 
レジスタインターフェイス
オペ
ラン
ド
1
オペ
ラン
ド
2
図8‒7：ALU が演算を終えるまで処理を遅延するために挿入できる命令。タイミングと遅延は、水平マイク
ロコードでは決定的に重要だ
8.18 　水平マイクロコードと並列処理
以上で、どのようにハードウェアが動作するかの基本を理解し、水平マイクロコードの概要
を知ることができたから、その重要な属性である「並列性」を評価できる。動作を並列化でき
るのは、根底にあるハードウェアユニット群が、それぞれ独立して動作するからだ。そしてプ
ログラマが並列処理を指定できるのは、命令に含まれている個別のフィールドで、それぞれの
ハードウェアユニットを制御できるからだ。
サンプルとして、1 個のALU と、個々のオペランドを別々に格納するハードウェアユニット
群を持つアーキテクチャを考えよう。そのALU は演算を完了させるのに複数の命令サイクル
を必要とする。ALU は最初のサイクルの間にオペランド群をアクセスしてしまうから、オペラ
ンドの格納に使われるハードウェアユニット群は、それに続くサイクルの間、ずっと使われな
いままになる。だからプログラマは、ALU の演算を続けながら、同時に新しい値をオペランド
ユニットに入れる命令を、挿入することができる。図8‒8 に、その命令を示す。
hi.0412.ko.2002@gmail.com
148
第8 章　CPU：マイクロコード、保護、プロセッサモード　
1 
1 
1 
1 
0 
0 
0 
0 
1 
0 
1 
1 
1
ALU 
結果1 結果2 
レジスタインターフェイス
オペ
ラン
ド
1
オペ
ラン
ド
2
図8‒8：ALU の演算を続けながら、レジスタ7 から得た値を、
「オペランド1」のハードウェアユニットに
ロードする命令。水平マイクロコードでは、並列処理を容易に指定できる!
要点をまとめよう。
水平マイクロコードの命令には、それぞれ1 個のハードウェアユニットを個別に制御す
るフィールド群が含まれているので、複数のハードウェアユニットが同時に行う並列処
理を、簡単に指定できる。
8.19 　先読みで実行を高速化する
実際にCPU で使われるマイクロコードは、この章で見ている単純化されたサンプルより、は
るかに複雑である。その複雑さを生む重要な要因の1 つが、高性能の追求だ。製造技術が高度
に進化して、1 個のチップに何十億ものトランジスタを集積できるのだから、すべて同時に動
作する無数の機能ユニットを1 個のCPU に載せることが可能である。
並列ハードウェアをプログラマから見えるようにするアーキテクチャについては、後の章で
考察する。いまは、アーキテクチャに関する以下の疑問について考えよう。機能ユニットを複
数持てば、マクロ命令セットを変更せずに性能を上げられるだろうか。具体的に言えば、CPU
の内部構成を工夫することで、並列実行が性能の向上をもたらすような状況を検出して利用で
きるようになるのだろうか。
最適化の些細な例は、すでに見ている。図8‒8 の水平マイクロコードは、ALU 演算を続行
させると同時に、オペランドを格納するハードウェアにデータ値を転送できることを示してい
た。けれども、その例ではマイクロコードを書くプログラマが、並列的な振る舞いを明示的に
コーディングする必要がある。
どうすれば並列処理を、CPU が自動的に利用できるのか。それを理解するために、インテリ
ジェントなマイクロコントローラと複数の機能ユニットを含むシステムを想像しよう。インテ
リジェントコントローラは、マクロ命令を1 個ずつ見ていくのではなく、数多くの命令をアク
セスする。コントローラは命令群を「先読み」して、もうじき必要になる値を見つけたら、その
値のフェッチまたは計算を開始せよと機能ユニットに指令する。たとえば、
「3 アドレス」アー
キテクチャで、次の4 個の命令をインテリジェントコントローラが見つけたとしよう。
hi.0412.ko.2002@gmail.com
　8.20
並列処理と実行順序
149
add
R1, R3, R7
sub
R4, R4, R6
add
R9, R5, R2
shift
R8, 5
インテリジェントコントローラは、必要な仕事を機能ユニットに割り当てることによって、
命令を「スケジューリング」する。たとえばコントローラは、オペランドをフェッチして値を準
備する機能ユニットに、それぞれのオペランドを割り当てることができる。ある命令が使うオ
ペランドの値が利用可能になったら、コントローラは、その命令を演算を実行する機能ユニッ
トに割り当てる。上にあげた命令群は、それぞれ1 個のALU に割り当てられる。最後にコン
トローラは、演算が完了したら、その結果を適切なデスティネーションレジスタに移す仕事を
機能ユニットに割り当てることができる。要するに次のようにまとめることができる。
もしCPU に十分な機能ユニットが含まれていたら、インテリジェントコントローラは、
これら4 個のマクロ命令を、同時に実行するようにスケジューリングできる。
8.20 　並列処理と実行順序
インテリジェントコントローラについての記述で、1 つ重要な詳細に触れずにいた。それは
マクロ命令セットが持つ意味（セマンティクス）である。要するに、値を計算するコントロー
ラは、並行処理を行うことで、プログラムが持つ意味を変えてはならない。たとえばこの命令
シーケンスを例としよう。
add
R1, R3, R7
sub
R4, R4, R6
add
R9, R1, R2
shift
R8, 5
1 つ前の例と違って、オペランドに重複がある。最初の命令でR1 をデスティネーションに
指定しているのに、3 つめの命令では、そのR1 をオペランドにしているのだ。マクロ命令セッ
トのセマンティクスは、命令の直列処理（シーケンシャルな実行）を命じるものだ。このシー
ケンスは、まず最初の命令でレジスタ1 に値を入れ、その後の第3 の命令で、その値を参照せ
よ、という意味を持つ。こういったシーケンシャルなセマンティクスを守るために、インテリ
ジェントコントローラは、重複する部分を理解して正しく対応する必要がある。要するにコン
トローラは、並行して実行される処理を最大化し、なおかつ元の（シーケンシャルな）意味を
維持するという、2 つの目標のバランスを取らなければならない。
hi.0412.ko.2002@gmail.com
150
第8 章　CPU：マイクロコード、保護、プロセッサモード　
8.21 　命令のアウトオブオーダー実行
並行処理のスケジューリングを行うコントローラは、ある命令のオペランドの1 つが、それ
より前の命令の結果に依存するというケースを、どのように扱うのだろうか。コントローラは、
「スコアボード」と呼ばれる機構を使って、実行する命令について、個々の状態を追跡する。と
くにスコアボードが管理するのは、マイクロコードの命令と、元のマクロ命令のシーケンシャ
ルな実行との間の、依存性に関わる情報である。コントローラは、そのスコアボードを使って、
いつオペランドをフェッチするか、いつ演算を続行するか、いつ命令が完了するかを判断する。
要するに、スコアボードのアプローチを使うコントローラは、命令を順番から外れた順序（out
of order）で実行しても、元のコードで指定された順序が反映されるように、結果を並び替え
ることができる。
最大の性能を得るために、現代のCPU には機能ユニットの複数のコピーが含まれ、複
数の命令を同時に実行することが可能になっている。インテリジェントなコントローラ
は、
「スコアボード」機構を使って、シーケンシャル処理を守っているように見える順序
で命令をスケジューリングする。
8.22 　条件分岐と分岐予測
条件分岐も並行処理に問題を投げかける。たとえば次の計算を見ていただきたい。
Y ←f(X)
if (Y > Z ) {
Q
} else {
R
}
これをマシン語命令に翻訳すると、実行の流れをQ のコードかE のコードのどちらかに導く
条件分岐が含まれる。その条件はY の値に依存するが、それは最初のステップで計算される。
命令を並列に実行できるCPU で、このコードを実行したとしよう。理論的に言えば、いったん
条件分岐に到達したCPU は、比較の結果を待たなければならない。R とQ の、どちらが選ば
れるかわからない間は、R またはQ のコードのスケジューリングは、開始できないはずである。
しかし実際には、条件分岐を処理するのに2 つのアプローチが使われる。第1 のアプロー
チは「分岐予測」と呼ばれるものだ。計測結果によれば、ほとんどのコードで、分岐はおよそ
60%の確率で発生する。ゆえに、分岐する経路の命令をスケジューリングするハードウェアを
作る方が、分岐しない経路の命令をスケジューリングするハードウェアよりも最適化される。
もちろん、分岐が発生するという予測は外れるかもしれない。もし分岐しないと決まったら、
結局CPU は分岐経路の結果を捨てて、分岐しない経路を進まなければならない。第2 のアプ
hi.0412.ko.2002@gmail.com
　8.23
プログラマにおよぼす影響
151
ローチは、とにかく両方の経路を並行して辿るという考えだ。つまりCPU は、条件分岐の両方
の結果のために、命令のスケジューリングを行う。分岐予測と同じように、CPU は結局どちら
の結果が正しいのかを決めなければならない。つまりCPU は命令の実行を続け、その結果を
留保する。いったん条件の値が判明したら、CPU は正しくなかった経路からの結果を捨てて、
正しかったほうの結果を対応するデスティネーションに移す。もちろんQ にでもR でも、第2
の条件分岐が発生するかもしれないのだから、スコアボード機構は、すべての詳細を処理しな
ければならない。
要点をまとめよう。
命令を並列実行できるCPU は、条件分岐で片方または両方の経路について、あらかじ
め値の計算を行っておき、あとで分岐条件の計算が完了したときに、どちらの値を使う
かを選ぶことができる。
あとで破棄される値を計算するのはCPU の無駄遣いだと思われるかもしれない。けれども
目標はエレガンスではなく高性能だ。それに、もしCPU が条件分岐の値がわかるまで待つよ
うに設計されていたら、そのハードウェアはアイドル状態になるだけだ。したがって、インテ
ルやAMD が製造しているような高性能CPU は、並列的な機能ユニットと洗練されたスコア
ボード機構を持つように設計されている。
8.23 　プログラマにおよぼす影響
どのようにCPU が構築されているかを理解したら、プログラマは、もっと速いコードを書け
るようになるのだろうか。場合によっては、そうなる。たとえばCPU が分岐予測を使うよう
に設計され、分岐が行われるという予測を行うとしたら、プログラマはもっとも一般的なケー
スで分岐が行われるようにコードを書くことで、性能を最適化できるはずだ。もしプログラマ
が、Y がZ より小さくなるケースが多いと知っていたら、Y > Z をテストするのではなく、Y
< Z をテストするようにコードを書き直すことができるだろう。
8.24 　まとめ
現代のCPU は複雑なプロセッサであり、複数の実行モードを使って、その複雑さの一部に
対処している。実行モードによって、実行が許可される命令や、現在の特権レベルなどのパラ
メータ群が選択される。ほとんどのCPU は、特権と保護のレベルを、少なくとも2 段階は提
供している（片方はOS に、もう片方はアプリケーションプログラムに使われる）
。
内部的な複雑さを緩和するため、しばしばCPU は、2 段階の抽象レベルで構築される。それ
は、デジタル回路で実装されるマイクロコントローラと、マイクロコードを追加することで作
られるマクロ命令セットだ。
マイクロコードも、大きく分けて2 種類がある。垂直型マイクロコードを使うマイクロコン
hi.0412.ko.2002@gmail.com
152
第8 章　CPU：マイクロコード、保護、プロセッサモード　
トローラは、従来のRISC プロセッサに似ている。典型的な垂直マイクロコードは、それぞれ
1 個のマクロ命令に対応するプロシージャの集合として構成される。CPU はフェッチ‒ 実行サ
イクルの間に、適切なマイクロコードを走らせる。一方、個々のサイクルで実行すべき機能ユ
ニットのスケジュールをプログラマが決める、水平型マイクロコードの命令では、それぞれの
フィールドが1 個の機能ユニットに対応する。ただし第3 の選択肢として、根底にあるシステ
ムの作成にFPGA テクノロジーを使うという方法もある。
高度に進化したCPU は、並列処理の拡張として、命令のスケジューリングを複数の機能ユ
ニットに分けて行う。スコアボード機構を使って、ある命令の結果が、その後の命令によって
使われるケースを扱うのだ。このアイデアを条件分岐に応用して、複数の経路で並列的に評価
を続ける場合、分岐の条件が定まったときには、取られなかった経路の値が捨てられる。
練習問題
8.1
もしクアッドコアCPU が20 億個のトランジスタを含むとしたら、コア1 個あたり、
およそいくつのトランジスタが必要でしょうか?
8.2
現代のCPU が複雑な理由を7 つあげてください。
8.3
ある種のCPU には
「後方互換性」
モードがあるといいます。そういうモードは、
ユー
ザーにとってメリットがあるのでしょうか?
8.4
あるスマートフォンで使われているCPU には、そのチップの過去3 バージョンのた
めのハードウェアが加えられています（つまり3 つの後方互換性モードがあるわけで
す）
。ユーザーの視点から見て、短所は何でしょうか?
8.5
クラウドデータセンターで使われる仮想化されたソフトウェアシステムには、しば
しば複数のOS を実行し制御する「ハイパーバイザ」が含まれ、それらのOS の1 つ
でアプリケーションが実行されます。このようなシステムにおける保護レベルは、従
来の保護レベルと、どう違うのでしょうか?
8.6
基本的な命令セットを持つプロセッサにFPGA を付け加えた形のチップを提供して
いる製造業者があります。チップの所有者は、FPGA で命令を追加するように設定で
きます。そういうチップで、従来のソフトウェアでは不可能なものを提供できるとし
たら、それは何でしょうか?
8.7
FPGA が、どのように「プログラマブル」なのかを調べましょう。FPGA のプログラ
ミングに使う言語は何でしょうか?
8.8
16bit 算術演算しか提供しないマイクロコントローラで32bit 乗算を実行するため
の、マイクロコードのアルゴリズムを組みましょう。そして、作成したアルゴリズム
をC 言語のshort 変数を使って実装しましょう。
8.9
同じ給料のプログラミング仕事を2 つ、オファーされたとします。片方は垂直型、も
う片方は水平型のマイクロコードを使うものです。あなたなら、どちらを選びますか?
hi.0412.ko.2002@gmail.com
　8.24
まとめ
153
その理由は?
8.10
水平型マイクロコードを使っている商用プロセッサの実例を見つけましょう。そし
て、図8‒4 と同じように、命令のビットが持つ意味を文書化してみましょう。
8.11
CPU チップのなかで「スコアボード」機構を使う動機は何でしょう。それは、どん
な機能を提供しますか?
8.12
もしラスベガスのカジノがプログラム実行のオッズを計算したら、分岐が行われる
ほうに、どのくらいのオッズが付くと思いますか。説明もお願いします。
hi.0412.ko.2002@gmail.com
hi.0412.ko.2002@gmail.com
第9 章
アセンブリ言語と
プログラミングパラダイム
9.1 　はじめに
これまでの章で、プロセッサの命令セットとオペランドのアドレッシングについて述べてき
た。この章では、プログラマが命令とオペランドアドレッシングのあらゆる詳細を指定できる
プログラミング言語について述べる。この章は、特定のプロセッサ用言語についてのチュート
リアルではなく、低水準言語で一般に見られる機能の概説を提供する。プログラミングで使わ
れる各種のパラダイム（理論的な枠組み）に注目して、低水準言語でのプログラミングが、通
常の言語でのプログラミングと、どのように違うのかを説明し、最後に低水準言語をバイナリ
の命令に変換するソフトウェアを解説する。
低水準プログラミングと、
そのプログラミング言語は、
厳密に言えばコンピュータアーキテク
チャの一部ではない。それでも、ここに入れたのは、そのような言語が根底にあるハードウェ
アと非常に密接な関係にあって、両者を容易に分離できないからである。この後の章ではハー
ドウェアの話に戻って、メモリと入出力機能を見ていく。
9.2 　高水準プログラミング言語の性質
プログラミング言語は、次の2 つのカテゴリーに大別できる。
•
高水準言語
•
低水準言語
hi.0412.ko.2002@gmail.com
156
第9 章　アセンブリ言語とプログラミングパラダイム　
Java やC のような一般的なプログラミング言語は、次の性質を持つので「高水準言語」に
分類される1。
•
1 対多の変換
•
ハードウェアに依存しない
•
アプリケーション指向
•
汎用的
•
強力な抽象
1 対多の変換
高水準言語のステートメント（文）は、複数のマシン命令に対応する。つまり、コンパイラ
が、ある言語のプログラムを、それと等価なマシン命令に翻訳するとき、1 個のステートメン
トが数個の命令に変換されるのが普通である。
ハードウェアに依存しない
高水準言語では、プログラマは根底にあるハードウェアに関する詳細を知らなくてもプログ
ラムを書くことができる。高水準言語を使うプログラマは、たとえば加算や減算などで浮動小
数点演算を指定するとき、ALU が浮動小数点演算を直接実装しているか、あるいは浮動小数点
演算用にコプロセッサを持っているか、といった詳細を意識しない。
アプリケーション指向
C やJava のような高水準言語は、プログラマがアプリケーションプログラムを書けるよう
に設計されている。だから高水準言語には、あらかじめ入出力機構が含まれているし、プログ
ラマが任意に複雑なデータオブジェクトを定義できるように援助する機構も含まれている。
汎用的
高水準言語は、特定のタスクや特定の問題領域に制限されない。C やJava のような言語に
は、プログラマが任意のタスクのためにプログラムを作れるように援助する機能が含まれて
いる。
強力な抽象
高水準言語は、たとえばプロシージャ（手続き）のような抽象を提供することによって、プ
ログラマが複雑なタスクを簡潔に表現できるようになっている。
1　訳注：これは、アセンブリ言語よりは高いレベルの言語という意味なので、相対的な言い方だ。より高
度な抽象性を持つ言語と比較する場合、C も「低水準言語」の扱いを受ける。
hi.0412.ko.2002@gmail.com
　9.3
低水準プログラミング言語の性質
157
9.3 　低水準プログラミング言語の性質
高水準言語とは対照的な「低水準言語」には、次の性質がある。
•
1 対1 の変換
•
ハードウェアに依存する
•
システムプログラミング指向
•
特殊用途
•
数少ない抽象
1 対1 の変換
一般に、低水準言語のステートメントは、それぞれ根底にあるプロセッサの命令1 つに対応
する。したがって、マシンコードへの変換は1 対1 である。
ハードウェア依存
それぞれのステートメントが1 個のマシン命令に対応するのだから、ある形式のプロセッサ
のために作られた低水準言語を、それとは形式の異なるプロセッサに用いることはできない。
システムプログラミング指向
高水準言語と違って、低水準言語はシステムプログラミングに最適である。この言語の機構
を使うプログラマは、オペレーティングシステムや、ハードウェアを直接制御するソフトウェ
アを組むことができる。
特殊用途
根底にあるハードウェアに重点を置く低水準言語は、精密な制御や極度な効率化が必要とさ
れるケースに限って使われる。たとえばコプロセッサとの通信には、普通は低水準言語が必要
とされる。
数少ない抽象
高水準言語と違って、低水準言語は、
（文字列やオブジェクトなど）複雑なデータ構造も、
（if-then-else やwhile のような）制御ステートメントも提供しない。低水準言語は、低い
レベルのハードウェア機構から抽象を構築する作業をプログラマに強制する2。
2　かつてコンピュータ科学者のアラン・パリス（Alan Perlis）が、
「プログラミングと無関係な詳細に気
を配る必要があったら、その言語は低水準だ」という名文句を披露したことがある（訳注：1982 年にACM
SIGPLAN で発表された”Epigrams in Programing”（https://cpsc.yale.edu/epigrams-programmin
g）にあった120 個のエピグラムの8 番目。
）
。ほとんどのアプリケーションには直接的な制御など不要だが、
低水準言語を使うと、アプリケーションに無用なオーバーヘッドが生まれる。
hi.0412.ko.2002@gmail.com
158
第9 章　アセンブリ言語とプログラミングパラダイム　
9.4 　アセンブリ言語
低水準言語でもっとも広く使われている形式は、
「アセンブリ言語」と呼ばれるものだ。そし
て、アセンブリ言語のプログラムを、ハードウェアが理解するバイナリのイメージに変換する
ソフトウェアは、
「アセンブラ」と呼ばれる。
「アセンブリ言語」という呼び名は、
「Java 言語」や「C 言語」のような呼び名とは意味が
違う。これは重要なポイントで、
「アセンブリ」という言語があるわけではない。どのアセン
ブリ言語も、ある特定のプロセッサ専用であり、命令セットとオペランドは、そのプロセッサ
のものを使う。したがってプロセッサごとに、多くのアセンブリ言語が存在する。プログラマ
は、
「MIPS アセンブリ言語」や「インテルx86 アセンブリ言語」について語る。
アセンブリ言語は、あるプロセッサに特有な性質（命令セット、オペランドアドレッシ
ング、レジスタなど）を含んだ低水準言語なので、数多くのアセンブリ言語が存在する。
プログラマにおよぼす影響は明らかだ。あるプロセッサから他のプロセッサへと移行すると
き、アセンブリ言語プログラマは、また新しい言語を覚えなければならない。やっかいなのは、
命令セットも、オペランドの型も、レジスタの名前も、アセンブリ言語ごとに違うことだ。し
かし、ほとんどのアセンブリ言語は、だいたい同じ基本的なパターンにしたがうので、いった
ん1 種類のアセンブリ言語を覚えてしまえば、他のも素早く覚えられる。重要なポイントとし
て、プログラマがアセンブリ言語の基本的なパラダイムを理解していれば、新しいアーキテク
チャに移行したとき、新しい詳細を学ぶ必要はあっても、新しいプログラミングのスタイルを
学ぶ必要はない。
相違は存在するにせよ、多くのアセンブリ言語には共通の基礎的構造がある。このため、
アセンブリプログラミングのパラダイムを理解しているプログラマは、新しいアセンブ
リ言語を素早く学ぶことができる。
アセンブリ言語のコンセプトを理解しようとするプログラマのために、今後の節では、ほと
んどのアセンブリ言語にあてはまる一般的な機能やプログラミングのパラダイムに重点を置く。
言語の詳細だけでなく、マクロのような概念も論じよう。
9.5 　アセンブリ言語の構文とオペコード
9.5.1
ステートメントのフォーマット
アセンブリ言語は低水準なので、1 ステートメントが1 個のマシン命令に対応する。言語の
ステートメントとマシン命令との対応を明らかにするため、ほとんどのアセンブラは、プログ
ラムの入力で1 行ごとに1 個ずつステートメントを入れることを要求する。次にフォーマット
の凡例を示す。
hi.0412.ko.2002@gmail.com
　9.5
アセンブリ言語の構文とオペコード
159
label: opcode
operand {1}, operand {2}, ...
ここで「label」はステートメントのラベルを示すオプションだ（分岐の飛び先に使われ
る）
。
「opcode」は命令として使える演算コード（オペコード）の1 つを指定し、それぞれの
「operand」は、その命令のオペランドを指定し、
「opcode」と他の項目との区切りには空白を
使う。
9.5.2
オペコードの名前
どのプロセッサのアセンブリ言語も、そのプロセッサが提供する個々の命令に1 個のシンボ
ル名を定義する。シンボル名の目的は、プログラマが命令の用途を覚えやすくすることだが3、
ほとんどのアセンブリ言語は、長い名前を使わず、極度に短い略称を使う。加算の命令なら、ア
センブリ言語でのオペコードは「add」になるかもしれないが、新たな場所に分岐する命令の場
合、オペコードは「b」という1 文字か、
「br」という2 文字で表現されるのが典型的だ。同様
に、ジャンプしてサブルーチンを呼び出す命令は、しばしば「jsr」というオペコードになる。
残念ながら、オペコードの呼び名は、基本的な演算に関しても統一されていない。たとえば、
ほとんどのアーキテクチャには、あるレジスタの内容を別のレジスタにコピーする命令がある。
その演算を表すのに、あるアセンブリ言語は”move”を略した「mov」というオペコードを使い、
別のアセンブリ言語は”load”を略した「ld」というオペコードを使うのだ。
9.5.3
コメントの書き方
オペコードが短いので、アセンブリ言語は書くのが簡単だが読むのが難しいという傾向があ
る。そのうえ水準が低いので、アセンブリ言語では、単純なタスクを実現するにも多くの命令
が必要になりがちだ。そこで、アセンブリ言語で書いたプログラムの可読性を確保するために、
プログラマは2 種類のコメントを加える。1 つはブロックコメントといって、大きなセクショ
ンに分けたコードについて、それぞれの目的を説明する。もう1 つは個々の行に付ける詳細な
コメントで、その行の目的を説明する。
プログラマがコメントを書きやすいように、たいがいのアセンブリ言語には、コメントを行
末までとする規約が採用される。つまり、そういう言語ではコメントを開始する文字（または
文字シーケンス）だけを定義するのだ。ある商用アセンブリ言語は、コメント開始にイゲタ文
字（#）を使うが、別のアセンブリ言語はコメントの開始をセミコロン（;）で表し、また別の
言語はC++のスタイルを採用して、2 個の連続するスラッシュ（//）を使う。ブロックコメン
トを書くときは、すべての行の先頭にコメント文字を置く。詳細コメントは、プログラムの各
3　訳注：このため、オペコードを表すシンボル名は、
「記憶を助ける」という意味の「ニーモニック」とい
う名で呼ばれる。
hi.0412.ko.2002@gmail.com
160
第9 章　アセンブリ言語とプログラミングパラダイム　
行に追加する。ブロックコメントを書くとき、プログラマは目立たせるために、その全体を文
字で囲むことが多い。たとえば、イゲタ文字がコメントの開始文字だとして、次のコメントは、
このセクションが、連結リストから指定サイズのメモリブロックを見つけ出すコードであると
説明している4。
################################################################
#
#
# Search linked list of free memory blocks to find a block
#
# of size N bytes or greater. Pointer to list must be in
#
# register 3, and N must be in register 4. The code also
#
# destroys the contents of register 5, which is used to
#
# walk the list.
#
#
#
# フリーメモリブロックの連結リストをサーチして、N バイト以上
#
# のサイズを持つブロックを見つける。リストへのポインタを　
　
#
# レジスタ3 で、N をレジスタ4 で指定すること。このコードは
#
# レジスタ5 を破壊する（リストを辿るのに使用する）
#
#
#
################################################################
ほとんどのプログラマはアセンブリコードの各行にコメントを追加して、その命令がアルゴ
リズムのなかで何をするのかを説明する。たとえばメモリブロックをサーチするコードは、次
のように始まるかもしれない。
ld
r5,r3
# リストのアドレスをr5 にロードする
loop 1:
cmp
r5,r0
# リストの終端か?
bz
notfnd
# リストの終端ならnotfnd に分岐する
...
コードの意味がわからないと思われるかもしれないが、この話の要点は、わりあい単純明快
だ。コードセクションの前にあるブロックコメントは、そのコードで「何が」達成されるかを
説明し、コードの各行にあるコメントは、その特定の命令が、最終的な結果を出すために「ど
う」貢献するかを示すのだ。
9.6 　オペランドの順序
あるアセンブリ言語から別のアセンブリ言語に移行するときプログラマが直面する問題の1
つが、オペランドの順序が違うという、微妙なだけにがっくりするような詳細の違いだ（もち
ろん所与のアセンブリ言語におけるオペランドの順序は一貫しているのだが）
。たとえば、あ
るレジスタから別のレジスタへと内容をコピーするロード（load）命令を例としよう。前記の
4　訳注：読者の便宜のため、対訳形式とします。
hi.0412.ko.2002@gmail.com
　9.6
オペランドの順序
161
コードでは第1 のオペランドが「ターゲット」レジスタを表し（コピー先のレジスタ）
、第2
のオペランドが「ソース」レジスタを表す（コピー元のレジスタ）
。そのように解釈されるか
ら、次のステートメントは、
ld
r5,r3
# リストのアドレスをr5 にロードする
レジスタ3 の内容をレジスタ5 にコピーする。プログラマは、右から左へ代入が行われるとい
う解釈を忘れないように「代入文では右辺の式の値が左辺に代入されますよね」と覚えさせら
れる。
ところが、別のアセンブリ言語では、逆の順序で指定する。ソースレジスタが左に、ターゲッ
トレジスタが右に置かれるのだ。そういうアセンブリ言語では、上記のコードのオペランドが
逆の順序で書かれる。
ld
r3,r5
# リストのアドレスをr5 にロードする
プログラマは、このように左から右に代入されるのを忘れないように「コンピュータは命令
を順番に読むのですよ」と覚えさせられる。
「テキストは左から右に読みますね? コンピュー
タも、まずオペコードを読み、第1 のオペランドを取り上げ、その値を第2 のオペランドに移
すのです」というわけだ。もちろん根底にあるハードウェアが命令を処理するのに、左から右
とか右から左とかいう順番があるわけではない。オペランドの順序は、あくまでアセンブリ言
語の構文にすぎない。
オペランドの順序を、さらに複雑にする要因が、まだいくつかある。第1 に、いまあげたサ
ンプルと違って、アセンブリ言語の命令には、オペランドが2 つないものも多い。たとえば
ビット反転命令に必要なオペランドは1 つだけである。さらに、たとえ命令にオペランドが2
つあっても、ソースとデスティネーションという考えがあてはまらない場合もある（たとえば
比較）
。だから、与えられたアセンブリ言語に慣れていないプログラマは、所与のオペコードに
ついて、オペランドの順序をたしかめるためマニュアルを参照する必要があるかもしれない。
もちろん、プログラマが書いたコードと、結果として生成されたバイナリの値を比べたら、
大きな違いが生じているだろう。アセンブリ言語は、プログラマにとって便利な記法を使うだ
けだ。ちなみにアセンブラは変換時にオペランドの順序を入れ換えることがある。私の経験で
は、2 つのアセンブリ言語を持つコンピュータを仕事で使ったことがある。片方はコンピュー
タのベンダーが作ったもので、もう片方はベル研（Bell Labs）の研究者たちが作ったものだ。
どちらも同じコンピュータで使うコードを生成するのだが、片方の言語はオペランドを左から
右の順で解釈し、もう片方は右から左の順で解釈していた。
hi.0412.ko.2002@gmail.com
162
第9 章　アセンブリ言語とプログラミングパラダイム　
9.7 　レジスタ名
典型的な命令は、少なくとも1 つはレジスタを参照するので、たいがいのアセンブリ言語に
はレジスタを指示する特別な方法が提供される。たとえば、多くのアセンブリ言語では、アル
ファベットの「r」に1 文字以上の数字が続く名前は、レジスタを参照するために予約されて
いる。だから、たとえば「r10」の参照は、レジスタ10 の参照である。
けれども、
レジスタ参照に統一規格は存在しない。あるアセンブリ言語では、
すべてのレジス
タ参照がドル記号（$）で始まり、その後に数字を付ける。だから、
「$10」はレジスタ10 なの
だ。他のアセンブラは、もっと柔軟性があって、プログラマがレジスタ名を選べるようになっ
ている。つまりプログラマは、レジスタの参照用に特定の名を定義する一連の「宣言」を挿入
できるのだ。だから、次のような宣言を見ることがあるかもしれない。
#
# このプログラムで使うレジスタ名の定義
#
r1
register 1
# レジスタ1 に、r1 という名前を定義する
r2
register 2
# 以下同様に、r2, r3, r4 を定義する
r3
register 3
r4
register 4
プログラマがレジスタ名を定義できるようにするのは、そのほうが読みやすくなるからだ。
プログラマは、意味のある名前を選ぶことができる。たとえば、あるプログラムが連結リスト
を管理するとしよう。レジスタを番号や「r6」のような名前で呼ぶ代わりに、意味のある名前
をレジスタに与えることができる。
#
# 連結リストのプログラムで使うレジスタ名の定義
#
listhd
register 6
# リストの先頭アドレスを入れる
listptr
register 7
# リスト巡回用のポインタを入れる
もちろん、レジスタ名をプログラマが選べるせいで意図しなかった結果が生じ、コードが理
解しにくくなるかもしれない。たとえば、あるプログラマが次の宣言を使って書いたプログラ
ムを、あなたが読むとしたら、どうだろうか。
r3
register 8
# レジスタ8 を、r3 という名前で定義する!
レジスタはアセンブリ言語プログラムに欠かせないので、どのアセンブリ言語でも、レ
ジスタを識別する方法が提供される。一部の言語では、特別な名前が予約されている。
hi.0412.ko.2002@gmail.com
　9.8
オペランドの型
163
プログラマがレジスタに名前を割り当てることができる言語もある。
9.8 　オペランドの型
第7 章で見たように、プロセッサが提供するオペランドには、しばしば複数の「型」がある。
個々のプロセッサのアセンブリ言語は、それぞれのハードウェアが提供する全部のオペランド
型に対応する必要がある。たとえば、あるプロセッサでは、それぞれのオペランドで、レジス
タか、即値（定数）か、メモリの位置か、あるいは「命令内のオフセットをレジスタの内容に加
算して得られるメモリの番地」を指定できる。このプロセッサのためのアセンブリ言語には、
これらのオペランド型に適した構文形式が必要だ。
前述したようにアセンブリ言語は、レジスタを他の値から区別するため、特殊な記号または
名前を使うことが多い。たとえば多くのアセンブリ言語では、
「10」と書けば定数値の10 を意
味するが、
「r10」と書けばレジスタ10 を参照できる。ただしアセンブリ言語によっては、定
数の前に特別なシンボルが必要なものもある（たとえば「#10」と書けば定数10 を意味する、
など）
。
どのアセンブリ言語も、利用可能なオペランド型のそれぞれに、
「構文形式」を提供する必要
がある。一例として、ソースからターゲットに値をコピーする場合を考えよう。あるプロセッ
サの命令で、レジスタを（直接的な）ソースとすることも、メモリの位置を（間接的な）ソー
スにすることも、どちらも可能だとしたら、そのアセンブリ言語は、その2 つをプログラマが
区別する方法を提供しなければならない。あるアセンブリ言語は、丸カッコを使って、2 つの
指定方法を区別する。
mov
r2,r1
# レジスタ1 の内容をレジスタ2 にコピー
mov
r2,(r1)
# r1 をメモリへのポインタとみなして、
# その場所のメモリからレジスタ2 にコピー
オペランドの話をまとめよう。
アセンブリ言語は、そのプロセッサがサポートする、それぞれのオペランド型に、構文
形式を提供する。それには、レジスタ参照も、即値も、メモリの間接参照も含まれる。
9.9 　アセンブリ言語プログラミングのパラダイムとイディ
オム
プログラミング言語は、プログラマがデータとコードを組織するのに使う枠組みを提供する。
このため、プログラミングのプロセスと、その結果であるコードに対して、プログラミング言
語が大きな影響をおよぼすかもしれない。アセンブリ言語は、高いレベルの構造を提供せず、
特定のスタイルを強制しないので、パラダイムがおよぼす影響が、とくに大きい。その代わり、
hi.0412.ko.2002@gmail.com
164
第9 章　アセンブリ言語とプログラミングパラダイム　
アセンブリ言語のプログラマは、任意の命令シーケンスを書くことができ、任意の場所にデー
タを格納できるという意味で、無制限の自由が与えられる。
経験を積んだプログラマは、こざかしいトリックや最適化よりも、一貫性と明快さのほうが
普通は重要だということを理解している。だから熟練プログラマは、
「イディオム」
（慣用句）
として蓄積されたパターンを一貫して使う。以下の節では、基本的な制御構造を使って、アセ
ンブリ言語のイディオムというコンセプトを例示していく。
9.10 　if 文のアセンブリコード
何らかの条件に依存して、コードが実行される場合と実行されない場合があることを、われ
われは「条件実行」という言葉で表現する。条件実行はプログラミングの基礎となるので、高
水準言語には、プログラマが条件実行を表現する方法が1 つ以上含まれるのが通例だ。条件実
行のもっとも基本的な形式は、
「if 文」
（if ステートメント）と呼ばれる。
アセンブリ言語で条件実行を行うためには、一連のステートメントをコーディングしなけれ
ばならない。図9‒1 は、高水準言語でよく使われる形式の条件実行と、それと等価な、アセン
ブリ言語でよく使われる形式を示している。
リスト9‒1：（a）高水準言語で条件実行を指定。
（b）それと等価なアセンブリ言語の書き方
if (条件) {
　
ここで条件をテスト（条件コード設定）
本文
　
条件が偽なら、label に分岐する
}
本文を実行するコード
次の文;
label:
次の文のコード
(a)
(b)
プロセッサによっては、図で示したように、条件実行の基礎となる機構として「条件コード」
を使うものがある。算術演算または比較を実行するとき、ALU が常に条件コードを設定するの
だ。条件コードのテストには条件分岐の命令を使うことができ、もし条件コードが命令と合致
していたら、分岐を実行する。こうしてif 文をエミュレートする際は、分岐命令で逆の条件を
テストする必要があることに注意しよう（つまり、条件が「満たされない場合」に分岐する）
。
次のif 文を例としよう。
if (a == b)
x
もしa とb がレジスタの5 と6 に格納されていたら、アセンブリ言語で次のように書けば
等価になる。
hi.0412.ko.2002@gmail.com
　9.11
if-then-else のアセンブリコード
165
cmp
r5, r6
# a とb の値を比較して条件コードを設定
bne
lab1
# 比較が等しくなかったらlab1 に分岐
x のコード
...
lab1:
次のステートメントのコード
9.11 　if-then-else のアセンブリコード
高水準言語で見られるif-then-else ステートメントでは、ある条件が真のときと偽のと
きの両方について、それぞれ実行すべきコードを指定する。リスト9‒2 に、if-then-else ス
テートメントと等価なアセンブリ言語の書き方を示す。
リスト9‒2：（a）高水準言語のif-then-else ステートメントと、
（b）等価なアセンブリ言語の書き方
if (条件) {
ここで条件をテスト（条件コード設定）
then の部分
　
もし条件が偽ならlabel1 に分岐
} else {
then の部分のコード
else の部分
label2 に分岐
}
label1:
else の部分のコード
次のステートメント;
　
　
label2:
次のステートメントのコード
(a)
(b)
9.12 　for ループのアセンブリコード
プログラミング言語の構造で、本文のコードを決まった回数だけ実行するものを、
「確定反
復」と呼ぶ。典型的な高水準言語では、for ステートメントを使って確定反復を実装する。リ
スト9‒3 に、for ループと、等価なアセンブリ言語の書き方を示す。
確定反復は、高水準言語とアセンブリ言語の興味深い相違を示している。それはコードを書
く場所の違いだ。アセンブリ言語では、制御構造を実装するためのコードを、別々の場所に分
けて書ける。具体的に言うと、高水準言語のプログラマは、初期化と続行判定とインクリメン
トをfor 文のヘッダで、まとめて指定するものと考えるが、それと等価なアセンブリ言語では、
本文のコードの後にインクリメントが置かれている。
hi.0412.ko.2002@gmail.com
166
第9 章　アセンブリ言語とプログラミングパラダイム　
リスト9‒3：（a）高水準言語のfor ステートメントと、
（b）等価なアセンブリ言語の書き方（レジスタ4
をインデックスとして使う）
for (i=0; i<10; i++) {
r4 にゼロをセット
本文
　
label1:
r4 を10 と比較
}
もし10 以上ならlabel2 に分岐
次のステートメント;
　
本文を実行するコード
r4 をインクリメント
label1 に分岐
label2:
次のステートメントのコード
(a)
(b)
9.13 　while 文のアセンブリコード
プログラミング言語の用語で「不確定反復」というのは、ゼロ回以上実行されるループのこ
とだ。高水準言語では不確定な反復を表すのに「while」というキーワードを使うことが多い。
リスト9‒4 に、while 文と等価なアセンブリ言語の書き方を示す。
リスト9‒4：（a）高水準言語のwhile 文と、
（b）等価なアセンブリ言語の書き方
while (条件) {
label1:
条件を計算するコード
本文
もし偽ならlabel2 に分岐
}
本文を実行するコード
次のステートメント;
label1 に分岐
label2:
次のステートメントのコード
(a)
(b)
9.14 　サブルーチン呼び出しのアセンブリコード
ひとかたまりのコードで、呼び出されたら何らかの計算処理を行ってから呼び出した側に制
御を返すものを、
「プロシージャ」または「サブルーチン」と呼んでいる。
「プロシージャコー
ル」
、
「サブルーチンコール」というのは、その「呼び出し」を意味する言葉だ。その鍵となる
のは、サブルーチンが呼び出されるとき、呼び出しが発生した場所をプロセッサが記録してお
き、サブルーチンが完了したら、記録した場所から実行を再開する、というアイデアだ。この
ため、どのサブルーチンも、プログラムの複数の場所から呼び出すことが可能である。なぜな
ら実行の制御は、常に、その呼び出しが発生した場所に戻されるからだ。
多くのプロセッサは、プロシージャコールのために2 つの基本的なアセンブリ命令を用意す
る。
「サブルーチン呼び出し」
（jsr）命令は、現在の場所を保存し、指定された場所のサブルー
チンに分岐する。そして、サブルーチンからの「リターン」
（ret）命令によって、プロセッサ
は、前に保存した場所に戻る（リターンする）
。リスト9‒5 は、プロシージャの宣言と2 回の
hi.0412.ko.2002@gmail.com
　9.15
引数付きでサブルーチンを呼び出すアセンブリコード
167
呼び出しを行うコードで、その2 種類のアセンブリ命令の使い方を示している。
リスト9‒5：プロシージャx の宣言と2 回の呼び出しを、高水準言語（a）と、それと等価なアセンブリ言
語（b）で示す
x() {
x:
x の本文のコード
x の本文
ret
}
x();
jsr x
その他のステートメント; 　
その他のステートメントのコード
x();
jsr x
次のステートメント;
　
次のステートメントのコード
(a)
(b)
9.15 　引数付きでサブルーチンを呼び出すアセンブリコード
高水準言語では、プロシージャコールがパラメータ化されることがあり、そのプロシージャ
本文は、パラメータを参照するように書かれる。そして呼び出し側は、
「引数」と呼ばれる値の
集合を、そのプロシージャに渡す。プロシージャがパラメータを参照するとき、その値は、対
応する引数から得られる。そこで問題だが、アセンブリ言語では、どうやって引数をプロシー
ジャに渡すのか。
残念ながら、引数渡しの詳細はプロセッサによって、まったく違う。たとえば次にあげる3
つの方法は、どれも、少なくとも1 つのプロセッサで使われている5。
•
プロセッサは、引数にメモリ内のスタックを使う
•
プロセッサは、レジスタウィンドウを使って引数を渡す
•
プロセッサは、特殊な引数用レジスタを使う
一例として、r1 からr8 までのレジスタを、プロシージャコールで引数を渡すために使うプ
ロセッサがあるとしよう。リスト9‒6 に、そういうアーキテクチャでプロシージャコールを行
うためのアセンブリ言語コードを示す。
5　
「ret」
命令で、
どこにジャンプしたら戻れるかを示す
「リターンアドレス」
に使われるストレージは、
し
ばしば引数に使われるストレージと関連がある。訳注：レジスタウィンドウは、本書の5.2 節に説明がある。
hi.0412.ko.2002@gmail.com
168
第9 章　アセンブリ言語とプログラミングパラダイム　
リスト9‒6：（a）は、パラメータ化されたプロシージャx の宣言と、2 回の呼び出しの、高水準言語での書
き方を示す。
（b）は、引数をレジスタで渡すプロセッサのための、それと等価なアセンブリ言語の書き方
x(a, b) {
x:
x の本文のコード。次を前提とする：
x の本文
レジスタ1 に、パラメータa が含まれる
}
レジスタ2 に、パラメータb が含まれる
ret
x(-4, 17);
レジスタ1 に、-4 をロードする
その他のステートメント;
　
レジスタ2 に、17 をロードする
x(71, 27);
jsr x
次のステートメント;
　
その他のステートメントのコード
レジスタ1 に、71 をロードする
レジスタ2 に、27 をロードする
jsr x
次のステートメントのコード
(a)
(b)
9.16 　プログラマにおよぼす影響
引数渡しに多種多様な方法が存在することの影響は明らかだろう。引数を渡し、それを受け
取るのに必要なアセンブリ言語コードは、プロセッサによって大きく異なる。重要なポイント
として、プログラマは性能を向上させるような新しい引数渡しの機構を自由に発明できる。メ
モリ参照はレジスタ参照よりも遅いから、たとえハードウェアがメモリ内のスタックを使うよ
うに設計されていても、プログラマは性能を高めるために、一部の引数をメモリではなく汎用
レジスタに入れて渡すのを選ぶかもしれない。
引数渡しにはさまざまなハードウェア機構が存在するので、アセンブリ言語で引数渡し
に使われるパラダイムは1 つに限定されない。そのうえ、プログラマは性能を最適化す
るために（たとえば値をレジスタに入れるなど）基本的な機構とは別の方法を使うこと
がある。
9.17 　関数呼び出しのアセンブリコード
「関数」と呼ばれるのは、結果を1 個の値で返すプロシージャだ。たとえばsine(x) を計
算する算術関数を作る場合は、引数で角度を指定された関数が、その角度の正弦（サイン）を
返す。プロシージャと同じく関数も引数を取ることができるし、プログラムの任意の場所から
呼び出せる。したがって、所与のプロセッサにおいて関数を呼び出すには、プロシージャを呼
び出すのと同じ基本的な機構が使われる。
関数とプロシージャは似ているけれど、関数呼び出しには、もう1 つ詳細が加わる。関数が
結果を返す具体的な方法について同意が必要なのだ。引数渡しと同じく、これにも多くの選択
hi.0412.ko.2002@gmail.com
　9.18
アセンブリ言語と高水準言語のやりとり
169
肢が存在する。関数の「戻り値」のために、専用のハードウェアレジスタを別に提供するプロ
セッサも作られている。別のプロセッサは、プログラムが汎用レジスタのどれかを使うことを
前提としている。いずれにしても関数は、ret 命令を実行する前に、そのプロセッサで使われ
る場所に戻り値をロードしなけければならない。リターンが実行されたら、呼び出し側のプロ
グラムは、その戻り値を取り出して使う。
9.18 　アセンブリ言語と高水準言語のやりとり
アセンブリ言語で書かれたコードと、高水準言語で書かれたコードとの間では、双方向のイ
ンタラクションが可能である。つまり、高水準言語で書いたプログラムから、アセンブリ言語
で書いたプロシージャや関数を呼び出すことができるし、アセンブリ言語で書いたプログラム
から、高水準言語で書いたプロシージャや関数を呼び出すことも可能である。もちろん、プロ
グラマが自在に制御できるのはアセンブリ言語のコードだけで、高水準言語のコードには、そ
れができないから、アセンブリ言語のプログラムのほうで、高水準言語が使っている「呼び出し
規約」にしたがわなければならない。つまりアセンブリコードは、戻り値の格納も、プロシー
ジャ呼び出しも、引数渡しも、関数値を返すにも、高水準言語が使うのとまったく同じ機構を
使わなければならない。
プログラマが、アセンブリ言語のコードを高水準言語で書いたコードと混在させる理由は何
だろうか。ある種の状況においては、高水準言語では根底にあるハードウェアと直接やりとり
できないので、アセンブリコードが必要になる。たとえば特殊なグラフィックスハードウェア
を持つコンピュータでグラフィックス機能を使うのに、アセンブリコードが必要かもしれない。
けれども多くの場合、アセンブリ言語は性能の最適化に使われるだけだ。ある特定のコードが
ボトルネックだと識別できたら、プログラマは、そのコードの最適化バージョンをアセンブリ
言語で書く。最適化されたアセンブリ言語コードは、プロシージャまたは関数としてまとめる
のが典型的であり、プログラムの残りの部分は、高水準言語で書いたまま残される。その結果、
高水準言語で書いたコードと、アセンブリ言語で書いたコードとのもっとも一般的なやりとり
は、高水準言語で書いたプログラムから、アセンブリ言語で書いたプロシージャまたは関数を
呼び出す形になる。
要点をまとめよう。
アプリケーションプログラムをアセンブリ言語で書くのは難しいので、高水準言語では
機能が足りないか十分な性能が得られないような状況に限って、アセンブリ言語が使わ
れる。
hi.0412.ko.2002@gmail.com
170
第9 章　アセンブリ言語とプログラミングパラダイム　
9.19 　変数とストレージのアセンブリコード
アセンブリ言語を使うプログラマは、命令を生成するステートメントだけでなく、データ項
目の定義も書くことができる。初期値を持つ変数も、初期化されない変数も、宣言できる。ア
センブラによって異なるが、たとえば16bit データ用にストレージを宣言するのに「.word」と
いうディレクティブ（疑似命令）を使い、32bit データ用にストレージを宣言するのに「.long」
というディレクティブを使う場合がある。リスト9‒7 に、高水準言語による宣言と、それと等
価なアセンブリコードを示す。
リスト9‒7：（a）高水準言語による変数宣言と、
（b）それと等価なアセンブリ言語による変数宣言
int x, y, z;
x:
.long
y:
.long
z:
.long
short w, q;
w:
.word
q:
.word
ステートメント... 　
ステートメント...
(a)
(b)
キーワードの「.word」や「.long」は、アセンブリ言語の「ディレクティブ」と呼ばれる
ものだ。これらはオペコードと同じ場所に現れるが、ディレクティブは命令に対応するのでな
く、変換を制御するものだ。この図のディレクティブは、変数の置き場所としてストレージ空
間を確保する。ほとんどのアセンブリ言語で、ストレージを予約するディレクティブでは、プ
ログラマが初期値を指定できる。だから、次のディレクティブ、
x:
.word 949
は、この場所に16bit のメモリを予約し、そこに949 という整数値を割り当て、プログラマが
その場所を参照するのに使う、x というラベル（名前）を定義している。
9.20 　アセンブリ言語のコーディング例
コンセプトを明らかにし、アセンブリ言語のイディオムが実際にどう使われるかを示すため
に、サンプルを示そう。x86 とARM のアーキテクチャを比較しやすいように、それぞれのアー
キテクチャで同じ例を使う。サンプルをわかりやすくするため、まずはC のプログラムを見て
から、同じアルゴリズムをアセンブリ言語で実装する方法を見ることにしたい。
すべてのイディオムを例示しようとしたら、長大で複雑なプログラムをサンプルに使う必要
がある。だから、ごく簡単な例を使って、いくつか基本的なイディオムだけを示そう。ここで
は不確定反復と条件実行を示す。サンプルは、
「フィボナッチ数列」の最初の部分をリストと
hi.0412.ko.2002@gmail.com
　9.20
アセンブリ言語のコーディング例
171
して表示するコードだ。この数列で、最初の2 つの値は、どちらも1 である。その後に続く値
は、どれも、その前にある2 つの値の和として計算される。したがって、その数列は、1, 1,
2, 3, 5, 8, 13, 21, ... と続く。
このコードは、フィボナッチ数列の値が（コンピュータアーキテクチャに関して述べた概念
を使って言えば）2 の補数形式の32bit 符号付き整数に収まるようにしている。その範囲の数
列を生成したら、コードは1000 よりも大きな値の数を数えてサマリー（要約）を表示する。
9.20.1
C によるフィボナッチのサンプル
リスト9‒8 は、フィボナッチ数列のうち、32bit 符号付き整数に収まる値をすべて計算するC
のプログラムだ。このプログラムはprintf を使って、それぞれの値を表示する。また、1000
よりも大きな値の数を計算し、サマリーとして、その総数とともに計算で使った変数の最終的
な値も、printf を使って表示する。
リスト9‒8：32bit 符号付き整数に収まるフィボナッチ数列の値を計算して表示するサンプルのC プログ
ラム
#include <stdlib.h>
#include <stdio.h>
#include <ctype.h>
int a = 1, b = 1, n, tmp;
void main(void) {
n = 0;
printf(" %10d\n", b);
printf(" %10d\n", a);
while ( (tmp = a + b) > 0 ) {
b = a;
a = tmp;
if (a > 1000) {
n++;
}
printf(" %10d\n", a);
}
printf("\nThe number of values greater than 1000 is %d\n", n);
printf("Final values are: a=0x%08X b=0x%08X tmp=0x%08X\n",a,b,tmp);
exit(0);
}
リスト9‒9 は、このプログラムの実行結果を示している。出力の最後に、while ループを
終えた後の変数、a、b、tmp の値を表示している。変数a の値（10 進数なら1,836,311,903）
は、16 進数の6D73E55F だ。
「tmp」変数の値はB11924E1 だが、これは最上位ビットが1 に
hi.0412.ko.2002@gmail.com
172
第9 章　アセンブリ言語とプログラミングパラダイム　
なっている。第3 章に説明があるが、このtmp は、符号付き整数として評価すると負の値にな
るので、そこでループが終わる。また、大きなフィボナッチ数を数えるカウンタ変数n の最後
の値は30 である。この数は、出力で1000 より大きな値のある行を数えれば検証できる。
リスト9‒9：これはリスト9‒88 のプログラムを実行した結果の出力である
1
1
2
3
5
8
13
21
34
55
89
144
233
377
610
987
1597
2584
4181
6765
10946
17711
28657
46368
75025
121393
196418
317811
514229
832040
1346269
2178309
3524578
5702887
9227465
14930352
24157817
39088169
63245986
102334155
165580141
267914296
433494437
701408733
hi.0412.ko.2002@gmail.com
　9.20
アセンブリ言語のコーディング例
173
1134903170
1836311903
The number of values greater than 1000d is 30
Final values are: a=0x6D73E55F b=0x43A53F82 tmp=0xB11924E1
9.20.2
x86 アセンブリ言語によるフィボナッチのサンプル
リスト9‒10 に示すのは、リスト9‒8 で見たプログラムと同じ出力を生成するx86 のアセン
ブリコードだ。このコードでは、gcc コンパイラの呼び出し規約を使って、printf を呼び出
している。
リスト9‒10：リスト9‒8 のC プログラムにしたがって書かれたx86 アセンブリ言語のプログラム
.data
a:
.long
1
# 初期値のあるデータ(a とb)
b:
.long
1
.comm
n,4,4
# 初期値のないデータ(n とtmp)
.comm
tmp,4,4
fmt1:
.string " %10d\n"
fmt2:
.string "\nThe number of values greater than 1000 is %d\n"
fmt3:
.string "Final values are: a=0x%08X b=0x%08X tmp=0x%08X\n"
.text
.globl
main
main:
movl
$0, n
# n = 0
movl
b, %esi
# a を表示するための引数を準備
movl
$fmt1, %edi
movl
$0, %eax
call
printf
movl
a, %esi
# b を表示するための引数を準備
movl
$fmt1, %edi
movl
$0, %eax
call
printf
while:
movl
a,%eax
# eax <- a
addl
b,%eax
# eax <- eax + b
movl
%eax,tmp
# tmp <- eax
testl
%eax, %eax
# eax をテスト
6
jle
endwhile
# もし0 または負なら、endwhile にジャンプ
movl
a, %eax
# eax <- a
movl
%eax, b
# b <- eax
movl
tmp, %eax
# eax <- tmp
movl
%eax, a
# a <- eax
cmpl
$1000, %eax
# 1000 とeax を比較
7
hi.0412.ko.2002@gmail.com
174
第9 章　アセンブリ言語とプログラミングパラダイム　
jle
endif
# もし「1000 <= eax」なら、endif にジャンプ
movl
n, %ebx
# ebx <- n
addl
$1, %ebx
# ebx <- ebx + 1
movl
%ebx, n
# n <- ebx
endif:
movl
a, %esi
# a を表示するための引数を準備
movl
$fmt1, %edi
movl
$0, %eax
call
printf
jmp
while
endwhile:
movl
n, %esi
# n を表示するための引数を準備
movl
$fmt2, %edi
movl
$0, %eax
call
printf
movl
tmp, %ecx
# a, b, tmp を表示するための引数を準備
movl
b, %edx
movl
a, %esi
movl
$fmt3, %edi
movl
$0, %eax
call
printf
movl
$0, %edi
# 引数0 で終了
call
exit
9.20.3
ARM アセンブリ言語によるフィボナッチサンプル
リスト9‒11 に示すのは、リスト9‒8 のプログラムと同じ出力を生成するARM のアセンブ
リコードだ。x86 コードもARM コードも、最適化されていないが、いずれにしても変数にレ
ジスタを使えば命令を節約できる。その一例として、ARM のコードに、わずかな最適化を施
してある。レジスタr4 からr8 までを、変数a、b、n、tmp のアドレスと、フォーマット文字
列fmt1 のアドレスで初期化したのだ。これらのレジスタをプログラムの実行中に変化させな
い理由は、値の保存と復元にサブプログラムの呼び出しが必要だからだ。この最適化により、
変数a を表示するためにprintf を呼び出すコードは、たった1 命令で、フォーマットのアド
レスを、第1 引数レジスタ（r0）に移すことができる。
mov r0, r8
さらに、変数a の値を第2 引数レジスタ（r1）に移すコードも、1 個の命令しか使ってい
6　訳注：x86 アセンブリ言語の基本事項は、本書の付録C にある。test 命令は、2 つのオペランドの論
理AND 演算を行って条件コードをセットする。次のjle 命令は、その値によって条件分岐を行う。
7　訳注：cmp 命令は、
比較を行った結果
（大か、
小か、
等しいか）
によって条件コードをセットする。test、
cmp、jle については、本書の付録C.14 節に簡単な説明がある。
hi.0412.ko.2002@gmail.com
　9.20
アセンブリ言語のコーディング例
175
ない。
ldr r1, [r4]
もっとコードを改善する方法は、練習問題で示唆しよう。
リスト9‒11：リスト9‒8 のアルゴリズムにしたがう、ARM アセンブリ言語のプログラム
.text
.align 4
.global main
main:
movw
r4, #:lower16:a
@ r4 <- &a
movt
r4, #:upper16:a
movw
r5, #:lower16:b
@ r5 <- &b
movt
r5, #:upper16:b
movw
r6, #:lower16:n
@ r6 <- &n
movt
r6, #:upper16:n
movw
r7, #:lower16:tmp
@ r7 <- &tmp
movt
r7, #:upper16:tmp
movw
r8, #:lower16:fmt1
@ r8 <- &fmt1
movt
r8, #:upper16:fmt1
mov
r0, #0
str
r0, [r6]
@ n = 0
ldr
r1, [r5]
@ r1 <- b
mov
r0, r8
@ r0 <- &fmt1
bl
printf
ldr
r1, [r4]
@ r1 <- a
mov
r0, r8
@ r0 <- &fmt1
bl
printf
while:
ldr
r3, [r4]
@ r3 <- a
ldr
r2, [r5]
@ r2 <- b
add
r1, r3, r2
@ r1 <- a + b
str
r1, [r7]
@ tmp <- r1 (つまりtmp <- a + b)
cmp
r1, #0
@ tmp をテストする
ble
endwhile
@ もしtmp <= 0 なら、endwhile に分岐
str
r3, [r5]
@ b <- a
str
r1, [r4]
@ a <- tmp
cmp
r1, #1000
@ a と1000 を比較する
ldrgt
r3, [r6]
@ もしa>1000 ならば、r3 <- n
addgt
r3, r3, #1
@ もしa>1000 ならば、r3 <- r3 + 1
strgt
r3, [r6]
@ もしa>1000 ならば、n <- r3
mov
r0, r8
@ r0 <- &fmt1
hi.0412.ko.2002@gmail.com
176
第9 章　アセンブリ言語とプログラミングパラダイム　
bl
printf
@ r1 は、まだa である
b
while
endwhile:
movw
r0, #:lower16:fmt2
movt
r0, #:upper16:fmt2
@ r0 <- &fmt2
ldr
r1, [r6]
@ r1 <- n
bl
printf
ldr
r3, [r7]
@ r3 <- tmp
ldr
r2, [r5]
@ r2 <- b
ldr
r1, [r4]
@ r1 <- a
movw
r0, #:lower16:fmt3
movt
r0, #:upper16:fmt3
@ r0 <- &fmt3
bl
printf
mov
r0, #0
bl
exit
@ 引数0 で終了
.align 4
.comm
tmp,4,4
@ 初期値のないデータ
.comm
n,4,4
.data
.align
4
b:
.word
1
@ 初期値のあるデータ
a:
.word
1
fmt1:
.ascii
" %10d\012\000"
fmt2:
.ascii
"\012The number of values greater than 1000 is %d\012\000"
fmt3:
.ascii
"Final values are: a=0x%08X b=0x%08X tmp=0x%08X\012\000"
9.21 　2 パスのアセンブラ
「アセンブラ」は、アセンブリ言語プログラムを、プロセッサが実行できるバイナリコードに
変換するソフトウェアだ。アセンブラは、ソースプログラムを受け取って、それと等価なバイ
ナリコードを出力として生成するのだから、コンセプトはコンパイラに似ている。違うのは、
コンパイラのほうが、アセンブラより大きな責任を負うことだ。たとえばコンパイラは、変数
をメモリに割り当てる方法を選べるし、それぞれの命令にどんな命令シーケンスを使うか、汎
用レジスタにどの値を入れていくかも、自ら選択する。アセンブラには、そういう選択ができ
ない。ソースプログラムによって詳細が厳密に定められているからだ。アセンブラとコンパイ
ラの違いは、次のようにまとめられる。
hi.0412.ko.2002@gmail.com
　9.21
2 パスのアセンブラ
177
コンパイラもアセンブラも、ソースプログラムを、それと等価なバイナリコードに変換
するが、コンパイラには、どの値をレジスタに入れておくかについて、個々のステート
メントの実装に使う命令について、あるいは変数をメモリに割り当てる方法について、
大きな選択の自由がある。アセンブラは、ソースプログラムに存在するステートメント
を、それと等価なバイナリ形式に1 対1 で変換するだけだ。
しばしばアセンブラは「2 パスのアルゴリズム」にしたがう。それは、アセンブラがソース
プログラムを2 度「走査」するという意味だ。なぜ2 パスが必要かを理解するために、多くの
分岐命令で参照する飛び先のラベルが、プログラムを読み進んだ先で定義される「前方参照」
になるケースが多いことに注目しよう。アセンブラが最初に分岐命令に到達したとき、アセン
ブラは、そのラベルに割り当てられるアドレスを知ることができない。だからアセンブラは、
第1 パスの実行時に、それぞれのラベルが最終的なプログラムで持つアドレスを計算し、その
情報を「シンボルテーブル」と呼ばれる表に保存する。次にアセンブラは第2 のパスを実行し
て、コードを生成する。表9‒1 は、アセンブリ言語のコード断片と、ステートメントの相対位
置を使って、このアイデアを示している。
表9‒1：架空のプロセッサにおける、アセンブリ言語のコードの断片と、それぞれのステートメントが置か
れる場所を示す。その位置（相対アドレス）は、アセンブラの第1 のパスで判明する
位置
アセンブリコード
0x00
-
0x03
x:
.long
0x04
-
0x07
label1:
cmp
r1, r2
0x08
-
0x0B
bne
label2
0x0C
-
0x0F
jsr
label3
0x10
-
0x13
label2:
load
r3, 0
0x14
-
0x17
br
label4
0x18
-
0x1B
label3:
add
r5, 1
0x1C
-
0x1F
ret
0x20
-
0x23
label4:
ld
r1, 1
0x24
-
0x27
ret
第1 パスの間にアセンブラは命令のサイズを計算するが、実際に詳細を記入するわけではな
い。いったん第1 パスを終えたアセンブラは、各ステートメントの位置を記録し終わっている。
したがってアセンブラには、プログラムに存在する、それぞれのラベルの値が、すでにわかっ
ている。表で言えば、label4 が0x20 番地（10 進では32）という位置にあることを、アセン
ブラは知っている。ゆえにアセンブラの第2 パスで次のステートメントに遭遇するとき、
br
label4
アセンブラは分岐命令のオペランドとして32 という即値を生成できる。同様に、他の分岐
命令についてもラベルの場所が判明しているからコードを生成できる。
hi.0412.ko.2002@gmail.com
178
第9 章　アセンブリ言語とプログラミングパラダイム　
アセンブラの詳細を理解することは重要ではないが、次のことは知っておくべきだ。
基本的に、アセンブラはアセンブリ言語プログラムを2 パスで走査する。第1 のパス
で、アセンブラは各ステートメントに位置を割り当てる。第2 のパスでアセンブラは、
割り当てた位置の情報を使ってコードを生成する。
このアセンブラの仕組みがわかったら、アセンブラを使う主な利点の1 つを論じることがで
きる。それは分岐アドレスが自動的に再計算されることだ。自動的な再計算が、どれほど役に
立つかは、それがなかったらどうなるかを想像すればわかる。プログラマが作成しているプロ
グラムの途中に命令を1 つ挿入したら、その後に続く命令の位置がずれてしまう。その結果、
挿入点よりも先にあるラベルを参照する分岐命令は、すべて変更しなければならない。
アセンブラがなければ、プログラマにとって分岐先を変更するのも、面倒でエラーを起こし
やすい作業になる。デバッグ中も、一連の変更をプログラムに加えることが多い。アセンブラ
があれば、プログラムは容易に変更できるようになる。ただアセンブラを再実行して、すべて
の分岐アドレスが更新されたバイナリイメージを作ればよいのだ。
9.22 　アセンブリ言語のマクロ
アセンブリは低水準言語なので、ありきたりの演算にも数多くの命令が必要になる。もっと
重要なことに、しばしばアセンブリ言語のプログラマは、同じコードシーケンスを、わずかに
変更しながら何度も繰り返して書いていることに気がつくものだ。コードシーケンスの繰り返
しによって、プログラミングは退屈な作業になりがちであり、コピー&ペーストをやっていて
間違いが生じることもある。
このように繰り返しの多いコーディングからプログラマを救うために、多くのアセンブリ言
語には「パラメータ付きマクロ」の機構が含まれている。プログラマがマクロ機能を使うには、
ソースプログラマに、
「定義」と「展開」という、2 種類の要素を追加する。ちなみに、読者が
C のプログラマなら、アセンブリ言語のマクロはC のプリプロセッサマクロと似たような働き
をするのだな、と思われるだろう。
マクロ機能によって、アセンブラに、もう1 つのパスが追加される。アセンブラの最初のパ
スでは、マクロが展開される。重要なのは、マクロ展開のパスがアセンブリ言語のステートメ
ントを構文解析せず、命令の変換も行わないということだ。マクロを処理するパスは、マクロ
を含むアセンブリ言語ソースプログラムを入力として受け取り、マクロを展開したアセンブリ
言語ソースプログラムを出力として生成する。マクロの前処理を行う、このパスの出力が、通
常の2 パスアセンブラの入力になるのだ。多くのアセンブラには、プログラマがデバッグ用に、
マクロ展開済みのソースコードを取得できるオプションがある（これによってプログラマは、
マクロが計画通りに展開されたかどうかを確認できる）
。
アセンブリ言語のマクロは、アセンブリ言語によって詳細が異なるが、コンセプトは単純明
快だ。マクロ定義は、通常は2 つのキーワード（たとえばmacro とendmacro）で前後を囲ま
hi.0412.ko.2002@gmail.com
　9.22
アセンブリ言語のマクロ
179
れた中に、コードシーケンスが入っている。たとえばスト9‒12 は、addmem という名前のマク
ロを定義している。このマクロは、場所を指定された2 つのメモリの内容を加算して、その結
果を第3 の場所に置くものだ。
リスト9‒12：キーワードのmacro とendmacro を使うマクロ定義の例。このマクロの要素は、パラメー
タのa、b、c を参照する
macro
addmem(a, b, c)
load
r1, a
# 第1 引数をレジスタ1 にロードする
load
r2, b
# 第2 引数をレジスタ2 にロードする
add
r1, r2
# レジスタ2 をレジスタ1 に加算する
store
r3, c
# 結果を第3 引数にストアする
8
endmacro
いったん定義したマクロは、展開することができる。プログラマがマクロを呼び出して、引
数群を提供する。アセンブラは、そのマクロ呼び出しを、マクロ本文のコピーで置き換えたう
えで、その「仮パラメータ」を実際の引数で置換する。たとえばリスト9‒13 は、リスト9‒12
で定義されたaddmem マクロを拡張して生成されたアセンブリコードである。
リスト9‒13：addmem マクロを展開して作られるアセンブリコードの例
#
# メモ: 下記のコードは、addmem(xxx, YY, zqz) からの結果
#
load
r1, xxx
# 第1 引数をレジスタ1 にロードする
load
r2, YY
# 第2 引数をレジスタ2 にロードする
add
r1, r2
# レジスタ2 をレジスタ1 に加算する
store
r3, zqz
# 結果を第3 引数にストアする
理解すべき重要なポイントとして、リスト9‒12 のマクロ定義はプロシージャ宣言に似てい
るが、マクロはプロシージャのように演算を実行するわけではない。第1 に、マクロを宣言す
ることでマシン命令が生成されるのではない。第2 に、マクロの呼び出しは、展開されるので
あって、コールされるのではない。つまり、マクロの本文全体の複製が、アセンブリプログラ
ムにコピーされるのだ。第3 に、マクロの引数は、それに対応するパラメータを置き換える文
字列として扱われる。それによって予期せぬ結果が生じることもあるから、引数が文字通りに
置換されることを、しっかりと認識すべきだ。たとえばリスト9‒14 は、マクロ展開の結果と
して不正なアセンブリプログラムが生じる可能性を示している。
8　訳注：このアセンブリ言語では、第1 オペランドがデスティネーションらしい。それなら、このstore
命令は、第3 引数のc をレジスタ3 にストアするから、本文やコメントの記述と矛盾する。何かの間違いと
思われるが、結果としては意図とは異なるバイナリコードが生成され、たぶんデバッグが必要になるだろう。
そのときマクロ展開したソースコードを見て、はじめて間違いに気付くかもしれない。store 命令も第1 オ
ペランドがディスティネーションだとすれば、結果を第３引数にストアするには、store
c, r1 と書く。
hi.0412.ko.2002@gmail.com
180
第9 章　アセンブリ言語とプログラミングパラダイム　
リスト9‒14：addmem マクロを展開した結果として生じた、不正なプログラムの例。アセンブラは引数に
よる置換を行うとき、その正当性をチェックしない!
#
# メモ：下記のコードは、addmem(1+, %*J , +) からの結果
#
load
r1, 1+
# 第1 引数をレジスタ1 にロードする
load
r2, %*J
# 第2 引数をレジスタ2 にロードする
add
r1, r2
# レジスタ2 をレジスタ1 に加算する
store
r3, +
# 結果を第3 引数にストアする
このリストが示すように、マクロの引数には任意の文字列を使えるから、プログラマが、うっ
かりミスを犯すことがあり得る。プログラマがソースプログラムを展開するまで、
何の警告も出
ない。たとえば、この例の最初の引数は「1+」という文字列だが、これは構文エラーである。こ
のマクロを展開すると、アセンブラが指定された文字列で置換を行った結果は次のようになる。
load r1, 1+
同じように、第2 の引数「%*J」による結果は次のようになる。
load r2, %*J
これらは、まったく意味を成さない。けれども、マクロの展開が実行されるまでは、何のエ
ラーも検出されず、アセンブラは、このプログラムをアセンブルしようとする。もっと重要な
ことに、マクロ展開がソースプログラムを作るのだから、行番号を参照するエラーメッセージ
は、拡張されたプログラムの行番号を参照しているのであって、プログラマが書いた元のソー
スコードの行番号ではない。
マクロ展開機構は、アセンブリ言語のソースプログラムに対する前処理であり、マクロ
の呼び出しをマクロ本体のテキストで置換した、もう1 つのソースプログラムを作る。
マクロ処理は単純にテキストの置換を行うもので、不正な引数があっても検出されない。
エラーの検出は、マクロの展開後にアセンブラが行うだけだ。
hi.0412.ko.2002@gmail.com
　9.23
まとめ
181
9.23 　まとめ
アセンブリ言語は、命令セット、オペランドのアドレッシングモード、レジスタといったプ
ロセッサの性質を含む、低いレベルの言語だ。多くのアセンブリ言語が、プロセッサの種類ご
とに、1 個ずつ（または、それ以上）存在する。たしかに相違はあるが、多くのアセンブリ言
語に共通する基本的な構造がある。
アセンブリ言語では、それぞれのステートメントが、根底にあるハードウェアへの1 個の命
令に対応する。ステートメントは、オプションのラベルと、オペコードと、オペランドで構成
される。あるプロセッサのアセンブリ言語は、そのプロセッサが受け入れるオペランド型のそ
れぞれに、文法的な形式を定義する。
アセンブリ言語は、それぞれに違いはあっても、同じ基本的パラダイムにしたがうものが多
い。典型的なアセンブリ言語のシーケンスとして、条件付きで実行される命令、条件によって
別の実行パスを持つ命令、確定的な反復、不確定な反復などがある。ほとんどのプロセッサに
は、サブルーチンまたは関数を呼び出すコール命令と、呼び出し側に戻るリターン命令が含ま
れる。ただし、引数の渡し方、リターンアドレスを格納するストレージ、結果として値を呼び
出し側に返す方法などの詳細は異なる。ある種のプロセッサは、引数をメモリに置くが、引数
をレジスタに入れて渡すプロセッサもある。
アセンブラは、
アセンブリ言語のソースプログラムを、
プロセッサが実行できるバイナリコー
ドに変換するソフトウェアだ。アセンブラはソースプログラムを、2 回のパスで走査する。第
1 パスでアドレスを割り当て、第2 のパスでコードを生成する。多くのアセンブラには、プロ
グラマがコードの面倒な繰り返しを避けられるように、マクロ機能を含んでいる。マクロの展
開によって生成されるのもソースコードであり、それがアセンブルされる。マクロの展開で使
われる処理はテキストの置換なので、その結果として不正なコードが生じても、その検出と報
告は、アセンブラ本体の2 パスによって行われるだけだ。
練習問題
9.1
低水準言語の性質をあげて、説明してください。
9.2
プログラマがアセンブリ言語を読むとき、コメントは、どこにあると思いますか?
9.3
プログラムに1 個のif-then-else ステートメントが含まれているとします。条件
が真だったとき、いくつの分岐命令が実行されますか? 条件が偽だったときは?
9.4
repeat ステートメントを実装するのに使われるアセンブリ言語は何ですか? 9
9.5
商用プロセッサで使われたことのある引数渡しの機構を、3 つあげてください。
9.6
アセンブリ言語で、2 つの引数を取り、それらを加算し、その結果を返す関数を書き
ましょう。その関数を、C から呼び出すことでテストしましょう。
9.7
アセンブリ言語で、3 個の変数を宣言し、それらに1 と2 と3 を代入し、printf を
呼び出して3 つの値を書式付きで表示するプログラムを書きましょう。
hi.0412.ko.2002@gmail.com
182
第9 章　アセンブリ言語とプログラミングパラダイム　
9.8
プログラマは、ときどき間違って「アセンブラ言語」と言うことがあります。何が間
違っているのでしょうか。正しい用語は?
9.9
表9‒1 で、もしlabel4 の次に、label2 にジャンプする命令を挿入したら、飛び先
のアドレスは何番地になりますか? また、新しい命令をlabel1 の前に挿入したら、
そのアドレスが変わりますか?
9.10
リスト9‒8 の例で、C で書かれたフィボナッチプログラムを見ました。このプログ
ラムを、もっと速くなるように書き直せますか? どうやって?
9.11
リスト9‒10 とリスト9‒11 のフィボナッチプログラムを、値をメモリではなくレ
ジスタに保存するように、最適化しましょう。また、レジスタを選択した理由を説明
してください。
9.12
リスト9‒10 とリスト9‒11 にある、フィボナッチプログラムのx86 版とARM 版
を比較しましょう。コードの量が多くなりそうなのは、どちらのバージョンですか?
その理由は?
9.13
gcc の-S オプションを使って、C プログラムからアセンブリコードを生成しましょ
う。たとえば、リスト9‒8 のプログラムで、試してみましょう。付加的に生成された
コードを、すべて説明してください。
9.14
アセンブリ言語で、関数の代わりにマクロを使うことの、主な短所は何ですか?
9　訳注：repeat は、この章の本文に出てこないが、たとえばMASM のディレクティブには、
「繰り返し
ブロック」機能を持つREPEAT があり、インテルx86 のストリング命令には、繰り返しを意味するREP プ
リフィクスがある。
hi.0412.ko.2002@gmail.com
第3部
メモリ
プログラムとデータを保存するテクノロジー
hi.0412.ko.2002@gmail.com
hi.0412.ko.2002@gmail.com
第10 章
メモリとストレージ
10.1 　はじめに
第2 部の各章で、コンピュータシステムの主なコンポーネントの1 つであるプロセッサを調
べてきた。それらの章では、命令セットやオペランドを含むプロセッサのアーキテクチャを検
討し、複雑なCPU の構造にも触れた。
この章では、コンピュータシステムにおける第2 の主要コンポーネントである、メモリを紹
介する。これに続く章では、メモリの基本的な形式として、物理メモリ、仮想記憶、キャッシュ
を調べる。その後で入出力を学び、デバイスの入出力にメモリを使う方法を覚えよう。
10.2 　定義
「メモリ」と聞いてプログラマが思い浮かべるのは、たいがい一般的なコンピュータにある
メインメモリ（主記憶）のことだ。プログラマの視点から見てメインメモリにあるのは、実行
中のプログラムと、そのプログラムが使うデータだ。もっと広い意味で、コンピュータシステ
ムで使われる「ストレージの階層構造」には、汎用レジスタ、メインメモリ、2 次ストレージ
（ディスクやフラッシュのストレージ）が含まれる。このテキストでは、
「メモリ」という用語
を、とくにメインメモリを指す言葉として使い、
「ストレージ」という用語は、より広範囲な階
層構造と、その階層においてプログラマが使う抽象に関して使用する。
アーキテクトの視点から見た「メモリ」
（記憶装置）とは、データの値にストレージ（置き場
所／格納庫）を提供する、ソリッドステートのデジタルデバイスである。メモリの概念は、今
後の節でさまざまな可能性を見るにつれて明らかになっていく。
hi.0412.ko.2002@gmail.com
186
第10 章
メモリとストレージ　
10.3 　メモリの主要な側面
アーキテクトがメモリシステムの設計を始めるときは、主に次の2 つを選択する。
•
テクノロジー
•
構成
ここでの「テクノロジー」は、メモリシステムの構築に使われる基礎的なハードウェア機構
の属性を意味する。使えるテクノロジーが数多く存在することを学び、それらの属性を示すサ
ンプルを見ていこう。また、それらの基本的なテクノロジーが、どのように動作するかを学び、
どんなときに適切かを理解しよう。
「構成」は、基礎的なテクノロジーを使って有用なシステムを形成する方法を意味する。1
ビットのメモリセルを組み合わせて複数ビットのメモリセルにする方法にも多くの選択肢があ
ること、あるメモリアドレスを根底にあるユニットにマップするにも複数の方法が存在するこ
とを、学んでいこう。
要するに、
「メモリテクノロジー」という言葉は、もっとも低いレベルのハードウェア部品
（1 つ1 つのチップ）を意味し、
「メモリ構成」という言葉は、それらの部品を組み合わせて有
意義なストレージシステムを作る方法を意味する。メモリシステムのコストとパフォーマンス
に、この両方の側面が貢献することを、これから見ていこう。
10.4 　メモリテクノロジーの特徴
メモリテクノロジーの定義は容易ではない。なにしろ広い範囲の技法が発明されてきた。あ
る型のメモリに限っても、広い目的と意図がある。それらを明らかにするため、技術者たちは
下記の性質を使う。
•
揮発性か、不揮発性か
•
ランダムアクセスか、シーケンシャルアクセスか
•
リードライトか、リードオンリーか
•
1 次記憶か、2 次記憶か
10.4.1
メモリの揮発性
メモリが「揮発性」と分類されるのは、電源が断たれたときにメモリの内容が失われる場合
である。ほとんどのコンピュータで使われているメインメモリ（RAM）は、揮発性だ。コン
ピュータをシャットダウンすると、メインメモリで実行されていたプログラムも、そこに格納
されていたデータも、消えてしまう。
hi.0412.ko.2002@gmail.com
　10.4
メモリテクノロジーの特徴
187
反対に、メモリが「不揮発性」とみなされるのは、その内容が電源を切った後でも残される
場合である1。たとえば、デジタルカメラやSSD に使われるフラッシュメモリは、不揮発性だ。
カメラやディスクに保存されたデータは、たとえ電源をOFF にしても、そのまま保持される。
実際、そういうデータは、ストレージデバイスをカメラやコンピュータから取り出しても、無
事に残される。
10.4.2
メモリアクセスのパラダイム
メモリでもっとも一般的なのは、
「ランダムアクセス」に分類される形式だ。その意味は、メ
モリに存在する値はすべて、どこにあっても、どういう順序でアクセスしても、一定の時間で
アクセスできるということだ。
「ランダムアクセスメモリ」を略した「RAM」という言葉は、
消費者がコンピュータを買うときも「RAM はどうか」と調べるくらいに普及している。その
ランダムアクセスと対照的なのが「シーケンシャルアクセス」で、ある値をアクセスするのに
要する時間が、その値がメモリに存在する場所や、その前にアクセスした値の場所によって異
なる（連続する位置のメモリをアクセスする方が、離れた位置のメモリをアクセスするより、
ずっと速いのが典型的だ）
。たとえばハードウェアで実装されたFIFO2のキューは、シーケン
シャルアクセスメモリの一例である。
10.4.3
値の永続性
メモリは、その値を取り出せるか、書き換えられるか、両方かによって特徴付けられる。一
般的なコンピュータシステムで使われる主な形式のメモリは、いつでも値をアクセスでき（読
み出し可能）
、いつでも更新できる（書き込み可能）
。それ以外の形式のメモリは、より強度な
永続性を提供する。たとえば、ある種のメモリが「リードオンリーメモリ」
、略して「ROM」と
呼ばれるのは、そのメモリに含まれるデータの値が、アクセスは可能だが変更できないという
性質を持つからだ。
ROM の一種である「PROM」は、いったんメモリにストアした値を頻繁にアクセスできる
ように設計される。極度なPROM には、一度だけしか書き込めないものもあり、チップを永
続的に書き換えるために高電圧が使われる。
中間的な永続性を持つメモリも存在する。たとえばスマートフォンやSSD で一般に使われ
るフラッシュメモリは、永続的なROM と、永続性の低いテクノロジーとの妥協を図っている。
つまり、電源を切ってもデータが維持されるが、フラッシュメモリのなかで永遠に残るわけで
はない。フラッシュデバイスがアイドル状態にあるとき、そのデータがどれほど長く保たれる
1　新しいテクノロジーである「不揮発性RAM」
（NVRAM）は、従来のメインメモリと同様に動作するが、
値は電源を切っても保持される。
2　FIFO（ファイフォ）は、先入れ先出し（First-In-First-Out）を略した言葉。訳注：
「キュー」は待ち行列
を意味する。
hi.0412.ko.2002@gmail.com
188
第10 章
メモリとストレージ　
かは、練習課題とするので、フラッシュテクノロジーの文献で調べていただきたい3。
10.4.4
1 次記憶と2 次記憶
「1 次記憶」
（プライマリメモリ）
、
「2 次記憶」
（セカンダリメモリ）というのは、質的な差を
示す用語である。本来この2 つは、コンピュータに内蔵された高速で揮発性がある主記憶と、
外部の電子機械的な記憶装置（たとえばハードディスク）が提供する、遅いが揮発性のないス
トレージとを、区別するための言葉だった。現在のコンピュータシステムの多くは、1 次のメ
モリにも2 次のストレージにも、ソリッドステートのメモリテクノロジーを使っているが、と
くに「SSD」が2 次ストレージとして使われている。
10.5 　記憶階層という重要な概念
1 次記憶、2 次記憶という認識は、コンピュータシステムにおける「記憶階層」の一部とし
て生まれた。この構造を理解するには、パフォーマンス（性能）とコスト（費用）の両方を考
慮する必要がある。最高の性能を持つメモリは、もっとも高価なメモリでもあるから、アーキ
テクトはコスト制限を満足させるメモリを選ばなければならない。
メモリの使い方に関する調査から興味深い原則が発見された。与えられたコストで最高のパ
フォーマンスを得るという目標は、コンピュータ全体を通じて一種類のメモリを使っていては
達成されない。そうではなく、概念的な「メモリの階層構造」として、各種のテクノロジーを
配置すべきなのである。その構造は、わずかな数の「最高性能メモリ」の層、それより少し多
くの「少しだけ遅いメモリ」の層、という具合に並ぶ。たとえばアーキテクトは、少数の汎用
レジスタと、それより大きな主記憶と、さらに大量の2 次記憶を選択する。原則は、次のよう
に要約できる。
所与のコストでメモリ性能を最適化するには、一群のテクノロジーを階層として配置す
る。その構造に含まれるのは、比較的少量の高速なメモリと、それより多くの安価だが
遅いメモリだ。
記憶階層については、さらに第12 章で調べる。その章では、階層構造の背後にある科学的
原理を紹介し、
「キャッシュ」と呼ばれるメモリ機構においてコストを抑えながら高い性能を達
成するために、その原理がどのように使われているかを説明する。
3　訳注：たとえば日本語Wikipedia の「フラッシュメモリ」に、
「保持期間」という項がある。脚注に記
事へのリンクがあり、参考文献もあげられている。
hi.0412.ko.2002@gmail.com
　10.6
命令とデータのストア
189
10.6 　命令とデータのストア
前にも触れたように、
最初期のコンピュータシステムには、
プログラムとデータのために別々
のメモリを持つ「ハーバード・アーキテクチャ」を使うものがあった。その後、ほとんどのアー
キテクトは、同じメモリにプログラムとデータの両方を入れる「フォン・ノイマン・アーキテ
クチャ」を採用してきた。
興味深いことに、特殊なソリッドステートメモリに関するテクノロジーの出現によって、プ
ログラムとデータのメモリを分離するというアイデアが、再び導入された。特殊な用途を持つ
システムでは、ときに別々のメモリが使われる。プログラムの格納に使われるメモリは「命令
ストア」と呼ばれ、データの格納に使われるメモリは「データストア」と呼ばれる。
別個の命令ストアを求める要請の1 つは、記憶階層という考え方から生まれた。多くのシス
テムにおいて、全体的な性能は、命令ストアの速度を上げることによって向上させることが可
能だ。これには、高速に実行される命令が、メモリ内の値ではなく汎用レジスタの値を演算す
る設計になっていることからも想像できるだろう。したがって、速度を最大にするには、可能
な限りデータをレジスタに入れる。けれどもプロセッサは、
「フェッチ‒ 実行」サイクルを繰り
返す毎に、必ず1 個の命令をアクセスする必要がある。ゆえに命令ストアはデータストアより
も頻繁に使われる。重要なポイントとして、データアクセスは、ある変数をアクセスして、ま
た別の変数をアクセスする、という具合にランダムなパターンにしたがう傾向があるけれど、
プロセッサは命令ストアをシーケンシャルにアクセスするのが典型的である。つまり命令はメ
モリ内で次から次へと順番に並んでいて、プロセッサは分岐が発生しない限り、それらを順番
に読んでいく。だからデータ用のメモリと分離すれば、設計者は命令ストアをシーケンシャル
アクセス用に最適化することが可能になる。
現在のコンピュータシステムのほとんどは、プログラムとデータを1 つのメモリに置く
が、命令ストアをデータストアから切り離すことは可能である。そうすればアーキテク
トは、それぞれの動作に適した性能のメモリを選択できるようになる。
10.7 　フェッチとストアのパラダイム
後述するように、すべてのメモリテクノロジーは、
「フェッチとストア」という共通のパラダ
イムを使う。いま理解すべき重要なポイントは、このパラダイムに関する基本的演算が2 つあ
るということだ。1 つはメモリから値を「フェッチ」
（取得）する演算、もう1 つは値をメモリ
に「ストア」
（格納）する演算である。フェッチ演算は、
「リード」とも「ロード」とも呼ばれ
る。そして、メモリを場所の配列と考えれば、メモリから値を読むのは、メモリアドレスを配
列のインデックスに使う次のような演算とみなすことができる。
値←メモリ[アドレス]
hi.0412.ko.2002@gmail.com
190
第10 章
メモリとストレージ　
ときに「ライト」演算とも呼ばれるストア演算にも、同じたとえを使える。つまり、メモリ
に値をストアするのは、値を配列にストアするのに似ている。
メモリ[アドレス] ←値
この考えは、次の章で、もっと詳しく説明する。入出力に関する後の章では、デバイスの入
力と出力に「フェッチとストア」のパラダイムが、どう使われるのかを調べ、根底にあるメモ
リアクセスと入出力との関係を説明しよう。
10.8 　まとめ
メモリ（記憶装置）でもっとも重要なのは、根底にあるテクノロジーと構成である。さまざま
なテクノロジーが存在するが、特徴的な性質として、揮発性と不揮発性、ランダムアクセスと
シーケンシャルアクセス、永続と非永続（リードオンリーとリードライト）
、1 次記憶と2 次記
憶がある。
所与のコストで最高の性能を得るために、アーキテクトは記憶装置を概念的な階層で構成す
る。その構造には、少量の高速メモリと、大容量だが低速なストレージが含まれる。
メモリシステムでは、フェッチとストアのパラダイムが使われる。メモリのハードウェアが
サポートする演算は、メモリから値を取り出すフェッチと、値をメモリに格納するストアの、2
つだけだ。
練習問題
10.1
ストレージの階層構造を定義して、一例をあげてください。
10.2
メモリシステムを設計するときアーキテクトが主として行う2 つの選択とは何で
すか?
10.3
典型的なコンピュータで使われる、RAM とSSD のテクノロジーについて調べま
しょう。それぞれのメモリで、バイトあたりのコスト（費用）は、だいたいどのくら
いですか?
10.4
上の問題の続きとして、それぞれのメモリのスピード（アクセス時間）を調べ、性
能と費用の比率を比較しましょう。
10.5
フラッシュメモリとROM で、より安全なのは（たとえば、誰かが内容を書き換え
ようとしても簡単にはできないのは）どちらですか?
10.6
揮発性メモリにストアされたデータは、電源が失われたき、どうなりますか?
10.7
DRAM がNVRAM で置き換えられるとしたら、どのような性質のメモリテクノロ
ジーが、重要性を失いますか（あるいは、消えてしまうのですか）
。
10.8
NVRAM と従来のRAM の性能を比較してください。NVRAM は、どれほど低速で
hi.0412.ko.2002@gmail.com
　10.8
まとめ
191
すか?
10.9
典型的なUSB フラッシュドライブについて調べましょう（商品名にはジャンプド
ライブ、サムドライブなどがあります）
。もしフラッシュドライブを使わずに放置した
ら、データはどれだけ長い期間、保持されますか。その答えを知って、驚きましたか?
10.10
レジスタはメインメモリより、ずっと高速なので、もし全部のデータをメインメ
モリではなくレジスタに入れたら、プログラムの実行が、はるかに高速化するはずで
しょう。なぜ設計者たちは、少数のレジスタを持つプロセッサを作るのでしょうか。
10.11
もしコンピュータがハーバード・アーキテクチャにしたがっていたら、2 つの同
じメモリを持つと思いますか?（片方は命令用、もう片方はデータ用に）
。理由も教え
てください。
10.12
「フェッチ‒ 実行」と「フェッチとストア」は、どちらも同じ概念を示す言葉で
すか? そのわけも説明してください。
hi.0412.ko.2002@gmail.com
hi.0412.ko.2002@gmail.com
第11 章
物理メモリと物理アドレッシング
11.1 　はじめに
前章でメモリの話題に入り、メモリシステムのさまざまな性質を列挙して、記憶階層のコン
セプトを説明した。この章では基本的なメモリシステムが、どのように動作するかを説明する。
それには、典型的なコンピュータ用メモリの製造に使われている基礎テクノロジーと、メモリ
を組織してバイトとワードに分ける構成の、両方が含まれる。次の章では、この章の続きとし
て、仮想メモリを考察する。
11.2 　コンピュータにおけるメモリの性質
ほとんどのコンピュータで主記憶システムとして使われている種類のメモリを、
技術者は
「ラ
ンダムアクセスメモリ」
、略して「RAM」と呼んでいる。この名前が示唆するように、RAM は
（シーケンシャルアクセスではなく）ランダムアクセスのために最適化されている。また、RAM
は読み書き可能なので、リードアクセスもライトによる更新も、同様に低コストである。最後
に、ほとんどのRAM は揮発性である。コンピュータの電源を落としたら、値は残らないのだ。
11.3 　SRAM とDRAM の違い
RAM の実装に使われるテクノロジーは、主に2 つの種類がある。そのうち、スタティック
RAM（SRAM：Static RAM）のほうが、プログラマには理解しやすいだろう。これはデジタル
論理の単純明快な拡張なのだ。SRAM は個々のビットをラッチに格納する。それは第2 章で紹
介したラッチと同様に複数のトランジスタで構成されるデジタル回路のミニチュアだ。内部の
実装方法は本書で扱う範囲を超えるが、図11‒1 に示すように、1 ビットのRAM に3 本の外
部接続がある。
hi.0412.ko.2002@gmail.com
194
第11 章
物理メモリと物理アドレッシング　
入力
出力
ライ
トイネーブル
1ビッ
トの回路
図11‒1：1 ビットを格納するミニチュアSRAM 回路。この回路には複数のトランジスタが含まれる
図を見ると、回路には2 本の入力と1 本の出力がある。書き込みを許可する「ライトイネー
ブル」の入力がON（論理値1）のとき、回路は出力を入力と同じ値に設定する（0 または1）
。
ライトイネーブルがOFF（論理値0）のとき、回路は入力値を無視して、出力を最後に設定し
たままにする。だからハードウェアが値をストアするには、まず入力に値を置き、いったんイ
ネーブルをON にして、またOFF に戻せばよい。
SRAM の動作は高速だが、重大な欠点もある。電力消費だ（熱も発する）
。このミニチュア
SRAM 回路にも複数のトランジスタが含まれ、それらが動作を続ける。それぞれのトランジス
タが少しずつ電力を消費し、それによって熱を発する。
スタティックRAM の代替候補として、
より消費電力の少ない
「ダイナミックRAM」
（DRAM：
Dynamic RAM）がある。DRAM の内部は驚くほど複雑で込み入った仕掛けになっている。ま
ずもっとも低いレベルで情報をストアするために、DRAM は、電荷を蓄える「コンデンサ」の
役割を果たす回路を使う。ある値がDRAM に書かれるとき、ハードウェアは、そのコンデン
サを充電あるいは放電して、1 または0 の値をストアする。その後DRAM から値を読むとき、
ハードウェアはコンデンサの電荷を調べて適切なデジタル値を生成する。
DRAM を理解しにくい原因はコンデンサの働きにある。これは物理的なシステムとして完
全ではなく、コンデンサは徐々に電荷を失う。要するにDRAM チップは不完全な記憶装置で
あって、時間が経過すると電荷が消え去って1 が0 になる。もっと重要なことに、DRAM は
短時間で電荷を失う（1 秒もかからないケースもある）
。
値がすぐ0 になるDRAM を、どうすればコンピュータのメモリに使えるのか。その答えは、
ごく単純なテクニックだ。電荷が消失する前に何らかの方法でメモリからビットを読み出し、
それと同じ値を書き戻せばよい。値を書くと、コンデンサは適切な電荷から放電を再開する。
読んだビットを書き戻すことで、ビット値を変えずにコンデンサをリセットできるのだ。
実際にDRAM を使うコンピュータには「リフレッシュ回路」が追加され、ビットを読んで
書き戻す仕事を担当する。図11‒2 に、その概念を示す。
リフレッシュ回路は、この図から受ける印象よりも複雑だ。回路を小さくするために、アー
キテクトはビットごとに1 個のリフレッシュ回路は作らない。代わりに1 個でメモリ全体を巡
回する小さなリフレッシュ機構を設計する。あるビットに到達すると、リフレッシュ回路はそ
のビットを読み、値を書き戻して次のビットに進む。リフレッシュ回路はメモリの通常の動作
hi.0412.ko.2002@gmail.com
　11.4
メモリテクノロジーの評価基準
195
ライ
トイネーブル
入力
出力
1ビッ
トの回路
リフレ
ッ
シュ
図11‒2：DRAM のビットを表す図。外部のリフレッシュ回路が周期的にデータ値を読んで書き戻す。さも
ないと放電により値が失われるてしまう
と協調する必要があるから、話はいよいよ複雑になる。まずリフレッシュ回路は、メモリの通
常の動作に干渉しても遅らせてもいけない。第2 にリフレッシュ回路は、自分がビットを読ん
でから同じ値を書き戻すまでの間に、通常のライト演算でビットが書き換わらないようにする
必要がある。こういうリフレッシュ回路が必要なDRAM だが、コストと電力消費のメリットが
非常に大きいので、ほどんどのコンピュータのメモリはSRAM ではなくDRAM で構成される。
11.4 　メモリテクノロジーの評価基準
アーキテクトがメモリテクノロジーの評価に使う量的な基準は、主に次の2 つだ。
•
密度
•
レイテンシとサイクル時間
11.5 　密度
「密度」という用語は、厳密にはシリコンの正方形領域におけるメモリセルの数を意味する。
ただし実際には、標準的なサイズのチップあるいは挿抜可能なモジュールで表現できるビット
数を密度と呼ぶことが多い。たとえばDIMM（Dual In-line Memory Module）パッケージに
含まれる一群のチップに、64 ビットの単位が1 億2800 万個あるとしたら、全部で81 億9200
万ビット、つまり1 ギガバイトになる。これを俗に「1 ギガモジュール」と呼んでいる。一般
に高密度が望ましいのは、同じ物理的空間に、より多くのメモリを詰め込めるからだが、高密
度には電力消費と発熱の増大という欠点がある。
メモリチップの密度は、根底にあるシリコンテクノロジー（トランジスタのサイズ）に関連
する。メモリ密度は、ムーアの法則にしたがって、およそ18 か月で2 倍に増える傾向にある。
hi.0412.ko.2002@gmail.com
196
第11 章
物理メモリと物理アドレッシング　
11.6 　リードとライトの性能を区別する
メモリテクノロジーを評価する第2 の基準はスピードを重視する。つまりメモリが要求に対
して、どれだけ素早く応答できるのかが問題となる。スピードを測るのは簡単そうに思われる
かもしれないが、そうではない。たとえば、これまでの章で見てきたようにメモリのテクノロ
ジーによっては、値を読むよりも書くほうが、ずっと長い時間がかかる。適切なメモリテクノ
ロジーを選ぶために、アーキテクトはアクセス（読み出し）のコストと更新（書き込み）のコ
ストの両方を知る必要がある。だから、第1 の原則として次のことが言える。
多くのメモリテクノロジーでは、メモリから情報をフェッチするのに必要な時間とメモ
リに情報をストアするのに必要な時間が異なり、その差が非常に大きいこともある。こ
のためメモリの性能を測るには、常にリード演算の性能と、ライト演算の性能の、2 つ
の値が必要だ。
11.7 　レイテンシとメモリコントローラ
リードとライトの演算を区別するだけでなく、何を計測するのかも正確に決める必要がある。
もっとも重要な基準は「レイテンシ」だと思われるかもしれない。これは演算の開始から完了
までに経過する時間だ。しかしレイテンシ（待ち時間）は単純な計測値であって、完全な情報
を提供してはくれない。
レイテンシだけではメモリ性能の基準として不足だという理由を知るには、ハードウェアの
仕組みを理解する必要がある。メモリチップの他に、
「メモリコントローラ」と呼ばれるハード
ウェアがあって1、それがプロセッサとメモリの間のインターフェイスを提供するからだ。図
11‒3 に、その構成を示す。
プロセッサ
コン
トローラ
物理メモリ
図11‒3：メモリアクセス用に使われるハードウェア。プロセッサと物理メモリの間にコントローラが置か
れる
デバイス（典型的にはプロセッサ）は、メモリをアクセスするために、コントローラに「リー
ド」
（読み込み）または「ライト」
（書き込み）の要求を出す。コントローラは、その要求を物
1　メモリコントローラについては、この章で後ほど詳しく述べる。
hi.0412.ko.2002@gmail.com
　11.8
同期とマルチデータレートの技術
197
理メモリに適した信号に変換し、その信号をメモリチップに渡す。レイテンシを最小にするた
め、コントローラは可能な限り早く（メモリが応答したら即座に）要求に返答する。しかしコ
ントローラには、デバイスに応答した後も、さらにクロックサイクルが必要かもしれない。そ
れはハードウェア回路をリセットして次の演算に備えるための時間である。
そこで、メモリ性能に関する第2 の原則が生まれる。
メモリシステムは、演算と演算の間にも時間が必要かもしれない。メモリの性能を評価
するには、レイテンシを測るだけでは不十分であり、連続する演算に必要な時間を計測
する必要がある。
つまり、メモリシステムの性能を評価するには、そのシステムが「演算のシーケンスを、どれ
だけ速く実行できるか」を計測する必要がある。この考えを把握するために、技術者は「メモ
リサイクル時間」という用語を使う。具体的には「リードサイクル時間」
（略称tRC）と、
「ラ
イトサイクル時間」
（略称tWC）という、2 つの別々の計測値が使われる。
メモリシステムの性能を測るのに、リードサイクル時間とライトサイクル時間を使うの
は、メモリシステムが連続する要求を、どれだけ迅速に処理するかを評価するためだ。
11.8 　同期とマルチデータレートの技術
コンピュータにある他の多くのデジタル回路と同じく、メモリシステムもクロックを使って
リードやライトの動作を始める正確なタイミングを制御している。図11‒3 で示したように、
メモリシステムはプロセッサと協調しなければならないし、コントローラは入出力デバイスと
協調する必要があるかもしれない。もしプロセッサのクロックと、メモリに使われるクロック
が違っていたら、どうなるのか。それでもシステムは動作する。なぜならコントローラは、プ
ロセッサからの要求またはメモリからの応答を、相手側の準備が整って「レディ」状態になる
まで、そのまま「維持」できるからだ。
とはいえ、クロックの周期が違うと性能に悪い影響があるもしれない。わずかな遅延時間で
も、メモリを参照するたびに遅延が発生すれば相乗効果が顕著になる。遅延をなくすために、
ある種のメモリシステムは「同期式」クロックシステムを使う。つまり、メモリシステムに使
うクロックパルスを、プロセッサの実行に使うクロックパルスと同調させるのだ。その結果、
プロセッサはメモリ参照の完了まで待つ必要がなくなる。この同期はDRAM にもSRAM にも
利用でき、それらは次のような名前で呼ばれる。
•
SDRAM（Synchronous Dynamic Random Access Memory）
：同期式DRAM
•
SSRAM（Synchronous Static Random Access Memory）
：同期式SRAM
同期の効果は実証済みだ。いまではほとんどのコンピュータが、同期式DRAM を主要なメ
hi.0412.ko.2002@gmail.com
198
第11 章
物理メモリと物理アドレッシング　
モリテクノロジーとして使っている。
多くのコンピュータシステムで、メモリがボトルネックである。メモリの性能を上げれば、
全体の性能が上がる。そのため技術者たちの意識は、よりサイクル時間が短いメモリテクノロ
ジーの探究に向かった。アプローチの1 つは、メモリシステムを通常のクロックレートの何倍
かで（2 倍あるいは4 倍で）実行することだ。クロックが速ければ、メモリはデータを高速に
渡せるのだ。この技術は「高速データレート」メモリとも呼ばれるが、典型的には「DDR」
（2
倍速）または「QDR」
（4 倍速）である。高速データレートのメモリは成功を収め、いまでは
ノートPC のような消費者向けシステムを含むほとんどのコンピュータで標準になっている。
以上は、RAM メモリ技術のハイライトを紹介しただけで、アーキテクトが使える幅広い選
択肢や、それらの微妙な違いなどに関しては、まだ述べていない。販売され利用可能なRAM
テクノロジーのうち、いくつかを表11‒1 に示しておこう。
表11‒1：商業的に利用可能なRAM テクノロジーの例。他にも多くの技術がある
テクノロジー
説明
DDR-DRAM
2 倍のデータレートを持つDRAM
（Double Data Rate Dynamic RAM）
DDR-SDRAM
2 倍のデータレートを持つ同期式DRAM
（Double Data Rate Synchronous Dynamic RAM）
FCRAM
高速サイクルのRAM
（Fast Cycle RAM）
FPM-DRAM
高速ページモード付きRAM
（Fast Page Mode Dynamic RAM）
QDR-DRAM2
4 倍データレートのDRAM
（Quad Data Rate Dynamic RAM）
QDR-SRAM
4 倍データレートのSRAM
（Quad Data Rate Static RAM）
SDRAM
同期式DRAM
（Synchronous Dynamic RAM）
SSRAM
同期式SRAM
（Synchronous Static RAM）
ZBT-SRAM
セロバスターンアラウンドのSRAM
（Zero Bus Turnaround Static RAM）
RDRAM
Rambus 式（Direct R）DRAM
（Rambus Dynamic RAM）
RLDRAM
短縮レイテンシDRAM
（Reduced Latency Dynamic RAM）
2　訳注：一般にDDR2 と呼ばれる。その2 倍の速度を持つのがDDR3 で、同期式DRAM ならば、DDR3
SDRAM と呼ばれる。2020 年の時点で、さらに高速なDDR4 SDRAM も一般に使われている。
hi.0412.ko.2002@gmail.com
　11.9
メモリ構成
199
11.9 　メモリ構成
メモリの主な側面が、根底にあるテクノロジーとメモリ構成の2 つだということを思い出そ
う。アーキテクトがさまざまなメモリテクノロジーから選択できることを、これまで見てきた。
次は第2 の側面を考えよう。
「メモリ構成」には、ハードウェアの内部構造だけでなく、メモ
リがプロセッサに提供する外部アドレッシングの構造も含まれる。両者の関係も見ていこう。
11.10 　メモリアクセスとメモリバス
メモリの構成を知るには、
「アクセス」のパラダイムを調べなければならない。図11‒3 で見
たように、物理メモリと、そのメモリを使うプロセッサの間のインターフェイスは、
「メモリコ
ントローラ」によって提供される3。ここで、いくつか疑問が生じる。プロセッサとメモリを繋
ぐのは、どういう構造なのか。その接続で、どのような値が渡されるのか。プロセッサからメ
モリシステムが、どう見えるのか。
高性能を達成するため、メモリシステムには「パラレル接続」を使う。プロセッサとコント
ローラの接続は、数多くの並列線で構成される。それらは同時に使用され、どの線も1 ビット
のデータを転送できる。図11‒4 に、そのコンセプトを示す。
パラレル
インターフェイス
プロセッサ
コン
トローラ
物理メモリ
図11‒4：プロセッサとメモリのパラレル接続。N 本の線を含む接続は、N ビットのデータを同時に転送で
きる
プロセッサとメモリを結ぶハードウェア接続は、
「バス」と呼ばれるものだ。この場合は「メ
モリバス」である。バスについては入出力に関する章で学ぶから、ここではバスがパラレル接
続を提供することを理解しておけば十分だ。
3　後の章で見るように、入出力デバイスもメモリコントローラを介してメモリをアクセスするが、いまは
プロセッサを例としよう。
hi.0412.ko.2002@gmail.com
200
第11 章
物理メモリと物理アドレッシング　
11.11 　ワード、物理アドレス、メモリ転送
メモリバスのパラレル接続は、コンピュータアーキテクトだけでなくプログラマにも関係が
ある。アーキテクトの観点から見れば、パラレル接続は性能を向上させる。プログラマの観点
から見れば、パラレル接続は「メモリ転送サイズ」を定義する。つまり、1 回の演算でメモリ
から読める、あるいはメモリに書ける、データの量だ。これから見るように、転送サイズはメ
モリ構成の決定的な側面である。
並列的なアクセスを可能にするため、物理メモリを構成するビット群は、N ビットのブロッ
クに分けられる。そのN が、メモリ転送サイズだ。N ビットのブロックは、ときに「ワード」と
呼ばれ、転送サイズは「ワードサイズ」あるいは「ワード幅」とも呼ばれる。メモリは、配列
状に組織されていると考えることが可能だ。配列の要素には、どれもユニークなインデックス
が割り当てられる。それに相当するのが「物理メモリアドレス」で、このアプローチを「ワー
ドアドレッシング」と呼んでいる。以上のアイデアを示すのが図11‒5 で、これを見れば、物
理メモリアドレスが、配列のインデックスそっくりであることがわかるだろう。
物理ア
ドレス
5
4
3
2
1
0
32ビッ
ト
ワー
ド 5
ワー
ド 4
ワー
ド 3
ワー
ド 2
ワー
ド 1
ワー
ド 0
図11‒5：1 ワードが32 ビットで構成されるコンピュータにおける物理メモリのアドレッシング。メモリ
はワードの配列とみなすことができる
11.12 　演算と物理メモリ
物理メモリのコントローラは、
「リード」と「ライト」の2 つの演算をサポートする。
「リー
ド」演算の場合、プロセッサはアドレスを指定する。
「ライト」演算の場合、プロセッサはアド
レスとともに、書き込むべきデータを指定する。基本的に、コントローラが受け取り、あるい
は送り出すのは、常にワード全体である。物理メモリのハードウェアは、完全なワードに満た
ない読み書きを提供しない（つまりプロセッサがワードの一部をアクセスあるいは変更するこ
とを、ハードウェアは許さない）
。
hi.0412.ko.2002@gmail.com
　11.13
メモリのワードサイズとデータ型
201
まとめると次のように言える。
物理メモリはワードで構成され、1 ワードはメモリ転送サイズに等しい。リードおよび
ライトの演算は、常に1 ワードの全体に適用される。
11.13 　メモリのワードサイズとデータ型
プロセッサとメモリを繋ぐパラレル接続は、前述したように、高性能を目標にして設計され
る。性能は、理論的にはパラレル線を増やすことで向上する。たとえば128 本の線を持つイ
ンターフェイスは、64 本のインターフェイスの2 倍のレートでデータを転送できる。そこで
問題はアーキテクトが選択すべき本数だ。つまり最適なワードサイズは、何ビットなのかだ。
この問題は、いくつかの要素によって複雑になる。第1 に、メモリはデータをストアするため
に使うのだから、ワードは普通に使われるデータの値を収容できるサイズでなければならない
（たとえば整数が入る大きさが必要だろう）
。第2 に、メモリはプログラムの格納に使うので、
ワードには頻繁に使われる命令を収容できるサイズが必要だ。そして第3 に、プロセッサをメ
モリに接続するにはプロセッサのピンが必要なので、インターフェイスの線を増やすとピン数
も増やすことになる（そしてピン数は、CPU チップ設計制限となる）
。したがって、ワードサ
イズの選択は、性能と、考慮すべきさまざまな事項との妥協である。いまは32 ビットのワー
ドサイズが普及し、とくに低電力のシステムで一般的である。高性能なシステムの多くは、64
ビットのワードサイズを採用している。
ほとんどの場合、アーキテクトはコンピュータシステム全体の構成部品を協調させる設計を
行う。だから、もしアーキテクトがメモリのワードサイズに32 ビットを選択したら、そのアー
キテクトは、標準の整数型も、単精度の浮動小数点値も、それぞれ32 ビットを占めるように
設計する。その結果、コンピュータシステムの性質は、しばしばワードサイズによって表現さ
れる（たとえば「32bit プロセッサ」など）
。
11.14 　バイトアドレッシングとワードへのマッピング
一般的なコンピュータを使っているプログラマは、物理メモリが「ワード」で構成されてい
ると聞いて、意外に思われたかもしれない。なぜなら、ほとんどのプログラマは「バイトアド
レッシング」と呼ばれる、もう1 つの形式に慣れているからだ。バイトアドレッシングが、と
くにプログラマにとって便利なのは、たとえばキャラクタのような小さいデータ項目をアクセ
スするのが簡単になるからだ。
バイトアドレッシングを使うとしたら、メモリを「ワードの配列」ではなく「バイトの配列」
として構成することになる。バイトアドレッシングを選ぶと、2 つの重要な結果が生じる。第
1 に、メモリ内のどのバイトにもアドレスが割り当てられるから、バイトアドレッシングには
ワードアドレッシングよりも多くのアドレスが必要になる。第2 に、バイトアドレッシングで
hi.0412.ko.2002@gmail.com
202
第11 章
物理メモリと物理アドレッシング　
は、プログラマが1 バイトの読み書きを行えるようになるから、メモリコントローラはバイト
転送をサポートしなければならない。
ワードサイズが大きいと高性能になる理由は、同時に数多くのビットを転送できるからだ。
ところが、もしワードサイズが8 ビットのバイトと等しければ、一度に転送できるのは8 ビッ
トだけだ。つまり、バイトアドレッシング用に作られたメモリシステムは、より大きなワード
サイズ用に作られたメモリシステムよりも、性能が劣るのである。興味深いことに、たとえバ
イトアドレッシングを使っても、プロセッサとメモリの間の転送には、多くの場合、複数のバ
イトが関わることになる。たとえば1 個の命令は複数バイトを占めるし、整数も、浮動小数点
値も、ポインタもそうだ。
ワードアドレッシングの高性能と、バイトアドレッシングのプログラムの書きやすさを、両
立させるメモリシステムを作れないだろうか。それは可能だが、そのためには、2 つのアドレッ
シング方式の間で変換処理を行うインテリジェントなメモリコントローラが必要だ。そのコン
トローラは、バイトのアドレスとサイズを指定する要求をプロセッサから受け取る。そしてコ
ントローラは、ワードアドレッシングを使って、物理メモリから適切なワード（複数かもしれ
ない）をアクセスし、指定された数のバイトを抽出する。図11‒6 に、バイトアドレッシング
とワードアドレッシングのマッピングを示す4。ここでワードサイズは32bit だ。
物理ア
ドレス
5
4
3
2
1
0
20 
21 
22 
23
16 
17 
18 
19
12 
13 
14 
15
8 
9 
10 
11
4 
5 
6 
7
0 
1 
2 
3
バイ
トア
ドレスが、
各ワー
ドを構成する
バイ
トに割り振られる
32ビッ
ト
図11‒6：根底にあるハードウェアは、ワードアドレッシングと32 ビットのワードサイズを使っている。そ
れにもかかわらず、バイトアドレスを、メモリの各バイトに割り当てることができる
図に示したマッピングを実装するには、
プロセッサが発行したバイトアドレスを、
コントロー
ラが、メモリシステムが使うワードアドレスに変換しなければならない。たとえば、もしプロ
セッサが、バイトアドレス17 の「リード」操作を要求したら、コントローラは、ワード4 の
「リード」要求を発行し、そのワードから第2 バイトを抽出する必要がある。
メモリは1 度にワード全体を転送することしかできないので、1 バイトの「ライト」演算は
4　訳注：アドレス空間を図にする場合、このように「低位アドレス」を下に、
「高位アドレス」を上にする
場合がある。
hi.0412.ko.2002@gmail.com
　11.15
2 の冪乗を使う
203
高価になる。たとえば、もしプロセッサがバイト11 に書こうとしたら、コントローラはメモ
リからワード2 を読み、その右端のバイトを書き換えて、ワード全体をメモリに書き戻さなけ
ればならない。
アドレス変換は、数学的には単純明快である。バイトアドレスB を、それに対応するワード
アドレスW に変換するとき、コントローラはB を1 ワードのバイト数N で割ればよい。そして
ワード内のバイトオフセットO には、B をN で割った余り（モジュロ）を使える。つまりワー
ドアドレスは、次の式で求められる。
W =
h B
N
i
そしてオフセットは次の式で得られる。
O = B mod N
たとえば、図11‒6 にある値を考えよう（ここではN=4）
。11 というバイトアドレスは、2 と
いうワードアドレスおよび3 というオフセット値に変換される。だからバイト11 は、ワード
2 のバイトオフセット3 にある5。
11.15 　2 の冪乗を使う
除算の実行にも剰余を求めるのも計算に時間がかかるから、ハードウェア（たとえばALU）
の追加が必要になりそうだ。そういう計算を避けるために、アーキテクトは「2 の冪乗」を使っ
てメモリを構成する。そうすればハードウェアは、上記の計算を行うのに、ただビットを抽出
すればよい。たとえば図11‒6 では、N= 22 である。つまり、オフセットを求めるには最下位
の2 ビットを抽出し、ワードアドレスを求めるには、下位2 ビットを除くすべてを抽出すれば
よい。このアイデアを図11‒7 に示す。
0 
0 
1 
0 
0 
0 
1
バイ
トア
ドレス B (17)
ワー
ドア
ドレス W (4)
オフセッ
ト O (1)
図11‒7：バイトアドレス17 を、ワードアドレス4 とオフセット1 にマップする例。ワードごとのビット
数に2 の冪乗を使えば、数値計算を避けられる
除算や剰余の計算を避けるため、物理メモリは、ワードごとのバイト数が2 の冪乗にな
るように構成される。このため、バイトアドレスからワードアドレスとオフセットを求
5　オフセットは0 から数える。
hi.0412.ko.2002@gmail.com
204
第11 章
物理メモリと物理アドレッシング　
める変換は、ビットの抽出によって実行できる。
11.16 　アラインメントとプログラミング
プログラマは、アラインメントという言葉に遭遇することがあるだろう。根底にあるハード
ウェアの仕組みを理解すれば、その概念を理解しやすくなる。ある整数を表現するバイト列が、
物理メモリのワード境界に対応しているとき、その整数値は「アライン」
（整列）されている。
たとえば図11‒6 において、バイト12、13、14、15 で構成される整数は整列しているが、バ
イト6、7、8、9 で構成される整数は整列していない。
ある種のアーキテクチャでは、このような「バイト整列」が要求される。もしプログラムが、
非整列アドレスを使って整数をアクセスしようとしたら、プロセッサはエラーを起こす。他の
プロセッサでは、アラインメントを無視したバイト列が許されるが、非整列アクセスは整列ア
クセスよりも性能が低くなる。非整列アドレスに、物理アドレスよりも多くのアクセスが必要
な理由は、おわかりだろう。メモリコントローラは、プロセッサの要求を、1 つ1 つ根底にあ
るメモリの操作に変換する必要があるのだ。もし整数が2 つのワードにまたがっていたら、コ
ントローラは、要求された複数バイトを取り出すのに、2 回の「リード」操作を実行しなけれ
ばならない。だからこそ、たとえプロセッサが非整列アクセスを許していても、プログラマは
データの値を整列するように強く推奨されるのだ。
物理メモリの構成は、プログラミングに影響をおよぼす。たとえプロセッサが非整列の
メモリアクセスを許していても、物理的なワードサイズに対応する境界にデータを整列
させることで、プログラムの性能が向上する。
11.17 　メモリ容量とアドレス空間
メモリは、どれだけ大きくできるのだろうか。メモリのサイズは経済的な問題だと思われる
かもしれない。メモリが多ければ、お金がかかるだろう。けれども容量は、メモリアーキテク
チャの本質的な側面の1 つである。メモリの総量は、メモリ設計における他の選択とリンクし
ている。とくにアドレッシングの方式によって、最大のメモリサイズが決まるのだ。
プロセッサのデータパスが、パラレルなハードウェアで構成されていることを思い出そう。
プロセッサを設計するとき、設計者は、それぞれのデータパス、レジスタ、その他のハードウェ
アユニットについて、あるサイズを選択しなければならない。その選択が、生成可能な（ある
いは、あるユニットから他のユニットに渡せる）アドレスのサイズに、固定された上限を定め
る。アドレスのサイズは整数のサイズと同じにするのが典型的だ。たとえば32 ビットの整数
を使うプロセッサなら32 ビットアドレスを使うし、64 ビットの整数を使うプロセッサなら64
ビットアドレスを使う。第3 章で指摘したように、k ビットの2 進数で、2k 個の値を表現でき
hi.0412.ko.2002@gmail.com
　11.18
ワードアドレッシング用のプログラミング
205
る。したがって、32 ビットの値で表現できるユニークなアドレスの個数は次の通り。
232 = 4, 294, 967, 296
アドレスは、0 から4,294,967,295 までだ。表現可能なアドレスの集合を、われわれは「ア
ドレス空間」と呼んでいる。
バイトアドレッシングとワードアドレッシングのトレードオフも、これで明らかになる。ア
ドレスサイズが固定であれば、アドレッシングできるメモリの量は、そのプロセッサがバイト
アドレッシングを使うか、それともワードアドレッシングを使うかで決まる。そして、ワード
アドレッシングを使うのなら、アドレッシングできるメモリの量は、ワードサイズによって決
まる。たとえば、1 ワードを4 バイトとするワードアドレッシングを使うコンピュータでは、
32 ビットの値に、合計17,179,869,184 バイトを扱うアドレスを格納できる（この数は、バイ
トアドレッシングを使う場合の4 倍だ）
。
11.18 　ワードアドレッシング用のプログラミング
バイトアドレッシングを使うプロセッサが多いのは、プログラマにとってもっとも便利なイ
ンターフェイスが、バイトアドレッシングによって提供されるからだ。けれどもバイトアド
レッシングではメモリサイズを最大にできない。したがって、専門的なシステム（たとえば数
値処理用に設計されたプロセッサ）は、所与のアドレスサイズで最大のメモリ容量をアクセス
できるように、ワードアドレッシングを使う。
ワードアドレッシングを使うプロセッサでは、ソフトウェアでバイト操作の詳細を扱わなけ
ればならない。基本的にソフトウェアは、バイトアドレッシングのアーキテクチャにおいて、
メモリコントローラと同じ機能を実行する。たとえば1 バイトを取り出すのに、ソフトウェア
は適切なワードをメモリから読んだ後にバイトを抽出する必要がある。同様に、1 バイトを書
くときソフトウェアは、そのバイトを含むワードを読んで、正しいバイトを更新して書き換え
てから、そのワードをメモリに書き戻さなければならない。ソフトウェアの性能を最大化する
には、アドレスを求めるのに除算や剰余を計算するのではなく、論理シフトとビットマスクを
使った操作を行う。同様に、ワードからバイトを抽出するのにも、シフトと論理演算を使う。
たとえば32 ビットのワードw から、もっとも左のバイトを抽出するのに、C 言語のプログラ
マなら次のコードを書く。
( w >> 24 ) & 0xff
このコードは、シフトの実行後に必ず下位8 ビットだけを残すように、
「論理積」と、定数
0xff を使っている。なぜAND 演算が必要かといえば、
第3 章で述べた事情によって、
（符号付
き整数の）右シフトにはサインビットが入り込むからだ。したがって、もしw に0xa1b2c3d2
が含まれていたら、w>> 24 という式は、0xffffffa1 を作るかもしれない。しかし「AND」を
hi.0412.ko.2002@gmail.com
206
第11 章
物理メモリと物理アドレッシング　
取った後の結果は、正しく0xa1 になる。
11.19 　メモリ容量と「2 の冪乗」
前述したように、物理メモリのアーキテクチャには、次の特徴がある。
物理メモリはM 個のワードで構成する。それぞれのワードがN バイトを含む。コント
ローラのハードウェア効率を上げるため、M もN も2 の冪乗を選ぶ。
ワードとアドレス空間のサイズに2 の冪乗を使うと、特筆すべき効果が得られる。メモリの
最大容量は、10 の冪乗ではなく、常に2 の冪乗になるのだ。その結果、メモリサイズは2 の冪
乗によって計られる。たとえば「キロバイト」
（Kbyte）は、210 バイトと定義され、
「メガバイ
ト」
（MB）は220 バイトと定義され、
「ギガバイト」
（GB）は230 バイトと定義される。これら
の定義は例外的なので用語の混乱が生じる。たとえばコンピュータネットワーキングで、
「毎秒
メガビット」というのは、底を10 にした値だ。したがって、メモリサイズと他の度量が混在す
るときは注意が必要だ（たとえば、1 バイトは8 ビットなのに、メモリにある1 キロバイトの
データは、ネットワークで送信される1 キロビットのデータの8 倍ではない!）
。要約しよう。
メモリについて言うときの、キロ、メガ、ギガは、2 の冪乗として定義されるが、同じ
コンピュータの世界でも、他の側面では（たとえばネットワークでは）これらが10 の
冪乗と定義されている6。
11.20 　ポインタとデータ構造
メモリアドレスは、連結リスト、キュー（待ち行列）
、木構造（ツリー）など、よく使われる
データ抽象の基礎としても重要だ。このため、多くのプログラミング言語では、プログラマが
メモリアドレスを格納する「ポインタ」変数を宣言できる。ポインタに値を代入して要素を取
得するのが「デリファレンス」だ。たとえばC 言語で書かれた、次の宣言を見てほしい。
char
*cptr;
変数cptr を、キャラクタ（メモリ内の1 バイト）を指すポインタとして宣言する。コンパ
イラは、変数cptr のために、メモリアドレスと等しいサイズのストレージを割り当てて、こ
の変数にメモリ内の任意のバイトを指すアドレスを代入できるようにする。次は「インクリメ
ント」ステートメントだ。
6　訳注：この問題があるので、たとえばタネンバウムの『コンピュータネットワーク』の第5 版では、両
者が違う表記で書き分けられている。その1.7 項に、詳しい記述がある（pp.93-94）
。
hi.0412.ko.2002@gmail.com
　11.21
メモリダンプ
207
cptr++;
cptr の値を1 だけ増やす（メモリ内の次のバイトにポインタを進める）
。おもしろいことに
C 言語は、バイトアドレッシングとワードアドレッシングの、どちらの作法も受け継いでいる。
ポインタに対する数値演算では、C は根底にある要素のサイズに合わせる。たとえば、次のよ
うに宣言してみよう。
int
*iptr;
これで変数iptr は、整数（int）型ポインタとして宣言された。コンパイラは変数iptr に
も、メモリアドレスと等しいサイズのストレージを割り当てる（前記のcptr と同じサイズだ）
。
ただし、このプログラムを、整数を4 バイトと定義するプロセッサ用にコンパイルして実行す
ると、次の「インクリメント」ステートメントは、
iptr++;
iptr の値を4 だけ増やす。つまり、もしiptr がメモリ内の1 ワードの先頭のバイトアド
レスとなるように宣言されていれば、このインクリメントは、メモリ内の次のワードのバイト
アドレスにポインタを進めるのだ。
上にあげたサンプルは、どれもバイトアドレッシング可能なコンピュータを前提としている。
コンパイラはインクリメントによって、キャラクタポインタなら1 だけ増やし、整数ポインタ
なら4 だけ増やすようなコードを生成する。C にはポインタを、ワードから次のワードへと進
める機能があるけれど、この言語は、もともとバイトアドレッシング可能なメモリで使うよう
に作られている。
11.21 　メモリダンプ
ごく簡単な例を見れば、ポインタとメモリアドレスの関係がわかりやすくなる。図11‒8 に
示す「連結リスト」について考えてみよう。
head
node 1
node 2
node 3
192
200
100
図11‒8：連結リストの例。リストのポインタは、どれもメモリアドレスに対応する
このようなリストを書くために、プログラマは、まずノードの中身を指定する宣言を書き、そ
hi.0412.ko.2002@gmail.com
208
第11 章
物理メモリと物理アドレッシング　
れから、リストを格納するメモリを割り当てなければならない。この簡単な例では、どのノー
ドも2 つの項目を含むことになる。それは整数のカウントと、そのリストにある次のノードへ
のポインタだ。C 言語では、ノードの内容を定義するのに構造体宣言を使う。
struct node {
int count;
struct node *next;
}
同様に、リストの先頭となる、head という名前の変数を、次のように宣言する。
struct
node *head;
このリストがメモリにあるとき、どのように見えるかを理解するために、表11‒2 に示す「メ
モリダンプ」を使おう7。
表11‒2：メモリの一部の内容を示すメモリダンプ。アドレスの欄は、その行の左端にあるバイトのメモリア
ドレスを示している。すべての値は16 進数
アドレス
メモリの内容
0001bde0
00000000
0001bdf8
deadbeef
4420436f
0001bdf0
6d657200
0001be18
000000c0
0001be14
0001be00
00000064
00000000
00000000
00000002
0001be10
00000000
000000c8
0001be00
00000006
表のサンプルは、バイトアドレッシングを使うプロセッサから取ったものだ。各行は、メモ
リで連続する16 バイトに対応し、それを4 バイトずつ4 個の項目に分けている。それぞれの
項目は、8 桁の16 進数で4 バイトの値を表す。行の先頭にあるアドレスは、その行の最初の
バイトのメモリアドレスで、各行のアドレスは、その前の行と比べて16 ずつ増えている。
連結リストの先頭が、0x0001bde4 というアドレスにあるとしよう。これはダンプの最初の
行にある。リストの最初のノード（node 1）は、0x0001bdf8 というアドレスから始まり、こ
れはダンプの2 行目にあって、整数の192（16 進数で000000c0 の定数値）を含んでいる。
このプロセッサはバイトアドレッシングを使うものだ。メモリのバイトは連続している。こ
の図のダンプで出力に空白を入れて項目を区切っているのは、ただ読みやすくするためである。
ただし項目を4 バイト単位にして、根底にあるワードサイズが4 バイト（32 ビット）である
ことを示唆している。
7　プログラマは、メモリダンプで項目を見分けやすい16 進の値で、メモリの内容を初期化できる。この
例では、deadbeef という目立つ値を使っている。
hi.0412.ko.2002@gmail.com
　11.22
間接参照と間接オペランド
209
11.22 　間接参照と間接オペランド
第7 章でオペランドとアドレッシングモードを論じたときに出た、
「間接参照」の話題を覚え
ているだろうか。メモリ構成を理解したいまでは、プロセッサが「間接オペランド」を、どう評
価するかを理解できる。一例として、あるプロセッサが実行する命令に、0x1be1f という即値
と間接参照を指定するオペランドがあるとしよう。また、このプロセッサは32 ビットの値を
使うように設計されているとしよう。オペランドが即値を指定しているので、プロセッサは、
まずその即値（16 進で1be1f）をロードする。オペランドが間接参照を指定しているので、プ
ロセッサは、ロードした値をメモリアドレスとして扱い、そのアドレスのワードをフェッチす
る。もしメモリの値が、表11‒2 に示した値に対応していたら、プロセッサは図の最下行の右
端にあるワードから値をロードするので、オペランドの最終的な値は6 になる。
11.23 　個別にコントローラを持つ複数のメモリ
物理メモリに関する議論では、1 個のメモリと1 個のメモリコントローラを前提としていた。
しかし実際には、複数の物理メモリを持つアーキテクチャが存在する。複数のメモリを使うと
きは、メモリの性能を高めるために、ハードウェアによる並行処理を採用できる。メモリシス
テムには、1 個のメモリと1 個のコントローラではなく、図11‒9 に示すように、並列に動作
する複数のコントローラを持たせることができるのだ。
インターフェイス
コン
トローラ 1
コン
トローラ 2
メモリ 1
メモリ 2
図11‒9：別々のコントローラを持つ2 個のメモリモジュールを接続する例
図に示している、インターフェイスのハードウェアは、プロセッサからの要求を受け取る。
インターフェイスは、その要求のアドレスを使って、どちらのメモリを使うかを決め、対応す
るメモリコントローラに要求を渡す8。
複数のメモリに、それぞれ独自のコントローラを持たせる利点は何だろうか。メモリをアク
8　このインターフェイスがMMU（Memory Management Unit）の役割を果たすことを、第13 章で説明
する。その機能も詳しく説明しよう。
hi.0412.ko.2002@gmail.com
210
第11 章
物理メモリと物理アドレッシング　
セスした後、その次のアクセスを可能にするため、いったんハードウェアをリセットする必要
があることを思い出そう。もし2 つのメモリを利用できるのなら、プログラマは、片方がリ
セットしている間に、もう片方をアクセスすることで、全体の性能を高められる。つまり、並
行して動作する2 つのメモリコントローラを持つことで、単位時間あたりのメモリアクセス回
数を増やせる。たとえばハーバードアーキテクチャで、より高い性能を得られるのは、命令の
フェッチがデータアクセスに干渉することがなく、その逆もないからだ。
11.24 　メモリバンク
複数の物理メモリは、フォン・ノイマン・アーキテクチャでも、小さなメモリモジュールを
複製して大きなメモリを作る便利な方法として利用できる。
「メモリバンク」と呼ばれる、その
アイデアは、インターフェイスのハードウェアを使って、アドレスを2 つの物理メモリにマッ
プするものだ。たとえば、2 つのまったく同じメモリモジュールに、それぞれ0 からM−1 ま
での物理アドレスがあるとしよう。インターフェイスで、これらを2 つの「バンク」として扱
うと、図11‒10 のように2 倍のアドレスを持つ大きな連続メモリを作れる。
2M－1
M
M－1
0
メモリ 2
メモリ 1
図11‒10：2 つの等価なメモリバンクで、2 倍のサイズを持つ1 個のメモリを形成する、論理的配置
図11‒10 では、0 からM−1 までのアドレスが第1 のバンクに、M から2M−1 までのアド
レスが第2 のバンクに割り当てられている。アドレスをマッピングする、極度に効果的な使い
方は、第13 章で見ることにしよう。
2 つのバンクが、まるで1 個の大きなメモリであるかのように配置されるが、根底にあるハー
ドウェアは図11‒9 に示したように構成されている。その結果、2 つのメモリバンクのコント
ローラは並列に動作できる。したがって、もし命令を片方のバンクに、データをもう片方のバ
ンクに配置すれば、より高い性能を得られる（この場合も命令のフェッチがデータアクセスに
干渉せず、その逆もないのだから）
。
プログラマの視点で、メモリバンクは、どう見えるのだろうか。ほとんどのアーキテクチャ
において、メモリバンクはトランスペアレント（透明）である。メモリのハードウェアが自動的
hi.0412.ko.2002@gmail.com
　11.25
インターリーブ
211
に並行処理を検出して利用するのだ。ただし埋め込みシステムや、特殊用途のアーキテクチャ
では、性能を上げるためにプログラマの責任で、項目を別のメモリバンクに配置する場合があ
る。たとえばプログラマは、コードを下位のメモリアドレスに、データ項目を高位のメモリア
ドレスに、配置する必要があるかもしれない。
11.25 　インターリーブ
メモリバンクと関連のある最適化として、物理メモリシステムで使われる手法に、
「インター
リーブ」
（相互配置）がある。この最適化を理解するには、多くのプログラムが連続するメモリ
アドレスから続けてデータをアクセスする「シーケンシャルアクセス」を行うことに注目しよ
う。たとえば、長い文章をメモリのある場所から別の場所へとコピーするときや、項目のリス
トを検索するとき、プログラムはメモリをシーケンシャルに参照する。バンクのあるメモリで
は、連続するアドレスが同じメモリバンクに入るので、シーケンシャルアクセスを続けるには、
コントローラによるリセットを待たなければならない。
インターリーブも、別々のコントローラを使うというアイデアは同じだが、メモリをバンク
で構成するのではなく、アドレスが連続するワードを、別々のメモリモジュールに、互い違い
に配置する。これによってシーケンシャルなメモリアクセスが高速化されるのは、前のワード
のメモリがリセットしている間に、次のワードをフェッチできるからだ。メモリのインター
リーブはプログラマから隠されるのが普通だ。根底にあるメモリシステムが、連続するワード
を別々のメモリモジュールにマップしていても、プログラマは、そのことを知らずにコードを
書ける。すべての詳細はメモリのハードウェアによって自動的に処理されるのだ。
われわれは、根底にあるメモリモジュールの数を示すのに「N 重インターリーブ」という用
語を使う（効率化のため、N には2 の冪乗が選ばれる）
。たとえば図11‒11 は、4 重インター
リーブで、メモリの連続するワードが4 つのメモリモジュールに、どのように割り当てられる
かを示している。
どうすればインターリーブを効率よく実現できるだろう。その答えは、バイナリ表現で考え
るとわかりやすい。たとえば図11‒11 で、ワードの0、4、8 などは、メモリモジュール0 に
置かれるが、これらのアドレスに共通するのは何だろうか。2 進数で表現すると、これらの値
は、どれも最下位の2 ビットが00 になる。同様に、モジュール1 に割り当てられるワードは
下位の2 ビットが01 であり、モジュール2 には下位2 ビットが10、モジュール3 には下位2
ビットが11 のワードが割り当てられる。したがってインターフェイスのハードウェアは、与え
られたメモリアドレスから下位の2 ビットを抽出し、それらを使ってモジュールを選択する。
おもしろいことに、モジュール内で正しいワードをアクセスするのも、同じように効率が良
くなる。モジュールそのものは標準のメモリモジュールで、ある値K について、0 からK−1
までのワードアドレスを提供する。インターフェイスはアドレスの下位2 ビットを無視して、
残りのビットをメモリモジュールへのインデックスとして使う。もし納得がいかなければ、実
hi.0412.ko.2002@gmail.com
212
第11 章
物理メモリと物理アドレッシング　
ワー
ド 0 
ワー
ド 1 
ワー
ド 2 
ワー
ド 3
ワー
ド 4 
ワー
ド 5 
ワー
ド 6 
ワー
ド 7
ワー
ド 8 
ワー
ド 9 
ワー
ド 10 
ワー
ド 11
要求
インターフェイス
モジュール 0 
モジュール 1 
モジュール 2 
モジュール 3
図11‒11：4 重のインターリーブ。メモリの連続するワードが、
性能を最適化するため複数のメモリモジュー
ルに分散される
際に、0、4、8、... を2 進数で書いてみよう。それから下位2 ビットを消せば、結果は0、1、
2、... のシーケンスになる。同様に、1、5、9、... から下位2 ビットを消した結果も、0、1、
2、... のシーケンスになる。
モジュールの数が2 の冪乗ならば、N 重インターリーブのハードウェアが、極めて効果
的だ。なぜなら、アドレスの下位2 ビットを使ってモジュールを選択でき、残りのビッ
トをモジュール内のアドレスに使えるからだ。
11.26 　CAM
テクノロジーとメモリ構成という、2 つの主要な側面を合成させた、特異な形式のメモリが
存在する。それは、
「CAM」
（Content Addressable Memory）という機構だ9。これから見る
ように、CAM は単純にデータ項目をストアするだけでなく、検索を高速化するためのハード
ウェアを含んでいる。
CAM は「2 次元配列状に組織されたメモリ」だと考えると、もっとも簡単に理解できる。そ
れぞれ1 個の項目を格納する「行」は、
「スロット」と呼ばれる。プロセッサは、各スロット
に値を置くことができるが、さらにCAM では、1 スロットとまったく同じ長さの「検索キー」
を、プロセッサが指定できる。検索キーが指定されたら、ハードウェアは表検索を実行して、
キーと一致するスロットの有無を判定できる。図11‒12 に、CAM の構造を示す。
もっとも基本的な形式のCAM 機構では、
「完全一致」
の検索が実行される。つまり、CAM の
9　訳注：content-addressable は、
「内容によってアドレッシングできる」という意味。この言葉は、1960
年代からデータベースストレージの機構に使われ（CAFS、CAS）
、メモリに関する同様な機構にもCAM と
いう言葉が使われている。日本語版Wikipedia の項目名は「連想メモリ」
。
hi.0412.ko.2002@gmail.com
　11.27
3 値CAM
213
キー
CAMス
トレージ
1個のスロ
ッ
ト
図11‒12：CAM は、メモリテクノロジーとともに、メモリ構成も提供する
ハードウェアがキーと各スロットを比較して、一致の有無を報告する。ただし通常のプロセッ
サで実行される巡回的なサーチと違って、CAM は結果を即座に報告する。CAM の各スロット
には、比較を実行するハードウェアが内蔵されているのだ。キーの各ビットから、すべてのス
ロットに向けてワイアが張り巡らされていると考えれば良い。どのスロットにも、キーのビッ
トとスロットにある値のビットとを比較するゲートが含まれている。すべてのスロットのハー
ドウェアが並列動作するので、検索を実行するのに必要な時間は、スロット数に依存しない。
もちろん、並列検索のハードウェアのおかげでCAM は非常に高価である。各スロット用に、
同じ検索機構を複製しなければならないからだ。また、CAM は従来のメモリより多くの電力
を消費する（発熱量も多い）
。このためアーキテクトは、コストと電力消費よりも検索の速度が
重要な場合にだけCAM を使う。たとえば高速なインターネットルータのシステムは、すべて
の受信パケットをチェックして、同じソースから到着済みの他のパケットがあるかを判定する
必要がある。高速な接続を処理するため、いくつかの設計は、ソース識別情報のリストを格納
するのにCAM を使っている。高速ネットワークでもCAM を使えば、高いレートで到着する
パケットに対応できるほど高速にサーチを実行できる。
11.27 　3 値CAM
CAM の、
もう1 つの形式である
「3 値CAM」
（TCAM）
は、
CAM のアイデアを拡張して
「部
分一致検索」を提供する。3 値とは要するに、スロットを構成する各ビットが、
「0」
、
「1」
、
「ど
ちらでも」の、3 種類の値を持つのだ。標準的なCAM と同じく、TCAM も、すべてのスロッ
トを同時に調べることで、検索を並行して実行する。ただし標準のCAM と違って、TCAM は
hi.0412.ko.2002@gmail.com
214
第11 章
物理メモリと物理アドレッシング　
0 または1 の値を持つビットに対してだけマッチを実行する。こうして部分一致を検出できる
TCAM は、CAM のエントリに重複がある場合に使える。つまりTCAM ならば、最良のマッ
チ（たとえば先頭からの最長一致）を見つけることができるのだ。
11.28 　まとめ
この章では、物理メモリの2 つの側面として、根底にあるテクノロジーとメモリ構成を調
べた。メモリテクノロジーは数多く存在する。その違いには、永続性（RAM かROM か）
、ク
ロック同期、リード／ライトのサイクル時間などが含まれる。
物理メモリはワードで構成され、コントローラを介してアクセスされる。プログラマから見
ればバイトアドレッシングが便利だが、ほとんどの物理メモリシステムは、ワードアドレッシ
ングを使う。インテリジェントなメモリコントローラは、バイトアドレッシングからワードア
ドレッシングへの変換を行える。コントローラでの算術演算を避けるため、メモリは、アドレ
ス空間と1 ワードのバイト数が2 の冪乗になるように構成される。
C などのプログラミング言語は、ポインタ変数とポインタ演算を提供して、プログラマがメ
モリアドレスを取得して操作できるようにしている。プログラムのデータ構造を、実行時のメ
モリに書かれた値と関連付けるには、メモリの内容をアドレス付きで表示するメモリダンプを
使える。
メモリバンクとインターリーブは、どちらも複数のメモリアドレスを使う機構だ。バンクは
小さなモジュールを集めて大きなメモリを組織するのに使われる。インターリーブは、
メモリで
連続するワードを別のモジュールに分配することで、シーケンシャルアクセスの速度を高める。
CAM は、メモリテクノロジーとメモリ構成の組み合わせだ。CAM はメモリをスロットの配
列として構成し、高速なサーチ機構を提供する。
練習問題
11.1
スマートフォンや、その他の携帯機器には、SRAM ではなくDRAM が使われるの
が典型的です。なぜでしょうか?
11.2
DRAM「リフレッシュ」機構の目的を説明してください。
11.3
コンピュータの物理メモリが64 ビットのワードで構成されているとします。次の
バイトアドレスのそれぞれに対応するワードアドレスとワード内オフセットを書きま
しょう。
0, 9, 27, 31, 120, 256
11.4
上の練習問題を基にして、答えを計算するコンピュータプログラムを書きましょう。
プログラムは入力として、
「ビット数で指定されるワードサイズ」と「バイトアドレ
ス」という2 つの値のペアを、何度でも受け取るものとします。それぞれの入力に対
して、プログラムは1 個のワードアドレスと、ワード内オフセットを返すようにしま
hi.0412.ko.2002@gmail.com
　11.28
まとめ
215
しょう。注意：ワードサイズはビット数で指定されますが、必ず2 の冪乗でなければ
なりません。
11.5
ARM プロセッサで、メモリから整数値をロードするとき、もしバイトアドレスが
4 の倍数でなければエラーになります。このようなエラーを、何と呼びますか?
11.6
もしコンピュータが64 ビットのアドレスを持ち、それぞれのアドレスが1 バイト
に対応するのなら、そのコンピュータがアドレッシングできるメモリは、何ギガバイ
トですか?
11.7
2 つのアドレスを指定する命令があって、命令自身と両方のオペランドのアドレス
が、どれも整列（アライン）されていないとしたら、何回のメモリ演算が必要になり
ますか?
11.8
C の関数で、静的整数配列のM を宣言し、その要素をバイト単位でアクセスできる
ように、シフトとブール演算を使ったfetch とstore の演算を実装しましょう。
11.9
PC 用のメモリを見つけて、使われているチップの型名を識別し、ベンダーの資料
でチップの仕様を調べて、メモリの形式とスピードを判定しましょう。
11.10
図11‒11 を、8 重インターリーブのメモリ用に描き直してみましょう。
11.11
物理メモリのエミュレーションを行いましょう。C のプログラムで、1000 個の整
数を持つ配列M（つまりワード配列）を宣言します。それから、fetch とstore とい
う2 つの関数を実装します。これらは配列M を使ってバイトアドレッシング可能な
メモリをエミュレートするものです。fetch(i) は、メモリのi 番目のバイトを返し、
store(i,ch) は、8 ビットのキャラクタch を、メモリのi バイト目にストアします
（i は0 から始まります）
。バイトポインタを使わずに、この章で得たアイデアをもと
に、指定されたバイトを含む正しいワードとワード内オフセットを計算するコードを
書いてください。
11.12
TCAM のシミュレーションを行いましょう。入力された文字列と、一群のパター
ンとのマッチングを行うプログラムを書きます。シミュレーションのため、ビットの
代わりに文字（8 ビットのキャラクタ）を使います。どのパターンも1 個の文字列を
含みますが、そのなかでアスタリスク（*）は、どんな文字にもマッチする「ワイルド
カード」と解釈します。すべてのパターンを巡回するより高速にマッチを得るような
方法を、考案できますか?
hi.0412.ko.2002@gmail.com
hi.0412.ko.2002@gmail.com
第12 章
キャッシュとキャッシング
12.1 　はじめに
物理メモリシステムについて論じた前章では、メモリシステムの構築に使われる基礎的なテ
クノロジーと、アドレス空間の構成に重点を置き、物理メモリがワード単位で組織されること
も述べた。
この章では、同じ問題を別の観点から取り上げる。つまり、メモリシシステム構築の技術で
はなく、メモリシステムの性能を改善する技術に重点を置くのだ。この章ではキャッシングの
基礎的な概念を紹介し、メモリリステムでキャッシュがどのように使われるかを示し、なぜ
キャッシングが欠かせないのか、キャッシュを使うことによって、なぜ高性能をローコストで
実現できるのかを説明する。
12.2 　情報はストレージの階層を伝播する
第10 章で見たように、ストレージ機構は階層的に組織され、そこには汎用レジスタ、メイ
ンメモリ、2 次ストレージが含まれる。データ項目は、普通はソフトウェアの制御によって、
その階層構造を上下に移動する。一般に、項目が上の階層へと移動するのは読み出されるとき
であり、下の階層へと移動するのは書き込まれるときである。たとえば数値演算のコードを生
成するとき、まずコンパイラは各項をメモリからレジスタに移動させる。計算を終えたら、そ
の結果は、たぶんメモリに戻されるだろう。もし項目をプログラムの終了後も保持する必要が
あれば、プログラマは、その項目をメモリから2 次ストレージにコピーするだろう。そのスト
レージ階層構造に、キャッシュがどう収まるのかを調べよう。そして、その階層の上下に項目
を移動させるのに、メモリキャッシュがソフトウェアではなくハードウェアを使うことを学ん
でいこう。
hi.0412.ko.2002@gmail.com
218
第12 章
キャッシュとキャッシング　
12.3 　キャッシングの定義
「キャッシング」は、何らかの情報取得を行うハードウェアやソフトウェアのシステムで、性
能を向上させるのに使われる重要な最適化技法である。メモリシステムでキャッシングを使う
と、
「フォン・ノイマンのボトルネック」を緩和することができる1。キャッシュは仲介者の役割
を果たす。つまりキャッシュは、要求を発行する機構と、その要求に応える機構を結ぶ経路の
中間に置かれ、すべての要求をインターセプト（横取り）して仲介するように構成されるのだ。
キャッシングの中心的なアイデアは、高速な一時的ストレージである。キャッシュは選択さ
れたデータのローカルコピーを蓄積し、要求に対して可能な限りローカルコピーから応答する。
それで性能が向上するのは、要求を満足させるのに使われる通常の機構より高速に答えを返す
ようにキャッシュが設計されるからだ。図12‒1 は、要求を発行する機構と、その要求に応え
る機構との中間にキャッシュが置かれることを示している。
要求する側
キャ
ッ
シュ
大きなデータス
トレージ
図12‒1：概念的な構成図。キャッシュは、要求を発する機構と、その要求に応答するストレージ機構を結ぶ
経路の中間に置かれる
12.4 　キャッシュの特徴
上に述べた説明は、わざと曖昧にしてある。その理由はキャッシングが、コンピュータと通
信のシステムに多様な形式で利用される幅広いコンセプトだからだ。この節では定義を明らか
にするため、そのコンセプトを、もっと詳しく説明していこう。キャッシングの利用方法は、
後の節で例をあげる。
キャッシュにはさまざまな機構が存在するが、どれにも共通する一般的な特徴がある。
•
小さい
•
アクティブ
•
トランスペアレント
•
自動的
1　フォン・ノイマンのボトルネックは、7.8 項で説明した。
hi.0412.ko.2002@gmail.com
　12.5
キャッシュの用語
219
小さい
経済的なコストを抑えるために、
キャッシュに割り当てるストレージの量は、
データ項目の全
体集合を格納するのに必要なストレージの量よりも、ずっと小さい。ほとんどのキャッシュの
サイズは、主記憶の10%以下であり、多くの場合、キャッシュのサイズはデータストアの1%に
満たない。ゆえに、設計上の中心的な問題は、キャッシュに入れるデータ項目の選択に関わる。
アクティブ
キャッシュには、それぞれの要求を調べて応答方法を定めるためのアクティブ（能動的）な
機構が含まれる。キャッシュが行う処理には、要求された項目がキャッシュに存在するかを
チェックし、もし項目をローカルに取得できなければデータストアからコピーし、どの項目を
キャッシュに入れておくかを判定する処理が含まれる。
トランスペアレント
キャッシュが「トランスペアレント」
（透明）だというのは、要求する側にもデータストアに
も変更を加えずにキャッシュを挿入できるという意味である。つまり、キャッシュが要求側に
提供するインターフェイスは、データストアが提供するインターフェイスと、まったく同じで
あり、キャッシュがデータストアに提供するインターフェイスも、要求側が提供するインター
フェイスと、まったく同じなのだ。
自動的
ほとんどの場合キャッシュの機構は、どう対応するかについて、つまり、どのデータ項目を
キャッシュにストアするかについて、命令を受けたりはしない。キャッシュには、要求のシー
ケンスを調べ、その要求を使ってキャッシュの管理方法を決めるためのアルゴリズムが実装さ
れている。
12.5 　キャッシュの用語
キャッシングはさまざまな文脈で使われるが、キャッシングに関する用語には、すべての種
類のキャッシングシステムに適用される普遍的性質を持つものがある。
「キャッシュヒット」
、
略して「ヒット」という用語は「根底にあるデータストアをアクセスすることなしに、キャッ
シュによって応答できる要求」と定義されている。逆に「キャッシュミス」
、略して「ミス」は、
「キャッシュでは応答できない要求」と定義されている。
もう1 つ、キャッシュで表現される参照シーケンスの特徴を表す用語がある。もしシーケン
スに、
同じ要求の繰り返しが含まれていたら、
その参照シーケンスは
「高い参照局所性」
を持つ。
そうでなければ、そのシーケンスは「低い参照局所性」を持つ。これから見ていくように、参照
の局所性が高いと性能が向上する。ここで局所性というのは、キャッシュ内に項目が存在する
という意味だ。したがって、もしキャッシュが大きなデータ項目（たとえばメモリの1 ページ）
を格納しているのなら、要求がキャッシュ内の同じ項目を参照している限り（たとえばメモリ
hi.0412.ko.2002@gmail.com
220
第12 章
キャッシュとキャッシング　
が同じページ内の要素を参照していれば）
、まったく同じ要求の繰り返しである必要はない。
12.6 　ベストケースとワーストケースのキャッシュ性能
前述したように、もしデータ項目がキャッシュに入っていたら、そのキャッシュ機構はデー
タストアよりも高速に、その項目を返すことができる。図12‒2 に示すように、データ取得の
コストは、要求する側の視点で評価する。
要求側
キャ
ッ
シュ
大きなデータス
トレージ
Cm
Ch
図12‒2：キャッシュを使う場合のアクセスコストを示す例。コスト（C）は要求側から見た評価である
この図で、Ch は、項目がキャッシュ内で見つかったとき（ヒット）のコストであり、Cm は、
項目がキャッシュで見つからなかったとき（ミス）のコストである。興味深いことに、単独の
コストは有益な情報ではない。キャッシュは要求の内容によって、どの項目を保持するかを決
めるから、キャッシュの性能は要求のシーケンスに依存する。したがって、キャッシングを理
解するには、要求シーケンスに対する性能を調べる必要がある。たとえば、N 個の要求を含む
シーケンスで起こり得る最良と最悪の振る舞いは、容易に分析できる。極端なケースとして、
どの要求も新しい項目を参照していたら、キャッシングはまったく性能を改善しない。キャッ
シュは、それらの命令を、1 つ1 つデータストアに渡さなければならないのだ。したがって、
このワーストケースにおけるコストは次のように示せる。
Cworst = NCm
(12.1)
ただし、この分析ではキャッシュを維持する管理のオーバーヘッドは無視している。要求毎
の平均コストを求めるためにN で割ると、その結果はCm である。
逆の極端なケースとして、もしシーケンスにある全部の要求が同じデータ項目を指定してい
たら（つまり参照局所性が最高ならば）
、もちろんキャッシュは性能を向上させる。最初の要求
を受け取るとき、キャッシュは、その項目をデータストアからフェッチして、コピーを保存す
る。その後に続く要求は、キャッシュ内のコピーを使って応答できる。したがって、このベス
トケースにおけるコストは次のようになる。
Cbest = Cm + (N −1)Ch
(12.2)
要求毎のコストを求めるために、N で割ると、
Cper request = Cm + (N −1)Ch
N
= Cm
N −Ch
N + Ch
(12.3)
hi.0412.ko.2002@gmail.com
　12.7
典型的なシーケンスにおけるキャッシュ性能
221
N が無限大に近づくと（N →∞）
、最初の2 項はゼロに近づく。ゆえに、ベストケースに
おける要求毎のコストは、ついにCh となる。なぜキャッシュが、それほど強力なツールなの
かは、それで理解できる。
オーバーヘッドを無視するなら、
最悪のケースにおけるキャッシング性能は、
キャッシュ
がない場合より悪くはならない。最良のケースにおける要求毎のコストは、キャッシュ
をアクセスするコストと、ほとんど同じとなり、そのコストは、データストアをアクセ
スするコストよりも低い。
12.7 　典型的なシーケンスにおけるキャッシュ性能
典型的な要求シーケンスに対するキャッシュの性能を見積もるには、そのキャッシュがヒッ
トとミスの両方を含むシーケンスを扱う方法を調べる必要がある。キャッシュ設計者は、シー
ケンスの中でキャッシュで応答可能な要求が占める割合を、
「ヒット率」と呼ぶ。ヒット率は、
次のように定義される。
ヒット率= ヒットする要求の数
全要求数
(12.4)
ヒット率は0 と1 の間の値である。
「ミス率」
は、
1 からヒット率を引いたものと定義される。
もちろん実際のヒット率は、要求シーケンスに依存する。しかし経験によればヒット率は、
実際に用いられる要求を見ても、だいたい同じになる傾向がある。このような場合、アクセス
のコストは、ミスのコスト（Cm）とヒットのコスト（Ch）から、次の式で求められる。
コスト= r Ch + (1 −r) Cm
(12.5)
ここでr は、上記の式（12.4）で定義された「ヒット率」である。
データストアをアクセスするコストは、この等式のCm で与えられる固定値である。した
がって、キャッシュ設計者がキャッシュの性能を上げるのに使える方法は、ヒット率を上げる
か、あるはヒットのコストを下げるかの2 つである。
12.8 　キャッシュの置換ポリシー
キャッシュ設計者は、どうすればキャッシュのヒット率を上げられるのだろうか。それには
2 つの方法がある。
•
キャッシュを拡大する
•
置換ポリシーを改善する
キャッシュを拡大する
前述したように、キャッシュは大きなデータストアと比べれば、ずっと小さいのが普通だ。
キャッシングを始めると、
キャッシュには、
それぞれの応答のコピーが保存されていく。キャッ
hi.0412.ko.2002@gmail.com
222
第12 章
キャッシュとキャッシング　
シュのストレージが満杯になったら、新しい項目を追加できるように、キャッシュから項目を
削除する必要がある。キャッシュが大きければ、それだけ多くの項目を保存できる。
置換ポリシーを改善する
新しい項目に遭遇したのにキャッシュが満杯なとき、キャッシュは「置換ポリシー」を使っ
て、どの項目を削除するかを決める。キャッシュの置換ポリシーは、その新しい項目を無視す
べきか、あるいは、新しい項目を入れられるように項目を排除すべきかを決め、排除するとき
は、その項目を選択する方法を指定する。再び参照される項目が残されるように置換ポリシー
を改善すれば、ヒット率が上がるだろう。
12.9 　LRU 置換
どんな置換ポリシーを使うべきだろうか。これには2 つの問題がある。第1 に、ヒット率
を上げるために置換ポリシーは、もっとも頻繁に参照されるであろう項目を残すべきである。
第2 に、とくにメモリキャッシュの置換ポリシーは実装コストを抑えるべきである。この両方
の基準を満足させる置換ポリシーとして、きわめて人気が高いのが、
「LRU」
（Least Recently
Used）という方式だ。このポリシーは、参照されてから経過した時間がもっとも長い項目から
置換する2。
LRU は実装が容易である。そのキャッシュ機構は、現在キャッシュにあるデータ項目のリス
トを管理する。項目が参照されると、その項目はリストの先頭に移される。置換が必要なとき
は、リストの末尾にある項目を削除する。
LRU は多くの状況で良好に動作する。一群の要求に高い参照局所性があるとき
（つまりキャッ
シングで性能が改善されるとき）は、少数の項目が何度も繰り返し参照される。LRU は、それ
らの項目をキャッシュに入れておく傾向があるので、アクセスのコストが低く抑えられる。
要約すると次のようになる。
キャッシュのストレージが満杯のときに新しい項目が届いたら、キャッシュは現在の項
目集合を維持するか、それとも現在の項目から1 つを選んで新しい項目と置換するかを、
選ばなければならない。LRU が、置換のポリシーとして人気があるのは、実装が容易
で、しかも、再び要求されそうな項目を残す傾向があるからだ。
2　LRU は、
「最後に使われたのがもっとも古い」項目から置換する、という意味である。”least”は「アク
セス数が少ない」という意味ではない。
hi.0412.ko.2002@gmail.com
　12.10
多段キャッシュの階層構造
223
12.10 　多段キャッシュの階層構造
キャッシングでもっとも驚くべき予想外の側面は、キャッシュの性能を向上させるために
キャッシュを使うという考えだ! そんな最適化が、どうして可能なのかを理解するには、次のこ
とを思い出そう。キャッシュを挿入することで項目を取り出すコストが下がるのは、項目の一
部の置き場所が要求側に近づくからだ。では、図12‒3 で示すように、要求側と既存のキャッ
シュとの間に、もう1 つキャッシュを置いたらどうなるかを考えてみよう。
要求する側
新しいキャ
ッ
シュ
元のキャ
ッ
シュ
大きなデータス
トレージ
図12‒3：追加のキャッシュを挿入したシステムの構成
第2 のキャッシュで性能は向上するだろうか。向上するが、それには条件があって、新し
いキャッシュをアクセスするコストが、元のキャッシュをアクセスするコストよりも低い場合
（たとえば新しいキャッシュの方が要求側に近い場合）に限られる。要するに、コストを求める
式は、次のようになる。
コスト= r1Ch1 + r2Ch2 + (1 −r1 −r2)Cm
(12.6)
ここで、r1 は新しいキャッシュにおけるヒット率を表し、r2 は元のキャッシュにおけるヒッ
ト率を表す。Ch1 は新しいキャッシュをアクセスするコストであり、Ch2 は元のキャッシュを
アクセスするコストである。
要求側からデータストアに至る経路で複数のキャッシュを使うとき、そのシステムは「多段
キャッシュの階層構造」を実装している。多段の階層構造の例としては、Web のキャッシュが
ある。ユーザーのコンピュータで実行されるブラウザに至るまでの経路は、ISP（情報サービス
プロバイダー）が提供するキャッシュと、ブラウザが提供するローカルキャッシュ機構の、両
方を通過する場合がある。
要点をまとめよう。
キャッシュを使うシステムの性能を上げるために、もう1 つのキャッシュを追加するこ
とが可能だ。それら複数のキャッシュは、多段の階層構造を成すと考えられる。
12.11 　キャッシュをプリロードする
キャッシュの性能を、もっと向上させるには、どうすればよいだろうか。キャッシュ設計者
たちは、多くのキャッシュシステムが安定な状態（システムが、しばらく実行された後）で優れ
た性能を発揮するが、始動時には高いコストを示すことを認めた。初期のヒット率がきわめて
hi.0412.ko.2002@gmail.com
224
第12 章
キャッシュとキャッシング　
低いのは、キャッシュが項目をデータストアからフェッチする必要があるからだ。場合によっ
ては、キャッシュを「プリロード」することで、始動時のコストを下げることができる。つま
りキャッシングの実行を始める前に、値をキャッシュにロードしておくのだ。
もちろん、プリロードを使えるのは、キャッシュが要求を予測できる場合に限られる。たと
えばISP のWeb キャッシュでは、プリロードに、
「ホット」なページ（たとえば、過去数日で
頻繁にアクセスされたページや、所有者が頻繁なアクセスを予期しているページ）を使えるだ
ろう。他の手段としては、プリロードに自動的な手法を使うキャッシュもある。その1 つは、
キャッシュが自分の内容のコピーを定期的に不揮発性ストレージにコピーしておいて、最近の
値を起動時にプリロードするという手法だ。もう1 つの手法では、キャッシュが参照を使って
関連データを「プリフェッチ」する。たとえば、もしプロセッサがメモリの1 バイトをアクセ
スするなら、キャッシュは128 バイトをまとめてフェッチしておく。そして、もしプロセッサ
が次のバイトをアクセスしたら（その確率は高い）
、その値はキャッシュから得られる。
プリフェッチは、とくにWeb ページで重要だ。典型的なWeb ページには、複数の画像へ
の参照が含まれていて、ページを表示する前に、ブラウザは、それぞれの画像のコピーをダウ
ンロードして、そのコピーをユーザーのコンピュータにキャッシュしておく必要がある。ペー
ジがダウンロードされるにつれて、ブラウザは画像への参照を走査し、それぞれの画像のプリ
フェッチを、ページ全体のダウンロードを待たずに開始することができる。
12.12 　メモリシステムで使われるキャッシュ
キャッシングの基本的なアイデアは、もう理解できた。次に、メモリシステムでキャッシュ
を利用する方法を、いくつか考えよう。実際、キャッシングという概念は、もともとコンピュー
タのメモリシステムから始まっている3。もともとの動機は、低いコストで高性能を得ること
にあった。メモリは高価で、しかも遅かったから、アーキテクトたちは高速メモリのコストを
背負い込むことなく性能を改善する方法を探していた。そして彼らは、少量だが高速なキャッ
シュによって、性能が劇的に改善されることを発見した。その結果が驚異的だったので、1980
年代には、ほとんどのコンピュータでプロセッサとメモリの間に1 個のキャッシュが置かれる
ようになった。物理的に言えばメモリの回路基板とは別の基板にキャッシュが置かれたので、
コンピュータの所有者がメモリだけ、あるいはキャッシュだけを、独立してアップグレードで
きた。上述したように、キャッシングの階層構造を使えば、1 個のキャッシュよりも性能を高
めることが可能である。このため、これから見ていくように、現代のコンピュータはメモリ
キャッシュに階層構造を採用し、さまざまな方法でキャッシングを利用している。以下の節で、
その例を見ていこう。
3　マイクロコードを導入した功績で名高いモーリス・ウィルクス（Maurice Wilkes）が、1965 年にメモ
リキャッシュのコンセプトを発明した。
hi.0412.ko.2002@gmail.com
　12.13
物理メモリのキャッシュ
225
12.13 　物理メモリのキャッシュ
キャッシングは、多大なコストをかけずにメモリの性能を高める手段として普及した。初期
のコンピュータは物理メモリシステムを使っていた。つまり要求を出すときプロセッサが指定
するのは物理アドレスであり、メモリシステムは、その物理アドレスに応答していた。このた
め、プロセッサとメモリを結ぶ経路に挿入されるキャッシュは、物理アドレスを理解して利用
する必要があった。
物理アドレスのキャッシュなど簡単だと思われるかもしれない。たぶん、メモリキャッシュ
が「フェッチ」要求を受け、その要求にキャッシュから応答できるかどうかチェックし、もし
キャッシュにない項目だったら、その要求を物理メモリに渡せば良いのだろう。そして、いっ
たん物理メモリから取り出した項目は、ローカルコピーを保存しておき、その値をプロセッサ
に返せば良いのだろう。
しかし、
「たぶん、そうだろう」と想像された単純なシナリオは誤解を招く。物理メモリの
キャッシュは、実際には上の記述よりも、はるかに複雑である。その理由を理解するには「ハー
ドウェアは並行処理で高速化を実現する」という原則を思い出す必要がある。たとえばメモリ
キャッシュは、
「フェッチ」要求を受けたときに、キャッシュをチェックしてから物理メモリ
をアクセスするのではない。キャッシュのハードウェアは、実際には、その2 つのタスクを
並行して行うのだ。キャッシュは要求を物理メモリに渡すと同時に、ローカルな答えをサーチ
する。もし答えがローカルに見つかれば、キャッシュはメモリ演算をキャンセルしなければな
らない。また、答えをローカルに見つけられなかったら、キャッシュは根底にあるメモリの演
算が完了するまで待たなければならない。そればかりか、答えがメモリから届いたときには、
キャッシュは再び並行処理を使って、その答えのローカルコピーを保存するとともに、それを
プロセッサにも渡すのである。こういう並行処理によって、ハードウェアは複雑になるのだ。
物理メモリのキャッシュは、高性能を達成するために、ローカルキャッシュをサーチす
ると同時に根底にあるメモリをアクセスするよう設計される。この並行処理で、ハード
ウェアは複雑になる。
12.14 　ライトスルーとライトバック
メモリキャッシュが複雑になる原因は、並行処理だけでなく「ライト」
（ストア）演算にもあ
る。そこでの問題は、性能と一貫性だ。そのうち、性能の問題はわかりやすい。キャッシュは
読み出しの要求に関しては性能を改善できるが、書き込みの要求には、それができない。
「ラ
イト」演算が遅いのは、根底にあるメモリの値を変更する必要があるからだ。もっと重要なこ
とに、キャッシュは要求をメモリに渡すだけでなく、その項目がキャッシュにあるかどうかも
チェックする必要がある。もしあれば、キャッシュはそのコピーも更新しなければならない。
事実、経験によって、メモリキャッシュは書き出した値すべてのローカルコピーを常に保存す
hi.0412.ko.2002@gmail.com
226
第12 章
キャッシュとキャッシング　
べきであることが判明している。なぜならプログラムには、自分が格納した値を時間をおかず
に再びアクセスする傾向があるからだ。
メモリキャッシュの最初の実装は、
「ライト」演算を上記のように処理していた。キャッシュ
はコピーを保存しつつ、
「ライト」演算を根底にあるメモリに渡していた。このアプローチを、
われわれは「ライトスルーキャッシュ」と呼んでいる。
もう1 つの手法である「ライトバックキャッシュ」は、書かれたデータ項目のコピーを保存
して、根底にある物理メモリの更新を後まわしにする。物理メモリを更新しなければならない
かどうかを知るために、ライトバックキャッシュは、それぞれの項目について、
「ダーティビッ
ト」という追加のビットを保存する。物理メモリのキャッシュにおいて、ダーティビットは、
キャッシュ内の各ブロックに関連付けられる。項目がフェッチされ、そのコピーがキャッシュ
に置かれたら、ダーティビットがゼロに初期化される。プロセッサが、その項目を更新すると
き（つまり「ライト」を実行するとき）
、ダーティビットは1 にセットされる。キャッシュから
ブロックを排除する必要が生じたとき、ハードウェアは、まずブロックに関連付けられたダー
ティビットを調べる。もしダーティビットが1 なら、そのブロックのコピーをメモリに書く。
しかし、もしダーティビットが0 なら、ブロックは単純に上書きできる。なぜなら、そのブ
ロックにあるデータは、メモリにあるコピーとまったく同じだからだ。要点をまとめよう。
ライトバックキャッシュは、
各ブロックに関連付けられるダーティビットによって、
その
ブロックがフェッチした後に更新されているか否かを記録する。キャッシュからブロッ
クを排除するとき、ハードウェアは「ダーティブロック」のコピーをメモリに書くが、
ブロックがダーティでなければ、単にその内容を上書きする。
なぜライトバックキャッシュによって性能が改善されるのか。それを理解するために、プロ
グラムの「for ループ」で、繰り返しのたびにメモリにある変数をインクリメントする場合を
考えよう。ライトバックキャッシュは、最初に参照するときに変数をキャッシュに入れる。そ
の後の繰り返しで変数に対して行われる変更は、キャッシュされたコピーだけに影響を与える。
ループを終えたプログラムは、その変数を参照しなくなると想定しよう。そのうちにプログラ
ムは、他の参照を数多く生成し、ついに変数はキャッシュ内で最後に使われたのがもっとも古
い項目になり、
「LRU」として置き換えの対象になる。新しい項目が参照されてキャッシュの
スロットが必要になったとき、キャッシュは変数の値を物理メモリに書く。したがって、変数
は何回も繰り返し参照され、あるいは変更されるが、メモリシステムが物理メモリをアクセス
するのは、たった1 回となる4。
4　最適化を行うコンパイラならば、さらに性能を改善するため、ループが終わるまで変数を汎用レジスタ
に入れておくことが可能だ（それも一種のキャッシングである）
。
hi.0412.ko.2002@gmail.com
　12.15
キャッシュの一貫性
227
12.15 　キャッシュの一貫性
メモリキャッシュは、マルチコアCPU のように複数のプロセッサを持つシステムでは、とく
に複雑である。前述したように、ライトバックキャッシュではライトスルーキャッシュよりも
高い性能が得られる。そしてマルチプロセッサ環境では、それぞれのコアに独自のキャッシュ
を持たせることで、さらに性能を最適化できる。しかし残念ながら、2 つの最適化は衝突する。
その理由を理解するために、図12‒4 のアーキテクチャを見よう。ここでは2 つのプロセッサ
が、それぞれプライベートなキャッシュを持っている。
プロセッサ1
プロセッサ2
キャ
ッ
シュ1
キャ
ッ
シュ2
物理メモリ
図12‒4：2 つのプロセッサが、根底にある1 つのメモリを共有している。それぞれのプロセッサが別々の
キャッシュを持っているので、両方のプロセッサが同じメモリアドレスを参照したら衝突が発生するかもし
れない
この2 つのキャッシュがライトバック方式を使っていたら、どうなるだろうか。プロセッサ
1 がメモリの場所X に書くときは、キャッシュ1 がX の値を保持する。その後、空間が足りな
くなったら、キャッシュ1 は、その値を根底にある物理メモリに書き出す。同様に、プロセッ
サ2 がメモリのどこかに書くときも、その値は空間が足りなくなるまでキャッシュ2 に置かれ
るだろう。問題は明らかだ。もし両方のプロセッサが、所与のアドレスに対して「リード」と
「ライト」の演算を同時に行ったら、何かの機構を追加しない限り間違った結果が生じるだろう。
衝突を回避するため、所与のアドレスをアクセスする全部のキャッシュは、値を調整するた
めの「キャッシュ一貫性プロトコル」にしたがう必要がある。たとえば、プロセッサ2 がアド
レスA から読むとき、一貫性プロトコルは、それをキャッシュ2 がキャッシュ1 に知らせる
ことを要求する。もしキャッシュ1 が、現在アドレスA の値を保持していたら、キャッシュ2
がもっとも新しい値を取得できるように、キャッシュ1 は物理メモリにA を書く。つまり、ど
ちらかのプロセッサが「リード」演算を行うと、それをトリガとして、現在そのアドレスのコ
ピーを保持しているキャッシュがライトバックを行うようにするのだ。同様に、どちらかのプ
ロセッサがアドレスA に対して「ライト」演算を行ったら、その他すべてのキャッシュに対し
て、A の値を破棄するように通知する必要がある。したがって、追加のハードウェアと、キャッ
hi.0412.ko.2002@gmail.com
228
第12 章
キャッシュとキャッシング　
シュ同士の通信機構が必要なだけでなく、キャッシュの一貫性を保つには遅延も生じるのだ。
12.16 　L1、L2、L3 のキャッシュ
前述したように、
複数のキャッシュで階層構造を作ることにより、
全体の性能を向上させるこ
とができる。実際、ほとんどのコンピュータで、メモリシステムに少なくとも2 段階のキャッ
シュ階層構造がある。コンピュータアーキテクトたちが記憶階層に第2 レベルのキャッシュを
追加した理由を理解するには、4 つの事実を考慮しなければならない。
•
伝統的なメモリキャッシュは、メモリからもプロセッサからも離れていた。
•
伝統的なメモリキャッシュをアクセスするために、プロセッサのチップは、プロセッ
サと他の部分とを接続するピンを使う必要があった。
•
ピンを使って外部ハードウェアをアクセスするのは、プロセッサ内部にある機能ユ
ニットをアクセスするより、ずっと長い時間がかかる。
•
テクノロジーの進化によって、チップに載せられるトランジスタの数が増え、もっと
多くのハードウェアをプロセッサのチップに搭載できるようになった。
結論は、明らかだろう。第2 のキャッシュを追加すればメモリシステムの性能を改善できる。
第2 のキャッシュをプロセッサのチップに入れれば、キャッシュのアクセス時間を大幅に短
縮できる。そして、いまのテクノロジーならチップベンダーは第2 のキャッシュをプロセッサ
チップに組み込める。ゆえに、第2 のメモリキャッシュはプロセッサのチップに埋め込むのが
合理的である。もしヒット率が高ければ、ほとんどのデータ参照はプロセッサのチップの外に
出ることがない。メモリアクセスの実質的なコストは、レジスタをアクセスするコストと、ほ
とんど同じになるだろう。
多重キャッシュというアイデアを表現する用語は、もともとコンピュータ製造業者たちが採
用したものだ。
「L1 キャッシュ」はプロセッサチップ内蔵のキャッシュ、
「L2 キャッシュ」は
外部キャッシュ、
「L3 キャッシュ」は物理メモリに組み込まれたキャッシュを意味していた。
つまり当時は、L1 キャッシュが「オンチップ」で、L2 とL3 が「オフチップ」だった。
ところがチップサイズが非常に大きくなって、
1 個のチップに複数のコアと複数のキャッシュ
を入れることが可能になった。そこでメーカーは、だんだんと「L1 キャッシュ」という言葉を
「ある特定のコアに割り当てられるキャッシュ」という意味で、
「L2 キャッシュ」を「共有可能
なオンチップキャッシュ」という意味で、
「L3 キャッシュ」を「複数コアが共有するオンチッ
プキャッシュ」という意味で使うようになった。典型的には、すべてのコアがL3 キャッシュ
を共有する。したがって、オンチップとオフチップを区別する意味は、消えてしまった。
多重キャッシュによる階層構造について、伝統的な用語によれは、L1 キャッシュはプ
ロセッサのチップに埋め込まれたもの、L2 キャッシュはプロセッサの外部にあるもの、
hi.0412.ko.2002@gmail.com
　12.17
L1、L2、L3 のキャッシュ容量
229
L3 キャッシュは物理メモリに組み込まれたものを意味する。しかし最近の用語では、L1
キャッシュは1 個のコアに割り当てられたオンチップキャッシュ、L2 とL3 のキャッ
シュは、すべてのコアが共有するオンチップキャッシュを意味するようになった。
12.17 　L1、L2、L3 のキャッシュ容量
ほとんどのコンピュータが、キャッシュの階層構造を採用している。もちろん最上位の階層
にあるキャッシュがもっとも高速だが、容量はもっとも小さい。表12‒1 に、キャッシュのメ
モリ容量の例を示す。L1 キャッシュは、命令用とデータ用に分けることも可能だが、それは次
の節で説明しよう。
表12‒1：キャッシュ容量の例（2016 年）
。実際の容量は、まだまだ変化し続けているが、4GB から32GB
というRAM 容量とキャッシュ容量との対比に注目していただきたい
キャッシュ
容量
メモ
L1
64KB から96KB
コアごとに1 個ある
L2
256KB から2MB
コアごとに1 個あるかもしれない
L3
8MB から24MB
すべてのコアで共有される
12.18 　命令キャッシュとデータキャッシュ
すべてのメモリ参照を、1 個のキャッシュに通して良いのだろうか。この質問の意味を理解
するために、命令が実行され、データがアクセスされるようすを想像しよう。命令のフェッチ
は局所性が高くなりがちだ。多くの場合、次に実行すべき命令は隣接するメモリアドレスに存
在する。しかも、プログラムでもっとも時間のかかるループは、普通は小さなループであり、
ループ全体がキャッシュに入ってしまうかもしれない。一方、
データアクセスの振る舞いは、
プ
ログラムによって高い局所性を示す場合も、示さない場合もある。たとえばプログラムがハッ
シュテーブルをアクセスするとき、参照される場所はランダムになるだろう（ある機会に参照
される場所が、次の機会に参照される場所と近い位置にあるとは限らない）
。
命令とデータでは振る舞いが異なるのに、この2 種類の参照を混ぜたら、キャッシュにど
ういう影響が現れるのか。基本的に、要求のシーケンスにランダムな性質があればあるほど、
キャッシュの性能は悪くなる（なぜならキャッシュは、再び必要にならないとしても、それぞ
れの値を保存するだろうから）
。原則を要約しておこう。
要求のシーケンスにランダムな参照が挿入されると、キャッシュの性能が悪化する。ラ
ンダムな参照が発生する回数を抑えれば、キャッシュの性能は向上する傾向がある。
hi.0412.ko.2002@gmail.com
230
第12 章
キャッシュとキャッシング　
12.19 　変形ハーバードアーキテクチャ
命令とデータに別々のキャッシュを持つことで、性能は最適化されるだろうか。単純な答え
は、
「もちろん」だ。データと命令を同じキャッシュに入れると、データ参照が命令をキャッ
シュから追い出す傾向があるので、性能が悪化する。命令専用にキャッシュを追加すれば、性
能は向上するに決まっている。
だが、この単純な答えでは不十分だ。ハードウェアを追加したら役に立つかどうかが問題な
のではなく、さまざまなトレードオフから正解を選ぶことが問題なのだ。ハードウェアを追加
すれば放熱量が増え、より多くの電力が消費され、携帯機器ではバッテリーの持ちが悪くなる。
だからアーキテクトはキャッシュの追加に関わるすべてのコストを秤にかけなければならない。
もしアーキテクトが、より多くのキャッシュハードウェアを追加すると決めたら、次の問題は、
そのハードウェアを使う最良の方策を選ぶことだ。たとえば、1 個のキャッシュでも容量を増
やせば、衝突が回避されて性能が上がるはずだ。キャッシュが十分に大きければ、命令とデー
タの参照を混在させても問題にならないだろう。命令キャッシュを別に追加するのと、キャッ
シュは1 個のままにして容量を増やすのと、どちらが良いのだろうか。
多くのアーキテクトたちが、追加のハードウェアが適切な量で収まる最適な方法と判断した
のは、新たにI キャッシュ（命令キャッシュ）を導入し、既存のキャッシュはD キャッシュ
（データキャッシュ）として使うという方法だった。命令キャッシュとデータキャッシュを分離
するのは、ハーバードアーキテクチャでは、まったく簡単なことだ。それならI キャッシュを
命令メモリに割り当て、D キャッシュをデータメモリに割り当てれば良い。だとしたら、フォ
ン・ノイマン・アーキテクチャを捨てるべきなのだろうか。
多くのアーキテクトたちは、
妥協案を採択した。つまり、
コンピュータは命令とデータに別々
のキャッシュを使うが、2 つのキャッシュの先にあるのは1 個のメモリである。この折衷案を、
われわれは「変形ハーバードアーキテクチャ」と呼んでいる。図12‒5 に、その変形アーキテ
クチャを示す。
プロセッサ
Iキャ
ッ
シュ
Dキャ
ッ
シュ
メモリ
図12‒5：変形ハーバードアーキテクチャは、命令用とデータ用に別々のキャッシュを持つが、その先の根底
にあるメモリは、両者で共用する
hi.0412.ko.2002@gmail.com
　12.20
メモリキャッシュの実装方法
231
12.20 　メモリキャッシュの実装方法
概念として、メモリキャッシュの各エントリには2 つの値が含まれる。メモリアドレスと、
そのアドレスにあるバイト値だ。しかし実際には、各エントリに完全なアドレスを格納するの
は効率が良くない。このため、メモリキャッシュは巧妙なテクニックを使って必要な空間の量
を減らしている。メモリキャッシュの最適化で、もっとも重要なテクニックは、次の2 つだ。
•
ダイレクトマップ方式
•
セットアソシアティブ方式
後述するように、どちらのキャッシュメモリ実装も、算術計算を避けるために2 の冪乗を利
用する（仮想メモリの機構も同様だ）
。
12.21 　ダイレクトマップ式メモリキャッシュ
「ダイレクトマップ式メモリキャッシュ」は、マッピングの技法を使ってオーバーヘッドを
回避する。メモリキャッシュはバイトアドレッシング可能なメモリで使われても、キャッシュ
に個々のバイトを記録するわけではない。キャッシュでは、メモリとキャッシュの両方を固
定サイズのブロックに分ける。ここでブロックサイズB（単位はバイト）は2 の冪乗にする。
ハードウェアは、あるブロック内のバイトが参照されたとき、そのブロック全体をキャッシュ
に入れる。キャッシュ用語を使えば、キャッシュ内のブロックは「キャッシュ行」である。ダ
イレクトマップ方式のキャッシュサイズは、しばしばキャッシュ行数にキャッシュ行のサイズ
を掛けた大きさで指定される。たとえば「4K 行で1 行が8 バイト」という具合にサイズを指
定するわけだ。このキャッシュでは、メモリが8 バイト単位のセグメントにわかれ、それぞれ
がキャッシュの1 行に割り当てられると考えれば良い。図12‒6 は、ブロックサイズが8 で4
行のキャッシュに、メモリのバイト群を割り当てるようすを示している（注意：メモリキャッ
シュは通常、4 行よりずっと多くの行を収納する。ここで小さなキャッシュサイズを選んだの
は、例を単純化するためだ）
。
メモリ上のブロックにはC で割ったあまり（剰余）の番号が振られる。C はキャッシュに
存在するスロットの数だ。ブロック番号は0 からC-1 までである（図ではC が4 である）
。2
の冪乗を使うのだから、バイトアドレスをブロック番号にマップするのに算術演算は不要であ
り、いくつかのビットを抽出することでブロック番号が得られる。この図の場合、ブロック番
号はアドレスの第4 ビットと第5 ビットを抽出することで計算できる。たとえばアドレス57
のバイトを考えてみよう。これをバイナリ表記すれば、111001 である（第4 と第5 のビット
に下線を引いて強調した）
。バイナリの11 は、10 進では3 である。その数は、図のブロック
番号と一致している。アドレス44 は、バイナリでは101100 である。第4、第5 のビットは
hi.0412.ko.2002@gmail.com
232
第12 章
キャッシュとキャッシング　
3 
56 
57 
58 
59 
60 
61 
62 
63
2 
48 
49 
50 
51 
52 
53 
54 
55
1 
40 
41 
42 
43 
44 
45 
46 
47
0 
32 
33 
34 
35 
36 
37 
38 
39
3 
24 
25 
26 
27 
28 
29 
30 
31
2 
16 
17 
18 
19 
20 
21 
22 
23
1 
8 
9 
10 
11 
12 
13 
14 
15
0 
0 
1 
2 
3 
4 
5 
6 
7
ブロ
ッ
ク
バイ
ト群のメモリ内ア
ドレス
図12‒6：ブロック数が4 で、1 ブロックが8 バイトのキャッシュのために、メモリの場所にブロック番号
を割り当てる例
01 であり、ブロック番号は1 である。このマッピングをプログラミング言語で表現するには、
次のように書ける。
b = ( byte address >> 3 ) & 0x03;
メモリキャッシュに関して計算は必要ない。ハードウェアは値を整数レジスタに置き、適切
なビットを抽出して、ブロック番号を作る。
ダイレクトマップ方式のキャッシュを理解するには、次のルールを把握することが重要だ。
「i という番号のメモリブロックだけを、キャッシュのスロットi に置くことができる」
。たとえ
ば、アドレスが16 から23 までのブロックは、スロット2 に置くことができる。アドレス48
から55 までのブロックも、同じスロットに置ける。
もし複数のメモリブロックが同じスロットに置かれるのなら、キャッシュはどうやって、ス
ロットに現在あるのがどのブロックかを知るのだろう? キャッシュはC 個のブロックで構成さ
れるグループに、それぞれユニークな「タグ」を付加するのだ。たとえば図12‒7 は、4 個のス
ロットを持つサンプルのキャッシュで、タグの値が各メモリブロックにどう割り当てられるか
を示している。
現在キャッシュのスロットに入っているブロックを識別するために、キャッシュのエントリ
には、それぞれタグの値が含まれる。もしキャッシュのスロット0 にタグk が含まれていた
ら、スロット0 に入っている値は、タグk を持つメモリ領域のブロック0 に対応するのだ。
なぜタグを使うのか。キャッシュはスロット内のエントリをユニークに識別できなければな
らない。タグで識別されるのは、ただ1 バイトのメモリではなく、大きなブロックのグループ
だ。タグを使えば、メモリのセクションを識別するのに、メモリの完全なアドレスよりも少な
いビット数で済む。そればかりか、次の節で説明するが、ブロックサイズとタグで識別される
メモリのサイズに2 の冪乗を選ぶことにより、キャッシュで行うルックアップの効率が極度に
向上する。
hi.0412.ko.2002@gmail.com
　12.22
2 の冪乗による効率化
233
キャ
ッ
シュ
タグ
値
メモリ
ブロ
ッ
ク
8バイ
ト
３
２
１
０
３
２
１
０
３
２
１
０
３
２
１
０
３
２
１
０
タグ3
タグ2
タグ1
タグ0
図12‒7：サンプルのメモリキャッシュにはブロック4 個分の空間があり、メモリは理論上、8 バイトのブ
ロックに分割される。4 個のブロックで構成されるメモリ上のグループに、それぞれユニークなタグが割り
当てられる
12.22 　2 の冪乗による効率化
上記のダイレクトマップ方式は複雑に思えるかもしれないが、ハードウェアの実装は2 の冪
乗を使うことで単純になる。実際、そのハードウェアはエレガントで、極度に効率が高いのだ。
剰余の演算を使う代わりに、タグもブロック番号も、メモリアドレスからビット群を取り出す
ことで計算される。アドレスの上位ビットがタグとして使われ、その下のビット群がブロック
番号になり、最後のビット群がブロック内のバイトオフセットになる。図12‒8 のように分割
するのだ。
タグ 
ブロ
ッ
ク 
オフセッ
ト
図12‒8：キャッシュは2 の冪乗を使って、メモリアドレスを3 つのフィールドに分割できる。これらはタ
グと、ブロック番号と、ブロック内のバイトオフセットに対応する
すべての値をビット抽出で得られるのだから、ダイレクトマップ式メモリキャッシュをルッ
クアップするアルゴリズムは単純明快だ。キャッシュを配列と考えれば、まずアドレスからブ
ロック番号を抽出し、そのブロック番号を配列のインデックスとして使う。配列のエントリは、
hi.0412.ko.2002@gmail.com
234
第12 章
キャッシュとキャッシング　
それぞれタグと値を含む。もしアドレス内のタグが、キャッシュスロット内のタグと一致した
ら、キャッシュは、その値を返す。もしタグが一致しなければ、キャッシュのハードウェアは、
そのブロックをメモリからフェッチし、コピーをキャッシュに置いてから、その値を返す。こ
れらのステップを、アルゴリズム12‒1 に、まとめておく。
アルゴリズム12‒1：ダイレクトマップ式メモリキャッシュにおける、キャッシュのルックアップ
所与の値:
1 個のメモリアドレス
求める値:
そのアドレスのバイトデータ
方法:
アドレスから、適切なビットフィールドを選ぶことによって、
タグ番号t、ブロック番号b、オフセットo を、抽出する
キャッシュのスロットb で、タグを調べる
もしキャッシュのスロットb のタグがt と一致したら{
o を使って、スロットb のブロックから適切なバイトを選び、
そのバイトを返す
} さもなければ{ /* キャッシュを更新する*/
根底にあるメモリからブロックb をフェッチし、
そのコピーをスロットb に置き、
スロットb のタグにt をセットし、
o を使って、スロットb のブロックから適切なバイトを選び、
そのバイトを返す
}
ただし、このアルゴリズムは重要な詳細を1 つ省いている。キャッシュの各スロットには、
そのスロットがすでに使われたかどうかを示す「有効ビット」がある。最初に（つまり、コン
ピュータが起動したときに）すべての有効ビットが0 にリセットされる。これは、どのスロッ
トにもメモリからコピーしたブロックが含まれていないという意味だ。スロットにブロックを
格納したら、キャッシュのハードウェアは、その有効ビットに1 をセットする。そしてスロッ
トのタグを調べるときに、もし有効ビットがセットされていなければ、ハードウェアはミスマッ
チ（不一致）を報告し、その結果メモリからブロックのコピーが強制的にロードされる。
12.23 　ダイレクトマップ式キャッシュのハードウェア実装
キャッシュのルックアップを記述するアルゴリズム12‒1 では、キャッシュを配列に見たて、
インデックス参照して要素を抽出するステップを示した。しかし実際には、キャッシュのス
ロットはメモリ内に配列として格納されるわけではない。これらはハードウェア回路で実装さ
れ、回路は並行動作する。たとえば、アドレスから要素を抽出する最初のステップは、アドレ
スを内部レジスタに置き（これは一群のラッチで構成されるハードウェア回路だ）
、そのアド
hi.0412.ko.2002@gmail.com
　12.23
ダイレクトマップ式キャッシュのハードウェア実装
235
レスの各ビットを1 個のラッチの出力にするハードウェア構成によって実装される。つまり、
いったんアドレスがレジスタに置かれたら、そのアドレスの各ビットは別の線によって表現さ
れるのだ。アドレスに含まれる要素、t、b、o は、単に出力線をグループ分けすることによっ
て取得される。
アルゴリズム12‒1 の第2 のステップでは、キャッシュのハードウェアがスロットの1 つを
調べる必要がある。そのハードウェアはデコーダを使って、該当するスロットを選択する。す
べてのスロットは共通の出力線に接続されているが、ハードウェアは選択したスロットだけ出
力するよう構成されている。アドレスのタグと、選択したスロットのタグとの比較には、
「コ
ンパレータ」回路を使う。図12‒9 に、キャッシュのルックアップを行う回路を単純化したブ
ロック図で示す。
入力のア
ドレス
V 
Tag 
Value
インデッ
クスのビッ
ト
デコーダが
1個のスロ
ッ
トを
選択する
ア
ドレスから得た
タグのビッ
ト
選択したスロ
ッ
トだけが値を渡す
コンパレータ
= ?
論理AND
「有効」
出力
 
「値」
出力
図12‒9：メモリキャッシュのルックアップを実装するために使われるハードウェアのブロック図
この回路は、メモリアドレスを入力として受け取り、2 つの出力を生成する。
「有効」出力は、
指定のアドレスがキャッシュにあったとき（つまり、キャッシュが値を返すとき）にだけ、1
になる。
「値」の出力は、指定されたアドレスにあるメモリの内容である。
この図で、各スロットがV とTag とValue に分割されているのは、それぞれのフィールド
に別々のハードウェア回路を使えるという意味だ。デコーダから右側の各スロットに向かう水
平の線は、そのスロットの回路をアクティブ化できる接続を示している。ただし、デコーダが
hi.0412.ko.2002@gmail.com
236
第12 章
キャッシュとキャッシング　
選択するのは、いつも、ただ1 個のスロットである（この図では、選択されたスロットを濃色
で強調している）
。
スロットから下に向かう垂直の線は、パラレル接続を表している。各スロットのハードウェ
アが、これらの垂直線に接続されるが、そこに値を置けるのは選択されたスロットだけだ。し
たがって、この例でAND ゲートの入力となるのは、選択されたスロットのV（有効）回路だ
けであり、コンパレータへの入力となるのは、選択されたスロットのTag（タグ）回路だけで
あり、
「値」出力となるのは、選択されたスロットのValue（値）回路だけである。キャッシュ
のルックアップは、組み合わせ回路によって素早く実行できる、というのが重要なポイントだ。
12.24 　セットアソシアティブ式メモリキャッシュ
ダイレクトマップ式メモリキャッシュに代わる主な選択肢は、
「セットアソシアティブ式メモ
リキャッシュ」と呼ばれる。セットアソシアティブ式メモリキャッシュの要点は、ハードウェ
アの並列回路を使って、より大きな柔軟性を得ることにある。セットアソシアティブ式のアプ
ローチでは、キャッシュを1 個だけ維持する代わりに、複数のキャッシュを根底で維持し、そ
れらすべてを同時にサーチできるハードウェアを提供する。重要なポイントとして、複数の
キャッシュを持つセットアソシアティブ式メモリキャッシュは、同じ番号を持つブロックを、
1 個ではなく複数格納できる。
ごく単純な例として、根底にあるハードウェアのコピーを2 つだけ持つセットアソシアティ
ブ式キャッシュを考えよう。図12‒10 に、そのアーキテクチャを示す。
パラレルテス
トのためのハー
ドウェア
tag 
value
3
2
1
0
3
2
1
0
tag 
value
図12‒10：セットアソシアティブ式キャッシュの例。根底にあるハードウェアのコピーを2 つ持ち、両方
のコピーを同時にサーチするハードウェアを含んでいる
セットアソシアティブ方式の長所を理解するために、あるプログラムが2 つのアドレス、A1
とA2 を、相互に繰り返し参照するときのことを考えよう。2 つのアドレスはタグが異なるけ
れど、どちらもブロック番号は0 というケースを考えるのだ。ダイレクトマップ式のメモリ
キャッシュでは、この2 つのアドレスがキャッシュ内の1 個のスロットを求めて競合する。A1
への参照によって、A1 の値がキャッシュのスロット0 にロードされ、A1 への参照によって、
A2 の値がキャッシュのスロット0 にロードされる。ゆえに、この2 つを相互に参照を行うシー
hi.0412.ko.2002@gmail.com
　12.25
プログラマにおよぼす影響
237
ケンスでは、参照するたびにキャッシュミスが生じる。ところが、セットアソシアティブ式の
メモリキャッシュでは、A1 を2 つある根底のキャッシュの片方に置き、A2 を、もう片方に置
くことができる。ゆえに、参照するたびにヒットする結果になる。
並行処理が大規模ならば、セットアソシアティブ式メモリキャッシュの性能は、それだけ向
上する。極端なケースとして、根底にあるキャッシュがスロットを1 つしか含まないが、その
スロットには任意の値を置けるという場合、そのキャッシュは「フルアソシアティブ」と呼ばれ
る。両極端を結ぶ連続体の、どこに位置するかは、並行処理の規模によって決まる。並行処理
がなければ、ダイレクトマップ式のメモリキャッシュになり、完全な並行処理を行えば、CAM
と等しいものになる。
12.25 　プログラマにおよぼす影響
キャッシングは、経験によればほとんどのコンピュータプログラムで良好に動作する。プロ
グラマが作り出すコードはループを含む傾向があり、それによってプロセッサは、ある小さな
集合に属する命令を繰り返し実行する（そして、また次の集合へと進む）
。同様に、プログラム
はデータ項目の集合を何度も参照してから、新しいデータ項目に進む傾向がある。そしてコン
パイラにも、キャッシングを意識して、コードがキャッシュを活用するように最適化してくれ
るものがある。
キャッシングは圧倒的な成功を収めたが、キャッシュを有効に利用するコードを書けるのは、
キャッシュの仕組みを理解しているプログラマである。たとえば、あるプログラムでは、大き
な配列の各要素について、数多くの演算を実行しなければならないとしよう。それには、一度
に1 種類ずつ演算を実行する方法もあるし（その場合プログラムは、配列の要素を何度も巡回
処理することなる）
、すべての演算を配列の1 個の要素に対して行って、それから次の要素に
進む方法もある（その場合、プログラムは配列を一度だけ巡回処理する）
。キャッシングの観点
からは、要素がキャッシュの中に留まる後者の方法が望ましい。
12.26 　まとめ
キャッシングは、多様なコンテクストで利用できる基礎的な最適化のテクニックだ。キャッ
シュは要求をインターセプトして（途中で奪い取って）自動的に値を格納しておき、可能な限
り要求に素早く応答する。バリエーションとしては、マルチレベルのキャッシュによる階層構
造や、プリロードされるキャッシュなどがある。
キャッシュによるメモリ性能の最適化は、きわめて重要だ。ほとんどのコンピュータシステ
ムが、マルチレベルのメモリキャッシュを採用している。もともと、L1 キャッシュはプロセッ
サと同じ集積回路に置かれるもので、L2 キャッシュはプロセッサから見て外部に置かれ、L3
キャッシュはメモリに付随するものだった。しかし集積技術が進み、回路が大きくなると、製
造業者たちはL2 とL3 のキャッシュもプロセッサのチップに移したので、いまではL1 キャッ
hi.0412.ko.2002@gmail.com
238
第12 章
キャッシュとキャッシング　
シュは1 個のコアに結び付いたもの、L2 とL3 のキャッシュは複数のコアが共有するもの、と
区別している。
ダイレクトマップ方式のメモリキャッシュは、キャッシュしている要素のリストを維持せず
に、ルックアップを処理する。ルックアップのアルゴリズムといえば複数のステップで実行す
るように思われるが、ハードウェアで実装されるダイレクトマップ方式のメモリキャッシュ
は、組み合わせ回路でルックアップを実行するのにプロセッサを必要としない。セットアソシ
アティブ式のメモリキャッシュは、ダイレクトマッピングのコンセプトを拡大して、並列的な
アクセスを可能にする。
練習問題
12.1
「トランスペアレント」という言葉は、メモリキャッシュで使うとき、どういう意
味になりますか?
12.2
ある区間のコードにおけるヒット率が0.2、キャッシュのアクセスに要する時間が
20 マイクロ秒、根底にある物理メモリをアクセスするのに要する時間が1 マイクロ
秒だとしたら、そのコードに関する実質的なメモリアクセス時間は?
12.3
ある物理学者が、大きな2 次元配列を巡回処理するため、C のコードを書きました。
float a[32768, 32768], sum;
...
for (i=0; i<32768; i++) {
for (j=0; j<32768; j++) {
sum += a[j,i];
}
}
この物理学者は、コードの実行が遅すぎて困ると訴えています。実行速度が上がるよ
うに、コードを簡単に修正できますか?
12.4
あるコンピュータは、個々のメモリアドレスの長さが32 ビットで、メモリシステ
ムには、4K 個までのエントリを格納できるキャッシュがあります。もしキャッシュ
のエントリすべてにアドレスとバイトデータが格納されるという愚直な方法を使った
ら、そのキャッシュには、どれほど多くのストレージが必要ですか? また、ダイレク
トマップ方式のメモリキャッシュを使い、それぞれのエントリに1 個のタグと4 バイ
ト構成のブロックデータが格納されるとしたら、ストレージの総量は、どれだけ必要
ですか?
12.5
上の課題の拡張です。愚直なソリューションの代わりに、キャッシュのサイズは同
じでも、より多くのデータ項目を格納できるようなソリューションは、何と呼ばれま
すか?
hi.0412.ko.2002@gmail.com
　12.26
まとめ
239
ヒント：もしプロセッサが、常にメモリ内の4 バイト整数をアクセスするのなら、ど
んな値をキャッシュに入れますか?
12.6
ベンダーの仕様書を参照して、最近のメモリシステムにおける、メモリアクセスの
コストと、キャッシュヒットのコストを求めましょう（12.6 節のCh とCm を参照）
。
12.7
上の課題で得た値を使って、ヒット率0 から1 までの変化に対応するメモリアクセ
スコストを、グラフにプロットしましょう。
12.8
12.6 の課題で得た、Ch とCm の値を使うとき、メモリシステムの平均アクセス時
間で、
（同じメモリシステムでキャッシュがない場合と比べて）30%の向上を達成する
には、どれほどのヒット率、r が必要ですか?
12.9
キャッシュのヒット率を改善する方法を、2 つあげてください。
12.10
キャッシュの一貫性とは何ですか? どのようなシステムで、それが必要ですか?
12.11
ダイレクトマップ方式のメモリキャッシュをシミュレートするコンピュータプロ
ラムを書きましょう。64 ブロックのキャッシュを使い、ブロックサイズは128 バイ
トとします。プログラムをテストするために、1000 x 1000 の整数配列を作ります。
プログラムが配列を辿る順序が、行ごとの場合と、列ごとの場合で、アドレス参照を
シミュレートしましょう。それぞれのケースで、ヒット率は、どうなりましたか?
12.12
図12‒9 が示すハードウェアのブロック図は、ルックアップに必要な回路だけを示
しています。この図を拡張して、メモリからキャッシュに値をロードする回路も入れ
ましょう。
hi.0412.ko.2002@gmail.com
hi.0412.ko.2002@gmail.com
第13 章
仮想メモリ技術と仮想アドレッシング
13.1 　はじめに
これまでの章で、
物理メモリとキャッシングを論じた。物理メモリについては、
メモリシステ
ムの製造に使われるハードウェア技術、物理メモリのワード構成、そして実際にメモリをアク
セスする物理アドレッシングの体系を考察した。キャッシングについては、メモリキャッシュ
がどのように組織されるか、なぜメモリキャッシュによって性能が劇的に改善されるのかを説
明した。
この章では仮想メモリ（あるいは仮想記憶）という重要なコンセプトについて学ぶ。その動
機と、仮想アドレス空間の作成に使われるテクノロジーと、仮想メモリと物理メモリのマッピ
ングを調べていこう。ハードウェアシステムに重点を置きながら想メモリ機構をどう使うのか
も説明しよう。
13.2 　仮想メモリの定義
われわれが「仮想メモリ」
（VM）と呼んでいるのは、根底にある物理メモリの詳細を隠して、
もっと使いやすいメモリ環境を提供する機構である。仮想メモリシステムは、現実には存在し
ないアドレス空間とメモリアクセスの体系を作り、それによって、物理メモリと物理アドレッ
シングの体系が持つ制限を克服する。あいまいな定義だと思われたかもしれないが、いまは広
い範囲のテクノロジーと用途を包括的に捉えなければならない。今後の節で、これまでに作ら
れた仮想メモリシステムと、それぞれの実装に使われたテクノロジーの例をあげて、この概念
をもっと細かく定義していく。さまざまな仮想メモリの体系が生まれたのは、あらゆるケース
に最適な体系が存在しないからである。
これまでに見たメモリシステムにも、われわれが定義する仮想メモリに該当するものがある。
第11 章で示したインテリジェントなメモリコントローラは、ワードアドレッシングを使う物
hi.0412.ko.2002@gmail.com
242
第13 章
仮想メモリ技術と仮想アドレッシング　
理メモリに、バイトアドレッシングを提供する。その実装に含まれるコントローラのおかげで、
プロセッサはバイトアドレッシングを使って要求を出すことができる。また、サイズの選択で
「2 の冪乗」を選ぶことによって、算術演算を回避でき、バイトアドレスとワードアドレスの変
換が、きわめて容易になることも学んだ。
13.3 　MMU とアドレス空間
アーキテクトは、インテリジェントなメモリコントローラを「メモリ管理ユニット」と呼び、
「MMU」
（Memory Management Unit）
という略語を使う。MMU は、
プロセッサのために
「仮
想アドレス空間」を作る。プロセッサが使うアドレスを「仮想アドレス」と呼ぶのは、MMU
によって、そのアドレスが根底にある物理メモリに変換されるからだ。そして、この機構全体
を「仮想メモリシステム」と呼ぶ理由は、それが根底にある物理メモリの一部ではないからだ。
なお、公式な呼び方ではないが、仮想メモリと物理メモリを区別するために、技術者が「実」
という言葉で物理メモリを形容することがある。たとえば物理アドレスに対して「実アドレス」
という言葉を使ったり、物理メモリによって認識されるアドレスを「実アドレス空間」と呼ん
だりする。
13.4 　複数の物理メモリシステムに対するインターフェイス
バイトアドレスを根底にあるワードアドレスに変換できるMMU の機能を、さらに拡張する
ことで、より複雑なメモリ構成を作れる。たとえばインテルは、SRAM とDRAM という2 種
類の物理メモリを使うネットワークプロセッサを設計した。SRAM はDRAM よりも高速だが
高価なので、そのシステムでは（頻繁にアクセスされる項目用に）少量のSRAM と、
（頻繁にア
クセスされない項目用に）大量のDRAM が使われた。それだけでなく、SRAM の物理メモリ
は4 バイトのワードで構成され、DRAM の物理メモリは8 バイトのワードで構成された。イ
ンテルのネットワークプロセッサは、両方のメモリをアクセスできる埋め込み型のRISC プロ
セッサを使った。しかも重要なポイントとして、そのRISC プロセッサはバイトアドレッシン
グを使うものだった。ただし、2 種類のメモリをアクセスするのに別の命令や別のオペランド
型を使うのではなく、インテルの設計は標準的なアプローチにしたがっていた。つまり、両方
のメモリを1 個の仮想メモリ空間に統合したのである。
2 つの異なる物理メモリシステムから均一な仮想アドレス空間を実装するには、メモリコン
トローラで必要な変換を行わなければならない。要するにMMU（メモリ管理ユニット）は、
根底にあるメモリシステムの詳細を隠す「抽象」を提供する必要がある。全体的なアーキテク
チャを、図13‒1 に示そう。
この図で、プロセッサは1 個のMMU に接続されている。そのMMU は、プロセッサから
のメモリ要求を受け取り、それぞれの要求を変換して、物理メモリ1 のコントローラまたは物
理メモリ2 のコントローラに渡す。この2 つの物理メモリコントローラの働きは、第11 章で
hi.0412.ko.2002@gmail.com
　13.5
アドレスの変換あるいはマッピング
243
プロセッサ
MMU
物理コン
トローラ
物理コン
トローラ
物理メモリ #1
物理メモリ #2
図13‒1：2 つの異なるメモリを1 個のプロセッサに繋げるアーキテクチャ。このプロセッサは、どちらの
メモリでも使える
述べた通りだ。コントローラはバイトアドレッシングを指定する要求を受け取って、その要求
を、ワードアドレッシングを使う動作に変換する。
図13‒1 のハードウェアは、どうやって仮想アドレス空間を提供するのだろうか。その答え
は、やはり第11 章で説明したメモリバンクと関係がある。MMU はアドレス空間を2 分し、
それらに物理アドレス1 と物理アドレス2 を割り当てるのだ。たとえば、もし双方の物理メモ
リが、それぞれ1 ギガバイト（0x40000000 バイト）のRAM を含んでいるとしたら、MMU
が作成する仮想アドレス空間のうち、0 から0x3fffffff までのアドレスを第1 のメモリに、
0x40000000 から0x7fffffff までのアドレスを第2 のメモリに割り当てることができる。そ
の結果として、図13‒2 のような仮想メモリシステムができる。
13.5 　アドレスの変換あるいはマッピング
図13‒2 の、根底にあるメモリシステムは、それぞれ独立した物理メモリのように動作する。
つまり、どちらのハードウェアも、要求は0 から始まるアドレスを参照するのだと想定する。
2 つのメモリは、どちらも同じアドレス集合を識別するわけだ。メモリ1 に割り当てられる仮
想アドレスは、ハードウェアが期待するのと同じ領域である。けれども、メモリ2 についてプ
ロセッサが生成する仮想アドレスは、0x40000000 から始まるのだから、MMU は、要求をメ
モリ2 に渡す前に、そのアドレスを低いほうの領域に（つまり実アドレス0 から0x3fffffff
までに）
「マップ」しなければならない。このことを、われわれはMMU がアドレスを「変換」
する、と言っている。
メモリ2 のためのアドレスマッピングは、数学的には単刀直入だ。MMU はアドレスから
hi.0412.ko.2002@gmail.com
244
第13 章
仮想メモリ技術と仮想アドレッシング　
仮想ア
ドレス
プロセッサには
1個の連続したメモリに
見える
メモリ 2
メモリ 1
0x7fffffff
0x40000000
0x3fffffff
0
図13‒2：アドレス空間を2 つの物理メモリに分ける仮想メモリシステム。MMU は、アドレスによって、
どちらのメモリをアクセスするかを決める
0x40000000 を差し引くだけである。リスト13‒1 に、このコンセプトを示す。
リスト13‒1：MMU が、図13‒2 に描いた仮想メモリを作るのに使うステップのシーケンス。MMU が、仮
想アドレス空間を2 つの物理メモリにマップする
プロセッサから仮想メモリの要求を受け取る
要求のアドレスをV に代入する
if (V < 0x40000000 ) {
要求そのまま(アドレスV) を、メモリ1 に渡す
} else { /* アドレスをメモリ2 のためにマップする*/
V2 = V-0x40000000;
書き換えた要求(アドレスV2) を、メモリ2 に渡す
}
以上の記述を要約しよう。
MMU は根底にある複数の物理メモリシステムを組み合わせて仮想アドレス空間を作る。
プロセッサからは、それが1 個の均一なメモリシステムのように見える。根底にあるメ
モリは、それぞれ0 から始まるアドレスを使うので、MMU は、プロセッサが生成する
アドレスと、個々のメモリが使うアドレスとの間で変換を行う必要がある。
hi.0412.ko.2002@gmail.com
　13.6
算術演算を避ける
245
13.6 　算術演算を避ける
MMU はアドレス変換を行うのに、
実際には減算を使わない。減算には大がかりなハードウェ
アが必要になるし（たとえばALU）
、個々のメモリ参照について実行すると時間がかかりすぎ
る。解決策は、2 の冪乗を使ってハードウェアを単純化することだ。たとえば図13‒2 のマッ
ピングを考えてみよう。アドレス0 から0x3fffffff までがメモリ1 にマップされ、アドレ
ス0x40000000 から0x7fffffff までがメモリ2 にマップされる。そこで図13‒3 を見ると、
バイナリで表現したとき、これらのアドレスは31 ビットを占めるが、上下の領域で違うのは
最上位ビットだけである。
 
0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 
から 
から
 0x3fffffff 
0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 
まで 
まで
 0x40000000 
1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 
から 
から
 0x7fffffff 
1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 
まで 
まで
ア
ドレス 
バイナリ表現 (31ビッ
ト)
図13‒3：0 から2 ギガバイトのアドレスをバイナリの値で見る。最上位ビットを除けば、1 ギガバイトを
超えた領域の値も、その下の領域の値と同じである
この例が示すように、2 の冪乗を選べば、下位のビットを物理アドレスとして使えるから減算
が不要になる。この例で2 つの物理メモリのうち片方にアドレスをマッピングするとき、MMU
はアドレスの最上位ビットを使って、どの物理メモリが要求を受けるべきかを判定できる。そ
して、物理アドレスを作るには仮想アドレスの残りのビットを抽出するだけでよい。
仮想アドレス空間を、2 の冪乗に対応する境界で分割すれば、MMU が物理メモリを選
択して必要なアドレス変換を実行するのに、算術演算は不要になる。
13.7 　不連続なアドレス空間
図13‒2 は、すべてのアドレスが物理メモリの1 つにマップされる「連続的仮想アドレス空
間」の例を示していた。プロセッサが、0 から最高位アドレスまで、どのアドレスでも参照で
きるのは、個々のアドレスが、必ず物理メモリの1 つに含まれる1 個の場所に対応するから
だ。興味深いことに、多くのコンピュータは物理メモリの設計に柔軟性を持たせ、メモリの増
設量をコンピュータの所有者が決められるようにしている。そういうコンピュータにはメモリ
モジュール用のスロットが複数あって、所有者は、すべてのスロットをメモリで満たすことも、
いくつかのスロットを空のまま残すこともできる。
hi.0412.ko.2002@gmail.com
246
第13 章
仮想メモリ技術と仮想アドレッシング　
コンピュータの所有者が任意のメモリを増設できるようにすると、結果として何が起きるだ
ろうか。コンピュータの作成時に定義される仮想メモリアドレス空間には、搭載可能な物理メ
モリの全部の場所に対応するアドレスが（つまり、そのコンピュータに増設可能な最大量のメ
モリのためのアドレスが）あるはずだ。もし所有者が、一部のメモリを足さないことに決めた
ら、仮想アドレス空間の一部が使えなくなる。そして、もしプロセッサが、物理アドレスに対
応しないアドレスを参照したら、結果はエラーになる。有効なアドレス領域の合間に無効なア
ドレス領域が挟まっていれば、仮想アドレス空間は連続しない。たとえば図13‒4 に示すのは、
仮想アドレス空間を2 つの物理メモリに割り当てたのに、それぞれの物理メモリの一部が省略
されたとき、その仮想アドレス空間がどう見えるかを示している。
ア
ドレス
N
N/2
N/2－1
0
穴(存在しない)
メモリ2
メモリ1
穴(存在しない)
図13‒4：N バイトの不連続な仮想アドレス空間が、2 つの物理メモリにマップされている。一部のアドレ
スは物理メモリに対応しない
仮想アドレス空間の一部が物理メモリにマップされないとき、われわれは、そのアドレス空
間には「穴」がある、という。たとえば図13‒4 の仮想アドレス空間には、穴が2 つある1。
ここまでの話をまとめよう。
仮想アドレス空間が連続する場合、どのアドレスも、根底にある物理メモリに存在する
場所へとマップされる。仮想アドレス空間が連続しない場合、そのアドレス空間には1
個以上の穴が開く。もしプロセッサが、物理メモリに対応しないアドレスに対して読み
書きを試みたら、結果はエラーになる。
仮想アドレス空間を物理メモリにマップする方法は、ほかにも数多く存在する。第11 章で
見たメモリのインターリーブを行うのなら、たとえばアドレスの下位2 ビットで4 個の別々な
物理メモリモジュール（バンク）を切り替え、アドレスの残りのビットでモジュール内の1 バ
イトを選択できる。モジュール群をバイト単位でインターリーブすることの主な利点の1 つ
1　穴の開いたアドレス空間の例は、入出力を論じるときにも登場する。
hi.0412.ko.2002@gmail.com
　13.8
仮想メモリを使う動機
247
は、根底にあるハードウェアが別々の物理メモリを同時にアクセスできることから生じる。下
位ビットでモジュールを選択するのだから、メモリで連続するバイト列が別々のモジュールに
分配される。とくにプロセッサが32 ビット構成のデータ項目をアクセスするなら、根底にあ
るメモリシステムは、その4 バイト全部を同時にフェッチできる。
13.8 　仮想メモリを使う動機
これまでは簡単なサンプルを使って、メモリシステムがプロセッサに、根底にある物理メモ
リとは異なる仮想アドレス空間を提供できることを示してきた。この章の残りの部分では、よ
り複雑なメモリシステムを調べていくが、そのほとんどは、これまでに述べたコンセプトを具
体化し拡張したものだ。複雑な仮想メモリを使う主な動機は、これから学ぶように、次の4 つ
である。
•
ハードウェアを均質に統合する
•
プログラミングの便宜を図る
•
マルチプログラミングをサポートする
•
プログラムとデータを保護する
ハードウェアの均質な統合
われわれのサンプルは、仮想メモリのシステムが複数の物理メモリに対して均質なインター
フェイスを提供できることを示している。もっと重要なのは、この方法により、根底にあるメ
モリを均等に扱えることだ。たとえば物理メモリの一部には32 ビットのワードサイズを使い、
他の物理メモリには64 ビットのワードサイズを使うことが可能である。また、一部のメモリ
のサイクル時間を、他のメモリより高速にできる。一部のメモリをRAM で構成し、他のメモ
リはROM にすることさえ可能だ。プロセッサが全部のメモリを1 個のアドレス空間からアク
セスできるように、MMU が、これらの違いを隠してくれる。
プログラミングの便宜
仮想メモリシステムの主な長所の1 つは、プログラミングが簡単になることだ。もし個々の
物理メモリが均一なアドレス空間に統合されなければ、プロセッサは、それぞれのメモリにつ
いて特別な命令（あるいは特殊な形式のオペランド）を使う必要がある。それではメモリをア
クセスするプログラミングが苦痛になってしまう。もっと重要なことに、もしプログラマが、
ある項目を、いまのメモリから別のメモリに移動しようと決めたら、そのプログラムを書き直
す必要が生じる。だから、そのような決定を実行時に行うことも、できない。
hi.0412.ko.2002@gmail.com
248
第13 章
仮想メモリ技術と仮想アドレッシング　
マルチプログラミングのサポート
現代のコンピュータシステムでは、複数のアプリケーションを同時に実行できる。たとえば、
文書を編集中のユーザーは、ワードプロセッサを開いたまま、一時的にWeb ブラウザを立ち
上げて参考資料を調べることができるし、その間ずっと音楽を聴いていることも可能だ。
「マ
ルチプログラミング」と「マルチプロセシング」は、どちらも、コンピュータが複数のプログ
ラムを同時に実行できることを意味する言葉だ。マルチプログラミングのサポートに仮想メモ
リシステムが必要なことを、これから学んでいこう。
プログラムとデータの保護
前述したように、CPU は「実行モード」によって、そのとき許可する命令群を決める。これ
から見るように、仮想メモリは本来、コンピュータのプロテクション機構とリンクされている
のだ。
13.9 　複数の仮想空間とマルチプログラミング
初期のコンピュータ設計者たちは、マルチプログラミングは実用にならないと考えていた。
その理由を理解するには、命令セットの働きを考える必要がある。間接参照を指定するオペラ
ンドは、それぞれ1 個のメモリアドレスを参照する。だから、もし2 本のプログラムが同じメ
モリにロードされて同時に実行されたら、衝突が起きるかもしれない。つまり、2 本のプログ
ラムが同じ場所のメモリを別の目的で使おうとしたら、矛盾が生じるかもしれない。したがっ
て、複数のプログラムを同時に実行するには、それらが同じメモリアドレスを使わないように
書く必要がある。
マルチプログラミングを実現するもっとも一般的な方法は、
仮想メモリを使って、
それぞれの
プログラムに別の仮想アドレスを作るというテクニックだ。どのように仮想メモリシステムを
使うかを、サンプルを見て学ぼう。図13‒5 は、単純明快なマッピングを示している。
この図の機構は、物理メモリをサイズが均等な領域、すなわち「パーティション」に分割して
いる。このようにパーティション分割されたメモリシステムは、かつて1960 年代や1970 年
代のメインフレームコンピュータで使われたが、その後は別の方式で置き換えられた。メモリ
をパーティションに分ける手法の主な短所の1 つは、あるプログラムで使えるメモリが、その
コンピュータにある物理メモリの総量の分数になるということだ。図13‒5 が示すように、メ
モリをパーティションに分けて使うシステムでは、メモリを4 つのパーティションに分けるの
が典型的だ。その場合、メモリ総量の1/4 が、それぞれのプログラムに割り当てられる。
図13‒5 は、MMU が複数の仮想アドレス空間を1 個の物理メモリに変換することを示唆し
ている。けれども実際のMMU のハードウェアは、より多くのマッピングを実行できる。たと
えばMMU は、仮想アドレス空間1 を、中間的な仮想アドレス空間に変換してから、その中間
的な仮想アドレス空間を、根底にある1 個以上の物理メモリに変換することもできる（さらに
バイトアドレスからワードアドレスへの変換も実装できるだろう）
。
hi.0412.ko.2002@gmail.com
　13.10
仮想空間を動的に生成する
249
仮想空間
４
仮想空間
３
仮想空間
2
仮想空間
1
M
0
M
0
M
0
M
0
物理メモリ
N
3N/4
N/2
0
図13‒5：1 個の物理メモリに4 つのパーティションがマップされている。個々の仮想アドレスは、アドレ
ス0 から始まる
13.10 　仮想空間を動的に生成する
仮想メモリシステムは、どのように作るべきだろうか。これまでの簡単なサンプルでは、仮
想アドレス空間（複数かもしれれない）から物理メモリへのマッピングを、ハードウェアの構築
時に選択していた。小規模な専用システムではマッピングをハードウェア設計に組み込むこと
があるが、汎用のコンピュータシステムでは、そうしないのが普通だ。汎用システムのMMU
は、代わりに実行時の動的な変更を可能にする。つまり、システムが起動されるとき、プロセッ
サがMMU に指令して、仮想アドレス空間を物理メモリにマップする方法を指定するのだ。
プロセッサで実行されるプログラムは、どうしてアドレス空間が変更されても実行を継続で
きるのだろうか。一般に、使用すべきアドレス空間は、
「プロセッサモード」の一部として選択
される。プロセッサの実行は「リアルモード」で始まる。これは、そのプロセッサが全部のメ
モリ参照を、MMU を使わずに、物理メモリに直接渡すという意味だ。リアルモードで実行中
のプロセッサは、MMU とのやりとりよって、マッピングを構築できる。いったんマッピング
を指定したら、そのプロセッサはモードを変更し、MMU を有効にして、指定されたアドレス
にジャンプする命令を実行できる。MMU は、構成されたマッピングにしたがって、それぞれ
のメモリ参照を変換する。
次の節では、動的な仮想メモリシステムを作るのに使われてきたテクノロジーを調べよう。
以下の3 つの例を、取り上げる。
•
ベースと境界のレジスタ
hi.0412.ko.2002@gmail.com
250
第13 章
仮想メモリ技術と仮想アドレッシング　
•
セグメンテーション
•
デマンドページング
13.11 　ベースと境界のレジスタ
「ベースと境界」という呼び名で知られる機構は、われわれが理解しておくべき動的な仮想
メモリ機構のううち、もっとも古く、もっともわかりやすいものの1 つだ。基本的に「ベース
と境界」の機構は、1 個の仮想アドレス空間を作り、その空間を物理メモリ領域の1 つに割り
当てるものだ。
「ベース」と「境界」は、MMU の一部である1 対のレジスタを指す。どちらの
レジスタも、MMU を有効にする前にロードする必要がある。ベースレジスタに格納するのは
物理メモリのアドレスで、どこに仮想アドレス空間をマップするかを指定する。そして境界レ
ジスタには、そのアドレス空間のサイズを指定する整数値を格納する。図13‒6 に、そのマッ
ピングを示す。
物理メモリ
仮想空間
M
bound
base
N
0
0
M
図13‒6：ベースと境界の機構を使う仮想メモリ。ベース(base) レジスタは、仮想アドレス空間の場所を指
定し、境界(bound) レジスタは、そのサイズを指定する
13.12 　仮想空間を変更する
ベースと境界が、仮想アドレス空間を1 個提供するだけなら、興味深い機構とは思えないだ
ろう。しかし、ベースと境界の機構は動的なのだ（つまり、変更が容易である）
。だからOS
は、ベースと境界の機構を使って、複数の仮想アドレス空間を使い分けることができる。たと
えばOS が、2 つのアプリケーションプログラムを、2 つの別々な場所のメモリにロードした
と考えよう。MMU を制御するのは、リアルモードで実行されるOS だ。アプリA の実行準備
hi.0412.ko.2002@gmail.com
　13.13
仮想メモリとプロテクション
251
が整ったら、OS はMMU をメモリでA が占めているセクションを指すように設定し、MMU
のマッピングを有効にして、そのアプリにジャンプする。後に、制御がOS に戻ったとき、OS
は、実行すべきアプリとして、もう1 つのB を選び、MMU をB のメモリを指すように設定し、
MMU を有効にして、B のコードにジャンプする。どちらのアプリも仮想アドレス空間は0 か
ら始まる。アプリケーションは、自分が物理メモリのどこにいるのか、気付かないままとなる。
要するにOS は、ベースと境界の機構を使っても、前述した静的な仮想メモリの機構と、ほ
とんど同じ機能を提供できるのだ。
ベースと境界の機構は、MMU の2 つの値を使って、どのように仮想アドレス空間を物
理アドレス空間にマップするかを指定する。ベースと境界の機構が強力なのは、OS が
マッピングを動的に変更できるからだ。
13.13 　仮想メモリとプロテクション
ベースと境界のアプローチは、何のために「境界レジスタ」を使うのだろう。その答えは「プ
ロテクション」
（保護）である2。仮想アドレスから物理アドレスへのマッピングは、ベースレ
ジスタだけで確立するが、そのマッピングは、プログラムが事故または悪意によって任意に大
きなメモリアドレスを参照することを妨げない。たとえば図13‒6 で、M よりも高位のアドレ
スは、プログムに割り当てられた領域を超えている（そのアドレスは、他のアプリケーション
に割り当てられているかもしれない）
。
ベースと境界の機構では、境界レジスタによって、プログラムが割り当て済みの空間を決し
て超えないことが保証される。もちろんプロテクションを実装するには、MMU が個々のメモ
リ参照をチェックして、もしプログラムがM より高位のアドレスを参照仕様としたらエラーに
しなければならない。ベースと境界によって提供されるプロテクションは、ある重要な概念の
例を示している。
マルチプログラミングをサポートする仮想メモリシステムは、プロテクションも提供し
なければならない。それによって、あるアプリケーションが、他のアプリケーションに
割り当てられているメモリを、読んだり書き換えたりすることを防ぐのだ。
13.14 　セグメンテーション
上述のメモリマップは、完全なアドレス空間のマッピングを行うものだった（完全な、とい
うのは、アプリケーションを実行するのに必要なメモリのすべてという意味で、コンパイルさ
れたプログラムと、そのプログラムが使うデータも含まれる）
。アドレス空間全体をマップす
る仮想メモリ技術は、
「粒度の粗いマッピング」と呼ばれる。それとは違って、アドレス空間を
2　訳注：実際、”bound register”は「保護境界レジスタ」とも訳される。
hi.0412.ko.2002@gmail.com
252
第13 章
仮想メモリ技術と仮想アドレッシング　
部分的にマッピングする技術は、
「粒度の細かいマッピング」と呼ばれる。
粒度の細かいマッピングを求める理由を理解するために、典型的なアプリケーションプログ
ラムについて考えてみよう。プログラムは関数群で構成され、その制御は、ある関数から別の
関数へと、プロシージャコールによって渡される。初期のコンピュータアーキテクトたちは、
こう考えた。メモリは貴重な資源なのに、粒度の粗い仮想システムではアプリケーション全体
がメモリを占める必要がある。しかし、ある時間でアクティブに実行される関数は1 つだけな
のだから、ほとんどのメモリは使われない。
そこで、必要なメモリの量を減らすためにアーキテクトたちが提案したのは、個々のプログ
ラムを可変長のブロックに分割し、いつでも必要なプログラムのブロックだけをメモリにロー
ドする機構だった。つまり、プログラムの各部は、必要になるまで外部ストレージ装置（典型
的にはディスク）に保存しておく。ある部分が必要になったら、OS が、十分に大きな未使用
メモリ領域を探し出して、必要になったプログラムの一部をロードする。次にOS は、MMU
を設定して、その部分が使う仮想アドレスと、その部分を入れたた物理アドレスとのマッピン
グを定める。プログラムの一部が不要になったときは、その部分をOS がディスクにコピーし
て、そのメモリを他の部分で使えるようにする。
可変長のメモリブロックを使う、この機構は「セグメンテーション」と呼ばれ、そこに入れ
るプログラムの一部分は、
「セグメント」と呼ばれた。いったん提案されたセグメンテーション
は、しかし多くの疑問を投げかけられた。セグメンテーションを効率化するには、どのような
ハードウェアサポートが必要になるのか。セグメントのサイズには、ハードウェアが上限を課
すべきだろうか。
多くの研究と、ハードウェアによる実験も行われた後、セグメンテーションは衰退した。セ
グメンテーションの中心的な問題は、OS がメモリからブロックの出し入れを始めた後に生じ
る。セグメントは可変サイズなので、未使用のメモリが数多くの小さなブロックに分割される
状況に陥りやすい。コンピュータ科学者たちは、この状況を「フラグメンテーション」と呼ん
で、メモリの断片化を指摘した3。
セグメンテーションとは、プログラムを可変サイズのブロックに分割して行う仮想メモ
リ機構であり、現在必要なブロックだけがメモリに置かれる。メモリの断片化という問
題を引き起こすので、セグメンテーションは、ほとんど使われていない。
3　メモリの断片化を防ぐため、何人かのアーキテクトたちは、より大きな、固定サイズのセグメントを使
う実験をした（たとえば64K バイトのセグメント）
。
hi.0412.ko.2002@gmail.com
　13.15
デマンドページング
253
13.15 　デマンドページング
セグメンテーションに代わる機構として大いに成功を収めたのが、
「デマンドページング」で
ある。このテクニックも、プログラムを小さな部分に分け、必要になるまで外部ストレージに
保存し、参照されたらメモリにロードする、という点はセグメンテーションと同じである。
デマンドページングがセグメンテーションともっとも大きく異なるのは、プログラムを分割
する方法だ。1 つの機能を完全に格納できる大きさの可変長セグメントを使う代わりに、デマ
ンドページングは、
「ページ」と呼ばれる固定サイズのブロックを使う。むかしはメモリもアプ
リケーションプログラムも、ずっと小さかったので、アーキテクトは512 バイトか1K バイト
のページサイズを選んでいたが、現在のアーキテクトは、もっと大きなページサイズを選んで
いる（たとえばインテルのプロセッサは4K バイトのページを使っている）
。
13.16 　デマンドページング用のハードウェアとソフトウェア
デマンドページングを効率よくサポートする仮想メモリシステムには、2 つの技術の組み合
わせが必要だ。
•
アドレスマッピングを効率よく処理して、ページが利用されたことを記録し、欠けて
いるページを検出できるハードウェア
•
ハードウェアを設定し、ページの利用状況を監視し、外部ストレージと物理メモリの
間でページの移動を行うソフトウェア
デマンドページングのハードウェア
ハードウェアアーキテクチャは、アドレスマッピングの機構を提供して、デマンド（要請）に
関する部分をソフトウェアが処理できるようにする。つまり、ソフトウェア（普通はOS）が、
まずMMU を設定して、仮想アドレス空間のうち、どのページがメモリに存在するか、それぞ
れのページがどこに位置するかを指定する。それからOS がアプリケーションを実行し、その
アプリケーションは、設定済みの仮想アドレス空間を使うことになる。アプリケーションが、
まだ利用できないアドレス（つまり、メモリに存在しないページのアドレス）を参照しない限
り、MMU がメモリアドレスを変換する。
欠けているページへの参照は「ページフォールト」と呼ばれ、一種の（たとえば0 による除
算のような）エラー状況として扱われる。つまりハードウェアは、欠けているページを外部ス
トレージからフェッチするのではなく、フォールトの発生をOS に報告して、OS がその問題
に対処できるようにするだけなのだ。通常、ハードウェアは「例外」を発生させるように作ら
れる。ハードウェアは、そのときの演算の状態を（フォールトを起こした命令のアドレスを含
めて）保存してから、
「例外ベクトル」を使う。これをOS の視点から見れば、ページフォール
hi.0412.ko.2002@gmail.com
254
第13 章
仮想メモリ技術と仮想アドレッシング　
トは「割り込み」のように働く4。いったんフォールトを処理したら、OS はプロセッサに、そ
のフォールトを起こした命令から実行を再開させることができる。
デマンドページングのソフトウェア
メモリを管理するのは、OS の責任である。OS のソフトウェアは、どのページをメモリに残
し、どのページをストレージに保存するかを決めなければならない。もっと重要なことに、ソ
フトウェアは、オンデマンドで（さしせまった要請に応じて）ページをフェッチする。つまり、
いったんハードウェアがページフォールトを報告したら、あとはページングソフトウェアの仕
事になるのだ。ソフトウェアは、必要なページを識別し、そのページを2 次記憶で探し当て、
それをメモリに読み込んでMMU を再設定する。いったんページをロードしたら、ソフトウェ
アはアプリケーションの実行を継続させる。そして「フェッチ‒ 実行」サイクルは、次にペー
ジフォールトが発生するまで続けられる。
もちろん、ページングのハードウェアとソフトウェアは協調する必要がある。たとえばペー
ジフォールトが発生したとき、ハードウェアが演算の状況として保存する値は、あとで実行を
継続するときロードできるように配置する必要がある。同様に、ソフトウェアはMMU の設定
方法を正確に理解する必要がある。
13.17 　ページ置換
ページングを理解するには、一群のアプリケーションが長時間実行されると何が起きるかを
考える必要がある。アプリケーションがページを参照すると、
仮想メモリシステムは、
そのペー
ジをメモリに移動する。いつか、メモリはページを満載した状態になる。さらにページが必要
だとOS が知るのは、そのページをアプリケーションが参照したときだ。その場合、さらに1
つページを加えるために、既存のページを1 つ選んで追い払うという、難しい選択をしなけれ
ばならない。ページを外部ストレージとメモリの間で移動するには時間がかかるので、近い将
来に必要とされないページを選んで移動すれば、性能が最適化される。このプロセスを「ペー
ジ置換」と呼ぶ。
ページ置換はソフトウェアが処理するので、そのアルゴリズムとヒューリスティクスの議論
は、本書の扱う範囲を超える5。ただし、OS による選択を援助する機構は、後述するように、
ハードウェアが提供する。
4　訳注：
「割り込み」とベクトルについては、入出力を扱う第16 章に解説がある。
5　訳注：ページ置換のソフトウェアに関する参考文献として、タネンバウムの『モダンオペレーティング
システム』
（第2 版）がある。4.4 節から4.8 節まで、各種のアルゴリズムが詳しく記述されている。
hi.0412.ko.2002@gmail.com
　13.18
ページングの用語とデータ構造
255
13.18 　ページングの用語とデータ構造
「ページ」という言葉は、プログラムのアドレス空間におけるブロックを意味する。そして
「フレーム」という言葉は、物理メモリにおいてページを格納できるスロットを意味する。だか
ら、ソフトウェアが「ページをメモリのフレームにロードする」という言い方ができる。ペー
ジがメモリ内にあるとき、そのページは「駐在している」と言われる。そして現在メモリに駐
在している、あるアドレス空間からのページの集合を、
「レジデントセット」と呼ぶ。
デマンドページングに使われる主要なデータ構造は、
「ページテーブル」と呼ばれる表だ。
ページテーブルを思い浮かべるには、ページ番号をインデックスとする1 次元の配列とみな
すのが一番簡単だ。つまり、テーブルのエントリには、0、1 などのインデックスが振られる。
ページテーブルの各エントリは、
（もしページが駐在していなければ）
「空の値」を含むか、あ
るいは、そのページを現在格納している物理メモリのフレーム番号を含むかの、どちらかであ
る。図13‒7 は、ページテーブルを図式化したものだ。
フレームに分割された
物理メモリ
ページテーブル
N
0
P
0
図13‒7：アクティブなページテーブルの例。一部のエントリは、メモリ内のフレームを指している。ペー
ジテーブルのエントリが、ヌル(ここではΛで表す) であれば、そのページは現在メモリに駐在していない
13.19 　ページングシステムにおけるアドレス変換
図13‒7 の項目は、フレームに対応するのであり、個々のワードに対応するのではない。ペー
ジングのハードウェアを理解するために、アドレス空間が図13‒8 のように固定サイズのペー
ジに分割されると考える。
hi.0412.ko.2002@gmail.com
256
第13 章
仮想メモリ技術と仮想アドレッシング　
ア
ドレス空間
3K－1
2K
2K－1
K
K－1
0
ページ2
ページ1
ページ0
図13‒8：仮想アドレス空間が、それぞれ1K バイトのページに分割されている
この図が示すように、もし各ページにK 個のバイトが含まれるのなら、ページ0 のバイトは
0 からK‒1 までのアドレスを持ち、ページ1 のバイトはK から2K‒1 のアドレスを持つ（以下
同様）
。
仮想アドレスV から、それに対応する物理アドレスP への変換を考えると、それには次の3
つのステップが必要だ。
1
アドレスV が属するページの番号を判定する。
2
そのページ番号をインデックスとして、ページテーブルを参照し、そのページを格納
しているフレームの、メモリ内の位置を調べる。
3
V が存在する位置のページ内オフセットを求め、その値をメモリ内のフレームに加え
た位置を求める。
図13‒8 は、アドレスとページとの対応を示している。数式で表すと、あるアドレスが置か
れているページ番号N は、そのアドレスを、ページ毎のバイト数K で割ることによって計算
できる。
ページ番号= N =
» V
K
–
(13.1)
同様に、そのアドレスのページ内オフセットO は、除算の剰余（モジュロ）として計算され
る6。
オフセット= O = V modulo K
(13.2)
したがって、仮想アドレスV を、対応する物理アドレスP に変換するには、ページ番号N と、
オフセットO を、次のように使う。
物理アドレス= P = ページテーブル[N] + O
(13.3)
6　ページ内のバイトアドレスを求める計算は、11.14 節で述べた、ワード内のバイトアドレスを求める計
算に似ている。
hi.0412.ko.2002@gmail.com
　13.20
2 の冪乗を使う
257
13.20 　2 の冪乗を使う
第11 章で論じたように、算術演算（たとえば除算）を、個々のメモリ参照について実行す
るのはコストが高すぎる。したがって、メモリシステムの他の部分と同じく、ページングシス
テムも算術演算を避けて設計される。ページ毎のバイト数は、2 の冪乗、2q になるよう選択
される。したがって、フレームにある最初のバイトのアドレスは、その下位q ビットがゼロに
なる。そして興味深いことに、フレームアドレスの下位ビット群が常にゼロであれば、ページ
テーブルに完全なアドレスを格納する必要がない。2 の冪乗を使うことによって、先ほど数式
で指定した除算と剰余の計算は、ビットの抽出で置き換えることができる。そればかりか、加
算の演算も、
「論理和」で置き換えられる。その結果、
（13.1）から（13.3）までの数式を使う
代わりに、MMU は次の式にしたがって、仮想アドレスV を物理アドレスP に変換できる。
P = ページテーブル[上位ビット群(V )] または下位ビット群(V )
(13.4)
図13‒9 は、MMU が仮想アドレスのマッピングを、どう実行するかを示している。この図を
見るときは、ハードウェアがビットを並行処理で移動できることを思い出そう。だから、仮想
アドレスの下位ビット群から物理アドレスの下位ビット群に向かう矢印は、パラレルなデータ
パスを表している。つまりハードウェアは全部のビットを同時に送るのだ。また、ページテー
ブルのエントリから物理アドレスの上位ビット群に向かう矢印は、そのページエントリにある
全部のビットをパラレルに転送できるという意味である。
仮想ア
ドレス
N
O
ページテーブル
F
F
O
物理ア
ドレス
図13‒9：ページングシステムにおいてMMU が行うアドレス計算。ページサイズを2 の冪乗にすれば、除
算と剰余の計算を行う必要がなくなる
hi.0412.ko.2002@gmail.com
258
第13 章
仮想メモリ技術と仮想アドレッシング　
13.21 　「存在」と「利用」と「変更」のビット
ページングのハードウェアについての記述では、いくつか詳細を省いていた。たとえばペー
ジテーブルのエントリには、そのページが位置するフレームを指定する値だけでなく、ハード
ウェアとソフトウェアが共同作業を行うための制御ビットも含まれている。表13‒1 は、ほと
んどのページングハードウェアにある3 つの制御ビット7を示している。
表13‒1：各ページエントリにある制御ビットと、それぞれについてハードウェアが行うこと。これらのビッ
トの目的は、OS でページ置換を行うソフトウェアを援助することだ
制御ビット
意味
存在ビット
ページが現在メモリに駐在しているかどうかを判定するため、ハード
ウェアがテストするビット。
利用ビット
ページが参照されたときに、ハードウェアによってセットされる。
変更ビット
ページが変更されたときに、ハードウェアによってセットされる。
存在ビット
もっとも単純明快な制御ビットが、
「存在ビット」と呼ばれるもので、これは、そのページが
現在メモリに存在するかどうかを示す。このビットはソフトウェアによってセットされ、ハー
ドウェアによってテストされる。OS は、いったんページをロードして、ページエントリの他
の値を記入し終えたら、
「存在ビット」に1 を設定する。そして、ページをメモリから追い出
したら、OS が「存在ビット」に0 を設定する。MMU は、アドレスを変換するときに、ページ
テーブルのエントリで「存在ビット」を調べる。もし「存在ビット」が1 なら、変換を続行す
る。もし「存在ビット」が0 なら、ハードウェアはページフォールトの発生を宣言する。
利用ビット
ページ置換に必要な情報を提供する「利用ビット」は、0 で初期化され、後にソフトウェア
によってテストされる。このビットをセットするのはハードウェアであり、その機構は単純明
快だ。MMU は、いつでもページエントリをアクセスするときには、その「利用ビット」を1
に設定する。OS は周期的にページテーブルを走査し、
「利用ビット」をテストして、そのペー
ジが前回の走査から後に参照されたかどうかを調べる。参照されなかったページは、追い出し
の候補になる。参照されていたら、OS が「利用ビット」をクリアして、そのページを次の走査
まで残す。
変更ビット
この「変更ビット」は、ソフトウェアによって初期化と後のテストが行われるが、セットする
のはハードウェアだ。ページングソフトウェアは、ページをロードしたときに、このビットを
7　訳注：Presence とUse とModiﬁed。これらを「存在／不在ビット」
、
「参照ビット」
、
「修正ビット」と
呼ぶ文献もある。
hi.0412.ko.2002@gmail.com
　13.22
ページテーブルのストレージ
259
0 に設定する。MMU は、そのページでライト演算が発生したときに、このビットを1 にセッ
トする。したがって「変更ビット」は、ページのどれかのバイトが、そのページをロードした
後で上書きされたら1 になる。この値はページ置換の際に使われる。追い出しの候補に選ばれ
たページの「変更ビット」を見て、OS は、そのページを外部ストレージに書き戻す必要がある
か、それとも単に破棄できるか（ページが外部ストレージにあるコピーと、まったく同じだか
ら）を、判定できる。
13.22 　ページテーブルのストレージ
ページテーブルは、どこに置かれるのか。一部のシステムでは、プロセッサの外部にある特
殊なMMP チップのなかにページテーブルが格納される。もちろんメモリ参照は、プロセッサ
の処理で重要な役割を果たすので、そのMMU は効率よく動作するよう設計しなければならな
い。メモリ参照がボトルネックにならないように、ある種のプロセッサは、MMU アクセス専
用の高速なハードウェアインターフェイスを使う。そのインターフェイスにはパラレル線が含
まれていて、プロセッサとMMU が、同時に数多くのビットを送信できるようにしている。
しかし驚くべきことに、多くのプロセッサはページテーブルをメモリに格納するよう設計さ
れている。プロセッサ（またはMMU）に特殊用途のレジスタが含まれていて、OS は、それを
使って現在のページテーブルの置き場所を指定できるのだ。ページテーブルの場所は、物理ア
ドレスで指定しなければならない。そのようなシステムは、図13‒10 に示すように、メモリを
3 つの領域に分割するように設計するのが典型的だ。
メモリ
OS
ページ
テーブル
フレームス
トレージ
図13‒10：ページテーブルをメモリに格納するアーキテクチャで物理メモリを分割する例。物理メモリの大
部分は、フレームのために予約される
この図の設計は、異種のテクノロジーを組み合わせてメモリシステムを作る動機の1 つを示
唆している。ページテーブルは頻繁に使われるから、ページテーブルの格納に使うメモリには
高性能が必要だ（SRAM など）
。けれども高性能なメモリは高価だ。もっとコストの安いメモ
リ（たとえばDRAM）をフレームの格納に使うことで、全体的なコストを抑えることができる。
アーキテクトは、ページテーブルにはSRAM を、フレームストレージにはDRAM を使うシス
テムを設計できるだろう。
hi.0412.ko.2002@gmail.com
260
第13 章
仮想メモリ技術と仮想アドレッシング　
13.23 　ページングの効率とTLB
すべての仮想メモリシステムに共通する中心的な疑問は、結果としてのシステムが、どれほ
ど効率的なのか、ということだ。この疑問を理解するには、アドレス変換を「あらゆる」メモリ
参照で（あらゆる命令フェッチで、メモリ参照のあらゆるオペランドで、あらゆる結果の格納
で）実行する必要があるという認識が重要だ。それほどメモリを酷使するのだから、アドレス
変換を実装する機構は極度に効率的でなければならず、さもないと変換がボトルネックになっ
てしまう。アーキテクトが主に関心を持つのは、MMU が仮想アドレスを物理アドレスに変換
するのに、どれだけ時間を使うかだ。OS がページテーブルを構成するのに必要とする時間に
は、それほど関心がない。
デマンドページングシステムの性能を最適化するテクニックには、飛び抜けて重要なものが
1 つある。そのテクニックは、
「トランスレーションルックアサイドバッファ」
、略して「TLB」
（Translation Lookaside Buﬀer）8と呼ばれる特殊な高速ハードウェアを使って、ページテーブ
ルのルックアップを高速に行うものだ。TLB はCAM の一種で、そこにはページテーブルで最
近使われた値が格納される。MMU は、あるアドレスを最初に変換するとき、そのページテー
ブルエントリのコピーをTLB に置く。その後のルックアップで、ハードウェアは2 つの処理を
並行して実行する。1 つは図13‒9 に示した通常のアドレス変換ステップにしたがうもの、も
う1 つはTLB の高速サーチだ。もし要求された情報がTLB で見つかれば、MMU は標準の変
換を中止して、TLB から得た情報を使う。もしエントリがTLB になければ、標準の変換処理
を続行する。
なぜTLB で性能が向上するのかを理解するために、
「フェッチ‒ 実行」サイクルについて考
えよう。プロセッサは、メモリの連続する場所から命令をフェッチする傾向がある。たとえプ
ログラムに分岐が含まれていても、その飛び先は近くにあり、同じページに存在する確率が極
めて高い。したがって、プロセッサは、ページをランダムにアクセスするより、同じページで
連続する命令をフェッチすることが多いのだ。TLB が性能を向上させるのは、ページテーブル
に対するインデックス参照を避けて、連続的なルックアップを最適化するからだ。性能の違い
が、とくに劇的に表れるのは、ページテーブルをメモリに格納するアーキテクチャである。そ
のようなシステムは、TLB がなければ遅すぎて使いものにならない。
ページングシステムの性能を最適化するため、TLB（トランスレーションルックアサイ
ドバッファ）と呼ばれる特殊な高速ハードウェアデバイスが使われる。TLB を持たない
仮想メモリは、耐えがたいほど遅い場合もある。
8　訳注：ルックアサイドというのは、サーチを高速化するためにデータ本体とは別の場所に置かれた計算
済みのキャッシュを見ることを意味する。TLB は、
「アドレス変換キャッシュ」とも呼ばれる。
hi.0412.ko.2002@gmail.com
　13.24
プログラマにおよぼす影響
261
13.24 　プログラマにおよぼす影響
経験によれば、デマンドページングは、ほとんどのコンピュータシステムで良好に働く。プ
ログラマが書くコードは、それぞれ1 個のページに収まるような機能で構成される傾向がある。
同じように、たとえば文字列のようなデータオブジェクトも、データが連続するメモリの場所
を占めるように設計されるので、いったんロードしたページは、メモリに存在している間に何
度も参照されることが多い。そして最後に、コンパイラがページングを理解して、データ項目
をページに収めることで性能を最適化してくれるかもしれない。
プログラミングが仮想メモリの性能に影響を与えるケースとしては、たとえば配列のアクセ
スがある。メモリに2 次元の配列があると考えよう。ほとんどのプログラミングシステムは、
配列を「行優先の順序」でメモリに割り当てる。つまり、図13‒11 のように、配列の各行が連
続するメモリに置かれる。
行0 
行1 
行2 
行3 
行4 
行5
行N
図13‒11：2 次元配列を、行優先の順序で格納する場合、それぞれの行は、メモリで連続している
この図でわかるように、行列の行はメモリで連続する位置を占める。したがって、もしA が
バイトの2 次元配列ならば、A[i,j] の位置は、次の計算で得られる。
A の位置+ i × Q + j
ここでQ は、1 行のバイト数だ。
行優先の順序に代わるものとして、
「列優先の順序」がある。配列を列優先の順序で格納する
とき、列の要素が連続したメモリを占める。行優先と列優先の、どちらを選ぶかは、通常はプ
ログラミング言語とコンパイラによって決まる（プログラマが決めるのではない）
。
しかしプログラマは、プログラムで配列を反復処理する方法を制御できる。そして、良い方
法を選べば仮想メモリの性能を最適化できる。たとえば大きな文字列配列、A[N,M] が、行優
先の順序で格納されるとき、次のようにネストしたループを書けば、
for i = 1 to N {
// 行インデックス
for j = 1 to M {
// 列インデックス
A[i,j] = 0;
}
}
2 つのインデックスを逆の順序で変化させる次のループを実行するより、必要な時間が短く
なるだろう。
hi.0412.ko.2002@gmail.com
262
第13 章
仮想メモリ技術と仮想アドレッシング　
for j = 1 to M {
// 列インデックス
for i = 1 to N {
// 行インデックス
A[i,j] = 0;
}
}
実行時間に違いが現れる理由は、行インデックスを変化させると、仮想メモリシステムは参
照を行うたびに別のページのメモリへの移動を強制されるが、列インデックスを変化させるの
なら、M 個の連続する参照が同じページに留まるからだ。
13.25 　仮想メモリとキャッシングの関係
仮想メモリシステムの主要なテクノロジーのうち2 つは、キャッシングに関係がある。そ
れはTLB と、デマンドページの置換だ。前述したようにTLB は、小さくて高速なハードウェ
ア機構を使って、デマンドページングシステムの性能を劇的に改善するものだ。実際TLB は、
アドレスマッピングのキャッシュに他ならない。MMU はページテーブルをルックアップする
たびに、そのエントリをTLB に保存する。その後、同じページをルックアップするときには、
TLB から答えが得られる。
多くのキャッシュシステムと同じく、TLB も普通はLRU（Least Recently Used）置換を使
う。アイデアとしては、あるエントリが参照されたら、TLB は、そのエントリをリストの先頭
に置く。そして新しい参照が発生したときキャッシュが満杯になっていたら、TLB はリストの
末尾にあるページテーブルエントリを破棄して、新しいエントリを入れる空間を作る。もちろ
んTLB では、メモリ上に連結リストを管理するなど論外である。代わりにTLB は、特殊用途
の「CAM」に値を高速で移動させるデジタル回路を含んでいる。
デマンドページングは、一種のキャッシングとみなすことができる。そのキャッシュはメイ
ンメモリに対応し、そのデータストアは、ページが必要になるまで保存しておく外部ストレー
ジに対応する。さらに、ページ置換のポリシーは、キャッシュ置換のポリシーの役割に対応す
る。実際、ページング用語の「置換ポリシー」は、キャッシング用語からの借用だ。
デマンドページングをキャッシュとして考えると、ある重要なコンセプトを理解するのに役
立つ。それは仮想アドレス空間を、物理メモリより、ずっと大きくできるのはなぜか、という
ことだ。キャッシュと同じく、物理メモリに格納できるのは、全部のページの一部にすぎない。
キャッシングを分析した結果、われわれは、デマンドページングの仮想メモリでも、物理メモ
リのそれに近い性能を得られることを知っている。
キャッシングに関するこれまでの章で分析したように、少量の物理メモリを持つコン
ピュータシステムでデマンドページングを使うと、仮想アドレス空間のすべてを格納で
きるほど大きな物理メモリを持つコンピュータと、ほとんど同程度の性能が得られる。
hi.0412.ko.2002@gmail.com
　13.26
仮想メモリのキャッシングとキャッシュフラッシュ
263
13.26 　仮想メモリのキャッシングとキャッシュフラッシュ
仮想メモリでキャッシュを使うのなら、そのキャッシュはプロセッサとMMU の間に置くべ
きだろうか、それとも、MMU とメモリの間に置くべきだろうか。つまり、メモリキャッシュに
は仮想アドレスと内容のペアを格納すべきなのか、それとも、物理アドレスと内容のペアを格
納すべきなのか。その答えは単純ではない。キャッシュに仮想アドレスを使えば、メモリアク
セスの速度が上がる。なぜなら、MMU が仮想アドレスを物理アドレスに変換する前にキャッ
シュが応答できるからだ。その一方で、仮想アドレスを使うキャッシュには、仮想メモリシス
テムとの相互作用を行うハードウェアが必要になる。その理由を理解するために、仮想メモリ
システムが、普通は実行されるアプリケーションのそれぞれに同じ範囲のアドレスを供給する
ことを考えよう（つまり、どのプロセスも0 から始まるアドレスを持つ）
。そして、OS がコ
ンテクスト切り替えを実行して、あるプロセスの実行を停止し、もう1 つのプロセスを実行さ
せたら、何が起きるかを考えよう。コンテクスト切換の前に、メモリキャッシュにはアドレス
2000 のためのエントリが入っていたとする。もしキャッシュがコンテクスト切換後も変化し
ないのなら、新しいプロセスが2000 の位置をアクセスすると、キャッシュは古いプロセスで
2000 の位置にあった値を返すことになってしまう。したがって、OS がプロセスを切り替える
ときには、キャッシュ内の項目も切り替える必要がある。
複数のプロセスが同じ範囲のアドレスを使うときに生じる多義性の問題を回避する手段を、
キャッシュのテクノロジーに組み込むことは可能だろうか。アーキテクトたちは、次の2 つの
ソリューションを使う。
•
キャッシュをフラッシュする
•
多義性を解決する識別子を使う
キャッシュのフラッシュ
キャッシュが正しくない値を決して報告しないようにする方法の1 つは、キャッシュから既
存のエントリをすべて削除することだ。それが、キャッシュの「フラッシュ」である。フラッ
シュを使うアーキテクチャでは、OS がコンテクスト切り替えを行って、あるアプリケーション
から別のアプリケーションに移行する際は、いつでもキャッシュをフラッシュする必要がある。
多義性の解決
キャッシュのフラッシュに代わる、もう1 つの方式は、実行中のプロセス（もっと正確に言
えば、そのアドレス空間）を識別するために、追加のビット群を使うことだ。プロセッサには、
アドレス空間のID を格納するハードウェアレジスタを追加する。多くのOS は、それぞれのプ
ロセスに対応するアドレス空間を作るとき、プロセスID（整数値）を使って、それらのアドレ
ス空間を識別する。そしてアプリケーションを切り替えるときは、必ず新しいアプリケーショ
hi.0412.ko.2002@gmail.com
264
第13 章
仮想メモリ技術と仮想アドレッシング　
ンのプロセスID を、アドレス空間ID レジスタにロードする。図13‒12 に示すように、キャッ
シュに要素を格納するときは、そのときのID レジスタの内容を、仮想アドレスの先頭に付加
する。つまり、たとえプロセス1 とプロセス2 が、どちらも同じアドレス0 を参照しても、そ
の2 つのキャッシュ内エントリは、異なる値を持つ。
キャ
ッ
シュで使うア
ドレス
仮想ア
ドレス
ID
図13‒12：複数の仮想アドレス空間で多義性を解消するために、ID レジスタを使う方法。どのアドレス空
間にもユニークな番号が割り当てられ、OS は、その値をID レジスタにロードする
図が示すように、このキャッシュはメモリシステムより長いアドレスを使うように設計され
ている。要求をキャッシュに渡す前に、プロセッサは仮想アドレスをプロセスID に繋げて合成
した長いアドレスを作り、それをキャッシュに渡す。キャッシュで見る限り、もう多義性はな
い。たとえ2 つのアプリケーションが同じ仮想アドレスを参照しても、ID のビット群によっ
て、2 つのアドレスが区別される。
13.27 　まとめ
仮想メモリシステムは、プロセッサと、そのプロセッサで実行されているアプリケーション
プログラムのそれぞれに、抽象的なアドレス空間を提供する。仮想メモリシステムは、根底に
ある物理メモリの詳細を隠す。
仮想メモリを実現するアーキテクチャは、
いくつか考えられる。仮想メモリシステムは、
ワー
ドアドレッシングの詳細を隠すこともできるし、複数のメモリテクノロジーを（たとえ種類が
異なっても）組み込んで、均一なアドレス空間を作ることもできる。
仮想メモリはプログラマにとって便利なマルチプログラミングのサポートやプロテクション
を提供する。複数のプログラムを同時に実行するとき、仮想メモリを使えば、それぞれのプロ
グラムに0 から始まるアドレス空間を提供できる。
仮想メモリのテクノロジーには、ベースと境界、セグメンテーション、デマンドページング
が含まれる。そのうちもっとも一般的なデマンドページングのシステムは、ページテーブルを
使って仮想アドレスを物理アドレスに変換する。ページテーブルのルックアップを効率よく行
うため、TLB と呼ばれる高速サーチ機構が使われる。
算術演算を避けるため、仮想メモリシステムは、物理メモリとページのサイズを2 の冪乗に
する。これによってハードウェアは、コストの高い演算を使わずにアドレスを変換できる。
hi.0412.ko.2002@gmail.com
　13.27
まとめ
265
物理アドレスも仮想アドレスも、キャッシュすることが可能だ。ただしキャッシュに仮想ア
ドレスを使うと、複数のアプリケーション（プロセス）が同じ仮想アドレスの範囲を使うこと
で多義性の問題が生じる。その問題を解決するには、2 つのテクニックを使える。OS で、ある
アプリケーションから別のアプリケーションへと切り替えるときに、キャッシュをフラッシュ
できる。あるいは、キャッシュのハードウェアを、長いアドレスを使うように設計する方法も
ある。長いアドレスは、アドレスの上位にアドレス空間のID（典型的にはプロセスID）を繋
げて合成する。
練習問題
13.1
コンピュータが、図13‒2 に示した仮想アドレス空間を使っているとします。C の
プログラムで、
char c;
char *p;
p = (char *)1073741826;
c = *p;
と書いたら、どちらのメモリモジュールが参照されますか? そして、そのモジュール
で参照されるバイトは、メモリ内のどの位置にありますか?
13.2
かつてのインテルPC には、メモリアドレス空間の「穴」が、640 キロバイトと1
メガバイトの間にありました。図13‒4 を例として、2 メガバイトのメモリを持つPC
のアドレス空間と穴を、図を描いて示してください。
13.3
仮想メモリの4 つの動機のうち、プログラマにとって便利なのは、どれですか。説
明も付けてください。
13.4
デマンドページングには、特殊なハードウェアか、特殊なハードウェアが必要です
か? 説明も付けてください。
13.5
ページテーブルが、配列の一種だとすれば、ページテーブル配列の、それぞれの要
素は何ですか。それを、どのように解釈しますか?
13.6
存在と利用と変更のビットについて考えます。それぞれのビットは、いつ変更され
ますか? また、変更するのはハードウェアと、ソフトウェアの、どちらですか?
13.7
ページサイズが4K バイトと想定して、アドレス100、1500、8800、10000 のペー
ジ番号とオフセットを計算してみましょう。
13.8
ページサイズとアドレスという2 つの入力値を受け取り、そのアドレスのページ番
号とオフセットを計算する、コンピュータプログラムを書きましょう。
13.9
上の課題の拡張です。ページサイズが2 の冪乗ならば、除算や剰余を使わずに答え
を計算するように書き直しましょう。
hi.0412.ko.2002@gmail.com
266
第13 章
仮想メモリ技術と仮想アドレッシング　
13.10
サンプルのページテーブルを格納するのに必要なメモリの量は? ページテーブルの
エントリは32 ビット、ページサイズは4K バイト、1 個のメモリアドレスは32 ビッ
トを占めます。
13.11
ページサイズとアドレス空間のサイズを入力として受け取って、上の問題と同じ
計算を行うコンピュータプログラムを書きましょう（サイズを2 の冪乗だけに制限し
てもかまいません）
。
13.12
ページ置換とは何ですか? それを行うのはハードウェアとソフトウェアの、どち
らですか?
13.13
2 段階のページング機構を考えます。アドレスの上位10 ビットは、ページテー
ブルを選択する「ディレクトリテーブル」へのインデックスとして使います。ページ
テーブルには、それぞれ1024 個のエントリが含まれます。そして、アドレスの次の
10 ビットは、ページテーブルエントリの選択に使います。アドレスの最後の12 ビッ
トは、ページ内の1 バイトを選択するのに使います。ディレクトリテーブルと、すべ
てのページテーブルを合計すると、どれだけのメモリが必要ですか?
13.14
TLB とは何ですか? なぜ必要なのですか?
13.15
行優先で格納される大きな2 次元配列にある、すべての場所を参照するプログラ
ムを書いてみましょう。2 つの書き方について、プログラムの実行時間を計測し、比
較します。片方は、すべての行を巡るループのなかで、それぞれの列に触れます。も
う片方は、すべての列を巡るループのなかで、それぞれの行に触れます。比較の結果
を説明してください。
13.16
メモリシステムが仮想アドレスをキャッシュし、どのプロセスもアドレス空間が
0 から始まるとしたら、OS はプロセスを切り替えるときに、何をする必要があります
か? その理由は?
hi.0412.ko.2002@gmail.com
第4部
入出力
外部接続とデータの動き
hi.0412.ko.2002@gmail.com
hi.0412.ko.2002@gmail.com
第14 章
入出力の概念と用語
14.1 　はじめに
コンピュータシステムを構成する主なコンポーネントのうち、これまでの章ではプロセッサ
とメモリの2 つについて述べた。個々のコンポーネントで使われるテクノロジーを記述するだ
けでなく、プロセッサとメモリの相互作用についても説明した。
この章では、アーキテクチャの主な側面の3 つめとして、コンピュータと外の世界との接続
を紹介する。これから学ぶように、プロセッサと入出力機器（I/O デバイス）との接続に使わ
れる基本的なパラダイムは、ほとんどのコンピュータにおいて、プロセッサとメモリの接続に
使われるのと同じものだ。しかも入出力機器は、プロセッサの制御のもとで動くだけでなく、
メモリと直接やりとりすることもある。
14.2 　入出力機器
もっとも古い電子式コンピュータ（電子計算機）は、数値計算のプロセッサとメモリで構成
されていて、現代のコンピュータに似ているよりも、むしろ電卓に似ていた。ヒューマンイン
ターフェイスは未熟だった。数値は一連のスイッチを手で操作して入力し、計算の結果は一連
の電球の光で表示された。1940 年代の終わり頃には、より良いインターフェイスの必要性が明
白になった。そうすれば基本的な計算以外の用途にも、デジタルコンピュータを使える。技術
者たちは、コンピュータを外部の機器と接続する方法を考えた。それらの外部機器は、
「入出力
機器」
、あるいはI/O デバイスと呼ばれるようになった。現代のI/O デバイスには、キーボー
ド、マウス、モニタ、センサー、ハードディスク、DVD ドライブ、プリンタの他、カメラ、イ
ヤホン、マイクなども含まれる。
hi.0412.ko.2002@gmail.com
270
第14 章
入出力の概念と用語　
14.3 　外部機器の制御
コンピュータに接続されたもっとも初期の機器は、CPU の制御下で動作する独立ユニットで
構成されていた。つまり、たいがいの機器は別の筐体に入っていて、電源も別に供給され、内
部の回路がコンピュータから切り離されていた。コンピュータと外部機器を繋ぐのは数本のワ
イヤで、制御信号だけを伝えていた（つまり、コンピュータのデジタルロジックから外部機器
のデジタルロジックに向かう信号だ）
。外部機器の中にある回路は、その制御信号を監視し、そ
れにしたがって機器の振る舞いを変えていた。
初期のコンピュータは、値を表示する一連のライトが付いていることが多かった。そこに表
示されるのは、コンピュータのアキュムレータの値、というのが典型的で、1 ビットの値が1
個のライトで表現された。ビットが1 ならばライトが点灯し、ビットが0 ならば消灯する。し
かし、電球をアキュミュレータの回路に直接繋ぐことは不可能だ。たとえ豆電球でも点灯する
には、デジタル回路で供給できるよりも、ずっと多くの電力が必要だ。したがって表示ユニッ
トには、デジタルロジックから受け取る一群の信号にしたがって一連の電球を制御する回路が
入っていた。図14‒1 に、そのハードウェア構成を示す。
デジタル信号
外部機器
回路
電気信号
ライ
ト
プロセッサ
電源
図14‒1：一連のライトを制御する外部回路の例。このデバイスには、デジタル回路から受け取った信号を、
電球を点滅させるのに必要な信号に変換する回路が含まれていた
この図が示すように、外部機器は、プロセッサとの間でデジタル信号が渡されるのを除けば、
概念としてプロセッサから独立している。もちろん実際には、プロセッサと同じ筐体に格納さ
れ、電源も共通なデバイスも存在する。しかし、そういう詳細は無視して、話題を制御信号に
絞ろう。
コンピュータがデバイスと相互作用を行うには、2 つの方法がある。コンピュータがデバイ
スを制御する場合と、コンピュータとデバイスがデータを交換する場合だ。前者の例としてプ
ロセッサは、ディスクの回転を開始したり、外部スピーカーの音量を調節したり、カメラに撮
影を命じたり、プリンタをOFF にしたりする。コンピュータが外部デバイスに制御の情報を
渡す方法は、次の章で学ぼう。
hi.0412.ko.2002@gmail.com
　14.4
データ転送
271
14.4 　データ転送
外部機器の制御は不可欠だが、ほとんどのデバイスにとって制御は2 次的な機能である。外
部デバイスの主たる機能は「データ転送」なのだ。実際、外部デバイスをめぐってアーキテク
トが下す判断は、デバイスとプロセッサの間でデータ交換を可能にする機構に重点が置かれて
いる。
データ転送に関して、いくつか疑問があるはずだ。第1 に、いったいどうやってデータを通
信するのか。第2 に、どちら側が転送を始動するのか（つまり、転送要求を出すのは、プロセッ
サか、それともデバイスか）
。第3 に、データを高速に転送するには、どんなテクニックと機
構が必要なのか。
その他の疑問は低いレベルの詳細に関するもので、プログラマとは、あまり関係がない。外
部デバイスとの通信に使われる電圧は何ボルトで、どのようにデータを表現するのか? その答
えは、デバイスの種類や、データ転送に要求される速度や、使用するケーブルの種類や、プロ
セッサとデバイスの間の距離に依存する。いずれにしても、図14‒1 に示したように、プロセッ
サが内部的に使うデジタル信号では、外部デバイスの回路を駆動することができない。
外部接続に使われる電圧と符号の体系は、内部で使われるものと異なるので、その2 つの
表現を変換するための特別なハードウェアが必要だ。外部デバイスへのインターフェイスを提
供するハードウェアを、われわれは「インターフェイスコントローラ」という用語で呼ぶ。図
14‒2 は、物理的な接続の両端にインターフェイスコントローラが必要なことを示している。
プロセッサ
デバイス
外部接続
コン
トローラ
コン
トローラ
図14‒2：外部接続の両端にコントローラのハードウェアがあるので、外部接続に使う電圧と信号が、内部で
使っている電圧等と違っていてもかまわない
14.5 　シリアルとパラレルのデータ転送
コンピュータのI/O インターフェイスは、どれも2 つの広いカテゴリーに分類できる。
•
パラレルインターフェイス
•
シリアルインターフェイス
hi.0412.ko.2002@gmail.com
272
第14 章
入出力の概念と用語　
パラレルインターフェイス
コンピュータと外部デバイスを繋ぐインターフェイスが「パラレル」に分類されるのは、そ
のインターフェイスで複数のデータビットを同時に転送できる場合である。要するに、パラレ
ルインターフェイスには複数の信号線が含まれ、どの瞬間も、それぞれの線が1 ビットのデー
タを運んでいる。
インターフェイスで使うパラレル線の本数を、われわれは「インターフェイス幅」と呼ぶ。技
術者の会話で、
「8bit インターフェイス」とか「16bit インターフェイス」とかいうのが、それ
だ。インターフェイスが、どうやってパラレルな信号線を使うのかは、次の章で学ぶ。
シリアルインターフェイス
パラレルインターフェイスに代わる選択肢で、どの瞬間も1 ビットのデータしか転送できな
い。一度に1 ビットだけ転送するインターフェイスは、どれも「シリアル」に分類される。
シリアルインターフェイスの利点は、ワイヤの本数が少なく、同時に転送される信号からの干
渉が少ないという点だ。原理的に、シリアルデータの転送に必要な線は2 本だけで、1 本は信
号を運び、もう1 本は電圧をかけるためのグランドの役割を果たす。シリアルインターフェイ
スの主な欠点は、レイテンシが大きいことから生じる。複数のビットを送信するとき、シリア
ルのハードウェアは、1 ビットの送信が終わるまで次のビットの送信を待たなければならない。
14.6 　セルフクロッキング式のデータ
デジタル回路はクロックを基準として動作する。クロックは継続してパルスを出す信号だ。
入出力で、とくにクロックが重要なのは、個々のI/O デバイスとプロセッサが、独自のクロッ
ク周期を持つことがあるからだ（つまり、それぞれのコントローラが独自のクロックを持つこ
とができる）
。したがって、外部インターフェイスでもっとも大きな関心事の1 つは、クロッ
ク周期の違いをインターフェイスで、どのように調停するかである。
「セルフクロッキング」という用語は、インターフェイスを超えて送られる信号に「送信側が
データを符号化した方法を受信側が正確に判定できる情報」が含まれる機構に使われる。たと
えば、ある種の外部装置は、第2 章で述べたクロックレスロジックの機構1と同様な方法を使
う。別の方法では、クロック情報を渡すために、別に追加した線を使う。データを送るとき送
信側は追加の線を使って、データのなかでビットの境界がどこにあるかを、受信側に知らせる。
1　クロックレスロジックは、2.25 節で説明した。
hi.0412.ko.2002@gmail.com
　14.7
全二重と半二重の交信
273
14.7 　全二重と半二重の交信
多くの外部I/O デバイスは「双方向転送」を提供する。これは、プロセッサがデバイスに
データを送ることも、デバイスがプロセッサにデータを送ることもできる、という意味だ。た
とえばディスクドライブは、リードとライトの両方の動作をサポートする。インターフェイス
のハードウェアで双方向転送を可能にする方法は、次の2 つがある。
•
全二重交信
•
半二重交信
全二重交信
双方向の転送を同時に進行させることが可能なインターフェイスは、
「全二重」インターフェ
イスと呼ばれる。基本的に、全二重のハードウェアは、2 個の並列する装置で構成され、互い
に独立した2 セットの配線で接続される。両方向のデータ送信に、それぞれ1 セットの配線が
使われる。
半二重交信
全二重に代わる選択肢は「半二重」インターフェイスと呼ばれ、転送は同時に一方向にしか
進行できない。つまり、プロセッサと外部デバイスを繋ぐ配線は1 セットだけで、それが共有
される。共有するには、次の章で学ぶように、ネゴシエーション（折衝）が必要だ。つまりプ
ロセッサもデバイスも、自分が転送を行う前に、現在の転送が終わるのを待ってから、通信線
を利用する権利を取得しなければならない。
14.8 　インターフェイスのスループットとレイテンシ
インターフェイスの「スループット」
（転送能力）は、単位時間内に転送できるビット数で表
され、通常は「毎秒メガビット」
（Mbps）または毎秒メガバイト（MBps）で計測される。シリ
アル通信では同時に1 ビットしか転送できないのだから、同時に複数のビットを転送できるパ
ラレルインターフェイスよりも、シリアルインターフェイスのほうが、常にスループットが低
いだろうと思われるかもしれない。けれども、パラレルのワイヤが近接していると、電磁的な
干渉を避けるためにデータレートを制限する必要が生じる。このため場合によってはシリアル
インターフェイスでも、パラレルインターフェイスより高いスループットでビット群を転送で
きることが実証されている。
インターフェイスを測定する第2 の基準は「レイテンシ」である。レイテンシは、あるビッ
トを送信してから、そのビットを受信するまでの遅延である（つまり、1 ビットを転送するの
にかかる時間だ）
。これは通常、ナノセカンド（ns）で計測される。メモリについても同じこと
を言えるのだが、レイテンシとスループットの違いに注意しなければならない。なぜなら、あ
hi.0412.ko.2002@gmail.com
274
第14 章
入出力の概念と用語　
るデバイスは「低いレイテンシ」を必要とし、他のデバイスは「高いスループット」を必要と
するからだ。
要点をまとめておこう。
インターフェイスのレイテンシは、転送に必要な時間を測る。インターフェイスのス
ループットは、単位時間内に転送できるデータの量を測る。
14.9 　多重化の基礎
インターフェイスの選択など、簡単だと思われるかもしれない。全二重で、レイテンシが低
く、スループットが高いのを選べばよいではないか。たしかに高性能は望ましいが、他にも多
くの要素があるからインターフェイスの選択は複雑なのだ。たとえば、どの集積回路にも、決
められた本数のピンがあり、それによって外部接続を行う。インターフェイスの幅を広くする
には、より多くのピンを使う必要があるから、他の機能に使えるピンが少なくなってしまう。
全二重の能力を提供するインターフェイスは、半二重の能力を提供するインターフェイスの、
およそ2 倍のピンを使う。
ほとんどのアーキテクトは、外部接続に、ある折衷案を使う。その接続は、いわば「制限付き
のパラレル」であって、そのハードウェアはデータを送るのに「多重化」と呼ばれるテクニッ
クを使う。詳細は複雑だが、多重化のコンセプトは理解しやすい。つまり、大きなデータ転送
をハードウェアで細分化して、一度に1 片ずつ送ろう、という考えだ。データの多重化を扱う
ハードウェアは、
「マルチプレクサ」
、
「デマルチプレクサ」と呼ばれる。たとえば図14‒3 は、
転送したい64ビッ
トのデータ
チャンク 1 
チャンク 2 
チャンク 3 
チャンク 4
多重化を行うハー
ドウェア
(マルチプレクサ)
多重化を復元するハー
ドウェア
(デマルチプレクサ)
16ビッ
ト幅の
パラレルインターフェイス
転送後に編成し直したデータ
チャンク 1 
チャンク 2 
チャンク 3 
チャンク 4
図14‒3：64 ビットのデータを16 ビットのインターフェイスで転送する。多重化を行うハードウェアが、
データを16 ビット単位に分割し、1 単位ずつ送信する
hi.0412.ko.2002@gmail.com
　14.10
外部インターフェイス毎に複数の機器を繋ぐ
275
多重化を行うハードウェアが、64 ビットのデータを16 ビットの「チャンク」
（塊）に分け、16
ビット幅のインターフェイスでチャンクを送信する方法を示している。一度に送信できるチャ
ンクは、1 個だけだ。
実際に、プロセッサと外部デバイスを結ぶ接続の多くが、多重化を使っている。そうするこ
とによってプロセッサは、任意の量のデータを、接続用のピン数を増やすことなく転送できる
のだ。次の章では、CPU の性能を多重化によって向上させる方法を学ぶ。
多重化は、固定された本数のパラレルなワイヤを使って、任意の量のデータを転送でき
るI/O インターフェイスの構築に使われる。多重化を行うハードウェアは、データをブ
ロックに分割し、それぞれのブロックを独立した状態で転送する。
われわれの定義は、シリアル通信にも同様にあてはまる。シリアルインターフェイスは、1
本のワイヤで多重化転送を行うと解釈できるのだ。したがって、シリアルインターフェイスの
チャンクは1 ビットの大きさである。
14.10 　外部インターフェイス毎に複数の機器を繋ぐ
この章で示したサンプルには、プロセッサからの外部接続のそれぞれに1 個のデバイスを繋
げるという暗黙の前提があった。しかしピン数と外部接続を節約するために、ほとんどのプロ
セッサは、外部接続の相手を1 個のデバイスに限定しない。代わりに、1 セットのピンが複数
のデバイスに接続され、いつでもプロセッサが、それら複数のデバイスのどれかと通信できる
ように、ハードウェアが構成される。この概念は、次の章で詳しく例をあげて説明しよう。
14.11 　プロセッサから見た入出力
前述したように、外部接続にはインターフェイスコントローラのハードウェアが付き物だ。
このため、プロセッサが外部デバイスと相互作用を行うときは、コントローラ経由で行う必要
がある。プロセッサはコントローラに要求を出して、その応答を受け取る。コントローラは、
それぞれの要求を、適切な外部信号に変換し、その信号によって、要求された機能が外部デバ
イスで実行される。プロセッサが対話処理を行う相手はインターフェイスであって、外部デバ
イスではない、というのが重要なポイントだ。
このアーキテクチャのコンセプトを、われわれは、コントローラがプロセッサに「プログラ
ミングインターフェイス」を提供する、と表現する。おもしろいことに、そのプログラミング
インターフェイスには、根底にあるデバイスが行う処理を正確に反映する必要がない。幅広く
使われているプログラミングインターフェイスの1 つは、次の章で見るように、すべての外部
的なやりとりを、1 つの単純化されたパラダイムに集約する。
プロセッサはインターフェイスコントローラのハードウェアを使って、デバイスとのや
りとりを行う。コントローラは、プロセッサからの要求を、適切な外部信号に変換する。
hi.0412.ko.2002@gmail.com
276
第14 章
入出力の概念と用語　
14.12 　まとめ
コンピュータシステムは、外部デバイスとの相互処理で、そのデバイスを（たとえば状態を
変えるために）制御するか、あるいはデータの転送を行う。外部インターフェイスには、シリ
アルかパラレルのアプローチを使える。同時に送信できるビット数を、パラレルインターフェ
イスの「幅」と言う。双方向インターフェイスでは、全二重または半二重の交信を使える。
インターフェイスを計測するには2 つの尺度がある。レイテンシは、所与のソースから所与
のデスティネーションに（たとえばメモリからプリンタに）1 ビットを送るのに要する時間で
あり、スループットは、単位時間ごとに送信できるビット数のことである。
ピン数が限られているので、プロセッサは任意の幅の外部接続を持つことができない。その
代わりに、インターフェイスのハードウェアが、大きなデータを少数のピンで転送する多重化
を行うように設計される。さらに、1 本の外部接続に複数の外部デバイスを繋げることが可能
である。インターフェイスコントローラは、それぞれのデバイスと個別に通信する。
練習問題
14.1
スマートフォンやノートPC のスピーカーは、実際にはアナログデバイスの一種で、
音量は提供される電圧に対応して大きくなります。ということは、
プロセッサに、
オー
ディオ用のアナログ出力も必要なのでしょうか。説明してください。
14.2
外部デバイスの主な機能と2 次的な機能は何ですか?
14.3
3.3V のデジタル信号で動作するデバイスを、5V のデジタル信号で動作するプロ
セッサに、接続することは可能ですか? 説明してください。
14.4
もしインターフェイスの幅が16 ならば、そのインターフェイスは、パラレルとシ
リアルの、どちらですか?
14.5
USB はシリアルインターフェイスに分類されますが、その分類は何を意味するので
すか?
14.6
あなたがネットワークI/O デバイスを買おうとしたら、同じベンダーに半二重と全
二重のインターフェイスがありました。どちらを選びますか? その理由は?
14.7
プロセッサとストレージデバイスの間のインターフェイスが32 ビット幅だとした
ら、プロセッサは64 ビットで構成されるデータを、どうやって転送しますか?
14.8
セルフクロッキング式で、片側からもう片側にデータを送ることのできるパラレル
インターフェイスを作るには、どうしますか?
ヒント：通信の両側が協調できるようにするワイヤが2 本あり、それとは別にデータ
転送用のワイヤがあります。
14.9
あるシリアルインターフェイスのレイテンシが200 マイクロ秒だとします。そのイ
ンターフェイスで1 ビットを転送するのに、どれだけ時間がかかりますか? また、そ
hi.0412.ko.2002@gmail.com
　14.12
まとめ
277
のインターフェイスで64 ビットを転送するのに、どれだけ時間がかかりますか?
14.10
あるパラレルインターフェイスは、幅が32 ビットで、レイテンシが200 マイク
ロ秒だとします。そのインターフェイスで32 ビットを転送するのに、どれだけ時間
がかかりますか? また、そのインターフェイスで64 ビットを転送するのに、どれだ
け時間がかかりますか? 詳しく説明してください。
hi.0412.ko.2002@gmail.com
hi.0412.ko.2002@gmail.com
第15 章
バスとバスアーキテクチャ
15.1 　はじめに
メモリに関する各章では、プロセッサとメモリシステムの間の外部接続を論じた。そして前
章では、
外部I/O デバイスとの接続を論じ、
プロセッサがデバイスを制御しデータを転送するの
に、その接続をどう使うかを示した。シリアルおよびパラレルの転送といった概念を明らかに
して用語を定義するほか、1 セットの配線で行うデータ転送の多重化という考え方も紹介した。
この章では、
その考え方を拡張して、
あらゆるコンピュータシステムに存在する基本的なアー
キテクチャの機能、すなわち「バス」を説明する。ここではバスを使う動機を述べ、その基本
的な動作を説明し、メモリとI/O デバイスでバスを共有する方法を示す。バスによってアドレ
ス空間が定義されることを知り、バスのアドレス空間とメモリのアドレス空間との関係を理解
しよう。
15.2 　バスの定義
「バス」は、2 つ以上の機能ユニットが制御信号やデータを転送できるようにするデジタル
通信機構だ。ほとんどのバスはコンピュータシステムの内部で使うように設計されるが、集積
回路の内部で使われるバスもある。バスは特定の用途に最適化できるので、さまざまな設計が
存在する。たとえば「メモリバス」は、プロセッサとメモリシステムの相互接続を目的とし、
「I/O バス」は、プロセッサと一群のI/O デバイスとの相互接続を目的とする。そして汎用的な
設計も可能である。それらを見ていこう。
hi.0412.ko.2002@gmail.com
280
第15 章
バスとバスアーキテクチャ　
15.3 　プロセッサとI/O デバイスとバス
バスは広大な概念で、ほとんどの外部接続を包括する（プロセッサとコプロセッサとの間の
接続もバスに含まれる）
。たとえばプロセッサとデバイスとの間の接続を前章では「1 セットの
配線」と表現していたが、
「2 つのユニットがバスで相互接続されている」と考えれば、概念が
明確になる。バスの概念を示すのに技術資料で一般に使われる図の描き方を、図15‒1 に示す。
プロセッサ
デバイス
バス
図15‒1：プロセッサと外部デバイスの接続にバスが使われている。バスは、ほとんどの外部接続に使われる
バスは、コンピュータシステムの機能ユニットを相互接続するデジタル通信機構である。
コンピュータには1 個以上のバスが含まれ、それを使ってプロセッサ、メモリ、外部I/O
デバイスが相互接続される。
15.3.1
バスの独自設計と標準化
バスの設計が私営の企業に占有され、他の会社が使えないとき（つまり特許で守られている
とき）
、そのバスは「独自設計」だと言われる。独自設計に代わる選択肢として、
「標準化され
たバス」がある。こちらは仕様書を入手できる。バスを標準化すれば、複数のベンダーによる
製品が、通信して相互作用を行えるようになる。だから標準化されたバスを持つコンピュータ
システムには、複数のベンダーから供給されたデバイスを組み込むことが可能だ。もちろんバ
スの標準規格では、ハードウェアの構築に必要なすべての詳細を指定しなければならない。そ
れには正確な電気的仕様（電圧など）
、信号のタイミング、データを符号化する方法なども含ま
れる。さらに、そのバスに接続される個々のデバイスも、正しく動作させるために、バスの標
準規格を厳密に実装しなければならない。
15.3.2
共通バスとアクセスプロトコル
バスはプロセッサと1 個のI/O デバイスを接続するのに使えるが、実際には、ほとんどのバ
スが「共有される」
。つまり共通のバスが、プロセッサをI/O デバイスの集合に接続するため
に使われる。同様に、もしコンピュータに複数のプロセッサが含まれていたら、すべてのプロ
セッサを共通のバスに接続できる。
共有を可能にするために、アーキテクトは、そのバスで使うべき「アクセスプロトコル」を
hi.0412.ko.2002@gmail.com
　15.4
物理的な接続
281
定義する必要がある。アクセスプロトコルは、接続されたデバイスが、そのバスをいま利用で
きるのか、あるいは使用中なのかを判定し、交代でバスを使えるようにする方法を定める。
15.3.3
複数のバス
典型的なコンピュータシステムには複数のバスが含まれる。プロセッサとI/O デバイスとメ
モリを接続する中心的なバスの他に、たとえばコプロセッサをアクセスする特殊用途のバスを
持つコンピュータがある。他にも、便利さと柔軟性を得るために複数のバスを持つコンピュー
タが多い。いくつもの標準バスを持つコンピュータは、より広範囲なデバイスを受け入れるこ
とができる。
興味深いことに、ほとんどのコンピュータには「内部」バスもある（つまりコンピュータの
所有者からは見えないバスだ）
。たとえば多くのプロセッサは、プロセッサチップ上に1 個以
上の内部バスを持っている。チップ上の回路は、そのオンボードバスを使って、たとえばオン
ボードキャッシュのような、他の回路との通信を行う。
15.3.4
パラレルでパッシブな機構
前章で述べたように、インターフェイスはデータ転送が「シリアル」か、
「パラレル」かの、
どちらかに分類される。コンピュータシステムで使われるバスは、ほとんどがパラレル転送だ。
つまり、バスは同時に複数ビットのデータを転送することができる。
もっともシンプルなバスは、
「パッシブ」
（受動的）に分類される。それはバス自身が電子部
品を含まないからで、その代わりにバスに接続される個々のデバイスに、バスを介した通信に
必要な電子回路が含まれる。したがって、バスとはパラレルな配線にデバイスが接続されるも
のだ、と考えることができる1。
15.4 　物理的な接続
バスは物理的に言えば、チップ上のシリコンにエッチングされた極細の導線か、複数の芯線
を含むケーブルか、回路基板に並ぶ金属配線で構成される。そのうち、ほとんどのコンピュー
タでI/O バスに使われるのが、第3 の形式だ。つまりバスは、
「マザーボード」と呼ばれるコ
ンピュータのメイン回路基板上に、パラレルな配線の集合として実装される。マザーボードに
は、バスに加えてプロセッサ、メモリ、その他の機能ユニットが搭載される。
マザーボードは、一連のソケットをバスに接続して、容易にデバイスを着脱できるようにし
ている（だからデバイスをバスに接続するには、ソケットの1 つに挿入すればよい）
、バスとソ
ケットは、外からアクセスしやすいようにマザーボードの片端に寄せて配置されるのが典型的
1　実際には、ある種のバスには「バスアービタ」と呼ばれるデジタル回路が含まれていて、それがバスに
接続されたデバイスを調停する。けれども、このような詳細は本書で扱う範囲を超える。
hi.0412.ko.2002@gmail.com
282
第15 章
バスとバスアーキテクチャ　
だ。図15‒2 に、マザーボード上のバスとソケットの配置を示す。
マザーボー
ド
マザーボー
ドで、
プロセッサ、
メモリ、
その他のユニッ
トが
搭載される領域
パラレル配線で
構成されたバス
ボー
ドの端に寄せて
並べられたソケッ
ト
図15‒2：パラレル配線で構成されるバスがマザーボード上でコネクタに接続されている。マザーボードに
は、ここでは見せていないが、他の部品も搭載される
15.5 　バスインターフェイス
デバイスをバスに接続するのは簡単な仕事ではない。正しく動作させるためには、デバイス
がバスの標準に準拠していなければならない。たとえばバスの共有や、所与のデバイスがバス
をアクセスしてデータを転送するタイミングが、バスの仕様に含まれる「アクセスプロトコル」
によって決まることを思い出そう。アクセスプロトコルを実装するために、そのバスに接続し
てバスの標準規格にしたがうことが可能なデジタル回路が、それぞれのデバイスに必要となる。
それを行うのが「バスインターフェイス」あるいは「バスコントローラ」と呼ばれる回路だ。
これによってバスのアクセスプロトコルを実装し、デバイスがいつどのようにバスを使うかを
精密に制御する。バスのプロトコルが複雑ならば、インターフェイス回路は大きくなる。多く
のバスインターフェイスは、複数のチップを必要とする。
バスインターフェイスの回路とバスは、物理的にどう繋がれるのだろうか。面白いことに、
多くのバスには、プリント回路基板（Printed Circuit Board：PCB）を直接挿入できるソケット
が選択される。基板側には、ソケットの幅に合わせて精密に切り出されたエッジ部分があって、
そこには金属端子の列が、ソケット側の接点と正確に一致するピッチで並んでいる。図15‒3
に、その概念を示す。
この図を見れば、コンピュータシステムを物理的に構築する方法を理解しやすくなる。もし
マザーボードがキャビネットの底部にあれば、そのマザーボードに差し込まれる外部装置用の
回路基板は、
それとは直角の関係だから、
デバイス用の回路基板は縦置きになる。物理的な配置
で重要な鍵となるのは、ソケットの並べ方だ。設計者がマザーボードの端に近い位置にソケッ
トを並べると、デバイス用の回路基板はキャビネットの側面に沿って並ぶ。その位置が側面に
近ければ、回路基板とキャビネットの外を結ぶ接続が短くなる。これが、典型的なPC で使わ
れる配置である。
hi.0412.ko.2002@gmail.com
　15.6
制御線、アドレス線、データ線
283
プリン
ト回路基板
（デバイスインターフェイス）
マザーボー
ド
（側面図）
ソケッ
ト
デバイスとの
外部接続
図15‒3：マザーボードの側面図で、PCB がバスのソケットに挿入されるようすを示す。PCB のエッジにあ
る金属端子が、ソケット側の金属接点に圧着される
15.6 　制御線、アドレス線、データ線
バスの物理的な構造も技術者にとって興味深い課題だが、もっと興味深いのは論理的な構造
だ。どのように配線が使われるのか、バスがサポートする演算は何か、プログラマにどういう
影響があるのかを、これから見ていこう。
バスを構成するワイヤの類は、
（とくに公式な言葉ではないが）
「線」と呼ばれる。線の機能
は、次の3 つに分類される。
•
バスの制御
•
アドレス情報の指定
•
データの転送
いまはバスの働きを理解するために、この3 つの機能に対応する独立した線の集合がバスに
含まれることを前提としよう2。図15‒4 は、その概念を示している。
制御線
ア
ドレス線
データ線
図15‒4：バスを構成する線を、制御とアドレスとデータに分割する
この図が示唆するように、バスの線を3 つの用途のために均等に分割する必要はない。とく
2　この記述は詳細を単純化している。後の節で説明するように、線を物理的にグループ分けしなくても、
同じ機能を達成することは可能だ。
hi.0412.ko.2002@gmail.com
284
第15 章
バスとバスアーキテクチャ　
に制御線は、他の機能と比較して少数の線しか必要としないのが普通だ。
15.7 　「フェッチとストア」のパラダイム
第10 章で見たように、メモリシステムで使われる「フェッチとストア」のパラダイムにお
いて、プロセッサは、メモリから値をフェッチするか、あるいはメモリに値をストアするか
の、どちらかである。バスで使われる基本的なパラダイムも、それと同じだ。つまり、バスは
「フェッチ」と「ストア」という2 つの演算しかサポートしない。意外に思われるかもしれな
いが、プロセッサがデバイスと通信するときも、バスを超えたデータ転送を行う通信にも、必
ずフェッチとストアの演算が使われる。興味深いことに、このフェッチとストアのパラダイム
は、あらゆるデバイスに利用される。その対象には、ディスクのようなストレージデバイスだ
けでなく、マイクも、ビデオカメラも、センサーも、ディスプレイも含まれるのだ。
すべてのデバイスをフェッチとストアのパラダイムで制御する方法については、後で見るこ
とにしよう。いまは、次の要点を理解すれば十分だ。
メモリシステムと同じく、バスも「フェッチとストア」のパラダイムを採用している。
制御とデータ転送を含む、すべての演算が、フェッチまたはストアによって実行される。
15.8 　「フェッチとストア」とバスのサイズ
バスが「フェッチとストア」のパラダイムを使うと知っていれば、図15‒4 で見た3 種類の
線の用途を理解しやすくなる。これら3 つのカテゴリーは、どれも「フェッチ」または「スト
ア」の演算に使われる。制御線は、バスで通信を行うものが、いつでも必ず1 つのペアとなり、
通信を行う2 者が確実に相互作用を行えるように設定される。アドレス線はアドレスを渡すの
に使われ、データ線はデータの値を転送するのに使われる。
図15‒5 は、3 種類の線が「フェッチ」と「ストア」の演算で、どのように使われるかを説
明している。それぞれの演算で実行されるステップをリストにし、個々のステップで、どのグ
ループの線が使われるかを指摘している。
前述したように、ほとんどのバスはパラレル転送を使う。バスには複数のデータ線があって、
個々のデータ線で同時に転送できるのは1 ビットである。したがって、もしバスにK 本のデー
タ線があれば、そのバスは一度にK ビットを転送できる。このことを、前章の用語を使って、
バスにはK ビットの「幅」があると言う。だから、32 本のデータ線を持つ（同時に32 ビット
を転送できる）バスは、
「32 ビットバス」と呼ばれる。
もちろんバスはパラレルだけでなく、
シリアルバスも存在する。シリアル通信なので、
同時に
1 ビットしか転送できない。だからシリアルバスは1 ビット幅のバスとも言えるが、技術者の
会話に「1 ビットのバス」などという言葉は出てこない。彼らは単に「シリアルバス」と呼ぶ。
hi.0412.ko.2002@gmail.com
　15.9
多重化
285
フェッチ
1
制御線を使ってバスのアクセス権を取得
2
アドレス線にアドレスを置く
3
制御線を使ってフェッチ演算を要求する
4
制御線をテストして、演算の完了を待つ
5
データ線から値を読む
6
制御線をセットして他のデバイスがバスを使えるようにする
ストア
1
制御線を使ってバスのアクセス権を取得
2
アドレス線にアドレスを置く
3
データ線に値を置く
4
制御線を使ってストア演算を要求する
5
制御線をテストして、演算の完了を待つ
6
制御線をセットして他のデバイスがバスを使えるようにする
図15‒5：バス経由でフェッチまたはストアの演算を実行するステップを記し、個々のステップで使われる線
のグループを示す
15.9 　多重化
バス幅は、どれくらいあればいいのだろうか。前章で見たように、パラレルインターフェイ
スには妥協が必要だ。幅を広げればスループットが上がるが、より多くの空間を占め、接続す
るデバイスにも、より多くの電子部品が必要になる。そればかりか、データの転送レートが高
いとパラレル線の信号が互いに干渉するかもしれない。だからアーキテクトは、バス幅を選ぶ
のに、空間とコストと性能の間で妥協を図る必要がある。
バスの線を少なくするのに、飛び抜けて役立つテクニックが「多重化」だ。バスを多重化す
る方法は、2 つある。単に「データの多重化」を行うか、2 つを組み合わせることによって「ア
ドレスとデータの多重化」を行うかだ。
データの多重化
データ多重化の仕組みは、前章で学んだ。たとえば、バスに接続されたデバイスから転送し
たいデータの量が多いとき、そのデバイスはデータを、バス幅とまったく同じサイズのブロッ
クに分割する。そしてデバイスは一度に1 個ずつブロックを送りながら、バスを繰り返し使う
のだ。
アドレスとデータの多重化
アドレスを多重化する目的は、線の総数を減らすことにある。アドレス多重化の仕組みを理
hi.0412.ko.2002@gmail.com
286
第15 章
バスとバスアーキテクチャ　
解するために、図15‒5 のステップを注意深く考察しよう。
「フェッチ」演算の場合、アドレス
線とデータ線を同時には使わない（同じステップで使用されない）
。だからアーキテクトは同じ
線集合を、アドレス送信とデータ受信の両方に利用できる。
「ストア」演算の場合は、多重化を
使える。つまりバスのハードウェアは、まずアドレスを送ってから、次にデータを送るのだ3。
ほとんどのバスは多重化を多用する。したがって、バスの線のカテゴリーは、典型的には3
つではなく2 つになる。何本かの制御線の他に、アドレスまたはデータの転送に使われる1
セットの線を持つのだ。この考えを、図15‒6 に示す。
制御線 
ア
ドレス／データ線
図15‒6：アドレスとデータの両方に1 セットの線を使うバス。線の集合を1 つ減らすことでコストを削
れる
多重化の長所は2 つある。第1 に、多重化を行うアーキテクトは、線数の少ないバスを設計
できる。第2 に、バスの線数が一定ならば、多重化によって全体の性能が向上する。その理由
を明らかにするために、データ転送について考えよう。もしバスでK 本の線がアドレス用に予
約されているのなら、それらK 本の線をデータの転送中に利用することはできない。しかし、
全部の線を両用にするなら、それぞれのバスサイクルで、さらにK ビットを追加して転送でき
る。だから全体のスループットが向上するのだ。
このような長所を持つ多重化だが、短所も2 つある。第1 に、多重化すると必要な時間が増
える。その理由は「ストア」演算でバスサイクルが2 つ必要になるからだ（1 つはアドレス転
送用、もう1 つはデータ項目の転送用）
。第2 に、多重化には、より洗練されたバスプロトコ
ルが必要なので、バスインターフェイスのハードウェアが、それだけ複雑になる。このように
短所はあるが、多くのバス設計は多重化を採用している。極端なケースとして、データとアド
レスの転送に使う線集合に制御情報まで多重化するバス設計さえ可能だ。
15.10 　バス幅とデータ項目のサイズ
多重化が使われるという事実は、コンピュータアーキテクチャの、もう1 つの側面も説明
してくれる。それは、アドレスを含む全部のデータオブジェクトのサイズが統一されるという
3　もちろん、多重化されたバスから要求を受け取るデバイスは、データの転送中にアドレスをストアして
おく必要がある。
hi.0412.ko.2002@gmail.com
　15.11
バスアドレス空間
287
ことだ。これから見ていくるように、プロセッサとメモリとデバイスの間で行われるすべての
データ転送は、バス上で発生する。そればかりか、バスは固定数の線での転送を多重化する。
バス幅とぴったり一致するデータ項目ならば1 サイクルで転送できるが、バス幅より大きな項
目には、それが何であっても複数のサイクルが必要となる。だからアーキテクトとしては、汎
用レジスタにも、ALU や機能ユニットが使うデータの値（整数値または浮動小数点値）にも、
バス幅と同じただ1 つのサイズを選択するのが合理的なのだ。もっと重要なことに、アドレス
も同じバス線で多重化されるのだから、アーキテクトとしては、他のデータ項目と同じサイズ
を、アドレスにも選択するのが合理的である。要点をまとめておこう。
多くのコンピュータでは、アドレスとデータの値が同じバスで多重化される。ハード
ウェアの性能を最適化するために、アーキテクトはデータ項目とアドレスの両方に、た
だ1 つの共通サイズを選択する。
15.11 　バスアドレス空間
プロセッサがメモリをアクセスするのに使う「メモリバス」は、もっとも理解しやすい形の
バスだ。メモリアクセスとメモリアドレス空間のコンセプトは、これまでの章で学んだ。その
コンセプトを実装するために、バスがどのように使われるかを学ぼう。図15‒7 が示すように、
メモリバスはプロセッサと1 個以上のメモリの間に物理的な相互接続を提供する。
バス
プロセッサ
メモリ
1
メモリ
N
バスインターフェイス
図15‒7：メモリバスを使うプロセッサとメモリの物理的な相互接続。それぞれのデバイスにあるコントロー
ラ回路が、バスアクセスの詳細を扱う
この図が示すように、メモリバスに接続されるプロセッサとメモリモジュールには、それぞ
れインターフェイス回路が入っている。このインターフェイスがバスプロトコルを実装して、
すべてのバス通信を処理する。インターフェイスは制御線を使ってバスへのアクセス権を得て
から、アドレスまたはデータ値を送り出して処理を遂行する。使用すべき電圧や制御信号のタ
イミングなど、バスの詳細を知っているのはインターフェイスだけだ。
プロセッサから見ると、バスインターフェイスは「フェッチとストア」のパラダイムを提供
するものだ。プロセッサにできるのは、バスアドレスからの「フェッチ」と、バスアドレスへ
hi.0412.ko.2002@gmail.com
288
第15 章
バスとバスアーキテクチャ　
の「ストア」という、2 つの動作だけだ。メモリを参照する命令に遭遇すると、プロセッサの
ハードウェアは、バスインターフェイスを起動する。たとえば、多くのアーキテクチャにおい
てロード命令はメモリから値をフェッチして、その値を汎用レジスタの1 つに置く。プロセッ
サがロードを実行するとき、そのハードウェアはバスインターフェイスに対して「フェッチ」の
指令を発効する。同様に、プロセッサがメモリに値を記入する命令を実行するとき、そのハー
ドウェアはバスインターフェイスに対する「ストア」の動作を使う。
バスインターフェイスは、プログラマから見えない。プログラマは、バスが「アドレス空間」
を定義していると考える。1 個のアドレス空間を作成する鍵は、メモリの構成にある。それぞ
れのメモリは、バスアドレスの特定の集合に応答するように設定される。つまり、メモリ1 の
インターフェイスには、メモリ2、メモリ2、メモリ4 などとは異なるアドレス集合が割り当て
られる。プロセッサがバスに対して「フェッチ」または「ストア」の要求を出すとき、すべて
のメモリコントローラが、その要求を受信する。どのメモリコントローラも、その要求にある
アドレスを、自分のメモリモジュールに割り当てられたアドレス集合と比較する。もし要求の
アドレスが自分の受け持ち範囲内ならコントローラは応答するが、そうでなければコントロー
ラは要求を無視する。
要求がバスを超えて渡されるとき、バスに接続されているすべてのメモリモジュールが、
その要求を受信する。ただしメモリモジュールが応答するのは、要求に含まれているア
ドレスが、そのモジュールに割り当てられた範囲に該当するときだけだ。
15.12 　エラーの可能性
リスト15‒1 は、個々のメモリモジュールのインターフェイスが実装する手順のステップを
示している。
リスト15‒1：メモリモジュールのバスインターフェイスがしたがう手順
/* R を、このモジュールに割り当てられているアドレスの範囲とする*/
永遠に繰り返す{
要求が現れるまでバスを監視する;
if ( 要求がR に含まれるアドレスを指定している) {
要求に応答する
} else {
要求を無視する
}
}
バスのハードウェアが報告するエラーは「バスエラー」と呼ばれる。典型的なバスプロトコ
ルには、各種のバスエラーを検出して報告する機構が含まれている。個々のモジュールに独立
した動作を許しているので、次の2 種類のバスエラーに、発生の可能性がある。
hi.0412.ko.2002@gmail.com
　15.13
アドレス構成とソケット
289
•
アドレス衝突
•
割り当てのないアドレス
「アドレス衝突」
という用語は、設定ミスのせいで2 つ以上のインターフェイスが所与のアド
レスに応答した結果として生じるバスエラーの記述に使われる。ある種のバスのハードウェア
は、システム起動時にアドレス衝突を検出して報告するように設計されている。また、衝突を
予防するように設計されるハードウェアもある。いずれにしても、ほとんどのバスプロトコル
には、実行時に発生するアドレス衝突のテストが含まれている。もし2 つ以上のインターフェ
イスが所与の要求に応答しようとしたら、バスのハードウェアは、アドレス衝突の問題を検出
し、制御線の設定によって、このエラーが発生したことを示す。バスを使うとき、プロセッサ
はバスの制御線をチェックし、もしエラーが発生したら対応する。
「割り当てのないアドレス」というバスエラーは、どのインターフェイスにも割り当てられ
ていないアドレスを、プロセッサがアクセスしようとしたときに発生する。割り当てのないア
ドレスを検出するために、ほとんどのバスプロトコルは「タイムアウト」機構を使う。要求を
バスに出したら、プロセッサはタイマを起動する。もしインターフェイスからの応答がなくタ
イマが時間切れになったら、プロセッサのハードウェアがバスエラーを報告する。割り当ての
ないアドレスの検出に使うタイムアウト機構によって、
（要求に応答しないメモリモジュール
など）ハードウェアの故障も検出される。
15.13 　アドレス構成とソケット
バスのハードウェアには、
バスエラーを防止するものもあるけれど、
割り当てのないアドレス
には、防止が困難な問題がある。このバスエラーを防ぐには、割り当て可能なアドレスを、もれ
なくメモリモジュールに割り当てる必要があるが、たいがいのメモリシステムは拡張できるよ
うに設計される。つまり、典型的なバスには、そのコンピュータで実装されているよりも多く
のメモリをアドレッシングできる線が含まれる（ゆえに、割り当てのないアドレスが生じる）
。
さいわい、所与の要求に対して2 つのモジュールが応答する衝突の問題については、アーキ
テクトたちが防止機構として「特別なソケット」を考案した。そのアイデアは単純明快である。
メモリは、マザーボードのソケットに挿入できる小さなプリント回路基板として製造される。
構成によるミスを防ぐために、すべてのメモリボードは同一に作られ、挿入前のボードには何
も設定する必要がない。その代わりに、マザーボードの側に回路と配線が追加される。それに
よって、第1 のソケットはアドレス0 からK‒1 までの要求だけを受け取り、第2 のソケット
はアドレスK から2K‒1 までの要求だけを受け取る（以下同様）
。あるソケットがアドレスを
認識したら、そのソケットは、アドレスの下位ビットだけをメモリに渡すのだ。いったん要点
をまとめよう。
メモリ構成の問題を防ぐためにアーキテクトたちは、小さなメモリボードを挿入するマ
hi.0412.ko.2002@gmail.com
290
第15 章
バスとバスアーキテクチャ　
ザーボード側のソケットに工夫をした。コンピュータの所有者がハードウェアを設定す
る必要がないように、どのソケットにもあらかじめ、そのメモリが応答すべきアドレス
の範囲を設定しておくのだ。
それに代わるもう1 つの方法として、一部のコンピュータには洗練された回路が含まれてい
て、コンピュータの起動時にMMU がソケットのアドレスを設定できるようになっている。ど
のソケットにメモリがあるかをMMU が判定して、それぞれにアドレスの範囲を割り当てる
のだ。これにはコストがかかるが、衝突を防ぐ回路を追加することによって、メモリのインス
トールは、ずっと容易になる。所有者はメモリモジュールを買ってきて、ソケットに挿すだけ
でよく、モジュールを設定する必要もなければ、衝突の危険もない。
15.14 　複数バスの問題
コンピュータシステムはバスを複数持つべきだろうか。持つとしたら、いくつだろうか。高
性能設計のコンピュータ（たとえばメインフレームコンピュータ）は、しばしば複数のバスが
存在した。それぞれのバスは、特定の用途のために最適化される。たとえばメインフレームコ
ンピュータは、メモリ用に1 本、高速I/O 用に1 本、低速I/O 用に1 本のバスを持つかもし
れない。けれども、それほど強力ではないコンピュータ（たとえばパーソナルコンピュータ）
は、しばしば1 本のバスを、すべての接続に使う。このシングルバス方式の主な利点は、コス
トが低く、汎用的であることだ。プロセッサは複数のバスインターフェイスを必要とせず、1
個のバスインターフェイスを、メモリとデバイスの両方に使える。
すべての接続用に1 本のバスを設計するのだから、もちろん妥協が必要である。どの用途に
も最適なバスが得られるわけではない。とくにプロセッサが1 本のバスを使ってメモリにある
命令やデータをアクセスするほか、入出力も実行する場合、バスがボトルネックになりやすい。
したがって、1 本のバスを使うシステムでは、しばしばメモリに対する要求のほとんどをバス
を使わず応答できるように、大きなメモリキャッシュを使う必要が生じる。
15.15 　「フェッチとストア」をデバイスに使う
プロセッサとI/O デバイスを繋ぐ主な接続はバスである。そして、バスに対するすべての演
算は「フェッチとストア」のパラダイムを使って行わなければならない。この2 つの文には、
矛盾があるように思われるかもしれない。
「フェッチとストア」はデータ転送には適している
が、デバイスの制御に使えるのだろうか。たとえば、無線通信がアクセスポイントの範囲内に
あるかのテストや、プリンタの紙送りといった操作を考えると、
「フェッチとストア」では不十
分に思える。デバイスには制御コマンドの大きな集合が必要ではないか。
バスの働きを理解するために、次のことを思い出そう。バスでは、あるユニットから別のユ
ニットに向けて通信するときに使うビット集合について、どのビットが何を意味するかを指定
hi.0412.ko.2002@gmail.com
　15.15
「フェッチとストア」をデバイスに使う
291
する必要がないのだ。
「フェッチ」と「ストア」という言葉からはメモリ内の値を連想しやすい
が、バスにおいては、各デバイスのインターフェイスハードウェアが、それぞれビット集合の
ユニークな解釈を提供する。だからデバイスは、あるビット集合を、データ転送の要求ではな
く何かの制御を行う演算として解釈できるのだ。
「フェッチとストア」のパラダイムとデバイス制御との関係は、例を見ればわかりやすくな
る。そこで、単純なサンプルを考えよう。16 個の状態表示ランプを持つ単純なハードウェアを
バスに繋げたい。バスが提供するのは「フェッチ」と「ストア」の演算だけだから、制御のた
めに「フェッチとストア」のパラダイムを使うインターフェイスハードウェアを作る必要があ
る。デバイスインターフェイスを設計する技術者は、まず最初に、実行される演算のリストを
作る。図15‒8 に、この架空の表示デバイスの5 つの機能をあげる。
•
表示をON にする
•
表示をOFF にする
•
表示の明るさを設定する
•
i 番目の状態ランプをON にする
•
i 番目の状態ランプをOFF にする
図15‒8：架空の状態表示ランプに必要な機能。どの機能も「フェッチとストア」のパラダイムで実装しなけ
ればならない
制御の演算を「フェッチとストア」のパラダイムで表現するために、技術者は、他のデバイス
が使っていないバスアドレスの集合を選んで、個々のアドレスに意味を割り当てる。たとえば、
架空の状態ランプ装置が32 ビットのバスに接続されるとして、設計者は10000 から10011 ま
でのバスアドレスを選び、表15‒1 に示す意味を割り当てるかもしれない。
表15‒1：デバイス制御の機能（図15‒8）に割り当てるアドレスと演算と意味
アドレス
演算
意味
10000
-
10003
ストア
データの値が0 以外なら表示をON にする。データの値が0 なら
表示をOFF にする。
10000
-
10003
フェッチ
もし現在の表示がOFF なら0 を返す。もし現在の表示がON なら
0 以外の値を返す。
10004
-
10007
ストア
明るさを変更する。データの値の下位4 ビットで、0（暗い）から
15（明るい）までの明るさを指定する。
10008
-
10011
ストア
データ値の下位16 ビットで、個々の状態ランプを制御する。ビッ
トが0 なら、対応するランプをOFF にする。ビットが1 なら、対
応するランプをON にする。
hi.0412.ko.2002@gmail.com
292
第15 章
バスとバスアーキテクチャ　
15.16 　インターフェイスの演算
バスの演算に「フェッチ」と「ストア」の名が付いていても、デバイスインターフェイスがメ
モリのように動作するわけではない。あとで取り出せるようにデータを保存するという意味の
「ストア」ではないのだ。デバイスはバス要求のアドレスと演算とデータを、単なるビットの集
合として扱う。インターフェイスに含まれる論理回路は、個々の要求のアドレス部分のビット
を、そのデバイスに割り当てられたアドレスと比較する。もし一致していたら、インターフェ
イスは「フェッチ」または「ストア」の演算に応答する回路を有効にする。たとえば表15‒1
の最初の項目は、アドレス10000 を持つ「ストア」の要求におけるデータ値のビットをテスト
して、そのデータを使って動作を行う。要するに、その回路が実行するのは、次のテストだ。
if ( address == 10000 && op == store && data != 0 ) {
turn on display;
} else if ( address == 10000 && op == store && data == 0 ) {
turn off display;
}
ここではプログラミング言語の書き方で演算を表現してみたが、インターフェイスのハード
ウェアはテストをシーケンスとして逐次実行するのではない。インターフェイスはブール論理
回路から構成され、アドレスと演算とデータ値を並行してテストして、適切な動作を行うこと
ができる。
15.17 　非対称な割り当てとバスエラー
表15‒1 で示した例は、一部のアドレスに対する「フェッチ」または「ストア」演算の影響
を定義していない。たとえば、この仕様にはアドレス10004 に対する「フェッチ」演算が定義
されていない。
「フェッチ」と「ストア」の両方の演算が、それぞれのアドレスに定義される
とは限らないのだ。そのことを、われわれは「非対称」な割り当てという言葉で表現する。表
15‒1 の仕様が「非対称」だというのは、プロセッサはアドレス10004 から始まる4 バイトに
値をストアできるのに、もしプロセッサがアドレス10004 からの読み出しを試みたら、バスエ
ラーという結果になるからだ。
15.18 　メモリとデバイスの統一アドレッシング
コンピュータによっては、1 本のバスがメモリとI/O デバイスの両方にアクセスを提供する。
そういうアーキテクチャでは、そのバスに対するアドレスの割り当てで、プロセッサから見た
アドレス空間が定義される。たとえば、図15‒9 のようなシングルバス形式のコンピュータシ
ステムを想像してみよう。
hi.0412.ko.2002@gmail.com
　15.19
バスアドレス空間の穴
293
プロセッサ
メモリ 1
メモリ 2
デバイス
1
デバイス
2
バス
図15‒9：シングルバス方式のコンピュータアーキテクチャ。1 本のバスにメモリとデバイスの両方が接続
される
この図では、
プロセッサが使う1 個のアドレス空間を、
バスが定義している。メモリモジュー
ル、I/O デバイスには、それぞれユニークなアドレスの範囲を割り当てる必要がある。たとえ
ばメモリの容量が、それぞれ1M バイトで、各デバイスに12 個のメモリアドレスが必要だと
しよう。このバスでそれらを使うには、たとえば表15‒2 に示すように、4 つのアドレス範囲
を割り当てる必要があるだろう。
表15‒2：バスアドレスに、図15‒9 のデバイスを割り当てる
デバイス
アドレスの範囲
メモリ1
0x000000 - 0x0fffff
メモリ2
0x100000 - 0x1fffff
デバイス1
0x200000 - 0x20000b
デバイス2
0x20000c - 0x200017
第11 章で行ったように、メモリアドレス空間を図にして見ることもできる。しかし当然な
がら、個々のデバイスが占めるアドレス空間はメモリが占める空間と比べて極度に小さいから、
ほとんど詳細を示すことができない。表15‒2 の割り当てを行った結果は、図15‒10 に示すよ
うになる。
15.19 　バスアドレス空間の穴
表15‒2 で示したようなアドレス割り当ては、アドレスの範囲にギャップがないので「連続
的」だと言われる。つまり、ある範囲に割り当てられた最初のバイトは、その前の範囲に割り
当てられた最後のバイトの直後に位置する。しかし連続的なアドレス割り当てが、必ず要求さ
れるわけではない。もしソフトウェアが間違って、割り当てのないアドレスをアクセスしたら、
バスのハードウェアが問題を検出してバスエラーを報告する。
第13 章の用語を使うと、もしアドレスの割り当てが連続的でなければ、そのアドレス空間
には1 個以上の「穴」が残る。たとえばバスが、メモリの下位アドレスをメモリに割り当て、
hi.0412.ko.2002@gmail.com
294
第15 章
バスとバスアーキテクチャ　
デバイス 1 
デバイス 2
メモリ 2
メモリ 1
0
図15‒10：アドレス空間の図で、表15‒2 で行ったアドレス割り当ての結果を示す。各デバイスに割り当て
るアドレス空間（12 バイト）は、それぞれのメモリが占める空間（1M バイト）と比べたら、微々たるもの
である
デバイスには高位のアドレスを割り当てたら、その2 つの領域の間に穴が残される。
15.20 　アドレスマップ
バスの標準規格は、仕様の一部として、それぞれのアドレスに使用できるハードウェアの種
類を厳密に指定する。この仕様のことを、
「アドレスマップ」と呼ぶ。アドレスマップはアドレ
ス割り当てと同じではない。マップは、どういう割り当てが可能かを指定するだけなのだ。た
とえば図15‒11 は、ある16 ビットバスのアドレスマップを示している。
この図でメモリに利用できる2 つのアドレス空間は連続せず、間に穴が開いている。さらに、
第2 のメモリ領域とデバイス領域の間にも穴がある。
コンピュータシステムを作るときは、アドレスマップにしたがう必要がある。たとえば図
15‒11 の15 ビットバスで、メモリは2 つのブロックで合計32,768 バイトしか利用できない。
予約されたメモリ空間を完全に満たさずにメモリを一部だけインストールすることは可能だが、
それより多くはインストールできない。
バスのアドレスマップで、とくに興味深いのはデバイスの空間だ。というのも、デバイスに
予約される空間は、必要な空間よりも、ずっと大きいことが多いからだ。とくに、ほとんどの
アドレスマップはデバイス用にアドレス空間の大きな塊を予約するので、何千ものデバイスと
いうような極端なケースにも対応できるバスになっている。ただし、典型的なコンピュータに
あるデバイスは1 ダース未満であり、典型的なデバイスが使うアドレスは数個にすぎない。そ
の結果として次のように言える。
hi.0412.ko.2002@gmail.com
　15.21
バスへのプログラムインターフェイス
295
0xffff
0xdfff
0xbfff
0x7fff
0x3fff
0x0000
デバイスに
利用可能
穴
（利用不可）
デバイスに
利用可能
デバイスに
利用可能
穴
（利用不可）
図15‒11：16 ビットアドレスで可能なアドレスマップの例。メモリ用に2 つの領域を使えるほか、デバイ
ス用に使える領域が1 つある
典型的なコンピュータで、
アドレス空間のうちデバイスで利用できる部分は、
まばらに使
われるだけだ。利用できるアドレスのうち、実際に使われる割合は、ごくわずかである。
15.21 　バスへのプログラムインターフェイス
プログラムの視点から見ると、バスの使い方は2 つある。1 つは、バスをアクセスするため
の特殊な命令をプロセッサが提供する方法。もう1 つは、どのようなメモリ演算でも、プロ
セッサがバスへの参照として解釈する方法だ。後者は「メモリマップト」アーキテクチャと呼
ばれる。メモリマップト方式を使う例として、表15‒1 に示した架空の状態ランプ表示のアド
レス割り当てを考えてみよう。このデバイスの表示をON にするために、プログラマは0 以
外の値を、アドレス10000 から10003 までの4 バイトにストアしなければならない。もし整
数が4 バイトで（32 ビット）
、プロセッサがリトルエンディアンだとしたら、そのプログラム
は10000 というアドレスの整数にゼロ以外の値をストアすればよい。C のプログラムなら、次
のように書けば、その演算を実行できる。
int
*ptr;
/* ptr を整数ポインタとして宣言*/
ptr
= (*int)10000;
/* ポインタにアドレス10000 を設定*/
*ptr = 1;
/* ゼロ以外の値をアドレス10000 - 10003 にセット*/
プロセッサはバスをアクセスするのに、特殊な命令を使うか、メモリマップト方式を使
う。後者は通常のメモリ演算を使って、メモリだけでなくデバイスとも通信できる。
hi.0412.ko.2002@gmail.com
296
第15 章
バスとバスアーキテクチャ　
15.22 　2 つのバスを繋ぐブリッジ
シングルバスには単純さとローコストという利点があるが、
所与のデバイスは特定のバスでし
か使えないかもしれない。たとえば、ある種のイヤホンには「USB」
（Universal Serial Bus）が
必要だし、イーサネットデバイスによっては、
「PCI」
（Peripheral Component Interconnect）
バスが必要かもしれない。複数のバスを持つコンピュータのほうが、より広範囲なデバイスを
扱えることは明らかだ。もちろん、複数のバスを持つシステムは高価で複雑になるかもしれな
い。そこで設計者たちは、コンピュータに複数のバスを繋ぐ、より安価で単純な方法を作って
きた。そういうアプローチの1 つは、
「ブリッジ」と呼ばれるハードウェアデバイスを使う。こ
れは図15‒12 のように、2 つのバスを相互接続する。
バス 1
ブリ
ッ
ジ
バス 2
図15‒12：2 つのバスをブリッジが繋いでいる。ブリッジは、それぞれのバスの標準にしたがわなければな
らない
このブリッジが使うアドレスがK 個あるとしたら、それぞれのバスからサイズK のアドレ
ス範囲を選択し、それをブリッジに割り当てる。2 つのアドレス割り当ては、普通は同じでは
ないが、ブリッジが変換を行うように設計される。片方のバスでの演算が、ブリッジに割り当
てられたアドレスに該当するとき、ブリッジの回路が、そのアドレスを変換して、もう片方の
バスで演算を実行する。したがって、もしプロセッサがバス1 で、ブリッジされたアドレスの
1 つにストア演算を実行したら、ブリッジのハードウェアは、それと同等なストア演算をバス
2 で実行する。実際ブリッジは（プロセッサもデバイスも複数のバスとブリッジが関わってい
ることに気がつかないという意味で）トランスペアレントである。
15.23 　メインバスと補助バス
ブリッジは、あるバスのアドレス空間から、もう1 つのバスのアドレス空間へと、
「1 対1 写
像」を行う。つまりブリッジは、あるバスのアドレス集合を、もう片方のアドレス空間にマッ
プする。図15‒13 に、アドレスマッピングのコンセプトを示す。この図を見ると、どちらのバ
スのアドレス空間も0 から始まっている。そして、
「補助バス」のアドレス空間は、メインバ
スのアドレス空間よりも狭い。もっと重要なポイントとして、アーキテクトは補助バスのアド
hi.0412.ko.2002@gmail.com
　15.23
メインバスと補助バス
297
レス空間のうち、ごく小さな部分だけを、メインバスでデバイス用に予約された領域にマップ
している。その結果、補助バスでマップされた領域のアドレスに応答するデバイスは、どれも
コンピュータのメインバスに接続されたように見える。
メインバスの
ア
ドレス空間
補助バスの
ア
ドレス空間
デバイスに
利用可能
デバイスに
利用可能
デバイスに
利用可能
マップされて
いない
ブリ
ッ
ジが提供する
マッ
ピング
0
0
図15‒13：補助バスのアドレス空間とメインバスのアドレス空間の間にブリッジが提供するマッピング。
マッピングする必要のあるバスアドレスは、ごく一部だけ
なぜブリッジがよく使われるのかを理解するために、一般的なケースを見よう。すでにバス
を持っているコンピュータに、新しいデバイスを追加する必要が生じた場合だ。もし新しいデ
バイスのインターフェイス仕様が、コンピュータのメインバスとマッチしなければ、新しいア
ダプタハードウェアを作るか、ブリッジを使ってシステムに「補助バス」を追加することがで
きる。ブリッジを使う方法には、2 つの利点がある。第1 に、新しいデバイスのそれぞれにバ
スインターフェイスを追加するよりシンプルだ。第2 に、いったんブリッジをインストールし
たら、コンピュータの所有者は、それ以上ハードウェアを変更することなく、補助バスに新し
いデバイスを追加できる。
まとめておこう。
ブリッジは、2 つのバスを相互接続し、両者間でアドレスのマッピングを行うハードウェ
アデバイスだ。ブリッジを使うコンピュータは、自分のメインバスを介してアクセスで
きる、1 本以上の補助バスを持つことができる。
hi.0412.ko.2002@gmail.com
298
第15 章
バスとバスアーキテクチャ　
15.24 　プログラマにおよぼす影響
図15‒13 のようにマップされたアドレスの集合は、両方のアドレス空間で同一である必要は
ない。要はブリッジを、ソフトウェアから見てトランスペアレントにすればよいのであって、
補助バスの存在をソフトウェアに意識させないことが目標である。けれども残念ながら、デバ
イスドライバのソフトウェアを書くプログラマや、コンピュータの設定を行う人は、マッピン
グを理解する必要がある。たとえば、デバイスを補助バスにインストールするとき、そのデバ
イスはバスアドレスを取得する。初期化シーケンスの一部で、そのデバイスがバスアドレスを
ドライバソフトウェアに報告するかもしれない4。ブリッジはアドレスを変換するだけで、デ
バイスとデバイスドライバとの通信で使われるデータ線の内容までは変更しない。したがって
ドライバのソフトウェアは、メインバスでのアドレスを生成するために、ブリッジがどのよう
にアドレスをマップしているのかを理解する必要があるのだ。
15.25 　バスに代わるスイッチングファブリック
バスは、ほとんどのコンピュータにとって根本的な存在だが、バスにも欠点がある。バスの
ハードウェアは、一度に1 つの転送しか実行できない。つまり、所与のバスには複数のハード
ウェアユニットを接続できるが、同時に通信できるのは、接続された1 対のユニットに限られ
る。バスの基本的なパラダイムは、常に3 つのステップで構成される。まずバスを排他的に利
用できるまで待ち、それから転送を実行し、最後に、他の転送を可能にするためバスを開放す
るのだ。
一部のバスは、このパラダイムを拡張して、接続されている複数のユニットがバスを取得す
るたびにN バイトのデータを転送できるようにしている。しかし、バスのアーキテクチャで
は不十分な状況もあるので、アーキテクトたちは、複数の転送を同時に行うことができる代替
技術を発明した。
「スイッチングファブリック」と呼ばれる、そのテクノロジーには、さまざ
まな形態がある。ある種のファブリックは、数個の接続ユニットを扱えるように設計され、他
のファブリックは何百でも何千でも扱えるように設計される。同様に、ある種のファブリック
は転送に制限を課して、同時に転送を起動できる接続ユニットの数を少なくしているが、他の
ファブリックは、多くの同時転送を許している。このように多様なアーキテクチャが存在する
ことには、経済的な理由がある。より高い性能には（たとえば同時に行えるデータ交換の数を
増やせば）ずっと多くのコストがかかる。あまりコストが高いと、採用が難しくなるだろう。
たぶんもっとも理解しやすいのは、
「クロスバースイッチ」で構成されるスイッチングファブ
リックだ。クロスバーは、N 個の入力とM 個の出力を持つ行列だと思えば良い。クロスバー
にはN × M 個の電子スイッチが含まれていて、その1 つ1 つが1 個の入力と1 個の出力を
4　なぜデバイスドライバがアドレス情報を必要とするかは、第17 章で説明する。
hi.0412.ko.2002@gmail.com
　15.26
まとめ
299
接続する。図15‒14 に示すように、クロスバーでは、いつでもスイッチを入れて入力と出力の
ペアを接続できる。
入力 1
入力 2
入力 3
入力 M
出力 1 
出力 2 
出力 3
出力 M
図15‒14：N 個の入力とM 個の出力を持つクロスバースイッチの概念図。黒丸はアクティブな接続を示して
いる。クロスバー機構では、所与の行あるいは列について、いつでも1 個の接続しかアクティブにならない
図を見て考えると、スイッチングファブリックが高価な理由が、わかりやすくなる。第1 に、
図の縦横の線は、どれも複数線で構成されるパラレルなデータ経路だ。第2 に入力と出力の交
差する点には、そこで入力と出力を接続できるように、もれなく1 個の電子スイッチを配置す
る必要がある。だからクロスバーにはN × M 個のスイッチ部品が必要であり、しかもそのス
イッチで、パラレル接続を切り替えなければならない。これと比べて、バスにはN + M 個の
電子部品が必要なだけだ（それによって、個々の入力と個々の出力をバスに接続する）
。コスト
は高いが、スイッチングファブリックは、高性能システムでよく使われる。
15.26 　まとめ
バスは、コンピュータシステムの中にあるメモリ、I/O デバイス、プロセッサを相互接続す
る基本的な機構だ。ほとんどのバスはパラレルに動作する（複数の並列線で構成され、複数の
ビットを同時に転送できる）
。
どのバスにも、接続したデバイスがバスをアクセスするために使うプロトコルが定義される。
ほとんどのバスプロトコルは、
「フェッチとストア」のパラダイムにしたがう。バスに接続され
るI/O デバイスは、
「フェッチ」または「ストア」の演算を受け取って、それをデバイス制御の
演算と解釈するように設計されるのだ。
概念としてバスのプロトコルは、制御、アドレス、データの3 種類の情報を別々に指定する。
hi.0412.ko.2002@gmail.com
300
第15 章
バスとバスアーキテクチャ　
しかし実際には、バスが3 種類の情報に独立した配線を持つ必要はない。バスプロトコルで多
重化を使えば、より小さな配線集合で通信を行えるからだ。
バスが定義するアドレス空間は、穴（割り当てのないアドレス領域）を含むことがある。コ
ンピュータシステムは、1 本のバスにメモリとI/O デバイスを接続することも、複数のバスを
使って、それぞれ特別な種類のデバイスを接続することもできる。バスの代わりに、
「ブリッ
ジ」と呼ばれるハードウェアデバイスを使うことも可能だ。ブリッジによって複数の補助バス
をコンピュータに追加できる。それには、補助バスのアドレス空間の全部または一部を、コン
ピュータのメインバスのアドレス空間にマップする。
バスに代わる主な手段として
「スイッチングファブリック」
がある。これなら並行処理を使っ
て、より高いスループットを達成できるが、スイッチングファブリックはバスよりもずっと高
価なので、ハイエンドのシステムに限って採用されている。
練習問題
15.1
ハードウェアアーキテクトが、どちらのバス設計が良いか選んでくれと言っていま
す。片方は、1 本の32 ビットバスで、データとアドレスの情報をバスで多重化しま
す。もう片方は、2 本の16 ビットバスで、1 つはアドレス情報を送るのに、もう1 つ
はデータを送るのに使います。どちらの設計を選びますか? その理由は?
15.2
コンピュータのバスとは何ですか。それは何を繋ぐのですか?
15.3
うちの会社のコンピュータは、Apple がパテントを持っている特殊なバスを使って
いるんだよ、と友人が主張しました。ある会社がパテントを持っているバス設計を、
どんな言葉で表現できますか?
15.4
バスの配線の、概念的な3 つのカテゴリーは何ですか。
15.5
「フェッチとストア」のパラダイムとは何ですか?
15.6
もしバスの配線が制御線と、その他の線にわかれていたら、
「その他の線」の主な用
途は何と何ですか?
15.7
それぞれのメモリチップ用に、別のソケットを持つことの利点は何ですか?
15.8
あるデバイスに、0x4000000 から0x4000003 までのアドレスが割り当てられてい
るとします。このアドレスに0xff0001A4 という値をストアするコードを、C で書き
ましょう。
15.9
もし、あるバスがサイクル毎に64 ビットを転送でき、66MHz のレートで動作する
としたら、そのバスのスループットは、毎秒何M バイトですか?
15.10
スイッチングファブリックとは何ですか? バスと比べて、主に何が優れているの
ですか?
15.11
N 入力、M 出力のクロスバー式スイッチングファブリックで、いくつの転送を同
時に行うことができますか?
hi.0412.ko.2002@gmail.com
　15.26
まとめ
301
15.12
インターネットを検索して、スイッチングファブリックの設計をリストにしてみ
ましょう。
15.13
CLOS ネットワークの解説をインターネットで読みましょう。これもスイッチン
グファブリックで使われます。短い説明文を書いてください。
15.14
ブリッジは何を繋ぐのですか?
hi.0412.ko.2002@gmail.com
hi.0412.ko.2002@gmail.com
第16 章
プログラム駆動と割り込み駆動の入出力
16.1 　はじめに
これまでの章で入出力（I/O）を紹介した。前章では、プロセッサと一群のI/O デバイスとの
接続を、
バスがどのように提供するかを説明した。そこではバスのアドレス空間を論じ、
メモリ
とI/O デバイスの組み合わせを1 個のアドレス空間に収める方法を示した。バスでも「フェッ
チとストア」のパラダイムが使われること、外部デバイスの制御や問い合わせにもフェッチと
ストアの演算を使えることも、前章で説明した。
この章は、その続きである。ここではプロセッサとI/O デバイスとの間で行われる相互作用
の、2 つの基本的なスタイルを記述して比較する。とくに重点を置くのは割り込み駆動の入出
力であり、オペレーティングシステムのデバイスドライバが、外部デバイスとの相互作用をど
のように行うかを説明する。
次の章では、同じ主題に別のアプローチから取り組む。つまりプログラマの視点から入出力
を調べるのだ。そこでは個々のデバイスに注目し、それらがプロセッサとの相互作用を行う方
法を記述する。
16.2 　入出力のパラダイム
前章で学んだように、I/O デバイスはバスに接続される。プロセッサはデバイスと相互作用
を行うために、デバイスに割り当てられたバスアドレスに向けて、フェッチとストアの演算を
発行する。それによって入出力の基本的な機構は指定できるわけだが、いくつか不明点が残っ
ている。それぞれのデバイスは、どのような制御をサポートすべきだろうか。プロセッサで実
行されるアプリケーションは、ハードウェアの詳細を知らずに、所与のデバイスを、どうして
アクセスできるのだろうか。プロセッサとI/O デバイスとの相互作用は、システム全体の性能
に影響をおよぼすだろうか?
hi.0412.ko.2002@gmail.com
304
第16 章
プログラム駆動と割り込み駆動の入出力　
16.3 　プログラム駆動の入出力
最初期のコンピュータは、入出力に対して単純明快なアプローチを取っていた。フェッチと
ストアの演算に対する外部デバイスの反応は、基本的なデジタル回路でハードウェアを制御す
ることだった。すべての詳細はCPU が扱った。たとえばディスクにデータを書くとき、デバ
イスに存在する回路を、CPU が1 つずつ順番に動かしていく。それらの回路によって、ディス
クのアームが所定の位置まで動き、ヘッドがデータブロックを書き込む。CPU からのコマンド
に応じて動作する基本的な回路のみで構成されていた初期の周辺機器は、
「インテリジェンス」
を持たないデバイスであった。この形式で行うやりとりは「プログラム駆動の入出力」と呼ば
れている。
16.4 　同期
プログラム駆動の入出力を実行するソフトウェアを書くのは、簡単だと思われるかもしれな
い。プログラムは、バスのアドレスに値を代入するだけなのだから。しかし、入出力プログラ
ミングを理解するためには、次の2 つのことを忘れてはならない。第1 に、インテリジェン
トではないデバイスは、一連のコマンドを記憶していることができない。デバイスの回路は、
プロセッサがコマンドを送るたびに、それぞれのコマンドを忠実に実行するだけなのだ。第2
に、プロセッサの処理速度は、I/O デバイスと比べて、はるかに高速である。もっとも遅いプロ
セッサでも、モーターや機械的なアクチュエータが物理的な機構を動かすのに費やす時間で、
何千もの命令を実行できる。
機械的なデバイスの例として、プリンタを考えてみよう。プリント機構はページにインクを
散布できるが、一度にプリントできるのは、ごく狭い帯だけである。プリント処理は、ページ
の先頭から始まる。1 本の水平な帯をプリントしたら、まず紙を少し送らなければ、その次の
帯をプリントできない。もしプロセッサが、1 個の項目をプリントしてから、紙送りの命令を
出し、紙の移動が終わらないうちに、また次の項目をプリントする命令を出したら、印刷がこ
すれて読めなくなるだろう。最悪の場合、プリント機構が紙送り中に動作できない設計になっ
ていたら、ハードウェアが損傷するかもしれない。
この問題を解決するために、プログラム駆動の入出力は「同期」を必要とする。つまり、いっ
たんコマンドを発行したら、プロセッサはデバイスとやりとりを行って、デバイスが次のコマ
ンドを受け付けられる「レディ」状態になるまで、待つ必要があるのだ。
プロセッサの実行速度はI/O デバイスよりも段違いに速いので、プログラム駆動の入出
力では、プロセッサ側で、制御を受けるデバイスとの同期を取る必要がある。
hi.0412.ko.2002@gmail.com
　16.5
ポーリング
305
16.5 　ポーリング
プロセッサが入出力デバイスとの同期に使う基本的な形式は「ポーリング」と呼ばれるもの
だ。ポーリングでは、プロセッサが何度も繰り返してデバイスに問い合わせを発行し、1 つ前の
操作が完了したことをを確認してから、また次の操作に進む。ある「プリント」操作を実行す
るために、プロセッサは、図16‒1 に示す各ステップでポーリングを行うことができるだろう。
•
プリンタの電源が入っているかチェックする
•
プリンタに、未使用の紙をロードさせる
•
紙がロードされたかどうかを、ポーリングで判定する
•
何をプリントするかを、メモリのデータで指定
•
データがロードされるまで、ポーリングで待つ
•
プリンタに、インクの帯の噴射を開始させる
•
インクの機構が完了したかどうかを、ポーリングで判定
•
プリンタに、次の帯まで紙を送らせる
•
紙送りが終わったかどうか、ポーリングで判定
•
それぞれの帯のプリントについて、上記の6 ステップを繰り返す
•
プリンタに、ページ送りを命じる
•
ページが送られたかかどうかを、ポーリングで判定
図16‒1：プロセッサと入出力機器との同期を示す例。プロセッサは、それぞれのステップの完了を待つ必要
がある
16.6 　ポーリングのコード
ソフトウェアは、どうやってポーリングを行うのだろうか。バスは「フェッチとストア」のパ
ラダイムにしたがうのだから、ポーリングには「フェッチ」演算を使う必要がある。つまり、デ
バイスに割り当てられているアドレスの1 つ以上がステータス情報に対応していて、プロセッ
サが、そのアドレスの値をフェッチすると、その応答としてデバイスは現在の状態を返すのだ。
プログラマが具体的にどうやってポーリングするかを理解するには、ハードウェアの詳細を
知る必要がある。ところが残念なことに、ほとんどのデバイスは驚くほど複雑だ。たとえば多
くのベンダーは「3 in 1」のプリンタを売っているが、これはスキャナーとしても、ファック
スマシンとしても、プリンタとしても使える。ここでは単純な例を示すために、きわめてシン
プルなプリンタを想像し、そのデバイスのためのインターフェイスをプログラミングすること
にしたい。われわれのサンプルとなるデバイスは市販の機器よりずっと単純だが、アプローチ
の概要は、まったく同じである。
デバイスには、アドレス空間に存在するアドレス領域が割り当てられる。デバイスは、自分
hi.0412.ko.2002@gmail.com
306
第16 章
プログラム駆動と割り込み駆動の入出力　
に割り当てられたアドレスに対するフェッチとストアの命令に応答するように作られている。
ただしデバイスを作る設計者は、実際に使われるアドレスを指定するのではなく、アドレス0
からN‒1 まで、という相対アドレスを使って仕様を書く。あとで、そのアドレスがコンピュー
タにインストールされたとき、実際のアドレスが割り当てられるのだ。仕様書が相対アドレス
を使うので、プログラマも実際のアドレスを知ることなしに、デバイスを制御するソフトウェ
アを書くことができる。それには、デバイスがインストールされた実際のアドレスを、引数と
してソフトウェアに渡せばよいのだ。
例を見れば概念が明白になるだろう。われわれが想像するプリンタは、32 バイトの連続する
アドレスを定義する。さらに、その設計はアドレスを8 ワードに分ける（それぞれのワードは
32 ビットである）
。これは典型的なワードの使い方だ。表16‒1 の仕様は、それぞれのアドレ
スに対するフェッチとストアの命令を、デバイスがどう解釈するかを示している。
表16‒1：架空のプリンタデバイスのバスインターフェイス仕様。プロセッサは、フェッチとストアによっ
て、デバイスの制御と状態の判定を行う
アドレス
演算
意味
0 - 3
フェッチ
プリンタの電源がON なら0 以外の値
4 - 7
ストア
0 以外の値で用紙をロードする
8 - 11
ストア
プリントするデータのメモリアドレス
12 - 15
ストア
0 以外の値でプリンタがアドレスを取り込む
16 - 19
ストア
現在の帯でインクジェットの噴射を開始
20 - 23
ストア
0 以外の値で次の帯まで紙を送る
24 - 27
フェッチ
Busy: デバイスがビジーなら0 以外の値
28 - 31
フェッチ
CMYK のインクレベル(8-bit x 4)
この表は、架空のI/O デバイスに割り当てたアドレスに対するフェッチとストアの演算につ
いて、それぞれの意味を示す仕様だ。上に述べたように、仕様のアドレスが0 から始まるのは
相対アドレスだからだ。デバイスがバスに接続されるとき、このデバイスにはバスアドレス空
間のどこかにある32 バイトの領域が割り当てられる。そしてソフトウェアがデバイスとの通
信に使うのは、その実際のアドレスである。
いったん表16‒1 のようなハードウェア仕様をもらったプログラマが、デバイスを制御す
るコードを書くのは簡単だ。たとえばわれわれのプリントデバイスに、開始アドレスとして
0x110000 を割り当てたと仮定しよう。表のアドレスにある0 から3 は、実際のアドレスでは
0x110000 から0x110003 に対応する。プリンタの電源がON になっているかを調べるために、
プロセッサはアドレス0x110000 から0x110003 までの値をアクセスするだけでよい。もし値
がゼロなら、プリンタはOFF である。このデバイスのステータスをアクセスするコードは、メ
モリのフェッチと同様だ。ステータスをテストするコードは、C なら次のように書ける。
hi.0412.ko.2002@gmail.com
　16.6
ポーリングのコード
307
int *p = (int *)0x110000;
if (*p != 0) {
/* プリンタはON か? */
% Date: 2020/08/31
/* プリンタはON */
} else {
/* プリンタはOFF */
}
この例では整数のサイズが4 バイトだと想定している。このコードは整数ポインタとしてp
を宣言し、
そのp を0x110000 で初期化し、
*p を使って、
アドレス0x110000 の値を取得する。
これでソフトウェアがデバイスと通信する方法がわかったから、
次は一連のステップと同期に
ついて考えよう。リスト16‒1 は、図16‒1 で示したステップの一部を実行するC のコードだ。
リスト16‒1：ポーリングを使って、図16-1 にあったステップの一部を実行する、サンプルのC コード。
この架空のプリントデバイスの仕様は表16‒1 にある
int
*p;
/* このデバイスのアドレス領域へのポインタ*/
p = (int *)0x110000;
/* ポインタをデバイスのアドレスで初期化*/
if (*p == 0)
/* プリンタの電源ON をテスト*/
error("printer not on");
*(p+1) = 1;
/* 用紙のローディングを開始*/
while (*(p+6) != 0)
/* ポーリングでロード完了を待つ*/
;
*(p+2) = &mydata;
/* メモリにあるデータの場所を指定*/
*(p+3) = 1;
/* プリンタにデータを取り込ませる*/
while (*(p+6) != 0)
/* ポーリングでデータ読み取り完了を待つ*/
;
*(p+4) = 1;
/* インクジェットの噴射を開始*/
while (*(p+6) != 0)
/* ポーリングでインクジェットの終了を待つ*/
;
*(p+5) = 1;
/* 次の帯まで用紙を送る*/
while (*(p+6) != 0)
/* ポーリングで用紙送りの完了を待つ*/
;
このコードは、デバイスに0x110000 というアドレスが割り当てられ、データ構造のmydata
には、プリントすべきデータが、プリンタが期待する通りのフォーマットで含まれていること
を前提としている。ポインタの使い方を理解するには、プログラミング言語C での「ポインタ
演算」の定義を思い出そう。整数ポインタにK を加算すると、ポインタはKN バイト前進する。
ここでN は整数1 個を構成するバイトの数だ。したがって、もし変数p の値が0x110000 な
ら、p+1 は0x110004 に等しい。
このサンプルコードは、もう1 つ、
（おかしなプログラミングだと思われたかもしれないが）
多くのデバイスに見られる特徴を示している。それは、1 個の操作のために複数のステップが
あることだ。この例では、プリントすべきデータがメモリにあるが、そのデータを指定するの
hi.0412.ko.2002@gmail.com
308
第16 章
プログラム駆動と割り込み駆動の入出力　
に2 つのステップを使っている。第1 のステップではデータのアドレスをプリンタに渡す。第
2 のステップでは、そのデータの値をロードせよ、とプリンタに命じている。そのために2 つ
のステップを使う必要はないだろうと思われるかもしれない。どうしてプリンタは、アドレス
が指定されたとき、自動的にデータのローディングを開始しないのか。それを理解するには、
デバイスの回路が個々のフェッチとストアの命令によって制御されることを思い出す必要があ
る。デバイスの設計者が、このような設計を選ぶのには、何か理由があるはずだ。メモリアド
レスを受け取る回路と、メモリからデータをロードする回路と、2 つに分けた方がハードウェ
アを組みやすかったのかもしれない。
デバイス制御のプログラムを書いたことのないプログラマが、あっと驚くようなコードとし
て、見たところ無限ループのようなwhile ステートメントが、4 回出てくる。もしそういう
コードが一般的なアプリケーションプログラムにあったら、そのステートメントは間違いだろ
う。あるメモリの場所を、そこに変更を加えることなしに、ただループでテストし続けるだけ
なのだから。けれども、この例でポインタp が参照するのはメモリではなく、デバイスである。
したがって、プロセッサがp+6 の位置から値をフェッチすると、その要求がデバイスに渡され、
デバイスはそれを、デバイスの状態を示す情報の要求だと解釈する。メモリの値と違って、こ
のデバイスが返す値は、時間が経てば変化する。プロセッサが何度もポーリングを行っている
うちに、いつかデバイスは現在の処理を完了して、状態を示す値として0 を返す。
ポーリングのコードは無限ループを含んでいるように見えるが、間違いだとは言えない。
なぜなら、デバイスから返される値は、時間が経つと変化するかもしれないからだ。
16.7 　CSR：コントロールとステータスのレジスタ
われわれは、デバイスが使うアドレスの集合を「CSR」
（Control and Status Registers）と
総称する。そのなかで、
「コントロールレジスタ」
（制御レジスタ）は、ストア演算に応える、
通常は整数と同じサイズの連続アドレスに対応し、
「ステータスレジスタ」
（状態レジスタ）は、
フェッチ演算に応える連続アドレスに対応する。
実際のCSR は、表16‒1 で見た単純なバージョンよりも、普通はもっと複雑である。たとえ
ば典型的なステータスレジスタは、個々のビットに意味を持たせる（ステータスワードの最下
位ビットがデバイスが動作中かどうかを指定し、その次のビットはエラーが発生したかどうか
を指定する。などなど）
。重要なポイントとして、多くのデバイスはアドレスを節約するため
に、コントロールとステータスのレジスタを組み合わせて1 連のアドレスとする。つまり、1
個のアドレスが両方の役割を持つのだ。そのアドレスに対するストア演算はデバイスを制御し、
同じアドレスに対するフェッチ演算は、デバイスの状態を報告する。
詳細の最後の例として、デバイスによっては、1 つの「フェッチ」演算を、ステータス情報の
要求と1 個の「制御」指令の、両方を兼ねるものとして解釈する場合がある。たとえばトラッ
クパッドは、ユーザーの指の動きを示すバイト群を送信する。プロセッサはフェッチ演算を
hi.0412.ko.2002@gmail.com
　16.8
CSR を構造体で定義する
309
使って、トラックパッドからデータを取得する。それだけでなく、フェッチするたびにトラッ
クパッドのハードウェアが、次の動きを計測するため自動的にリセットされる。
16.8 　CSR を構造体で定義する
リスト16‒1 のコードでは、個々の項目を参照するのにポインタとポインタ演算を使ってい
た。実際にプログラムを書くときには、C なら構造体を作るのが普通で、それでCSR を定義し
てから、構造体の名前付きメンバを使ってSCR の項目を参照する。たとえばリスト16‒2 は、
リストl1603 と同様なコードを、CSR の定義に構造体を使って書いたものだ。
リスト16‒2：リスト16‒1 のコードを、C の構造体を使って書き直した
struct csr {
/* プリンタのCSR のためのテンプレート*/
int csr power;
/* プリンタの電源はON か? */
int csr load;
/* 用紙をロードする*/
int csr addr;
/* プリントするデータのアドレス指定*/
int csr getdata;
/* メモリからデータをロードする*/
int csr spray;
/* インクジェットの噴射を開始する*/
int csr advance;
/* 次の帯まで紙送り*/
int csr dev busy;
/* 0 以外ならば、デバイスはビジー*/
int csr levels;
/* CMYK のインクレベル(4 バイト) */
}
struct csr *p;
/* デバイスのアドレス領域へのポインタ*/
p = (struct csr *)0x110000;
/* p にデバイスのアドレスをセット*/
if (p->csr power == 0);
/* プリンタの電源はON か? */
error("printer not on");
p->csr load = 1;
/* 用紙のローディングを開始*/
while (p->csr dev busy)
/* ポーリングでロード完了を待つ*/
;
p->csr addr = &mydata
/* メモリにあるデータの場所を指定*/
p->csr getdata = 1;
/* プリンタにデータを取り込ませる*/
while (p->csr dev busy)
/* ポーリングでデータ読み取り完了を待つ*/
;
p->csr spray = 1;
/* インクジェットの噴射を開始*/
while (p->csr dev busy)
/* ポーリングでインクジェットの終了を待つ*/
;
p->csr
= 1;
/* 次の帯まで用紙を送る*/
while (p->csr dev busy)
/* ポーリングで用紙送りの完了を待つ*/
;
この例が示すように、構造体を使うコードは読みやすく、デバッグもしやすい。構造体のメ
ンバには意味のある名前を付けられるから、コードを読むプログラマは、たとえ最初はデバイ
スに慣れていなくても、その目的を推測できる。また、構造体を使うとプログラムの構成が改
善される。なぜならCSR の個々のレジスタのオフセットが、コードのあちこちに埋め込まれ
るのではなく一箇所で指定されるからだ。
hi.0412.ko.2002@gmail.com
310
第16 章
プログラム駆動と割り込み駆動の入出力　
プログラマは、CSR の参照をコード全体に散らす代わりに、CSR のすべてのレジスタを
構造体によって宣言してから、その構造体のフィールドを参照することで、コードを読
みやすくすることができる。
16.9 　プロセッサの有効利用とポーリング
プログラム駆動I/O アーキテクチャの主な利点は、経済的な優位性から生じる。洗練された
デジタル回路を含まないので、プログラム駆動に頼るデバイスは安価である。逆に、プログラ
ム駆動I/O の主な欠点は、計算処理のオーバーヘッドから生じる。それぞれのステップでプロ
セッサがI/O デバイスとのやりとりを行う必要があるからだ。
ポーリングが望ましくない理由を理解するには、I/O デバイスと計算処理に基本的な相違が
あることを思い出す必要がある。I/O デバイスは電子機械的な装置なので、その処理にはプロ
セッサよりも桁違いに長い時間がかかるのだ。さらに、もしプロセッサがI/O デバイスの制御
にポーリングを使うのなら、プロセッサが待ちに使う時間は一定で、プロセッサのスピードと
は関係がない。
重要なポイントを要約しよう。
典型的なプロセッサはI/O デバイスよりもずっと高速だが、ポーリングを使うシステム
のスピードは、I/O デバイスのスピードだけに依存する。高速なプロセッサを使っても、
入出力が実行される比率が増えるわけではない。
これから、容易に次の推論が得られる。もしプロセッサがI/O デバイスを待つのにポーリン
グを使うのなら、高速なプロセッサを使っても、そのプロセッサはデバイスを待つのに、より
多くの命令を実行するだけである（つまり、リスト16‒1 で見たようなループが、より高速に
実行されるだけだ）
。つまり高速なプロセッサは、単にI/O デバイスを待つだけのために、余
計なサイクルを浪費する。プロセッサがポーリングを行う必要がないのなら、代わりに計算処
理を行うこともできるだろう。
16.10 　割り込み駆動の入出力
1950 年代から1960 年代に、アーキテクトたちはプロセッサと入出力装置のスピードの違い
を意識しはじめた。その違いが、とりわけ重要になったのは、真空管を使っていた第1 世代の
コンピュータが、ソリッドステート機器を使う第2 世代で置き換えられたときである。ソリッ
ドステート機器（つまりトランジスタ）を使うことによってプロセッサのスピードが増したの
に、入出力装置のスピードは、ほとんど同じままだった。そこでアーキテクトたちは、入出力
とプロセッサの処理速度の不均衡を克服する方法を探索した。
1 つの優れたアプローチが生まれ、コンピュータアーキテクチャの革命をうながし、それに
よって第3 世代のコンピュータが誕生した。
「割り込み」と呼ばれるその機構は、いまではプ
hi.0412.ko.2002@gmail.com
　16.10
割り込み駆動の入出力
311
ロセッサ設計の標準になっている。
「割り込み駆動の入出力」の優位性は明らかだ。プロセッサは、ポーリングで時間を浪費する
かわりに、I/O デバイスの処理中にも計算を実行し続けることができる。デバイスが処理を終
えたら、そのことをデバイスからプロセッサに知らせて、プロセッサがデバイスを扱えるよう
にする。
「割り込み」という名前が示唆するように、進行中の計算は、入出力を扱うため、ハー
ドウェアによって一時的に割り込まれる。いったんデバイスに対するサービスを終えたら、プ
ロセッサは、割り込まれたその場所から、計算を再開することができる。
実際に割り込み駆動の入出力を行うには、コンピュータシステムのあらゆる側面を、割り込
みをサポートするように設計しなければならない。それには次のものが含まれる。
•
I/O デバイスのハードウェア
•
バスのアーキテクチャと機能
•
プロセッサのアーキテクチャ
•
プログラミングのパラダイム
I/O デバイスのハードウェア
割り込み駆動のI/O デバイスは、ただプロセッサの制御にしたがって動くのではなく、いっ
たん起動されたら独立して稼働する必要がある。その後、
処理を終えたら、
デバイスはプロセッ
サに割り込みをかけるのだから、その能力も必要である。
バスのアーキテクチャと機能
バスは、双方向の通信をサポートしなければならない。それによってプロセッサは、デバイ
スに処理の開始を指示することができ、デバイスは、処理が完了したときプロセッサに割り込
むことができる。
プロセッサのアーキテクチャ
プロセッサは、通常の計算処理を一時的に「サスペンド」
（保留）し、デバイスを扱ってか
ら、元の計算を「レジューム」
（再開）することが可能でなければならない。
プログラミングのパラダイム
おそらくもっとも重要な変化は、プログラミングパラダイムのシフトに関するものだ。ポー
リングにはシーケンシャルで「同期式」なプログラミングを使い、プログラマはI/O デバイス
が実行する処理をステップごとに指定する。しかし次の章で見るように、割り込み駆動のプロ
グラミングでは「非同期式」のプログラミングを使い、プログラマはイベント処理のコードを
書く。
hi.0412.ko.2002@gmail.com
312
第16 章
プログラム駆動と割り込み駆動の入出力　
16.11 　割り込み機構と「フェッチ‒ 実行」サイクル
「割り込み」という言葉が示唆するように、デバイスの「イベント」は一時的なものだ。デ
バイスがサービスを必要とするとき（たとえば処理が完了したとき）
、そのデバイスのハード
ウェアは、バスを介してプロセッサに割り込み信号を送る。プロセッサは命令の実行を一時的
に中断し、あとで実行を再開できるように必要な情報を保存してから、デバイスを処理する。
割り込み処理を終えたら、プロセッサは保存した情報を再びロードして、割り込みが発生した
その地点から、実行を再開する。
割り込み機構は、プロセッサを一時的に借りて、I/O デバイスを処理させる。割り込み
が発生すると、ハードウェアが計算の状態を保存し、割り込み処理が終わったら、その
計算を再開する。
アプリケーションプログラマから見ると、割り込みは「透明」である。つまり、プログラマ
は、割り込みなど存在しないかのようにアプリケーションを書くことができる。命令の実行中
に割り込みが発生しなくても、1 度発生しても、何度も発生しても、同じ計算結果が得られる
ようにハードウェアが設計される。
ハードウェアは、どうやってプロセッサに割り込むのだろうか。デバイスは、ただサービス
を要求するだけだ。割り込みの実装は、
「フェッチ‒ 実行」サイクルに変更を加えて、プロセッ
サが要求に応答できるようにするのだ。アルゴリズム16‒1 が示すように、割り込みは2 つの
命令実行の間に発生する。
アルゴリズム16‒1：割り込みを扱う「フェッチ‒ 実行」サイクル
永遠に繰り返す{
テスト: もしデバイスから割り込みを要求されていたら、
その割り込みを処理してから、ループの次の繰り返しに進む。
フェッチ: プログラムが格納された場所から、プログラムの次のステップを取り出す。
実行: プログラムのステップを実行する。
}
16.12 　割り込み処理
割り込みを処理するために、プロセッサのハードウェアは図16‒2 にあげる5 つのステップ
を実行する。
状態の保存と復旧は、もっとも理解しやすい。ハードウェアは、割り込みが発生したときに
情報を（普通はメモリに）保存する。そして特別な「割り込みからのリターン」命令を実行す
ると、状態が再びロードされる。アーキテクチャによっては、すべての汎用レジスタの内容を
含む完全な状態情報を保存するものがある。他のアーキテクチャでハードウェアが保存するの
hi.0412.ko.2002@gmail.com
　16.13
割り込みベクトル
313
は、命令カウンタのような基本情報だけで、汎用レジスタなどの値を保存しリストアするなら、
ソフトウェアで明示的に行う必要がある。いずれにしても、状態の保存と復旧は対称的な演算
だ。割り込みからのリターンを行う命令では、割り込み発生時にハードウェアが保存したのと
まったく同じ情報が復旧される。そのことをわれわれは、プロセッサは割り込みを処理すると
き一時的に「実行コンテクスト」を切り替える、と表現している。
•
現在の実行状態を保存する
•
どのデバイスからの割り込みか判定する
•
そのデバイスを扱う関数を呼び出す
•
バス上の割り込み信号をクリアする
•
現在の実行状態をリストア(復旧) する
図16‒2：プロセッサのハードウェアが割り込みを処理するために実行する5 つのステップ。これらのステッ
プはプログラマからは隠される
16.13 　割り込みベクトル
プロセッサは、どうやって割り込みをかけたデバイスを特定するのだろうか。それには、い
くつかの機構が使われる。たとえば、ある種のアーキテクチャは、すべての入出力を処理する
ために特殊用途のコプロセッサを使う。デバイスを始動するとき、プロセッサは、そのコプロ
セッサに要求を送る。デバイスがサービスを必要とするときは、コプロセッサが状況を検出し
て、プロセッサに割り込みをかける。
ほとんどのアーキテクチャは、
バス上の制御信号を使って、
割り込みが必要なことをプロセッ
サに知らせる。プロセッサは、
「フェッチ‒ 実行」サイクルを繰り返すたびにバスをチェック
する。割り込み要求を検出したら、プロセッサの割り込みハードウェアが特別なコマンドをバ
スに送って、どのデバイスがサービスを必要としているのかを判定する。バスで同時に応答で
きるのは、1 個のデバイスに限られる。典型的には、それぞれのデバイスにユニークな番号が
割り当てられ、デバイスは自分の番号を返すことによって応答する。
デバイスに割り当てる番号は、ランダムではない。デバイスの番号は、プロセッサのハード
ウェアが、メモリ内の予約された領域にあるポインタ配列のインデックスとして解釈できるよ
うになっている。その配列の項目は「割り込みベクトル」と呼ばれるもので、そのデバイスを
処理するソフトウェアへのポインタである。これによって割り込みは「ベクトル化」され、ベ
クトルが指し示すソフトウェアは「割り込みハンドラ」と呼ばれる。図16‒3 に、そのデータ
構造を示す。
この図が示すのは、個々の物理デバイスにユニークな割り込みベクトルが割り当てられる、
もっとも単純な割り込みベクトルの配置である。実際には、数多くのデバイスを使えるように
設計されたコンピュータシステムでは、複数のデバイスが同じ割り込みベクトルを共有するこ
hi.0412.ko.2002@gmail.com
314
第16 章
プログラム駆動と割り込み駆動の入出力　
メモリに並ぶ
割り込みベク
トル
デバイス3の
ハン
ドラ
デバイス2の
ハン
ドラ
デバイス1の
ハン
ドラ
デバイス0の
ハン
ドラ
3
2
1
0
図16‒3：メモリに並ぶ割り込みベクトルは、それぞれのデバイスの割り込みハンドラへのポインタである
とが多い。その場合は割り込み発生後に、割り込みハンドラのコードが再びバスを使って、ど
の物理デバイスから来た割り込みかを判定する。いったん物理デバイスを特定したら、ハンド
ラは、そのデバイスに適した処理を選択する。割り込みベクトルを複数のデバイスで共有する
ことの利点は、スケーリングである。つまり、固定数の割り込みベクトルを持つプロセッサが、
任意の数のデバイスを扱えるようになるのだ。
16.14 　割り込みの初期化と禁止
割り込みベクトルのテーブルに、どうやって値を記入するのだろうか。割り込みベクトルは
ソフトウェアが初期化しなければならない。プロセッサもデバイスのハードウェアも、この
テーブルに記入せず、書き換えることもない。ハードウェアは、割り込みベクトルが初期化さ
れていることを前提とするのだ。割り込みが発生したら、プロセッサは状態を保存し、バスを
使ってベクトル番号を要求し、その番号をインデックスとしてベクトルのテーブルを参照し、
そのアドレスのコードに分岐する。プロセッサは、ベクトルに書かれていたアドレスが何であ
れ、そのアドレスにジャンプして、そこから命令を実行しようとする。
テーブルを初期化する前に割り込みが発生することがないように、ほとんどのプロセッサは
割り込みを「禁止」したモードで実行を開始する。つまりプロセッサは割り込みをチェックす
ることなく「フェッチ‒ 実行」サイクルの実行を続ける。あとで、プロセッサが（通常はOS
が）割り込みベクトルの初期化を終えたら、ソフトウェアの命令で明示的に、割り込みを「許
可」する。多くのプロセッサでは、割り込み状態がプロセッサの「モード」によって制御され
る。プロセッサが最初のスタートアップモードから、プログラムの実行に適したモードに切り
替わると、割り込みは自動的に許可される。
hi.0412.ko.2002@gmail.com
　16.15
割り込みハンドラへの割り込み
315
16.15 　割り込みハンドラへの割り込み
いったん割り込みが発生して、割り込みハンドラが走っているときに、もし他のデバイスの
準備ができて割り込みを要求したら、どうなるのだろうか。もっとも単純なハードウェアは単
純明快なポリシーにしたがう。つまり、いったん割り込みが発生したら、現在の割り込み処理
が完了してリターンするまで、割り込みは自動的に禁止される。したがって、混乱は起こりよ
うがない。
もっとも洗練されたプロセッサは、
「複数レベルの割り込み機構」を提供する。これは「複
数の割り込み優先順位」とも表現され、どのデバイスにも割り込みの優先順位あるいはレベル
（典型的には1 から7 の範囲）が割り当てられる。プロセッサは、いつでも、どれか1 つの優
先順位で実行される。優先順位が0 ならば、プロセッサは現在割り込みを処理していない（つ
まり、アプリケーションを実行している）
。0 より大きなN のレベルにあるとき、プロセッサ
は、レベルN が割り当てられたデバイスからの割り込みを処理している。
ルールをまとめると次のようになる。
優先レベルK で動作しているとき、プロセッサは、K ＋1 よりも高いレベルが割り当て
られたデバイスだけから、割り込みを受ける。つまり、すでにレベルがK の割り込みが
発生していれば、レベルがK 以下の割り込みは起こらない。その結果、それぞれのレベ
ルで同時に進行できる割り込みは、多くても1 個である。
16.16 　割り込みの設定
前述したように、どのデバイスにも割り込みベクトルを、
（そして可能ならば割り込みの優先
順位も）割り当てる必要がある。デバイスのハードウェアも、プロセッサで実行されるソフト
ウェアも、その割り当てに関して同意していなければならない。デバイスが割り込みベクトル
の番号を返すとき、それに対応する割り込みベクトルは、そのデバイスのハンドラを指してい
なければならない。
割り込みの割り当ては、どうやって行うのか。2 つのアプローチが使われてきた。
•
手動割り当て：小規模な埋め込みシステムに限られる
•
自動割り当て：ほとんどのコンピュータシステムで使われる
手動割り当て
初期のコンピュータで使われた方法だが、小規模な埋め込みシステムでは、いまも使われて
いる。手動割り当てでは、コンピュータの所有者がハードウェアとソフトウェアの両方を設定
する。たとえば、一部のデバイスは回路基板上に物理的なスイッチを付けて製造され、そのス
イッチを使って割り込みベクトルの番号を入力する。もちろんオペレーティングシステムも、
hi.0412.ko.2002@gmail.com
316
第16 章
プログラム駆動と割り込み駆動の入出力　
デバイス側で選んだ値と一致するように設定する必要がある。
自動割り当て
自動的に割り込みベクトルを割り当てるのが、もっとも広く採用されているアプローチだ。
そうすれば手動設定を避けることができ、デバイスはハードウェアを変更する必要なしにイン
ストールできる。プロセッサは、起動時にバスを使って、どういうデバイスが接続されている
かを判定する。そしてプロセッサが、それぞれのデバイスに割り込みベクトル番号を割り当て、
適切なデバイスハンドラのソフトウェアをメモリにコピーして、割り込みベクトルをメモリ上
に構築する。もちろん、自動的な割り当てを行うことによって、コンピュータが起動するまで
の遅延は長くなる。
16.17 　動的バス接続と挿抜可能なデバイス
バスと割り込みに関するこれまでの記述では、コンピュータの電源が落ちているときにデバ
イスがバスに接続されること、割り込みベクトルが起動時に割り当てられること、そしてコン
ピュータが動いている間、すべてのデバイスがそのまま接続されていることを前提としていた。
実際、初期のバスは、この記述通りに設計されていた。けれども、最近のバスはコンピュータの
実行中にデバイスを抜き差しできるように作られている。そのようなバスは「挿抜可能な」デ
バイスをサポートするのだ。たとえば「USB」
（Universal Serial Bus）は、いつでもユーザー
がデバイスを装着できるように作られている。
USB は、どのような仕組みで動作するのだろうか。基本的にUSB は、コンピュータのメイ
ンバス上の、1 個のデバイスのように見える。コンピュータの起動時に、USB には通常通りに
割り込みベクトルが割り当てられ、そのハンドラがメモリに置かれる。その後、ユーザーが新
しいデバイスを装着すると、USB のハードウェアが割り込みを生成し、プロセッサがハンドラ
を実行する。そのハンドラは、USB バス経由で要求を送って、デバイスの問い合わせを行い、
どんなデバイスが装着されたのかを判定する。いったんデバイスを識別できたら、USB ハンド
ラが、2 次的なデバイス固有のハンドラをロードする。デバイスはサービスを必要とするとき、
割り込みを要求する。USB ハンドラが割り込みを受け、どのデバイスが割り込んだのかを判定
し、制御をデバイス固有のハンドラに渡す。
16.18 　割り込みと性能とスマートデバイス
なぜ割り込み機構がコンピュータアーキテクチャに革命を起こしたのだろうか。答えは簡単
だ。まず、入出力はコンピュータにとって重要な側面で、最適化する必要がある。第2 に、割
り込み駆動の入出力なら、プログラマが特別な処置を講じる必要なしに、計算処理と入出力処
理が自動的に重複する。割り込みは、どんなスピードのプロセッサにもI/O デバイスにも、自
動的に適合する。入出力処理の間に、どれだけの命令を実行できるかをプログラマが見積もる
hi.0412.ko.2002@gmail.com
　16.18
割り込みと性能とスマートデバイス
317
必要がないのだから、割り込みには過小評価も過大評価もない。
割り込みを使うコンピュータは、ポーリングを使うコンピュータよりも、プログラミン
グしやすく、全体の性能も高くなる。さらに、割り込み処理は、どんなスピードのプロ
セッサにも、どんなスピードのI/O デバイスにも、自動的に適合する。
興味深いことに、いったん基本的な割り込み機構が発明されると、アーキテクトたちは、さら
なる改良が可能であることに気付いた。その改良を理解するために、ディスクデバイスについ
て考えよう。ディスクからデータを読み出してメモリに置くためには、根底にあるハードウェ
アで、いくつかのステップが必要だ。図16‒4 に、そのステップを要約する。
•
ディスクがスピンしていなければ、フルスピードになるまで回転を加速する。
•
要求されたブロックが存在するシリンダ(トラック) を計算し、ディスクのアームを、
そのシリンダまで動かす。
•
ディスクが正しいセクタまで回転するのを待つ。
•
ディスクから1 ブロックのデータを読み出し、それをハードウェアのFIFO に置く。
•
FIFO からメモリにバイトデータを転送する。
図16‒4：ディスクドライブから1 ブロックのデータを読むのに必要なステップ
初期のハードウェアでは、プロセッサが上記のステップを、まず処理を開始させ、それから
割り込みを待つという具合に、1 つずつ処理しなければならなかった。たとえばプロセッサは、
ディスクがスピンしていることを確認し、もしディスクがアイドル状態だったら、まずプロセッ
サがモーターを始動するコマンドを発行して、割り込みを待たなければならなかった。
そこで鍵となったのは、I/O デバイスにもっとデジタル論理を入れれば、デバイスがプロセッ
サに頼る必要性を減らせるだろう、という洞察だ。プロセッサに、個々のステップを処理して
もらわなければならないデバイスのことを、アーキテクトは非公式に「ダムデバイス」と呼び、
一連のステップを自分で実行できるデバイスを「スマートデバイス」と呼んだ。ディスクデバ
イスのスマートなバージョンには、ブロックの読み込みに関わる全部のステップを処理するの
に十分なロジックが（もしかしたら埋め込みプロセッサが）入っている。したがってスマート
デバイスは、それほど頻繁に割り込みをかけず、プロセッサが個々のステップの面倒を見る必
要がなくなる。図16‒5 は、プロセッサとスマートなハードディスク装置の間で交わされるや
りとりの例である。
デバイスとの相互作用の記述では、多くの詳細を省いた。たとえば、ほとんどのI/O デバイ
スは、エラーを検出して報告する。ディスクが回転しないとか、ディスクの表面（プラッタ）
に欠陥があってハードウェアがディスクブロックを読み出せない、などのエラーだ。したがっ
て、割り込み処理は、先ほど記述した内容よりも複雑である。割り込みが起きたら、プロセッ
サはディスクに割り当てたCSR を問い合わせて、処理が成功したのか、それともエラーが起き
hi.0412.ko.2002@gmail.com
318
第16 章
プログラム駆動と割り込み駆動の入出力　
たのかを判定する。それだけでなく、デバイスが「ソフトエラー」
（データエラーなど）を報告
する場合、プロセッサは、その処理をリトライして、エラーが一時的なものか、それとも永続
的かを判断しなければならない。
•
プロセッサがバスを使ってディスクにメモリ内の場所を指定し、リード演算を要求
する。
•
ディスクデバイスが、すべてのステップを実行する。それにはバイトデータをメモリ
に移動する処理も含まれ、割り込みは処理が完了したときにだけ発行する。
図16‒5：ディスクのブロックを読み出すときの、プロセッサとスマートディスク装置の相互作用
16.19 　DMA
上記の議論は、スマートなI/O デバイスがCPU を使わずにデータをメモリに転送できるこ
とを示唆していた。事実、そのような転送は可能であり、高速入出力の鍵となっている。I/O
デバイスがメモリと相互作用を行えるようにするテクノロジーは、
「DMA」
（Direct Memory
Access）と呼ばれている。
DMA を理解するために、ほとんどのアーキテクチャにおいて、メモリとI/O デバイスの両
方が中心的なバスに接続されていることを思い出そう。したがって、I/O デバイスとメモリの
間には直接的な経路がある。スマートデバイスにプロセッサが埋め込まれていると想像したら、
DMA の背後にあるアイデアが明らかになるだろう。I/O デバイスに入っている埋め込みプロ
セッサは、フェッチまたはストアの要求を出し、メモリがそれに応答する。もちろんバスは、
複数のプロセッサが（メインのプロセッサと、個々のスマートデバイスに入っている埋め込み
プロセッサが）順番にバスを共用できるように、しかも複数の要求を同時に送信できないよう
に、設計しなければならない。このような機構をバスがサポートしていれば、I/O デバイスは
メモリとデバイスの間でプロセッサを使うことなくデータを転送できる。
要約しておこう。
DMA と呼ばれるテクノロジーによって、スマートデバイスはメモリを直接アクセスす
ることができる。DMA を使うデバイスは、デバイスとメモリの間でプロセッサを使わ
ずにデータを転送できるので、性能が向上する。
16.20 　バッファの連鎖によるDMA の拡張
高性能を保証するには、DMA を使うスマートデバイスで十分だと思われたかもしれない。プ
ロセッサを使わずに、デバイスとメモリとの間でデータを転送でき、デバイスは処理のステッ
プごとに割り込みをかける必要がないのだから。けれども、さらに性能を向上させる最適化の
hi.0412.ko.2002@gmail.com
　16.20
バッファの連鎖によるDMA の拡張
319
技法が発見されている。
どうすればDMA を改善できるのかを理解するために、高速ネットワークを考えよう。ネッ
トワークからのパケットは、しばしば「バースト」の状態で配送される。つまり一群のパケッ
トが、ほとんど間を置かずに、連続するパケット間の時間が最小の状態で届くのだ。もしネッ
トワークインターフェイス装置がDMA を使うのなら、そのデバイスは受信した1 個のパケッ
トをメモリに置くとプロセッサに割り込みをかけるだろう。プロセッサは、次のパケットに使
うバッファの位置を指定して、デバイスを再び始動する必要がある。このイベントシーケンス
は、
（次のパケットが到着する前に）素早く発生する必要がある。ところが残念なことに、シス
テムに存在する他のデバイスも割り込みをかけるかもしれず、そうなるとプロセッサの処理が
少し遅れるかもしれない。高速ネットワークでは、プロセッサは、次のパケットのキャプチャ
に間に合う時間で割り込みをサービスできないかもしれない。
このように、データが連続して届く場合の問題を解決するために、ある種のスマートI/O デ
バイスは、
「バッファの連鎖」と呼ばれるテクニックを使う。プロセッサは複数のバッファを割
り当てて、メモリに「連結リスト」を作る。そしてプロセッサは、そのリストをI/O デバイス
に渡し、デバイスがそれぞれのバッファに記入できるようにする。スマートデバイスは、バス
を使ってメモリから値を読み出せるので、連結リストを辿って、それに続く次のバッファに受
信中のパケットを置くことができる。図16‒6 に、このコンセプトを示す1。
デバイスに渡されるア
ドレス
データバッ
ファ 1 
データバッ
ファ 2 
データバッ
ファ 3
図16‒6：バッファの連鎖。プロセッサはバッファのリストをスマートI/O デバイスに渡す。そしてデバイ
スは、プロセッサを待つことなく、リストのそれぞれのバッファを埋めていく
上記のネットワークの例は、バッファの連鎖を高速な入力に使うものだが、バッファの連鎖
は出力にも使える。プロセッサはデータを一連のバッファに置き、それらのバッファを連結リ
ストにして、そのアドレスをスマートI/O デバイスに渡して起動をかける。するとデバイスは
リストを辿って、メモリ内のバッファから次々にデータを取り出しながら、データの出力処理
を行うことができる。
1　この図では3 個のバッファを示しているが、ネットワークデバイスでは普通、32 個か64 個のバッファ
を連鎖する。
hi.0412.ko.2002@gmail.com
320
第16 章
プログラム駆動と割り込み駆動の入出力　
16.21 　スキャッターリードとギャザーライト
とくにバッファの連鎖が有効なのは、I/O デバイスで使われるデータブロックのサイズより
も、ソフトウェアが使うバッファのほうが小さいコンピュータシステムである。バッファの連
鎖を入力に使うと、デバイスは大きな転送データを、より小さなバッファの集合に分割できる。
出力に使うと、デバイスは小さなバッファの集合から取り出したデータを組み合わせて、1 個
のブロックにすることができる。たとえば、OS がネットワークパケットを作るのに、パケッ
トのヘッダを1 つのバッファに置き、パケットのペイロードを別のバッファに置くことがあ
る。このようにバッファの連鎖を使えば、OS は、すべてのバイトを1 個の大きなバッファに
コピーすることなくパケットを送信できる。
われわれは、
入力データの大きなブロックを複数の小さなバッファに分ける手法を
「スキャッ
ターリード」と呼び、複数の小さなバッファからデータを集めて1 個の出力ブロックを作る手
法を「ギャザーライト」と呼んでいる。もちろん、バッファの連鎖を使うためには、出力バッ
ファの連結リストで各バッファのサイズ（データが何バイトあるのか）を指定する必要がある。
同様に、入力バッファの連結リストには、そのバッファに何バイト記入したかをデバイスが指
定できるように、長さのフィールドを入れなければならない。
16.22 　演算の連鎖
バッファの連鎖は、ある演算が多くのバッファで繰り返されるような状況を扱えるが、デバ
イスが多種類の演算を実行できる場合には、さらなる最適化が可能である。これを理解するた
めに、個々のブロックに対して「リード」と「ライト」の両方の演算が可能なディスクデバイ
スについて考えよう。性能を最適化するには、現在の演算が完了したら、すぐに次の演算を始
める必要がある。しかし残念ながら、その2 つの演算は、
「リード」と「ライト」なのだ。
遅延なしに新しい演算を開始させるのに使うテクノロジーは、
「演算の連鎖」と呼ばれる。演
算の連鎖を使うプロセッサは、バッファの連鎖と同じように、メモリに連結リストを作って、
そのリストをデバイスに渡す必要がある。ただしバッファの連鎖と違って、連結リストのノー
ドでは演算を完全に指定する。つまりノードはバッファポインタだけでなく、演算と、それに
必要なパラメータも指定するのだ。たとえばディスクに使うリストのノードは、
「リード」演
算とディスクのブロックを指定する。図16‒7 に、演算の連鎖の例を示す。
hi.0412.ko.2002@gmail.com
　16.23
まとめ
321
デバイスに渡すア
ドレス
データバッ
ファ 1 
データバッ
ファ 2 
データバッ
ファ 3
R
17
W 29
61
R
図16‒7：スマートディスクドライブ用の演算の連鎖。それぞれのノードで、演算(R またはW) と、ディス
クのブロック番号と、メモリ内のバッファを指定する
16.23 　まとめ
入出力装置（I/O デバイス）を扱う方法には、プログラム駆動の入出力と、割り込み駆動の
入出力という、2 つのパラダイムがある。プログラム駆動の入出力では、プロセッサが演算の
各ステップを主導し、デバイスをポーリングする必要がある。プロセッサはI/O デバイスより
も、はるかに高速なので、デバイスを待つ間にプロセッサは大量のサイクルを費やす。
第3 世代のコンピュータで導入された割り込み駆動の入出力において、デバイスはプロセッ
サに通知を送る前に処理を完結できる。割り込みを使うプロセッサは、追加のハードウェアに
よって「フェッチ‒ 実行」サイクル毎に割り込みを要求したデバイスの有無をチェックする。
割り込みはベクトル化される。つまり、割り込みをかけるデバイスがユニークな整数を提供
し、プロセッサはその数をインデックスとして、ハンドラを指すポインタの配列を参照する。
割り込みが実行中のプログラムに影響をおよぼすことがないように、ハードウェアは割り込み
に際して状態の情報を保存し、それを復旧する。複数レベルの割り込みを使うと、デバイスに
優先順位を付けることができる。
スマートなI/O デバイスには、プロセッサからの援助なしに一連のステップを実行できるロ
ジックが追加されている。スマートデバイスの性能は、バッファの連鎖、演算の連鎖というテ
クニックを使って、さらに最適化できる。
練習問題
16.1
仮に、あるRISC プロセッサが1 命令を実行するのに2 マイクロ秒かかり、ある
I/O デバイスは割り込みがサービスされるまで、最大1 ミリ秒しか待てないとします。
割り込みを禁止して実行できる最大の命令数は、いくつですか?
16.2
2 種類の入出力パラダイムとは、何と何ですか? 違いを説明してください。
16.3
CSR は何を略した用語ですか? それは、どういう意味ですか。
16.4
あるソフトウェア技術者が、デバイスドライバをデバッグしようとしています。そ
して、無限ループらしいものを見つけました。
hi.0412.ko.2002@gmail.com
322
第16 章
プログラム駆動と割り込み駆動の入出力　
while (*csrptr->tstbusy != 0)
; /* do nothing*/
このコードを見せられたら、どんな対応をしますか?
16.5
バス上のデバイスのそれぞれに対する割り込み優先順位の割り当てについて、調べ
ましょう。ディスクとマウスでは、どちらが優先されていますか? その理由は?
16.6
ほとんどのシステムで、デバイスドライバのコードは、全部あるいは一部をアセン
ブリ言語で書く必要があります。なぜでしょう。
16.7
割り込みベクトルは、概念として、どのようなデータ構造になっていますか。割り
込みベクトルの各エントリには、何が入っていますか?
16.8
演算の連鎖を使うデバイスの、最大の利点は何ですか?
16.9
ポーリングと比較するとき、割り込みの主な利点は何ですか?
16.10
ユーザーがデバイスを10 個インストールしたと仮定します。それらのデバイス
は、どれも1 個のコンピュータに対してDMA を実行するもので、複数のデバイスを
同時に操作しようとします。そのコンピュータでボトルネックになりそうなのは、ど
のコンポネントですか?
16.11
スマートディスクデバイスがDMA を使い、ディスクのブロックに、それぞれ512
バイトが含まれるとしたら、プロセッサが2048 バイト（ブロック4 個分）を転送す
るとき、そのディスクは何回割り込みをかける必要があるでしょうか?
16.12
デバイスが連鎖を使うとき、デバイスドライバがメモリに置いて、一連のコマン
ドをデバイスに送るデータ構造は、どのような型ですか?
hi.0412.ko.2002@gmail.com
第17 章
デバイスと入出力とバッファの
プログラミング
17.1 　はじめに
これまでの章では入出力のハードウェア面を扱った。そこではデバイス、プロセッサ、メモ
リを相互接続するのに使われるバスのアーキテクチャや、外部デバイスがプロセッサに処理の
完了を知らせる割り込みの機構を説明した。
この章では主題をソフトウェアに切り替えて、プログラマの視点から入出力を考察する。デ
バイスを制御するのに必要なソフトウェアと、入出力機能を使うアプリケーションソフトウェ
アの、両方の面を調べよう。デバイスドライバの重要なコンセプトを理解して、
「リード」や
「ライト」のような演算をドライバがどのように実装するかを把握しよう。デバイスは、バイト
指向とブロック指向の2 つに分類できる。それぞれに対して行われる相互作用も理解しよう。
デバイスドライバを書くプログラマは数少ないが、デバイスドライバがどんな処理をして、
低いレベルのI/O がどのように発生するかを理解したプログラマは、より効率の良いアプリ
ケーションを書けるようになる。デバイスドライバの機構を見た後は、バッファリングのコン
セプトに注目し、なぜプログラマにとってバッファを使うことが重要なのかを理解しよう。
17.2 　デバイスドライバの定義
前章では基本的なハードウェア割り込みの機構を説明した。その割り込み機構を使って入出
力を実行する、低いレベルのソフトウェアについて、これから考えていこう。アプリケーショ
ンプログラムと外部のハードウェア機器との間にインターフェイスを提供するソフトウェアは、
「デバイスドライバ」と呼ばれる。たいがいのコンピュータシステムは外部デバイスごとに1 つ
のデバイスドライバを持ち、そのデバイスをアクセスするアプリケーションは、どれも同じド
ライバを使う。デバイスドライバは、コンピュータのOS の一部になるのが典型的だから、そ
のコンピュータで実行されるアプリケーションは、デバイスと交信するときに必ずデバイスド
hi.0412.ko.2002@gmail.com
324
第17 章　デバイスと入出力とバッファのプログラミング　
ライバを使うことになる。
デバイスドライバは、特定のハードウェア機器の詳細を理解しているのだから、ドライバに
は「低いレベルのコード」が含まれている。ドライバはバスを通じてデバイスとの相互作用を
行い、デバイスの「CSR」を理解し、デバイスからの割り込みに対処する。
17.3 　デバイスに依存しない：カプセル化と隠蔽
デバイスドライバの主目的は「デバイスに依存しないこと」1である。つまり「アプリケー
ションプログラムからハードウェアの詳細をすべて取り去れ、それらはドライバに任せよ」と
いうのが、デバイスドライバのアプローチだ。
デバイスに依存しないことが、なぜ重要なのか。それを理解するには、初期のソフトウェア
が、どのように構築されたかを知る必要がある。アプリケーションプログラムが、それぞれ特
定のブランドのコンピュータで特定のメモリサイズを使い、入出力機器の特定の集合を使うよ
うに設計されていた時代である。アプリケーションには、そのコンピュータのバスを使って特
定の機器と通信するのに必要なコードが、すべて含まれていた。特定の機器を使うように書か
れたプログラムは、他の機器で使うことができない。たとえばプリンタを新しいモデルにアッ
プグレードするには、すべてのアプリケーションを描き直す必要があった。
この問題を解決するために、デバイスドライバは、
「デバイスに依存しない」インターフェイ
スをアプリケーションに提供する。たとえばプリンタを使うすべてのアプリケーションが、そ
のプリンタのデバイスドライバに依存するので、アプリケーションは組み込まれているハード
ウェアについて詳細な知識を持たない。その結果、プリンタを交換しても、必要なのはデバイ
スドライバの交換で、すべてのアプリケーションは、そのままでよい。このことを、われわれ
の用語では、デバイスドライバがアプリケーションから詳細を「隠蔽する」‒ あるいは、デバ
イスドライバがハードウェアの詳細を「カプセル化する」
、と表現する。
要約しておこう。
デバイスドライバは、ある特定のデバイスと低いレベルで行う通信の詳細を、すべて理
解して処理するソフトウェアで構成される。デバイスドライバは、アプリケーションに
高いレベルのインターフェイスを提供するので、もしデバイスが変更されても、アプリ
ケーションプログラムを書き換える必要はない。
1　訳注：
「デバイスに依存しないこと」
（device independence）という言葉の意味は、
「アプリケーション
ソフトウェアを、デバイスに多少の違いがあっても使えるようにすること」
、別の言い方をすれば「デバイス
のハードウェアの差異を吸収すること」である。
「デバイス独立」などの訳語も使われる。
hi.0412.ko.2002@gmail.com
　17.4
デバイスドライバの構成
325
17.4 　デバイスドライバの構成
デバイスドライバの機能は、バスを介して通信を行うコード、デバイスの詳細を扱うコード、
アプリケーションとのやりとりを行うコードの共同作業で実装される。さらに、デバイスドラ
イバは、コンピュータのOS とも、やりとりを行う必要がある。この複雑さを緩和するため、プ
ログラマはデバイスドライバを3 つに分けて考える：
•
「下層」には、割り込みが発生したときに呼び出されるハンドラがある。
•
「上層」には、入出力処理を要求するアプリケーションによって呼び出される関数群
がある。
•
「共有変数群」には、下層と上層が協調するための、状態を表す情報が格納される。
「上層」とか「下層」とかいう呼び名には、デバイスドライバを書くプログラマの視点が反
映されている。つまりプログラマは、ある階層構造の最上位にアプリケーションがあり、最下
位にハードウェアがあると考えるのだ。図17‒1 に、プログラマから見た構成図を示す。
アプリケーシ
ョ
ンプログラム
上層
：
 
アプリケーシ
ョ
ンから
呼び出される
共有変数群
下層:
割り込みによって
呼び出される
デバイスのハー
ドウェア
図17‒1：デバイスドライバを3 つの部分に分ける、概念的な構成図。デバイスドライバは、高いレベルで
アプリケーションとのインターフェイスを提供し、低いレベルでデバイスのハードウェアとのインターフェ
イスを提供する
hi.0412.ko.2002@gmail.com
326
第17 章　デバイスと入出力とバッファのプログラミング　
17.5 　デバイスの分類（キャラクタ指向とブロック指向）
デバイスドライバについて、さらに理解を深めるには、その前にハードウェアがドライバに
提供するインターフェイスについても知っておく必要がある。デバイスは、大きく分類すると、
デバイスが使うインターフェイスの形式によって、次の2 つにわかれる。
•
キャラクタ指向のデバイス
•
ブロック指向のデバイス
キャラクタ指向のデバイス
データを1 バイトずつ転送する。たとえばキーボードをコンピュータに繋ぐのに使われるシ
リアルインターフェイスは、1 つキーが押されるたびに、1 キャラクタ（1 バイト）を転送す
る。デバイスドライバの視点から見ると、キャラクタ指向のデバイスは、1 キャラクタの送信
または受信を行うたびに1 回の割り込みを生成する。N 個のキャラクタで構成されるデータブ
ロックを送信または受信する際は、N 回の割り込みが発生するわけだ。
ブロック指向のデバイス
ブロック全体のデータを一度に転送する。根底にあるハードウェアによってブロックサイズ
B が定まり、すべてのブロックが必ずB 個のバイトを含むという場合もある。たとえばディス
クドライブは、ディスクのセクタサイズに等しいブロックサイズを定義する。しかし他の場合
では、ブロックのサイズは可変である。たとえばネットワークインターフェイスはブロックを、
パケットと同じ大きさと定義する（パケットサイズには上限を設定するが、パケット交換のソ
フトウェアは、パケット毎にサイズが異なるのを認める）
。デバイスドライバから見ると、ブ
ロック指向のデバイスは、1 個のブロックを送信あるいは受信するたびに、1 回の割り込みを
生成する。
17.6 　デバイスドライバにおける制御の流れ
デバイスドライバプログラミングの詳細は、本書で扱う範囲を超える。しかしコンセプトを
理解しやすいように、デバイスドライバがどのように基礎的な出力を扱うかを考えてみよう。
例として、アプリケーションがデータをインターネット越しに送信する場合を想定する。アプ
リケーションが、送信すべきデータを指定する。プロトコルソフトウェアがパケットを作成し、
そのパケットをネットワークデバイス用のデバイスドライバに転送する。図17‒2 に、パケッ
ト転送に関わるモジュール群を示し、出力を行うステップをリストにする。
この図が示すように、単純明快な処理にも一連の複雑なステップが必要となる。アプリケー
ションがデータを送るとき、そのアプリケーションのプロセスはOS に入り、そこで制御はパ
ケットを作成するプロトコルソフトウェアに渡る。プロトコルソフトは、送信すべきパケット
hi.0412.ko.2002@gmail.com
　17.6
デバイスドライバにおける制御の流れ
327
アプリケーシ
ョ
ンがインターネッ
トを越えるデータを送信
プロ
トコルソフ
トがパケッ
トを
ドライバに渡す
ドライバが送信パケッ
トを共有変数に格納
上層がパケッ
トの場所を指定してデバイスを起動
上層からプロ
トコルモジュールに戻る
プロ
トコルソフ
トからアプリケーシ
ョ
ンに戻る
デバイスが割り込みをかけ、
ドライバ下層が実行される
下層がパケッ
トのコピーを共有変数から削除する
コンピュータ
アプリケーシ
ョ
ン
プロ
トコル
ドライバ上層
共有変数
ドライバ下層
デバイス
外部のハー
ドウェア
OS
実行されるステ
ップ
図17‒2：アプリケーションが出力処理を要求するときに発生するステップを単純化した例。OS の中にある
デバイスドライバが、このデバイスとの全部の通信を処理する
を、適切なデバイスドライバの上層に渡す。デバイスドライバは、そのパケットを共有変数の
セクションに置き、デバイスにパケット転送の実行を開始させて、プロトコルソフトウェアに
リターンし、プロトコルソフトはアプリケーションのプロセスにリターンする。
これで制御はOS から戻るが、出力すべきパケットは、まだ共有変数のデータ領域に残って
いる。そのデータを、デバイスがDMA でアクセスする。いったんデバイスがパケット送信を
完了したら、デバイスからの割り込みによって、制御はデバイス下層に渡される。そのとき下
層は、パケットを共有領域から削除する。
hi.0412.ko.2002@gmail.com
328
第17 章　デバイスと入出力とバッファのプログラミング　
17.7 　キューを使う出力処理
サンプルのドライバに使った設計は実現可能だが、このアプローチは製品システムで使うに
は効率が悪すぎる。デバイスが最初のパケットを送信し終わる前に、アプリケーションが次の
パケットを送ろうとしたら、デバイスドライバはデバイスがパケットを使い終わるまでポーリ
ングを続けなければならない。その待ち状態を防ぐために、製品システムのデバイスドライバ
が実装するのが、
「リクエストキュー」
（要求の待ち行列）だ。出力時にドライバ上層はデバイ
スが「レディ」になるのを待つのではなく、その代わりに、出力すべきデータをキュー（待ち行
列）に入れ、必ずデバイスが割り込みを生成するように設定してからアプリケーションに戻る。
その後、デバイスが現在の処理を完了して割り込みを生成すると、下層がキューから次の要求
を取り出し、デバイスを始動して割り込みから戻る。図17‒3 に、その概念的な構成を示す。
上層
下層
共有変数のデータ領域にある
リクエス
トキュー
図17‒3：リクエストキューを使うデバイスドライバの概念的構成を示す。出力のとき、ドライバ上層はデバ
イスを待つことなく項目をキューに入れ、下層がデバイスを制御する
出力キューを使うデバイスドライバは、リクエストキューによってドライバの上層と下層が
協調するエレガントな設計である。出力時に上層と下層がしたがうステップを図17‒4 に示す。
この図が示すように、デバイスドライバの上層と下層で実行されるステップは単純明快だ。
ほとんどの仕事を下層で行っていることに注目しよう。下層は、デバイスからの割り込みを処
理するだけでなく、キューをチェックし、もしキューが空でなければ次の項目を取り出してデ
バイスを起動する。デバイスは処理を完了させるたびに割り込みをかけるので、下層は出力処
理ごとに1 回呼び出され、その機会に次の処理を開始させる。したがって下層はキューが空に
なるまで何度も繰り返し呼び出される。
キューから最後の要素を取り出した後は、どうなるのだろう。下層は、最後の出力処理が完
了した後に呼び出されるが、そのときはキューが空である。そこでデバイスはアイドル状態に
なる。無駄な割り込みを避けるために、下層はデバイスを制御して、すべての割り込みを止め
る。その後、アプリケーションが上層を呼び出して新しい項目をキューに入れるときに、上層
がデバイスの割り込みを再開して出力が進行する。
hi.0412.ko.2002@gmail.com
　17.8
デバイスに割り込みを強制する
329
初期化（コンピュータシステムが起動するとき）
1
出力キューを空の状態に初期化する
上層（アプリケーションが「write」を実行するとき）
1
データ項目をキューに入れる
2
CSR を使って割り込みを要求する
3
アプリケーションに戻る
下層（割り込みが発生したとき）
1
もしキューが空なら、デバイスに割り込みを停止させる
2
もしキューが空でなければ、項目を1 つ取り出して、出力を開始する
3
割り込みから戻る
図17‒4：キューイングを使って出力を処理するとき、デバイスドライバの上層と下層が実行するステップ。
上層は割り込みを強制するが、デバイスの出力を始動しない
17.8 　デバイスに割り込みを強制する
要求のキューが多くのデバイスドライバで使われるので、技術者たちは、図17‒4 で概要を
示したプログラミングパラダイムに適したハードウェアを、設計するようになった。とくに、
CSR に特別なビットを準備して、プロセッサがそのビットをセットすることで割り込みを強
制できるようにしたデバイスが多い。第16 章で述べたように、CSR のビットをセットする
コードは単純で、代入ステートメントを使えばよい。ソフトウェアがデバイスの現在の状態を
チェックする必要がないように、もしデバイスがアクティブ化されていたらビットをセットし
ても何の影響もない機構が設計されている。
•
デバイスのCSR にB というビットがあり、デバイスに割り込みを強制するのに使わ
れる。
•
もしデバイスがアイドル状態なら、ビットB をセットすれば、デバイスは割り込みを
生成する。
•
もしデバイスが現在処理中ならば、ビットB をセットしても影響はない。
言い換えると、もし現在の処理が完了したら割り込みをかけるように設定済みなら、そのデ
バイスは処理の完了を待って、通常通りに割り込みを生成する。もし進行中の処理がなければ、
デバイスは即座に割り込みを生成する。つまり、割り込みを強制するCSR ビットをセットし
ても、そのときビジーなデバイスには、処理が完了するまで影響を与えないのである。この工
夫のおかげで、ずいぶんプログラミングが単純化される。その理由は、図17‒4 のリストを見
ればわかるはずだ。デバイスドライバの上層は、デバイスがビジーかどうか（つまり処理が進
hi.0412.ko.2002@gmail.com
330
第17 章　デバイスと入出力とバッファのプログラミング　
行中か否か）
、テストする必要がない。かわりに上層は、常にCSR ビットをセットする。もし
処理がすでに進行中なら、デバイスのハードウェアは、ビットがセットされても無視して処理
の完了を待つ。もしデバイスがアイドル状態なら、ビットがセットされたら即座に割り込みを
かける。それによってドライバ下層はキューから次の要求を取り出してデバイスを起動する。
17.9 　キューを使う入力処理
デバイスドライバでは入力にキューを使うこともできる。ただし、2 つの理由から、さらに
調整が必要となる。第1 に、アプリケーション側で入力を読む準備ができる前に、デバイスド
ライバを、入力を受け取れるように設定する必要がある（たとえば、ユーザーが事前にタイプ
し始めるかもしれないからだ）
。したがって、入力キューはデバイスの初期化時に作成する必
要がある。第2 に、もしアプリケーションが読み出すときに、まだ入力が届いていなければ、
デバイスドライバは、入力が届くまで一時的にアプリケーションをブロックして、その実行を
止めなければならない。図17‒5 は、キューを使うデバイスドライバが入力を処理するための
ステップを示す。
初期化（コンピュータシステムが起動するとき）
1
入力キューを空の状態に初期化する
2
デバイスに割り込みを強制する
上層（アプリケーションが「read」を実行するとき）
1
もし入力キューが空なら、アプリケーションを一時的に止める
2
入力キューから次の項目を取り出す
3
項目を持ってアプリケーションに戻る
下層（割り込みが発生したとき）
1
もしキューが満杯でなければ、次の入力を開始
2
もしアプリケーションを止めていたら、その実行を再開させる
3
割り込みから戻る
図17‒5：キューイングを使う入力処理で、デバイスドライバの上層と下層が実行するステップ。上層は、
データを得られるまで一時的にアプリケーションを止めて待たせる
ここでのデバイスドライバの説明は、多くの詳細を略しているが、デバイスドライバが使う
全般的なアプローチを正確に描いたものだ。
製品のデバイスドライバは入出力にキューを使って項目をストアする。上層は要求の
キューイングを行い、下層はデバイスとの通信で詳細を扱う。
hi.0412.ko.2002@gmail.com
　17.10
非同期デバイスドライバと排他制御
331
17.10 　非同期デバイスドライバと排他制御
第16 章で、割り込みの機構では「非同期式」のプログラミングモデルが使われると述べた。
いまなら、その理由を理解できる。従来のプログラムと同じく、ポーリングが「同期式」なの
は、制御がコードの最初から最後まで継続するからだ。割り込みを処理するデバイスドライバ
が非同期なのは、プログラマがイベント処理のコードを別に書くからだ。上層のルーチンの1
つは、アプリケーションが入出力を要求するときに呼び出される。下層のルーチンの1 つは、
入出力の操作が発生するときか、割り込みが発生したときに呼び出され、初期化のルーチンは、
デバイスが始動されたときに呼び出される。
非同期式プログラミングは、同期式プログラミングよりも難度が高い。イベントはプログラ
ムとの順序と関係なく発生するので、プログラマは共有変数を使って現在の状態（たとえば、過
去に発生したイベントと、その影響）を記録しておく必要がある。非同期プログラムのテスト
が難しくなる理由は、プログラマがイベントのシーケンスを容易に制御できないからだ。さら
に重要なポイントとして、プロセッサで実行されているアプリケーションと、デバイスのハー
ドウェアの両方が、同時にイベントを生成する可能性がある。その同時発生イベントのおかげ
で、非同期デバイスドライバのプログラミングが、とくに難しくなる。
一例としてコマンドの連鎖を使うスマートデバイスについて考えてみよう。プロセッサはメ
モリ内に演算の連結リストを作り、デバイスは、そのリストを辿って演算を自動的に実行して
いく。プログラマは、プロセッサとスマートデバイスの相互作用を調停しなければならない。
その理由を理解するために、ドライバの上層がリストに項目を追加するのと同時に、スマート
デバイスがリストから項目を取り出す場合を想像してみよう。スマートデバイスがリストの終
わりに到達して処理を停止した直後に、デバイスドライバが新しい項目をリストに追加したら、
問題が生じないだろうか。同様に、もし独立した2 つのハードウェアが、リストにあるポイン
タを同時に操作しようとしたら、リンクが無効にならないだろうか。
スマートデバイスと相互作用を行うデバイスドライバは、同時アクセスによって生じるエ
ラーを防ぐために「排他制御」を実装しなければならない。つまりデバイスドライバは、リス
トの変更が完了するまでスマートデバイスがリストをアクセスできないようにする必要がある
し、スマートドライバも、リストの変更が完了するまでデバイスドライバがリストをアクセス
できないようにする必要がある。こういった排他的アクセスを確実に行うために、さまざまな
機構が使われている。たとえば、ある種のデバイスではCSR に特別な値があって、プロセッサ
が、それを設定すると、デバイスは一時的にコマンドリストをアクセスできなくなる。他のシ
ステムには、プロセッサがバスの利用を一時的に制限できる機構がある（もしバスを使えなけ
れば、スマートドライブはメモリ内のリストを変更できない）
。最後に、相互排除を提供できる
「テスト&セット」命令を、プロセッサ自身が提供してくれる場合もある。
hi.0412.ko.2002@gmail.com
332
第17 章　デバイスと入出力とバッファのプログラミング　
17.11 　アプリケーションから見た入出力
これまでの節で、デバイスドライバをプログラミングする方法について述べてきた。しかし
デバイスドライバを書く人が少ないのは、前述した通りだ。したがって、CSR アドレス、割り
込みベクトル、リクエストキューといった詳細は、典型的なプログラマからは隠されたままと
なる。デバイスドライバと低いレベルの入出力を学ぶ動機はバックグランド（背景知識）だ。
それを知っていれば、低いレベルのサービスを効率よく使うアプリケーションを作成する方法
を理解しやすくなる。
プログラマは高水準言語を使うことが多いので、低いレベルの入出力機構を直接呼び出すこ
とが少ない。入出力処理を表現するために一般のプログラマが使うのは、プログラミング言語
が提供する「抽象」である。たとえばアプリケーションプログラムが「ディスクデバイス」を
使うことは、めったにない。その代わりに、プログラミング言語または根底にあるシステムが、
高いレベルの「ファイル」という抽象をプログラマに提供する。同様に、多くのシステムはプ
ログラマに「ディスプレイハードウェア」を差し出す代わりに、
「ウィンドウ」という抽象をプ
ログラマに提供する。
ここまでの要点をまとめておこう。
多くのプログラミングシステムにおいて、入出力はプログラマから隠される。ディスク
やディスプレイ画面のようなハードウェアデバイスを操作する代わりに、プログラマが
使うのは、ファイルやウィンドウのような抽象だけである。
アプリケーションプログラマが実際にI/O デバイスを制御できる埋め込みシステムの場合で
も、なるべく多くの詳細をプログラマから隠すようにソフトウェアを設計するのが普通である。
具体的にアプリケーションが指定できる操作は、汎用的な高いレベルの入出力に限定される。
コンパイラがプログラムを特定のコンピュータで使えるバイナリ形式に翻訳するとき、高いレ
ベルの入出力操作はコンパイラによって低いレベルの一連のステップにマップされる。
ただし典型的なコンパイラは、個々の入出力操作を、基本的なマシン命令のシーケンスに直
接変換するわけではない。その代わりにコンパイラは、入出力を担当するライブラリ関数を呼
び出すコードを生成する。だから、そのプログラムは実行する前に、適切なライブラリ関数と
リンクする必要がある。
コンパイルされたプログラムに加わるライブラリ関数の集合は、
「ランタイムライブラリ」と
呼ばれる。もちろん、コンパイラとライタイムライブラリが協力できるように、統合的な設計
が必要である。コンパイラは、どんな関数を使えるのか、どういう引数をいくつ渡すのかを知
る必要があるし、関数の意味も理解する必要がある。
アプリケーションプログラマが、デバイスドライバと直接やりとりすることは、めった
にない。代わりに彼らは、仲介となるランタイムライブラリに依存する。
hi.0412.ko.2002@gmail.com
　17.12
ライブラリとOS の分割
333
ライタイムライブラリに仲介させることの主な利点は、柔軟性と変更の容易さから生じる。
根底にある入出力機構（デバイスドライバ）を使う方法を知っているのは、ランタイムライブラ
リの関数だけだ。もし入出力のハードウェアまたはデバイスドライバが（あるいは、その両方
が）変更されても、更新する必要があるのはランタイムライブラリだけで、コンパイラはその
まま使える。実際、ランタイムライブラリをコンパイラから切り離すことによって、コードを
一度コンパイルしておけば、あとからさまざまなランタイムライブラリと組み合わせたイメー
ジを生成することで、OS の複数のバージョンに対応できるようになる。
17.12 　ライブラリとOS の分割
ご承知のように、デバイスドライバはOS の中にあり、アプリケーションが入出力の実行に
使うランタイムライブラリの関数は、
（アプリケーションにリンクするのだから）OS の外にあ
る。概念としては、図17‒6 のように、デバイスのハードウェアの上に3 層のソフトウェアが
あると考えられる。
アプリケーシ
ョ
ン
ランタイムライブラリ関数への
インターフェイス
OSの入出力関数へのインターフェイス
ランタイムライブラリ
デバイス
ドライバ
デバイスのハー
ドウェア
図17‒6：アプリケーションのコードと、ランタイムライブラリのコードと、デバイスドライバの配置を、イ
ンターフェイスとともに示した概念図
ここで、いくつか疑問が生じる。ソフトウェアの各層は、それぞれどんなサービスを提供す
るのか。アプリケーションとランタイムライブラリのインターフェイスとは、また、ランタイ
ムライブラリとOS のインターフェイスとは、いったい何なのか。この2 つのインターフェイ
スを使うことによる相対的なコストは、どのくらいか。
17.13 　OS がサポートする入出力演算
まずは、ランタイムライブラリとOS のインターフェイスを調べよう。C のような低水準言
語では、アプリケーションからOS とのインターフェイスを直接利用できる。したがって、ロ
グラマは、入出力ライブラリを使うか、OS の機能を直接呼び出すか、どちらかを選ぶことが
hi.0412.ko.2002@gmail.com
334
第17 章　デバイスと入出力とバッファのプログラミング　
できる2。
入出力演算の具体的な詳細はOS に依存するが、ある包括的なアプローチが一般に使われて
いる。それは「open/read/write/close」のパラダイムと呼ばれるもので、基本的な関数が6 つ
提供される。表17‒1 にあげるのは、Unix OS で使われた関数名である。
表17‒1：
「open/read/write/close」のパラダイムを構成する6 つの基本I/O 関数。これらの名前はUnix
OS に由来する
関数
意味
open
デバイスを使う準備を整える（たとえば電源投入）
read
デバイスからアプリケーションにデータを転送する
write
アプリケーションからデバイスにデータを転送する
close
デバイスの使用を終える
seek
デバイス上で、新たなデータ位置に移動する
ioctl
多種多様の制御関数（たとえばボリュームを変更する）
例として、
「DVD」
（Digital Video Disk）の読み書きを行うデバイスドライバを考えてみよ
う。
「open」関数は、ドライブのモーターを始動してディスクの挿入状態を確認するのに使え
るだろう。いったんドライブを始動したら、
「read」関数で、そのディスクからデータを読む
ことも、
「write」関数でディスクにデータを書くこともできる。
「seek」関数は、新たな位置ま
で（たとえば特定のビデオセグメントに）移動するのに使える。そして「close」関数は、ディ
スクの電源を落とすのに使える。最後に（
「I/O control」を略した）
「ioctl」関数は、その他の
機能（たとえばディスクを取り出す「eject」機能）に使える。
当然これらの関数は、それぞれ詳細を指定するための引数を取る。たとえば「write」関数は
引数として、使用するデバイス、データの場所、書き込むデータの量を取る必要がある。いや、
そもそもデバイスドライバは、それぞれの演算と引数を根底にあるデバイスの操作にマップす
る方法を理解していなければならない。たとえばドライバが「control」関数の1 つ（たとえば
「eject」
）を受け取るとき、そのドライバは、デバイスのハードウェアに対して、その関数を実
装する方法を（たとえばデバイスのCSR レジスタに値を代入する方法を）知っていなければな
らない。
2　C で使える標準入出力ライブラリについては、後の節で論じる。
hi.0412.ko.2002@gmail.com
　17.14
入出力演算のコスト
335
17.14 　入出力演算のコスト
アプリケーションプログラムがランタイムライブラリの関数を呼び出すとき、そのコストは
関数呼び出しのコストと、まったく同じである。なぜなら、そのライブラリ関数のコードは、
プログラムの構築時にアプリケーションにコピーされ、その中に組み込まれているからだ。ゆ
えに、ライブラリ関数を呼び出すコストは、わりあい安価である。
しかし、
アプリケーションプログラムまたはランタイムライブラリ関数が、
「read」
や
「write」
のような入出力関数を呼び出すときは、
「システムコール」を介して3OS の適切なデバイスド
ライバに制御を渡す必要がある。残念ながら、システムコール経由でOS の関数を呼び出すこ
とには、きわめて大きなオーバーヘッドがある。その理由は3 つある。第1 に、OS はアプリ
ケーションよりも優先順位が高いので、プロセッサは優先モードを切り替える必要がある。第
2 に、プロセッサはアドレス空間を、アプリケーションの仮想アドレス空間から、OS のアドレ
ス空間に切り替えなければならない。そして第3 に、プロセッサはアプリケーションのアドレ
ス空間とOS のアドレス空間の間で、データをコピーしなければならない。
デバイスドライバと通信するためにシステムコールを使う際のオーバーヘッドは大きい。
システムコールは、たとえばライブラリ関数を呼び出すような通常の関数コールと比べ
て、ずっとコストが高い。
もっと重要なポイントとして、システムコールのオーバーヘッドの多くの部分が、ドライバ
が実行する仕事ではなく、呼び出しそのものに関わっている。したがって、性能を最適化した
いプログラマは、システムコールの回数を最小化する方法を探すことになる。
17.15 　システムコールのオーバーヘッドを減らす
システムコールのオーバーヘッドを、
どうすれば減らせるだろうか。それには、
まずワースト
ケースについて考慮するのが良い。アプリケーションが文書を印刷しなければならず、そのた
めには合計N バイトのデータをアプリケーションからプリンタに送る必要があると想定する。
最大のコストが発生するのは、アプリケーションが1 バイトのデータを転送するたびにシステ
ムコールを行う場合だ。その場合、アプリケーションは合計N 回のシステムコールを行う。代
案として、もしアプリケーションがテキストを1 行生成してからシステムコールを発行して、
その行全体を転送させるのなら、オーバーヘッドはN 回のシステムコールからL 回のシステム
コールに削減される。ここでL は、ドキュメントを構成する行数だ（つまり、L < N である）
。
文書を印刷するオーバーヘッドを、もっと削減できるだろうか。答えはイエスだ。アプリ
ケーションの設計を変更して、文書の1 ページが全部入る大きさのメモリを割り当て、ページ
を生成してから、1 回のシステムコールでページ全体をデバイスドライバに送ればよい。その
3　「システムコール」の代わりに「トラップ」という用語を使うコンピュータアーキテクチャもある。
hi.0412.ko.2002@gmail.com
336
第17 章　デバイスと入出力とバッファのプログラミング　
結果、アプリケーションはP 回のシステムコールを行うだけになる。ここでP は文書内のペー
ジ数だ（おそらくP << N だろう）
。
ゆえに、原則は次のようになる。
オーバーヘッドを削減して入出力の性能を最適化するプログラマは、アプリケーション
から呼び出すシステムコールの回数を減らさなければならない。システムコールを減ら
すには、システムコールごとに転送するデータを増やすことが鍵となる。
もちろん、入出力に使うシステムコールの回数を減らすことが、常に可能とは限らない。た
とえばテキストエディタや電子メール作成のアプリケーションは、ユーザーが文字を入力する
ごとに表示する。そういうアプリケーションは、ユーザーが1 行あるいは1 ページのテキス
トをタイプし終わるまで待つことができない。個々の文字が、即座に画面に現れなければいけ
ないのだ。このように、キーボードからの入力を受け取るプログラムは、1 行あるいは1 ペー
ジの入力を待たずに1 文字ずつ受け取る必要があることが多い。さいわい、そのようなアプリ
ケーションで行われるユーザーとのやりとりは入出力が比較的遅いので、速度の最適化は重要
ではない。
17.16 　バッファリングの重要性
上述したように、アプリケーションプログラマは、システムコールの回数が少なくなるよう
にコードを書き直すことで入出力の性能を最適化できる。この最適化は入出力を高速化する非
常に重要な手段なので、ほとんどのコンピュータソフトウェアに組み込まれている。入出力ラ
ンタイムライブラリが、自動的な最適化を行うように設計されているので、それを使うプログ
ラマはコードを書き直す必要がないのだ。
われわれは、入出力の転送を行う前にデータを蓄積することを「バッファリング」と呼び、
そのデータを置くメモリ領域を「バッファ」と呼ぶ。
バッファリングの原則
システムコールの回数を減らすには、毎回のシステムコールで多量のデータを転送でき
るよう、データをバッファに蓄積する。
バッファリングを自動化するために、
ライブラリのルーチンには、
どのアプリケーションにも
使える機構が必要だ。このため、ライブラリ関数は行やページではなく固定サイズのバッファ
を使う。バッファリングを利用したいアプリケーションは、システムコールの代わりに、その
ライブラリ関数を呼び出す必要がある。入出力機構が組み込まれているプログラミング言語の
場合、ランタイムライブラリがバッファリングを実装し、コンパイラは適切なライブラリルー
チンを呼び出すコードを生成する。組み込みの入出力機構を持たないプログラミング言語の場
合は、プログラマがシステムコールの代わりにバッファリングを行うライブラリルーチンを呼
び出す必要がある。
hi.0412.ko.2002@gmail.com
　17.17
バッファ付き出力の実装
337
バッファリングを実装するライブラリルーチンは、概念として表17‒2 にあげる5 つの関数
を提供するのが普通である。
表17‒2：バッファ付き入出力を提供する典型的なライブラリが提供する関数の概念
関数
意味
setup
バッファを初期化する
input
入力処理を実行する
output
出力処理を実行する
terminate
バッファの使用を中止する
ﬂush
バッファの内容を強制的に書き出す
この図にあげた演算は、OS がデバイスとのインターフェイスとして提供する演算に似て
いる。実際、
「バッファ付きI/O ライブラリ」の実装のうち、少なくとも1 つは関数名が
「open/read/write/close」のバリエーションである。表17‒2 では、同じ概念でも違う名前の
付け方があることを明らかにした。
17.17 　バッファ付き出力の実装
バッファリングの仕組みを理解するために、表17‒2 の「バッファ付き出力関数」を、アプリ
ケーションがどう使うかを考えよう。最初にアプリケーションはsetup 関数を呼び出してバッ
ファリングを初期化する。実装によっては、アプリケーションがバッファのサイズを指定でき
るように、引数を提供するものもある。その他の実装では、バッファサイズが定数である4。い
ずれにしても、setup がバッファを割り当て、そのバッファを空の状態に初期化してくれるの
が前提だ。いったんバッファが初期化されたら、アプリケーションはデータを転送するために
output を呼び出すことができる。毎回の呼び出しで、アプリケーションは1 バイト以上のデー
タを供給する。そして最後に、データ転送を終えるとき、アプリケーションはterminate 関
数を呼び出す（flush という関数の使い方は、後の節で述べる）
。
バッファ付き出力を実装するのに必要なコードの量は、ごくわずかだ。それぞれの出力用関
数を実装するのに使うステップを図17‒7 に示す。C のような言語では、それぞれのステップ
を1 行か2 行で実装できる。
terminate 関数を使う理由は、もう明らかだろう。出力がバッファリングされるので、アプ
リケーションが終了するとき、まだバッファにデータが残っているかもしれない。だからアプ
リケーションは、バッファの残りの内容を書き出すように、強制する必要があるのだ。
4　バッファサイズはコンピュータシステムによって異なるが、8K バイトから128K バイトまでの範囲が
典型的である。
hi.0412.ko.2002@gmail.com
338
第17 章　デバイスと入出力とバッファのプログラミング　
Setup(N)
1
N バイトのバッファを割り当てる
2
グローバルポインタp を作り、バッファの最初のバイトのアドレスでp を初
期化する。
Output(D)
1
バッファの、ポインタp が指す位置に、データバイトD を置き、p を次のバ
イトの位置に進める。
2
もしバッファが満杯なら、バッファの内容をすべて書き出すシステムコール
を発行し、p をバッファの先頭にリセットする。
Terminate
1
もしバッファが空でなければ、ポインタp の直前までのバッファの内容を書
き出すシステムコールを発行する。
2
もしバッファを動的に割り当てていたら、割り当てを解除する。
図17‒7：バッファ付き出力を実現するためのステップ
17.18 　バッファをフラッシュする
出力にバッファリングを使えないアプリケーションもあるだろう。たとえば2 人のユーザー
がコンピュータネットワークを介して対話するアプリケーションの場合を考えてみよう。メッ
セージを送り出すとき、アプリケーションは、そのメッセージが送信され、相手側に届くこと
を想定する。しかし残念ながら、もしバッファリングを使っていたら、そのメッセージは、ま
だバッファ内で転送待ちの状態かもしれない。
もちろんプログラマは、データを内部でバッファリングしてシステムコールを直接発行する
ように、アプリケーションを書き換えることもできる。けれども、汎用的なバッファリングを
行うライブラリの設計者は、バッファ付き入出力を使うアプリケーションが、システムコール
の発行が必要なタイミングを指定する手段を準備している。その機構がflush 関数だ。アプリ
ケーションは、これを呼び出すことで、たとえバッファが満杯でなくても強制的にデータを送
り出すことができる。いくらかデータが貯まっているバッファを強制的に出力することを、プ
ログラマは「バッファをフラッシュする」と言う。アプリケーションがflush を呼び出したと
き、もしバッファが空だったら、その呼び出しには何の効果もない。バッファにデータがあれ
ば、flush 関数はシステムコールを発行してデータを書き出してから、グローバルポインタを
リセットしてバッファを空の状態に戻す。図17‒8 に、flush 関数を実装するステップを示す。
ここで、図17‒7 に示したterminate 関数の実装を振り返ってみよう。もしライブラリが
ﬂush 関数を提供するなら、terminate の最初のステップは、flush 関数の呼び出しで置き換
hi.0412.ko.2002@gmail.com
　17.19
入力のバッファリング
339
Flush
1
もし現在のバッファが空であれば、何もしないで呼び出し側に戻る。
2
もし現在のバッファが空でなければ、システムコールを発行してバッファの
内容を書き出し、グローバルポインタp に、バッファの最初のバイトのアド
レスをセットする。
図17‒8：バッファ付きI/O ライブラリでflush 関数を実装するのに必要なステップ。フラッシュによっ
て、アプリケーションはバッファが満杯になる前にデータを強制的に出力できる
えることができる。
バッファのフラッシュを要約しておこう。
プログラマはflush 関数を使って、たとえバッファが満杯でなくてもバッファ内の出力
データを送り出すように指定できる。現在のバッファが空ならば、flush 演算には何の
効果もない。
17.19 　入力のバッファリング
これまでバッファリングを出力に使う方法を説明してきた。多くの場合、バッファリングは
入力のオーバーヘッドを削減するのにも利用できる。その仕組みを理解するために、データを
シーケンシャルに読む場合について考えよう。アプリケーションがN バイトのデータを読むの
に、一度に1 バイトずつなら、システムコールを合計N 回行うことになる。
根底にあるデバイスからデータをまとめて転送できるのなら、システムコールの回数を減ら
すのにバッファリングを使える。アプリケーション（またはランタイムライブラリ）は、大き
なバッファを割り当て、1 回のシステムコールでバッファを満杯にして、その後の要求にバッ
ファから対応するのだ。図17‒9 に、必要なステップを示す。出力のバッファリングと同じく、
実装は単純明快だ。C のような言語なら、それぞれのステップを、ごくわずかなコードで実装
できる。
17.20 　バッファリングの効率
なぜバッファリングが、それほど重要なのか。たとえ小さなバッファでも入出力の性能に大
きな影響を与えることがあるからだ。その理由を知るには、バッファ付き入出力を使うときは
バッファ毎に1 回しかシステムコールの必要がないことに注目する5。1 バイトごとの呼び出
しをやめて、N バイトのバッファを使えば、システムコールの回数は1/N に減少する。もしア
プリケーションがS 回のシステムコールを発行していたら、たった8K バイトのバッファを使
5　ここでの分析では、アプリケーションが頻繁にflush を呼び出すような状況を無視している。
hi.0412.ko.2002@gmail.com
340
第17 章　デバイスと入出力とバッファのプログラミング　
Setup(N)
1
N バイトのバッファを割り当てる。
2
グローバルポインタp を作り、バッファが空の状態を示すように初期化する。
Input(N)
1
もしバッファが空なら、システムコールを発行してバッファを満杯にし、ポ
インタp をバッファの先頭にセットする。
2
1 バイトのデータ(D) を、ポインタp が指すバッファの位置から取り出し、
p を次のバイトに進め、呼び出し側にD を返す。
Terminate
1
もしバッファを動的に割り当てていたら、割り当てを解除する。
図17‒9：バッファ付き入力の達成に必要なステップ
うことで、システムコールの回数は、S/8192 まで減少する。
バッファリングを行うのはランタイムライブラリだけではない。このテクニックは非常に重
要なので、デバイスドライバも、しばしばバッファリングを実装する。たとえばディスクのド
ライバには、ディスクのブロックをメモリ内にコピーしておき、そのブロックのデータをアプ
リケーションが読み書きできるようにするものがある。もちろんOS でバッファリングを行っ
ても、システムコールがなくなるわけではないが、そういうバッファリングで性能が向上する
ことはたしかである。なぜなら、外部データ転送はシステムコールよりも遅いからだ。重要な
ポイントは、もし高価な演算を、もっと安価な演算で置き換えられるのなら、バッファリング
を使えば入出力のオーバーヘッドを削減できるということだ。
バッファリングの重要性は、次のように要約できる。
N バイトのバッファを使うことで、根底にあるシステムを呼び出す回数を、1/N まで減
らすことができる。より大きなバッファを使えば、高速な入出力機構と、耐えがたいほ
ど遅い入出力機構との違いが、明らかになるだろう。
17.21 　キャッシングとの関係
バッファリングは、第12 章で述べたキャッシングの概念と、近い関係にある。主な違いは。
項目をアクセスする方法に起因する。キャッシュシステムは、ランダムアクセスを使えるよう
に最適化される。バッファリングシステムは、シーケンシャルアクセスのために最適化される。
基本的に、キャッシュが「参照された」項目を重視して保存するのに対して、バッファは
（シーケンシャルアクセスを前提として）
「これから参照する」項目を保存する。仮想メモリシ
ステムにおいてキャッシュにメモリのページ全体を保存する場合、ページのどれかのバイトが
参照されたら、そのページ全体をキャッシュに入れる。それとは対照的に、バッファに格納さ
hi.0412.ko.2002@gmail.com
　17.22
例：C 標準入出力ライブラリ
341
れるのはバイトのシーケンスである。したがって、1 バイトが参照されるとき、バッファリン
グシステムは、それに続くバイト列をプリロードしておく。もし参照された1 バイトがページ
の最後にあったら、バッファリングシステムは次のページからバイト列をプリロードする。
17.22 　例：C 標準入出力ライブラリ
バッファリングを行う入出力ライブラリで、おそらくもっとも有名なものは、プログラミン
グ言語C とUnix OS のために作成された6。
「標準I/O ライブラリ」あるいは「stdio」と呼
ばれる、そのライブラリは入出力両方のバッファリングをサポートする。Unix 標準I/O ライ
ブラリにある、いくつかの関数と、その目的を、表17‒3 に示す。
表17‒3：Unix OS で使われた標準I/O ライブラリに含まれる関数の例。このライブラリには、このリスト
に入れていない関数も含まれる
関数
意味
fopen
バッファのセットアップ
fgetc
1 バイトのバッファ入力
fread
複数バイトのバッファ入力
fwrite
複数バイトのバッファ出力
fprintf
複数バイトのフォーマット付きバッファ出力
ﬄush
バッファ出力用のフラッシュ
fclose
バッファの使用を中止する
17.23 　まとめ
入出力にはプログラマにとって重要な側面が2 つある。デバイスドライバを書くシステムプ
ログラマは、デバイスに固有な低いレベルの詳細を理解しなければならない。そして入出力機
構を使うアプリケーションプログラマは、その相対的なコストを理解しなければならない。
デバイスドライバは、3 つの部分に分けられる。アプリケーションとのやりとりを行う上層、
デバイスそのものとやりとりを行う下層、
そして一群の共有変数だ。上層の関数は、
アプリケー
ションがデータを読み書きするときに制御を受け取る。下層は、デバイスが入力や出力の割り
込みをかけたときに制御を受け取る。
プログラマが、シーケンシャルな入出力の性能を最適化するために使う基本的なテクニック
は、
「バッファリング」と呼ばれるものだ。バッファリングは、入力にも出力にも使用でき、し
ばしばランタイムライブラリによって実装される。データ転送のタイミングをアプリケーショ
6　訳注：そのstdio は、LINUX とANSI C にも引き継がれた。Robert Love 著『LINUX システ
ムプログラミング』の「3.2 標準I/O」などに解説がある。man ページも参照できる（日本語版：
https://nxmnpg.lemoda.net/ja/3/stdio）
。
hi.0412.ko.2002@gmail.com
342
第17 章　デバイスと入出力とバッファのプログラミング　
ンから制御する「フラッシュ」演算もあるので、バッファリングは任意のアプリケーションで
利用できる。
バッファリングは、システムコール毎に転送するデータを増やすことによって、システム
コールのオーバーヘッドを削減する。バッファリングで性能が大きく向上するのは、N バイト
のバッファを使えばアプリケーションが発行するシステムコールの回数を、1/N まで減らせる
からだ。
練習問題
17.1
デバイスドライバが提供するのは何ですか? デバイスドライバを使うと、どうして
アプリケーションを書くのが簡単になるのでしょうか。
17.2
デバイスドライバの、概念的な3 つの部分は、どういう名前ですか? それぞれの用
途も教えてください。
17.3
デバイスドライバでの出力キューの使い方について、キューに項目を入れる方法と、
そのタイミング、そして項目を出す方法とタイミングを教えてください。
17.4
ユーザーがファイルを書くアプリを起動しました。そのアプリは、ファイルをどれ
だけ書いたかの進捗を示すプログレスバーを表示します。プログレスバーが50%に
達したとき、バッテリーが故障して、デバイスがクラッシュしました。ユーザーがデ
バイスを再起動したら、実際に書かれたファイルは20%未満でした。なぜアプリは
50%と報告したのでしょう?
17.5
プログラムがfputc をコールするとき、
そのプログラムは何を呼び出すのでしょう?
17.6
flush 関数とは何でしょう。なぜ必要なのですか?
17.7
アプリの性能を上げるために、プログラマがアプリを書き換えて、1 度に1 バイト
ずつ読む代わりに8000 バイト読んでから処理するようにしました。このプログラマ
が使ったテクニックを、何といいますか?
17.8
大きなファイルをコピーするのに、write を使う場合と、fwrite を使う場合で、必
要な時間を比較しましょう。
17.9
標準I/O 関数のfseek を使うとランダムアクセスが可能になります。ファイルの
小さな領域内でfseek を使う場合と、もっと大きな領域で使う場合とで、必要になる
時間の差を計測しましょう。
17.10
引数としてプリントしたい文字（キャラクタ）を受け取るバッファ付き出力ルー
チン、bufputc を書きましょう。bufputc は、呼び出されるたびに、キャラクタを
バッファに格納し、バッファが満杯になるたびに1 回write を呼び出します。あな
たが書いたバッファ付きルーチンと、1 キャラクタごとにwrite を呼び出すプログラ
ムで、性能を比較しましょう。
hi.0412.ko.2002@gmail.com
第5部
高度な話題
並列処理とパイプライン
hi.0412.ko.2002@gmail.com
hi.0412.ko.2002@gmail.com
第18 章
並列処理
18.1 　はじめに
これまで、コンピュータアーキテクチャの主要なコンポーネントである、プロセッサ、メモ
リシステム、入出力の3 つを見てきた。この章からは、コンポーネントの境を超えて、アーキ
テクチャの基本的な概念を説明する。
この章では並列（パラレル）ハードウェアの使い方に焦点を絞る。コンピュータシステム全
体で、並列処理を使ってスピードを上げられることを示そう。この章では用語と概念を紹介し、
パラレルアーキテクチャの分類法を示し、並列処理という基本的パラダイムを中心として全体
が構築されるコンピュータシステムを調べ、最後にパラレルアーキテクチャの限界と問題点を
論じる。
次の章では、本章の議論の続きとして、第2 の基本的な技法であるパイプライン処理を調べ
る。高性能設計には、並列処理とパイプライン処理の両方が重要であることがわかるだろう。
18.2 　並列とパイプラインのアーキテクチャ
並列処理も、パイプライン処理も、本書で例を出し、使い方を示している。
「ハードウェアの
スピードを増す基本的なテクニックは、並列化とパイプライン化の2 つしかない」と断言する
アーキテクトもいる。しかし、他のアーキテクトは、並列処理とパイプラインを、もっと広い
視野で捉え、これらの技法を基礎として中心に置き、そのまわりにシステムを設計する。多く
の場合、そのアーキテクチャ全体が、そのどちらかの技法によって完璧に支配されるので、結
果としてシステムは（非公式な呼び方だが）
、
「並列コンピュータ」あるいは「パイプライン式
コンピュータ」と呼ばれることになる。
hi.0412.ko.2002@gmail.com
346
第18 章
並列処理　
18.3 　並列処理の特徴
コンピュータアーキテクトたちは、アーキテクチャを「並列」か「非並列」かに分類するの
ではない。所与の設計に存在する「並列性」の形式と度合いを表すために、さまざまな用語を
使っている。多くの場合、それらの用語で記述されるのは、ある型の並列性の極限だ。アーキ
テクチャを分類するには、アーキテクチャが2 つの極限の間のどこにあるかを示さなければな
らない。図18‒1 は、ある古典的な論文1でマイケル・J・フリンが提案した用語を使って、主な
特徴をリストにしたものだ。これらの用語について、今後の節で例をあげて説明していこう。
•
微視的対巨視的
•
対称的対非対称的
•
細粒度対粗粒度
•
明示的対暗黙的
図18‒1：コンピュータアーキテクチャに存在する並列性の型と度合いを表すのに使う用語
18.4 　微視的／巨視的な並列性
並行性は基本である。アーキテクトは、並列ハードウェアを考えることなくコンピュータを
設計することができない。それほど並列処理が普遍的なので、コンピュータが並列ハードウェ
アを、きわめて大量に使わない限り、並列性に言及しないのが普通である。あるコンピュータ
の並列性の大半が、その構成部品に隠れている場合、われわれは「微視的並列性」という用語
を使って表現する。われわれをとりまく世界に微生物が存在するように、微視的並列性も存在
するのだが、近寄って見なければ目立たないのである。
要約しておこう。
並列性は、あまりにも基礎的である。事実上すべてのコンピュータシステムが、何らか
の並列ハードウェアを含んでいるのだ。
「微視的並列性」というのは、たしかに存在する
が、あまり目に付かないような並列機構を特徴付ける用語だ。
もっと厳密に言うと「微視的並列性」は、ある特定のコンポーネントの中に存在する（たと
えばプロセッサの内部や、ALU の内部にある）並列ハードウェアに対する言及である。それに
対して「巨視的並列性」は、並列処理を基本的な前提として、それを中心にシステムが設計さ
れるような使い方を言う。
1　M. J. Flynn, ”Some Computer Organizations and Their Eﬀectiveness,” IEEE Transactions on
Computers, C-21(9):948‒960, September 1972.
hi.0412.ko.2002@gmail.com
　18.5
ミクロ（微視的）な並列処理の例
347
18.5 　ミクロ（微視的）な並列処理の例
微視的な並列処理をプロセッサやメモリシステムや入出力のサブシステムで使う例は、これ
までの章でも見てきた。以下の各段落では、いくつかの具体例に注目する。
ALU
ALU は論理と算術の演算を処理するユニットだ。整数演算は、ほとんどのALU で、複数の
ビットの並列処理によって実行される。整数を扱う設計のALU は、1 対の32bit 値に対する
ブール演算を一度に計算できる並列ハードウェアを含んでいる。反対に、1 ビットずつ処理す
るALU を使うアプローチは「ビット直列処理」と呼ばれる。ビット直列処理では、複数のビッ
トを並列に計算するより、ずっと長い時間がかかることは明らかだ。ゆえにビット直列演算は、
特殊な用途にだけ使われる。
レジスタ
CPU の汎用レジスタでは。微視的並列処理が、大いに利用される。レジスタを構成するビッ
トは、それぞれ別々のデジタル回路（ラッチ）で実装される。さらに高速演算を保証するため、
汎用レジスタとALU の間で行うデータ移動には並列のデータ経路が使われる。
物理メモリ
微視的並列性の、もう1 つの例として、物理メモリシステムがある。これは「フェッチ」と
「ストア」の演算を実装するのに並列ハードウェアを使う。物理メモリのハードウェアは、それ
ぞれの演算でワード全体を転送するように設計される。ALU と同じくメモリも、微視的並列性
によって劇的に速くなる。たとえば64bit ワードを実装するメモリシステムは、1 度に1 ビッ
トをアクセスするメモリシステムと比べて、約64 倍のデータを同時にアクセスあるいはスト
アすることが可能である。
並列バスアーキテクチャ
すでに見たようにコンピュータの中心となるバスは、普通は並列ハードウェアを使って、プ
ロセッサ、メモリ、I/O デバイスの間で高速データ転送を達成する。現代の典型的なコンピュー
タは、32bit 幅または64bit 幅のバスを持っている。つまり、そのバスでは32 ビットまたは
64 ビットのデータを、1 回のステップで転送できるのだ。
18.6 　マクロ（巨視的）な並列処理の例
前節で例示したように、ミクロ（微視的）な並列処理は高性能を得るのに不可欠だ。並列ハー
ドウェアがなければ、コンピュータシステムのさまざまなコンポーネントが高速に動作できな
くなる。しかしグローバルなアーキテクチャが個々のサブシステムの性能よりシステム全体の
性能に大きな影響を与えることを、コンピュータアーキテクトは知っている。ただ1 個のサブ
hi.0412.ko.2002@gmail.com
348
第18 章
並列処理　
システムで並列性を高めても、システム全体の性能は改善されないかもしれない2。
最大の効果を達成するには、システムの複数のコンポーネントに並列性が必要だ。つまり並
列処理をコンポーネント単位の性能を上げるためにだけ使うのではなく、システムの複数のコ
ンポーネントが協力できるようにする必要がある。コンピュータシステムを構成する大規模な
複数のコンポーネントで協調的な並列処理を行うことを、
「巨視的並列性」という。その概念
は、例を見ると明らかになるだろう。
複数の同一なプロセッサ
巨視的並列性を持つシステムでは、何らかの形で複数のプロセッサを使うのが普通である。
たとえばPC の広告で、デュアルコアやクアッドコアを売り物にしているのを見かけるが、こ
れらは同じプロセッサのコピーが2 つまたは4 つ、1 個のチップに入っているという意味だ。
チップは、それらのプロセッサを同時に運用できるように作られる。ただしハードウェアがコ
アの使い方を決めるわけではない。それぞれのコアにコードを割り当てるのは、OS だ。OS は、
たとえば入出力処理を（つまりデバイスドライバの実行を）あるコアに割り当て、他のコアに
はアプリケーションを割り当てて実行する。
複数の異なるプロセッサ
巨視的並列性の、もう1 つの例は、用途に応じたコプロセッサを多用するシステムに見るこ
とができる。たとえば高速グラフィックスに特化したコンピュータには、4 台のディスプレイが
接続され、それぞれ専用のグラフィックスプロセッサが実行されるかもしれない。グラフィッ
クスプロセッサは、インターフェイスカードに搭載されるのが典型的で、CPU と同じアーキテ
クチャを使うのではない。グラフィックスプロセッサには、グラフィックス演算用に最適化さ
れた命令が必要だからだ。
18.7 　対称的／非対称的な並列性
「対称的並列性」というのは、同じ要素（通常はプロセッサまたはコア）の複製を同時に動
作させる設計のことだ。たとえば先ほど述べたマルチコアのプロセッサは、すべてのコアが同
一なので、対称的と言える。
対称的並列設計の対極にあるのが、
「非対称」な並列設計だ。非対称な設計には、同時に機能
するが互いに異なる複数の要素が含まれる。たとえばCPU と、グラフィックスプロセッサと、
数値演算コプロセッサと、入出力コプロセッサを持つPC は、非対称並列性を持つと分類され
る。この4 個のプロセッサは同時に動作できるが、内部は互いに異なっているからだ3。
2　性能については、第21 章で詳しく論じる。
3　アーキテクトによっては、マルチコア設計でも、メモリとI/O デバイスに対するアクセスがコアによっ
て違っていれば「非対称」と呼ぶことがある。
hi.0412.ko.2002@gmail.com
　18.8
細粒度／粗粒度の並列性
349
18.8 　細粒度／粗粒度の並列性
「細粒度の並列性」を持つコンピュータは、個々の命令あるいは個々のデータ要素のレベル
で並列処理を提供する。そして「粗粒度の並列性」を持つコンピュータは、プログラムあるい
は大きなデータブロックのレベルで並列処理を提供する。たとえば16 個の並列ハードウェア
ユニットを使って、最大16 バイトの画像を同時に更新できるグラフィックスプロセッサは、細
粒度の並列性を持つ。それとは対照的に、デュアルコアのPC が、1 つのコアで文書を印刷し、
もう1 つのコアで電子メールメッセージを作成するとしたら、そのPC は粗粒度の並列処理を
行っている。
18.9 　明示的／暗黙的な並列性
ハードウェアが自動的に並列処理を行うアーキテクチャ（つまりプログラマが並列実行を始
動あるいは制御する必要がないアーキテクチャ）は、
「暗黙的並列性」を提供する。並列ユニッ
トをプログラマが制御しなければならないアーキテクチャは、
「明示的並列性」を提供する。明
示的／暗黙的な並列性の長所と短所は、あとで検討することにしよう。
18.10 　並列アーキテクチャの種類（フリンの分類）
多くのシステムに何らかの形で複数のプロセッサが含まれているが、
「並列アーキテクチャ」
という言葉は、自在にスケーリングできる設計にだけ使うのが普通だ。つまりアーキテクトが
「並列アーキテクチャ」と言うときは、プロセッサの数を任意に（あるいは少なくとも正当な範
囲で）増やせる設計を意味するのが普通である。たとえば、1 個または2 個のプロセッサを持
つことができるコンピュータを考えてみよう。第2 のプロセッサを追加すれば並行性が高まる
けれど、そういうアーキテクチャは並列アーキテクチャというより「デュアルプロセッサ」の
コンピュータに分類するのが普通だ。同様に、4 個のコアを持つPC は、
「クアッドコア」PC
に分類される。けれども、32 個のPC を相互接続したクラスタがあって、1024 個のPC まで
スケーリング可能だとしたら、それは並列アーキテクチャに分類される。
並列アーキテクチャを理解するもっとも簡単な方法は、このアーキテクチャを、それぞれ並
列処理の1 つの型を表現する大まかなグループに分けることだ。もちろん絶対的な分割はあり
得ない。ほとんどの実用的なコンピュータは、2 つ以上のグループの機能を含むハイブリッド
（混成物）だ。とはいえ、さまざまなシステムを論じて特徴を指摘するには、それらを分類して
基本的な概念と用語を定義しなければならない。
並行性を記述する一般的な方法として、フリンの功績とされるものがあり、これは処理また
はデータが複製されるかどうかを考察する。
「フリンの分類」
（Flynn classiﬁcation）と呼ばれ
る、その体系は、コンピュータが、複数の独立したプロセッサを持つのか、それらが別々のプ
ログラムを実行するのか、それとも1 個のプログラムが複数のデータ項目に適用されるのかに
hi.0412.ko.2002@gmail.com
350
第18 章
並列処理　
注目する。表18‒1 に示すのは、フリンの分類で並列処理の種類を定義するのに使われた用語
だ。今後の節で、これらの用語を説明し、それぞれの例を示そう。
表18‒1：各種の並列コンピュータを記述するために、フリンの分類で使われた用語4
名前
意味
SISD
単一命令ストリーム、単一データストリーム
（Single Instruction stream Single Data stream）
SIMD
単一命令ストリーム、複数データストリーム
（Single Instruction stream Multiple Data streams）
MISD
複数命令ストリーム、単一データストリーム
（Multiple Instruction streams Single Data stream）
MIMD
複数命令ストリーム、複数データストリーム
（Multiple Instruction streams Multiple Data streams）
18.11 　SISD（単一命令、単一データ）
「SISD」という名称は、巨視的並列性をサポートしないアーキテクチャを記述するのに使
われた。並列アーキテクチャではないという点を強調するため、SISD と呼ぶ代わりに、
「直列
アーキテクチャ」あるいは「ユニプロセッサアーキテクチャ」という言葉が使われることも多
い。基本的に、SISD と呼ばれるのは従来型の（つまりフォン・ノイマンの）アーキテクチャ
である。そのプロセッサは標準的な「フェッチ‒ 実行」サイクルで、同時に1 個の演算を実行
する。SISD という言葉は、1 個の従来型のプロセッサによって実行される命令が、それぞれ1
個のデータ項目を処理するというアイデアを表している。つまり、並列アーキテクチャと違っ
て、従来のプロセッサは同時に1 命令しか実行できないし、個々の命令は、それぞれ1 つの計
算を意味する。
もちろん、SISD コンピュータでも内部的に並列処理を使えることは、これまで見てきた通
りである。たとえばALU は、複数ビットに対する演算を並列的に実行できるだろうし、CPU
はコプロセッサを呼び出せるだろう。あるいはCPU の内部に、2 バンクのメモリから同時に2
つのオペランドをフェッチできる機構があるかもしれない。けれども、SISD アーキテクチャ
の全体的な効果としては、シーケンシャルな命令実行によって、データ項目を1 個ずつ処理す
るのである。
4　MISD は特殊なカテゴリーで、通常のハードウェアに使うものではない。たとえば図19‒5 に示すパイ
プライン式アーキテクチャは、複数の命令を1 個のデータに対して実行するMISD だ。信頼性を上げるため
に、複数のプロセッサを冗長的に使うMISD もある。
hi.0412.ko.2002@gmail.com
　18.12
SIMD（単一命令、複数データ）
351
18.12 　SIMD（単一命令、複数データ）
「SIMD」という名称は、それぞれの命令が1 個の演算（たとえば整数の加算）を指定する
が、その演算が複数のデータ項目に対して同時に適用されるという形式の並列アーキテクチャ
を記述するために使われた。典型的なSIMD コンピュータは、64 の同時演算（たとえば64 の
同時加算）を扱えるだけのハードウェアを持っている。
ベクトルプロセッサ
SIMD アーキテクチャは、ワードプロセッサや電子メールのアプリケーションに便利なもの
ではない。SIMD は、同じ演算を一群の値に適用するアプリケーションに使うのだ。たとえば
グラフィックスや、ある種の科学的アプリケーションには、値の大規模な集合に1 個の演算を
適用できるSIMD アーキテクチャが適している。このアーキテクチャは、
「ベクトル」という
数学的概念や、
「配列」という計算の概念から名を取って、
「ベクトルプロセッサ」とも「アレ
イプロセッサ」とも呼ばれる。
SIMD の動作を示す例として、N 個の要素を持つベクトルV の値を正規化する方法を考えよ
う。正規化するため、ベクトルに含まれる個々の要素に、ある浮動小数点値、Q を掛ける。こ
のベクトルを、SISD のような直列アーキテクチャで正規化するアルゴリズムは、リスト18‒1
に示すようなループになる。
リスト18‒1：ベクトル正規化のシーケンシャルなアルゴリズム
for i from 1 to N {
V [i] ←V [i] × Q;
}
一方、SIMD アーキテクチャでは、根底にあるハードウェアによって、ある算術演算を、配
列に含まれるすべての値に同時に適用することが可能だ（ただし配列のサイズがハードウェア
の並列性を超えないことが前提となる）
。たとえば64 個の並列ユニットを持つハードウェアな
ら、1 ステップで、64 個の要素を持つ配列の全部の値に乗算を実行できる。だからSIMD コン
ピュータで配列の正規化を行うアルゴリズムは、次の1 ステップとなる。
V ←V × Q;
ベクトルV の大きさがハードウェアの容量を超えていたら、複数のステップが必要になるの
は当然のことだ。ここで重要なのは、SIMD アーキテクチャのベクトル命令が、単なるループ
の略称ではないという点である。根底にあるシステムに含まれる複数のハードウェアユニット
が並列動作することによって、かなりの高速化がもたらされる。とくに大きな行列を使う計算
では、性能が顕著に改善される。
もちろん、SIMD アーキテクチャの全部の命令を、値の配列に使えるわけではない。アーキ
hi.0412.ko.2002@gmail.com
352
第18 章
並列処理　
テクトは、ベクトルに使える演算の部分集合を選んで、それぞれに特別なベクトル命令を定義
する。たとえば配列全体の正規化が可能になるのは、ベクトルに存在するそれぞれの値に定数
を掛けるベクトル乗算命令を、アーキテクトが選んだ場合に限られる。
1 個の定数と1 個のベクトルを使う演算だけでなく、SIMD コンピュータは普通、2 つのベク
トルを使う命令も提供する。つまり1 個のベクトル命令が、それぞれ1 つのベクトルを指定す
るオペランドを1 個またはそれ以上受け取るのだ。たとえばSIMD アーキテクチャは、行列の
乗算に関わる問題にも使われる。ほとんどのSIMD で、あるベクトルを指定するオペランド1
個が、2 つの情報を持つ。1 つはメモリにおけるベクトルの位置、もう1 つは、そのベクトル
のサイズ（ベクトルに含まれる要素の数）を指定する整数だ。マシンによっては、ベクトル命
令の制御に特殊用途のレジスタを使い、ベクトル命令を呼び出す前に、それぞれのベクトルの
アドレスとサイズを、そのレジスタにロードするものもある。いずれにしても、ハードウェア
がサポートする最大のサイズを超えないようにベクトル内の要素数を決めるのは、ソフトウェ
アの仕事である5。
グラフィックスプロセッサ
SIMD アーキテクチャは、グラフィックス用途にも人気がある。その理由を理解するには、典
型的なグラフィックスハードウェアでは画面上の画素（ピクセル）の値が、メモリ内の連続す
るバイトデータに格納されることを認識すべきだ。たとえばビデオゲームで、背景のシーンを
固定しながら前景の人物を動かす場合を考えてみよう。そのゲームのソフトウェアは、前景の
人物に対応するバイトデータを、ある場所から別の場所へとコピーする必要がある。直列アー
キテクチャならば、プログラマがループの指定によって、1 度に1 バイトずつコピーすること
になるだろう。ところがSIMD アーキテクチャならば、プログラマはベクトルのサイズを指定
してから、1 個のコピーコマンドを発行すればよい。すると根底にあるSIMD ハードウェアが、
複数のバイトを同時にコピーしてくれるのだ。
18.13 　MIMD（複数命令、複数データ）
「MIMD」という名称は、並列アーキテクチャの各プロセッサが、それぞれ独立した計算を
同時に実行するという意味だ。内部ユニットとして複数のプロセッサを含むコンピュータは多
いが、MIMD と呼ばれるのは、個々のプロセッサがプログラマから見えるようなコンピュータ
だ。つまりMIMD コンピュータでは、複数の独立したプログラムを、同時に実行できる。
SMP（対称型マルチプロセッサ）
MIMD アーキテクチャのもっともよく知られた例は、
「SMP」
（Symmetric Multiprocessor）
と呼ばれるコンピュータだ。SMP には、それぞれプログラムの実行に使えるN 個のプロセッ
5　ベクトルがハードウェアの容量を超える場合に、どうすれば高速化できるかは、練習問題とする。高速
化の定義は、18.15 節にある。
hi.0412.ko.2002@gmail.com
　18.13
MIMD（複数命令、複数データ）
353
サ（あるいはN コア）が含まれる。典型的なSMP 設計では、どのプロセッサも同じだ。それ
らは同じ命令セットを持ち、同じクロックレートで動き、同じメモリモジュールをアクセスし、
同じ外部デバイス群をアクセスできる。したがって、どのプロセッサでもまったく同じ演算を
実行できる。図18‒2 に、そのコンセプトを示す。
メインメモリ
（さまざまな
モジュール）
デバイス群
P1
P2
Pi
Pi+1
Pi+2
PN
図18‒2：N 個の同一なプロセッサが、それぞれメモリとI/O をアクセスできる、SMP の構成図
一群の研究者たちがシリコンチップの性能を高める方法を探究している間に、より強力なコ
ンピュータを生み出す方法として、MIMD 形式の対称型マルチプロセッサを探究する人たちが
いた。その中でも、もっとも有名なプロジェクトの1 つがカーネギー・メロン大学の研究で、
Carnegie Multi-Mini-Processor（C.mmp）というプロトタイプが作成された。その後、1980
年代にはSMP のアプローチを使って「マルチプロセッサ」と呼ばれる最初期の製品が、いくつ
かのベンダーによって作られた。
（後にIBM に買収された）Sequent 社が、Unix を実行する
対称型マルチプロセッサを作り、Encore 社が、Mutimax という名前の対称型マルチプロセッ
サを作った。
AMP（非対称マルチプロセッサ）
MIMD アーキテクチャで人気があるのはSMP だが、他の形式も実現可能だ。SMP に対抗す
る主な選択肢として、
「AMP」
（Asymmetric Multiprocessor）がある。AMP も、同時に運用で
きるプログラミング可能なプロセッサを複数持つが、すべてのプロセッサに同一の能力を持た
せる必要はない。AMP 設計では、与えられたタスクに適切なプロセッサを選択できる。たと
えば、あるプロセッサは高速ディスクストレージデバイスの管理用に最適化し、他のプロセッ
サはグラフィックス表示用に最適化することが可能だ。
たいがいのAMP アーキテクチャは「主従関係」アプローチにしたがう。つまり、あるプロ
セッサ（場合によっては一群のプロセッサ）が全体の実行を管理し、必要に応じて他のプロセッ
サを呼び出すのだ。実行を管理するプロセッサが「主」
、他のプロセッサが「従」である。
AMP アーキテクチャがN 個のプロセッサを持つとき、理論的にはそれらを、相互にまった
く異質なプロセッサにすることが可能だ。しかし実際には、ほとんどのAMP 設計が、2 種類
から4 種類のプロセッサを持っている。典型的な汎用設計のAMP アーキテクチャは、全体を
hi.0412.ko.2002@gmail.com
354
第18 章
並列処理　
制御するために最適化された少なくとも1 個のプロセッサ（マスター）と、算術演算や入出力
などの副次的な機能のために最適化された、その他のプロセッサを含む。
算術とグラフィックスのコプロセッサ
これらは非対称アーキテクチャを使う市販のコンピュータシステムで使われている。もっと
も広く一般に知られているAMP 設計は、1980 年代の終わりから1990 年代の始めにかけて、
PC のメーカーが売り出し始めた「算術コプロセッサ」で、そのアイデアは単純明快だ。算術コ
プロセッサは、CPU が浮動小数点演算を実行したいときに呼び出す特殊用途のチップである。
コプロセッサは、1 つの仕事のために最適化されるので、その仕事をCPU よりも高速に実行で
きる。
CDC の周辺プロセッサ
CDC（Control Data Corporation）が作った6000 シリーズのメインフレームは、AMP アー
キテクチャをメインフレームで使うというアイデアの先駆けとなった。CDC のアーキテクチャ
は、入出力を扱うために10 個の「周辺プロセッサ」を使った。CPU とI/O デバイスの間に周
辺プロセッサを配置する、その概念的な構成を図18‒3 に示す。おもしろいことに、CDC の
周辺プロセッサは入出力に限定されなかった。周辺プロセッサは、汎用的な命令群を持つミニ
コンピュータに似ていて、なんでもプログラマが選んだ目的に使うことができた。るまり周辺
プロセッサはメモリをアクセスできたので、どこにある値でも読み書きできたのだ。CPU よ
りは、かなり低速だったが、CDC の周辺プロセッサは10 個すべてを同時に実行できたので、
I/Oデバイス群
CPU
PP1
PP2
PP3
PP4
PP5
PP6
PP7
PP8
PP9
PP10
図18‒3：CDC 6000 シリーズのメインフレームコンピュータで使われた非対称アーキテクチャの構造
hi.0412.ko.2002@gmail.com
　18.14
通信、協調、競合
355
CPU だけでなく周辺プロセッサにも仕事を割り振ることによって、プログラムの性能を最適化
することが可能だった。
CDC コンピュータは製造をやめてしまったが、プログラミング可能なI/O プロセッサとい
う基本的なアイデアは、いまも使われている。興味深いことに、このアプローチはマルチコア
チップのおかげで、再び実現可能になった。多くのコアがあるから、1 個以上のコアを入出力
専用に使えたのである。
I/O プロセッサ
ほとんどのメインフレームコンピュータは、入出力を高速に処理するためにAMP アーキテ
クチャを使って、CPU が遅くなるのを防いでいる。外部入出力との接続に、それぞれ専用のプ
ログラマブルなプロセッサが配置される。CPU は、バスを操作したり割り込みを処理したりす
る代わりに、プログラマブルなプロセッサにプログラムをダウンロードするのだ。そうすれば
プロセッサが、入出力のすべての詳細を処理してくれる。たとえばIBM 社が販売するメイン
フレームコンピュータは、プログラマブルなI/O プロセッサを「チャネル」と呼んでいる。
18.14 　通信、協調、競合
マルチプロセッサアーキテクチャのほうが、ユニプロセッサアーキテクチャより、常に性能
が良いのだろうと思われるかもしれない。たとえば対称型マルチプロセッサ、M を考えてみる。
コンピュータM がユニプロセッサの性能をしのぐことは直感できる。なにしろM は、同時に
N 倍の演算を実行できる。そればかりか、もしチップのベンダーが1 個のプロセッサでもM
より速くする方法を見つけたら、M を売っているベンダーは、M で使っているプロセッサを新
しいチップと交換することで、より高速なマルチプロセッサを作れるだろう。実際、マルチプ
ロセッサを作成した会社の多くは、このような言説で顧客を惹きつけてきた。
しかし残念ながら、コンピュータの性能に関する直感は、誤解を招きかねない。高性能な並
列アーキテクチャの設計に、主に3 つの課題があることが、アーキテクトたちによって指摘さ
れている。
•
通信
•
協調
•
競合
通信
何十個もの独立したプロセッサを持つコンピュータは、容易に想像できるかもしれないが、
そのコンピュータは、プロセッサが相互に、そしてメモリと、そしてI/O デバイスと通信でき
る機構も提供しなければならない。さらに重要なポイントとして、その通信機構は多数のプロ
セッサを扱う規模までスケーリング可能でなければならない。アーキテクトは、通信が深刻な
hi.0412.ko.2002@gmail.com
356
第18 章
並列処理　
ボトルネックにならない並列コンピュータを作るのに、かなりの労力を費やす必要がある。
協調
並列アーキテクチャでは、複数のプロセッサが協力して計算を実行する必要があるから、プ
ロセッサを制御する協調機構が必要だ。前述したように、非対称設計ではプロセッサの1 つが
「マスター」となって、他のすべてのプロセッサを制御して協調させる。一部の対称型設計も、
主従関係のアプローチを使う。それ以外のアーキテクチャは、分散された協調機構を使うので、
それぞれのプロセッサを、マスターなしで互いに協調できるようにプログラミングする必要が
ある。
競合
2 つ以上のプロセッサが、同時に同じリソースをアクセスしようとする場合、それらのプロ
セッサは、リソースを争って「競合する」と言われる。リソースの「競合」は、並列アーキテ
クチャの設計において、最大の難関の1 つである。プロセッサの数が増えれば競合も増えるか
らだ。
なぜ競合が問題なのかを理解するために、メモリについて考えよう。もし複数のプロセッサ
のすべてが、同じ場所のメモリをアクセスできるのなら、そのメモリに対する同時アクセスを
1 個のプロセッサにしか与えない機構が必要だ。N 個のプロセッサが、そのメモリを同時に使
おうとしたとき、ハードウェア競合機構が、1 つを除いて他のすべての試みをブロックする。
つまり最初のメモリアクセスでは、その間にN‒1 個のプロセッサがアイドル状態になるし、次
のアクセスでは、N‒2 個のプロセッサがアイドルのままとなる。次のことは明白だ。
並列アーキテクチャでは、共有リソースの競合によって性能が顕著に低下する。同時に
所与のリソースを使えるプロセッサが1 個に限定されるので、ハードウェア競合機構は
他のプロセッサを、アクセスを待つ間は強制的にアイドル状態にする。
18.15 　マルチプロセッサの性能
マルチプロセッサのアーキテクチャは、スケーラブルで高性能なコンピューティングという
約束を、まだ果たしていない。その理由は、OS のボトルネック、メモリの競合、入出力であ
る。現代のコンピュータシステムでは、OS が全部の処理を制御する。それにはプロセッサへ
のタスクの割り振りも入出力処理も含まれる。デバイスは、複数のプロセッサから同時に指令
を受けられない。このため、実行できるOS のコピーは、ただ1 つである。マルチプロセッサ
においても、同時にOS のソフトウェアを実行できるプロセッサは、最大で1 個なのだ。その
ため、複数のプロセッサがOS という共有リソースを競合する形になる。その結果OS は、急
速にボトルネックとなる。プロセッサは、それを直列にアクセスする。もしK 個のプロセッサ
がアクセスを必要としたら、そのうちK‒1 個のプロセッサは待たなければならない。
メモリの競合は、とくに難しい問題であることがわかっている。第1 に、複数のポートを持
hi.0412.ko.2002@gmail.com
　18.15
マルチプロセッサの性能
357
つメモリのハードウェアは、極度に高価である。第2 に、メモリシステムで使われる最適化の
中でも、とくに重要なキャッシングは、マルチプロセッサで使うと問題を起こす。もしキャッ
シュを共有したら、そのアクセスで複数のプロセッサが競合する。もし個々のプロセッサに、
それぞれ自分用のキャッシュを持たせたら、更新を全部のキャッシュに伝播するために、すべ
てのキャッシュを協調させる必要がある。残念ながら、そのような協調はオーバーヘッドをも
たらす。
多くのマルチプロセッサアーキテクチャは、もう1 つの弱点に悩まされる。ユニプロセッサ
アーキテクチャよりも優れた性能を出せるのは、大量の計算を集中的に行うときだけなのだ。
驚くべきことだが、ほとんどのアプリケーションは、実行する計算の量によって制限されるの
ではない。ほとんどのアプリケーションは、
「入出力に束縛される」
。それはアプリケーション
が、計算の実行より入出力を待つことに多くの時間を費やすという意味だ。たとえば文書やス
プレッドシートの作成、ビデオゲーム、Web ブラウザといった一般的なアプリケーションで生
じる遅延の大半が、ファイルまたはネットワークの入出力を待つときに生じる。したがって、
根底にあるコンピュータの計算能力を増強しても、その計算を実行するのに必要な時間は短縮
されない。追加したプロセッサは、入出力を待ってアイドル状態になるのだ。
N 個のプロセッサを使うシステムの性能を評価するために、われわれは、1 個のプロセッサ
による性能とマルチプロセッサによる性能との比率を、
「高速化」として定義する。具体的な高
速化の定義は、次のものだ。
Speedup = τ1
τN
ここで、τ1 は1 個のプロセッサにおける実行時間、τN はマルチプロセッサにおける実行時
間を表す6。性能は、それぞれのケースで使える最良なアルゴリズムで計測するものとする。つ
まり、並列ハードウェアの利点を生かすために、プログラムを書き直すことが許される。
マルチプロセッサによる汎用的な計算タスクの実行を計測すると、興味深い結果が現れる。
理想的な状況では、マルチプロセッサに、より多くのプロセッサを追加すれば、性能の線形な
向上が期待されるだろう。ところが実際には、メモリの競合、プロセッサ間の通信、OS のボ
トルネックといった問題が生じて、マルチプロセッサではリニアな高速化を達成できない。図
18‒4 に示すように、しばしば性能は、ある限界に到達する。
驚くべきことに、この図に示すような性能さえも、現実には達成できないかもしれない。マ
ルチプロセッサの設計によっては、通信のオーバーヘッドとメモリの競合が実行時間を支配す
る。どんどんプロセッサを追加していくと、逆に性能が低下し始めるのだ。たとえば、ある対
称型マルチプロセッサ設計では、少数のプロセッサならば若干の高速化が得られる。ところが、
64 個のプロセッサを使うと、通信のオーバーヘッドによって、1 個のプロセッサによるシステ
ムよりも性能が悪くなる。要約しておこう。
6　1 個のプロセッサによる処理時間は、マルチプロセッサによる処理時間より長くなることが期待される
ので、1 より大きな高速化が期待される。
hi.0412.ko.2002@gmail.com
358
第18 章
並列処理　
高速化
理想
実際
プロセッサの数(N)
16
12
8
4
1
1 
4 
8 
12 
16
図18‒4：マルチプロセッサでプロセッサの数を増やすときの、理想と典型的な性能の違い。Y 軸の値は、1
個のプロセッサと比較した、相対的な高速化である
汎用的なコンピューティングに使う場合、マルチプロセッサでは良い性能を出せないか
もしれない。場合によっては、オーバーヘッドが加わるために、プロセッサを追加する
ことによって性能が悪化する。
18.16 　プログラマにおよぼす影響
並列性によって、プログラミングは、より複雑になるのが普通だ。プログラマは、並列実行
を意識する必要があり、並列的な動作が互いの妨げになるのを避けなければならない。以下の
項で、プログラマが利用できる機構と機能を、いくつか記述する。
18.16.1
ロックと排他制御
複数のプロセッサを使うコーディングは、1 個のプロセッサのためのコーディングよりも複
雑になる。その複雑さを理解するために、共有変数の使い方を考えてみよう。たとえば2 つの
プロセッサが、カウンタを格納するために、1 個の変数x を使うと想定しよう。そしてプログ
ラマが、次のようなステートメントを書く。
x = x + 1;
コンパイラは、このステートメントを一連のマシン命令に変換する。それは、リスト18‒2
に示すようなシーケンスになるだろう。
hi.0412.ko.2002@gmail.com
　18.16
プログラマにおよぼす影響
359
リスト18‒2：メモリの変数をインクリメントするのに使われるマシン命令のシーケンス。ほとんどのアー
キテクチャで、インクリメントはロードとストアの演算を引き起こす
load
x, R5
# 変数x をR5 にロード
incr
R5
# R5 の値をインクリメント
store
R5, x
# R5 をx に書き戻す
残念ながら、もし2 つのプロセッサが、ほとんど同時にx をインクリメントしようとしたら、
x の値は2 回ではなく1 回しかインクリメントされないかもしれない。その誤りが発生する理
由は、2 つのプロセッサが勝手に演算をして、メモリアクセスが競合するからだ。その演算は、
図18‒5 のような順序で実行されるかもしれない。
•
プロセッサ1 が、x をレジスタ5 にロード
•
プロセッサ1 が、そのレジスタ5 をインクリメント
•
プロセッサ2 が、x を自分のレジスタ5 にロード
•
プロセッサ1 が、自分のレジスタ5 をx にストア
•
プロセッサ2 が、自分のレジスタ5 をインクリメント
•
プロセッサ2 が、そのレジスタ5 をx にストア
図18‒5：2 つの独立したプロセッサないしコアが、共有メモリの変数x をアクセスするときに起こり得る
ステップのシーケンス
図18‒5 に示したような問題を避けるために、マルチプロセッサのハードウェアは、
「ハード
ウェアロック」を提供する。プログラマは共有項目に、それぞれ1 個のロックを割り当て、項
目の更新中は、他のプロセッサがその項目を変更できないようにロックを使う必要がある。た
とえば、もしロック17 を変数x に割り当てていたら、プログラマはx を更新する前に、ロック
17 を取得する必要がある。このアイデアは「排他制御」あるいは「相互排他」と呼ばれる。プ
ロセッサは値を更新する前に、変数の「排他使用権」を取得しなければならない。リスト18‒3
に、その命令シーケンスを示す。
リスト18‒3：変数への排他的アクセスを保証するために使われる命令の例。それぞれの共有項目に別々の
ロックが使われる
lock
17
# ロック17 を待つ
load
x, R5
# 変数x をR5 にロード
incr
R5
# R5 の値をインクリメント
store
R5, x
# R5 をx に書き戻す
release
17
# ロック17 を解放する
ロックを獲得できるプロセッサが必ず1 個だけになることが、根底にあるハードウェアに
よって保証される。したがって、もし2 つ以上のプロセッサが同時に同じロックを取得しよう
としたら、そのうち1 つがアクセスを取得して実行を続け、他のプロセッサは実行をブロック
hi.0412.ko.2002@gmail.com
360
第18 章
並列処理　
される。実際、あるプロセッサがロックを保持している間、任意の数のプロセッサがブロック
され得る。ロックを保持するプロセッサが、それを解放したら、ハードウェアはブロックして
いるプロセッサを1 つ選び、そのプロセッサにロックを与えて実行を続けさせる。したがって、
所与のロックを保持できるのは、いつでも最大1 個のプロセッサとなることが保証される。
ロックによってプログラムに、かなりの複雑さが加わる。それには、いくつもの理由がある。
第1 に、ロックが特例的なので、マルチプロセッサのプログラミングに不慣れなプログラマは
共有変数をロックするのを忘れやすい。おまけに、アクセスを保護しなくても必ずエラーにな
るわけではないから、問題の検出が難しくなる。第2 に、ロックによって性能が顕著に悪化す
るかもしれない。もしK 個のプロセッサが同時に1 個の共有変数をアクセスしようとしたら、
ハードウェアが、そのうちK‒1 個のプロセッサを、アクセスを待つ間アイドル状態にする。第
3 に、ロックの取得と解放に別の命令を使うので、ロッキングそのものがオーバーヘッドにな
る。だからプログラマは、個々の演算についてロックを取得するか、それとも、いったんロッ
クを取得したら、その変数に対する一連の演算を実行している間はロックを保持し、それから
ロックを解放するかを、決める必要がある。
18.16.2
明示的／暗示的な並列コンピュータのプログラミング
並行性を管理する責任がソフトウェアにあるのか、それともハードウェアになるのか、とい
う問題も、プログラマにとって重要だ。暗黙的並列性を使うシステムは、明示的並列性を使う
システムよりも、ずっとプログラミングが容易だ。たとえば、プロセッサがコンピュータネッ
トワークから到着するパケットを処理するように設計されるとしよう。暗黙的な設計では、プ
ログラマは1 個のパケットを処理するコードを書き、ハードウェアは自動的に、同じプログラ
ムをN 個のパケットに並列的に適用する。明示的な設計では、プログラマは事前に計画を立て
て、N 個のパケットを読み出し、それぞれを別々なコアに送り、コアが処理を終わるのを待っ
て、その結果からパケットを抽出する必要がある。多くの場合、並列なコアを制御して、それぞ
れの完了を判定するのに必要なコードのほうが、期待された計算そのものを実行するコードよ
りも複雑になる。そして、もっと重要なポイントとして、並列なハードウェアユニットを制御
するコードは、ハードウェアが任意の順序で動作するのを許容しなければならない。たとえば
パケット処理に必要な時間は、そのパケットの内容に依存するから、コントローラには、ハー
ドウェアユニットが任意の順序で処理を完了するのを待つ準備が必要である。要するに次のこ
とが言える。
プログラマの視点から見ると、明示的並行性を使うシステムは、暗黙的並列性を使うシ
ステムよりも、ずっとプログラミングが複雑である。
hi.0412.ko.2002@gmail.com
　18.17
冗長と並列のアーキテクチャ
361
18.16.3
対称的／非対称的マルチプロセッサのプログラミング
対称性がもたらす重要な利点の1 つは、プログラマに与えるポジティブな影響に起因する。
つまり、対称的マルチプロセッサは、非対称なマルチプロセッサと比べて、かなりプログラミ
ングが容易になるかもしれない。なぜなら第1 に、もし全部のプロセッサが同一ならば、プロ
グラマは、ただ1 つのコンパイラ、ただ1 つの言語しか必要としない。第2 に、対称的ならば
プログラマは、どのタスクがどのプロセッサに適しているかを考慮する必要がない。第3 に、
同一のプロセッサは普通は同じスピードで動くから、プログラマは、所与のプロセッサでタス
クを実行するのに必要な時間について心配する必要がない。第4 に、すべてのプロセッサが命
令とデータに同じ符号化形式を使うのだから、あるプロセッサから別のプロセッサへと、バイ
ナリのプログラムまたはデータ値を移すことができる。
もちろん、どんな形式のマルチプロセッサでも、複雑さは加わる。他のすべての注意事項に
加えて、プログラマは、コーディング上の判断が性能に与える影響を考慮しなければならない。
たとえばネットワークから到着するパケットを処理する計算を考えてみよう。伝統的なプログ
ラムなら、グローバルカウンタをメモリに置いておき、パケットが届いたら、そのカウンタを
更新するだろう。しかし共有メモリのアーキテクチャでは、メモリの値の更新が、もっと高価
になる。それはプロセッサがメモリで共有される値を更新する前にロックを取得する必要があ
るからだ。したがってログラマは、メモリにある共有カウンタの更新といった些細な詳細の影
響も考慮しなければならない。
18.17 　冗長と並列のアーキテクチャ
これまでの議論は、性能または機能を高めるために並列ハードウェアを使うことに重点を置
いていた。けれども並列ハードウェアは、信頼性を向上させ故障を防ぐためにも利用できる。
つまりハードウェアの複数のコピーを、互いの計算を確認するために使うことができる。
「冗長ハードウェア」という言葉は、ある演算を並列に実行する、ハードウェアユニットの
複数のコピーを指して使うことが多い。冗長ハードウェアと並列アーキテクチャの基本的な違
いは、使われるデータ項目に関するものだ。並列アーキテクチャは、それぞれ別のデータ項目
を処理するために、ハードウェアの複数のコピーを利用する。冗長アーキテクチャは、まった
く同じ演算を実行するために、すべてのコピーを利用する。
冗長ハードウェアを使うのは、計算が正しいことを立証するためだ。もしハードウェアの冗
長なコピーで結果が違っていたら、どうなるのだろう。その答えは、根底にあるシステムの詳
細と目的によって異なる。1 つの可能性として、多数決がある。ハードウェアユニットのK 個
のコピーが、それぞれ計算を実行して値を生成する。その出力を、特別なハードウェアユニッ
トで比較して、もっとも多く現れた値を選択するのだ。もう1 つの可能性として、冗長ハード
ウェアを使ってハードウェアの故障を検出することもある。もしハードウェアの2 つのコピー
で一致が得られなければ、そのシステムはエラーメッセージを出し、壊れたユニットを修理ま
hi.0412.ko.2002@gmail.com
362
第18 章
並列処理　
たは交換するまで停止する。
18.18 　コンピュータの分散とクラスタ
この章で論じた並列アーキテクチャは、並列ハードウェアユニットが同じコンピュータシス
テムの内側に位置するので、
「密結合」と呼ばれる。その反対に「疎結合」と呼ばれるアーキテ
クチャは、複数のコンピュータシステムを、長距離におよぶ通信機構によって相互に接続した
ものだ。たとたとえばコンピュータネットワークまたはインターネットによって接続された一
群のコンピュータを呼ぶには、
「分散アーキテクチャ」という用語を使う。分散アーキテクチャ
において、個々のコンピュータは独立して運用されるが、ネットワークを超えてメッセージを
送ることによって通信できる。
分散コンピューティングシステムの特別な形態で、
「ネットワーククラスタ」または「クラス
タコンピュータ」
と呼ばれるものがある。基本的にクラスタコンピュータは、
高速なコンピュー
タネットワークで接続された、よくあるPC のような独立したコンピュータの集合で構成され
る。科学者は、極めて大きなデータ集合に対する計算を実行するのにクラスタコンピュータを
使う。インターネット検索の会社はクラスタを使ってユーザーの検索語に応答し、クラウドプ
ロバイダーはクラスタのアプローチを使ってクラウドデータセンターを構築する。N 個のコン
ピュータによるクラスタにおいて、計算を分割方法はさまざまだ。クラスタのコンピュータに
は柔軟性があって、1 個の問題を解くためにも、それぞれ別の問題を解くためにも、使うこと
ができる。クラスタのコンピュータは独立して実行される。もしクラスタで1 個の問題を解く
のなら、結果を収集して最終的な出力を生成することもできる。
小さなリクエストを数多く扱う大容量のWeb サイトを作るには、クラスタコンピューティン
グの特殊なケースを使う。そのクラスタの、それぞれのコンピュータで、同じWeb サーバー
のコピーを実行する。そして「Web ロードバランサ」と呼ばれる特殊用途のシステムが、クラ
スタ内のコンピュータに、到着するパケットを分担させる。リクエストが届くたびに、ロード
バランサが、そのクラスタでもっとも負荷の少ないコンピュータを選んで、それにリクエスト
をまわす。これによって、N 個のコンピュータによるクラスタを持つWeb サイトは、1 個の
コンピュータと比べて、毎秒およそN 倍のリクエストに応答することができる。
疎結合の分散コンピューティングには、もう1 つ「グリッドコンピューティング」と呼ばれ
る形式のものがある。グリッドコンピューティングは、一群のコンピュータとともに、グロー
バルなインターネットを通信機構として使う。それらのコンピュータ（典型的には、個人が所
有するパーソナルコンピュータ）は、空いているCPU サイクルをグリッドのために提供するこ
とに同意している。それぞれのコンピュータで実行されるソフトウェアは、繰り返しリクエス
トを受けては、要求された計算を実行し、その結果を返す。グリッドを使うためには、問題を
数多くの小さな部分に分ける必要がある。細分化された問題の各部が、あちこちのコンピュー
タに送られ、それらのコンピュータは、すべて同時に実行可能である。
hi.0412.ko.2002@gmail.com
　18.19
最近のスーパーコンピュータ
363
18.19 　最近のスーパーコンピュータ
「スーパーコンピュータ」という非公式な言葉は、メインフレームコンピュータよりずっと
大きな処理能力を持つ、高度なコンピュータシステムの呼び名として使われる。しばしば科学
的な計算に使われるので、スーパーコンピュータの性能は、毎秒に実行可能な浮動小数点演算
の数（FLOPS）によって評価されるのが典型的だ。
並行処理は常にスーパーコンピュータで重要な役割を果たしてきた。初期のスーパーコン
ピュータは16 個または64 個のプロセッサを持っていた。最近のスーパーコンピュータの1
つは、高速なLAN（Local Area Network）で相互接続された大量のPC によるクラスタで構成
されている。さらに、それぞれのPC のプロセッサがマルチコアを持つ。現代のスーパーコン
ピュータは、並列性を驚くような規模で追求している。たとえば中国の天河二号（Tianhe-2）
スーパーコンピュータは16,000 個のIntel ノードからなるクラスタで構成された7。それぞれ
のノードが独自のメモリと一群のプロセッサを持ち、それぞれのプロセッサがマルチコアを持
つ。その結果、システム全体で312 万個のコアがある。300 万を超えるコアを持つコンピュー
タの計算能力は、想像し難い。
18.20 　まとめ
並行処理はハードウェアの性能を高めるために使われる基本的な最適化技法だ。コンピュー
タシステムの、ほとんどのコンポーネントに並列ハードウェアが含まれる。アーキテクチャが
「並列」に分類されるのは、そのアーキテクチャに並列プロセッサ群が含まれるときだけだ。明
示的な並列処理では、プログラマが並列機構の使い方を制御できる。暗黙的な並列処理では、
並列化が自動的に行われる。
ユニプロセッサ（単一プロセッサ）のコンピュータが、SISD（単一命令、単一データ）アー
キテクチャに分類されるのは、いつでも1 個の命令が1 個のデータ項目に適用されるからだ。
SIMD（単一命令、複数データ）アーキテクチャでは、1 つの命令を値の配列に適用できる。典
型的なSIMD マシンに、ベクトルプロセッサとグラフィックスプロセッサがある。MIMD（複
数命令、複数データ）アーキテクチャは、同時に動く複数の独立したプロセッサを採用し、そ
れぞれ別々のプログラムを実行できる。典型的なMIMD マシンには、対称型と非対称なマル
チプロセッサが含まれる。SIMD やMIMD に代わるアーキテクチャとしては、冗長、分散、ク
ラスタ、グリッドがある。
N 個のプロセッサを持つ汎用的なマルチプロセッサでは、理論上は1 個のプロセッサよりN
倍高速な性能を得られるはずだ。しかし実際には、メモリの競合と通信のオーバーヘッドがあ
り、協調も必要なので、マルチプロセッサの性能は、プロセッサを増やしても線的には改善さ
7　訳注：スーパーコンピュータのランキング「top500.org」で本書翻訳中の2020 年6 月に1 位となった
日本の「富岳」は、総ノード数が158,976 個である。
hi.0412.ko.2002@gmail.com
364
第18 章
並列処理　
れない。極端な場合、プロセッサを追加すると、そのオーバーヘッドのおかげで、かえって性
能が低下することもある。複数のプロセッサを持つコンピュータのプログラミングは難題とな
るかもしれない。プログラマには他に考慮すべき事項があるが、共有する項目を排他的にアク
セスするために、ロックを使わなければならないのだ。
現代のスーパーコンピュータは、プロセッサの大規模なクラスタで構成される。問題を細分
化できれば、スーパーコンピュータのクラスタに含まれるプロセッサ群で、問題の各部を並列
に処理できる。
練習問題
18.1
巨視的な並列処理を定義して、その例を1 つあげてください。
18.2
もしコンピュータに4 コアのCPU と2 コアのGPU があれば、そのシステムが持
つのは、対称型並列性か、非対称並列性か、それとも両方を少しずつですか? 説明し
てください。
18.3
フリンの分類を使って、デュアルコアのスマートフォンを分類してください。
18.4
競合とは何ですか? どうして性能に影響を与ぼすのですか?
18.5
C のプログラマが、マルチコアで実行されるコードを書いていて、共有変数x をイ
ンクリメントする必要がありました。
x = x + 1;
と書く代わりに、そのC プログラマは、
x++;
と書いたのですが、この形式で、2 つのコアがインクリメントを互いに干渉すること
なく実行できるのでしょうか。説明してください。
18.6
あなたは同じ給料の仕事を2 つ、オファーされました。1 つは明示的な並列化を使
うシステムのためのコーディング、もう1 つは暗黙の並列化を使うシステムのための
コーディングです。あなたは、どちらを選びますか? その理由は?
18.7
10×20 の行列2 つを、ベクトル計算能力を持つコンピュータで乗算したいのです
が、個々のベクトルのサイズが、要素数16 に限定されています。このコンピュータ
で、どうすれば行列の乗算を処理できるでしょうか。また、何回のベクトル乗算が必
要でしょうか?
18.8
前の問題で、もしユニプロセッサなら（つまりSISD アーキテクチャなら）何回のス
カラー乗算が必要でしょうか。もし加算を無視して乗算だけを計測するなら、スピー
ドアップ（高速化）は、どれほどですか? 100×100 の行列を乗算するときは、スピー
ドアップが変わりますか?
18.9
もしあなたが、同じクロックレートを持つ、シングルプロセッサとデュアルプロ
セッサのコンピュータをアクセスできるのなら、CPU 時間を大量に消費するプログラ
hi.0412.ko.2002@gmail.com
　18.20
まとめ
365
ムを書いて、両方のコンピュータで複数のコピーを実行し、実行時間を記録しましょ
う。実質的なスピードアップは、どれくらいですか?
18.10
前の問題で、プログラムを大量のメモリを参照するように変更しましょう（たと
えば、大きな配列に値x を代入し、次にその配列に値y を代入する、などの繰り返し
を行います）
。メモリ参照は、スピードアップに、どう影響しますか?
18.11
マルチプロセッサによって、線形よりも優れた高速化を達成できる場合がありま
すか? 答えを得るために、暗号解読のアルゴリズムについて考えましょう。これは暗
号鍵の24(4!) の組み合わせを試みる必要があり、それぞれの鍵について最大1024 の
演算を実行しなければなりません（解が見つかからない限り、途中で停止しません）
。
もしマルチプロセッサで、1024 の演算を実行するのにK ミリ秒かかるとしたら、問
題を完全に解くまでに費やす時間は、平均してどれだけになるでしょうか。また、32
個のプロセッサを持つMIMD マシンで同じ問題を解くのに、どれだけ時間がかかる
でしょう。それで、どれだけの高速化を得られるでしょうか?
18.12
Web を検索して、スーパーコンピュータのトップ10 のリストを見つけましょう。
それぞれ、いくつのコアを持っていますか?
hi.0412.ko.2002@gmail.com
hi.0412.ko.2002@gmail.com
第19 章
パイプライン処理
19.1 　はじめに
これまでの章では、コンピュータアーキテクチャの基本的な側面として、プロセッサ、メモ
リシステム、入出力を論じてきた。そして前章では性能を上げるために並列性を使う方法を示
し、さまざまな並列アーキテクチャを説明した。
この章では、性能を上げる主なテクニックの2 つめとして、データのパイプライン処理に重
点を置く。この章ではパイプラインを採用する動機を論じ、パイプラインを使うさまざまな方
法を説明し、パイプライン化によってハードウェアの性能が向上する理由を示す。
19.2 　パイプライン処理の概念
「パイプライン処理」という用語は、広範囲なアーキテクチャに使われるが、デジタル情報
が、図19‒1 に示すように一連の「ステージ」を通過して流れて行き、その過程で、情報の監
視、解釈、変更などが行われることを意味する。
情報が到着する
情報が出て行く
ステージ1 
ステージ２ 
ステージ3 
ステージ4
図19‒1：パイプライン処理のコンセプト。このサンプルのパイプラインには4 つのステージがあり、すべ
ての情報は、これらのステージを順に通過する
われわれにとって主な関心は、ハードウェアアーキテクチャと、1 個のコンピュータシステム
におけるパイプラインの使用方法だが、パイプラインのコンセプトそのものはハードウェアに
hi.0412.ko.2002@gmail.com
368
第19 章
パイプライン処理　
限定されない。パイプライン処理は、1 個のコンピュータに限定されず、デジタル情報の特定
の型やサイズに束縛されず、長さも規定されない（つまり一定のステージ数に限定されない）
。
むしろパイプライン処理は、計算のさまざまな状況で使われる基礎的なコンセプトなのだ。
この概念を理解するために、そのさまざまな性質を考慮しよう。まずはパイプラインが持つ
性質のさまざまな表現を、図19‒2 に示し、その後の各段落で、それぞれの性質を説明する。
•
実装はハードウェアか、ソフトウェアか
•
スケールが大きいか、小さいか
•
データのフロー（流れ）は同期的か、非同期か
•
フローはバッファリングされるか、されないか
•
有限のチャンクか、連続的なビットストリームか
•
データフィードは自動的か、それともマニュアルか
•
パス（経路）はシリアルか、パラレルか
•
各ステージは同質か、それとも異質か
図19‒2：パイプラインをデジタルシステムで使うさまざまな方法の区分
ハードウェアまたはソフトウェアによる実装
パイプライン処理は、ソフトウェアでもハードウェアでも実装できる。たとえばUnix には、
ソフトウェアパイプラインとして利用できる「パイプ」機構がある。一群のプロセスから、あ
るプロセスの出力を次のプロセスの入力に繋げるパイプが作られる。ハードウェアパイプライ
ンについては、今後の節で調べていこう。ただし、ソフトウェアパイプラインとハードウェア
パイプラインが独立した存在であることは、特記すべきだろう。たとえハードウェアアーキテ
クチャとしてパイプラインを使わないコンピュータでも、ソフトウェアパイプラインは作成で
きる。そしてパイプラインハードウェアは、プログラマから見えるものとは限らない。
スケールの大小
パイプラインのステージは単純なものから強力なものまでさまざまだ。パイプラインの全長
も、短いものから長いものまで存在する。1 つの極端なケースとして、ハードウェアパイプラ
インの全体が、ただ1 つの小さな機能ユニットまたはチップに収まる場合もある。その反対の
極端なケースでは、それぞれ別々のコンピュータで実行されインターネットを使って通信する
一連のプログラムにデータを渡すことで、ソフトウェアパイプラインを作ることもできる。短
いパイプラインは、2 つのステージで作ることができる。片方が情報を生成し、もう片方が、そ
れを消費するのだ。そして長いパイプラインは何百ものステージを含むことができる。
同期的または非同期なデータフロー
同期的なパイプラインは、組み立て工程の流れ作業のように動作する。どのタイミングでも、
それぞれのステージが、ある量の（たとえば1 バイトの）情報を処理している。グローバルな
hi.0412.ko.2002@gmail.com
　19.2
パイプライン処理の概念
369
クロックが、それらの動きを制御する。つまり、すべてのステージが同時に、自分のデータ（処
理の結果）を次のステージに送るのだ。逆に、非同期なパイプラインのステージは、いつでも
情報を送ることができる。非同期通信が、とくに魅力的なのは、あるステージで処理に費やさ
れる時間が、そのステージが受け取るデータに依存するような場合だ。とはいえ非同期通信で
は、あるステージが遅くなって、次のステージが、それを待つことになるかもしれない。
データフローにおけるバッファリングの有無
図19‒1 に示した概念図は、パイプラインのステージが次のステージに直接データを送るこ
とを示唆していた。しかし、一対のステージの間にバッファを置くパイプラインを構築するこ
とも可能である。バッファリングが非同期なパイプラインで有効なのは、バースト状の情報を
処理する場合だ（つまり、パイプラインのステージが、絶え間のない繰り返しで出力を送り出
した後、いったん出力が途切れ、それからまた絶え間なく出力を繰り返すような場合である）
。
有限のチャンクまたは連続するビットストリーム
パイプラインを通過するデジタル情報の構成は、小さなデータ項目のシーケンス（たとえば
コンピュータネットークからのパケット）にも、任意の長さのビットストリーム（たとえば連
続的なビデオフィード）にもできる。さらに、個々のデータ項目を処理するパイプラインには、
すべてのデータ項目を同じサイズとする設計（たとえば、それぞれK バイトのディスクブロッ
ク）も、データ項目のサイズを固定しない設計（たとえば可変長のEthernet パケットによる
シーケンス）も可能である。
自動的またはマニュアルのデータフィード
パイプラインの実装には、情報の移動に別の機構を使うものも、それぞれのステージが情報
の移動に参加する必要があるものもある。たとえば同期的なハードウェアパイプラインでは、
ステージからステージへと情報を移動させるのに、補助的な機構に頼るのが典型的である。け
れどもソフトウェアパイプラインの場合は、それぞれのステージが明示的に出力データを書き、
入力データを読むのが普通だ。
シリアルまたはパラレルのデータ経路
図19‒1 の太い矢印は、ステージからステージへのデータ移動に並列パスを使うことを示唆
している。たしかに一部のハードウェアパイプラインはパラレルなデータ経路を使うが、多く
の場合はシリアル通信が使われる。しかもステージ間の通信に、一般的な通信手段を使う必要
もない（たとえばコンピュータネットワークを使ってもよいし、共有メモリを使ってもよい）
。
同質または異質なステージ群
図19‒1 ではパイプラインの各ステージに同じサイズと形を使っているが、ステージの同質
性は必須ではない。実装によって、各ステージに適した種類のハードウェアを選択するパイプ
ラインもある。
hi.0412.ko.2002@gmail.com
370
第19 章
パイプライン処理　
19.3 　ソフトウェアによるパイプライン
プログラマの視点から見ると、ソフトウェアパイプラインは2 つの理由で魅力がある。第1
に、ソフトウェアパイプラインは複雑さを扱う手段として優れている。第2 に、ソフトウェア
パイプラインならプログラムを再利用できる。この2 つをソフトウェアパイプラインで実現で
きる主な理由は、プログラマが大きくて複雑な仕事を、もっと小さくて一般的な部分に分割で
きるからだ。
ソフトウェアパイプラインの一例として、Unix のシェル（コマンドインタープリタ）が提供
するパイプライン機能を考えてみよう。ソフトウェアパイプラインを作るとき、ユーザーはコ
マンド名のリストを、
「|」という縦線文字で区切って入力することにより、それらのプログラ
ムをパイプラインとして実行させる。シェルは、あるプログラムの出力が次のプログラムの入
力となるようにする。どのプログラムも、0 個以上の引数で処理の制御が可能である。たとえ
ば次に示すシェル入力は、cat、sed、more という3 つのプログラムを1 個のパイプラインの
中で接続せよという指定である。
cat x | sed ’s/friend/partner/g’ | more
この例でcat プログラムは、ファイルx のコピーを（たぶんテキストファイルだろう）出力
として書き出す。それがsed プログラムの入力になる。パイプラインの中央に位置する、その
sed プログラムは、cat から入力を受け取って、出力をmore に送る。sed には引数があり、
"friend"というワードがあれば、どれも"partner"で置換せよ、と指定されている。パイプラ
インの最後にあるmore プログラムは、sed から受け取った入力を、ユーザーが読みやすいよ
うに表示する。
この例はとても簡単だが、ソフトウェアパイプラインが、どれだけプログラマの役に立つか
を示している。1 個のプログラムを、より小さく、それほど複雑ではない一連のプログラムに
分解することで、そのソフトウェアは作成もデバッグも容易になる。そればかりか、注意深く
分割すれば、その一部は他のプログラムでも再利用可能となる。プログラマは、パイプライン
を使って計算の入力と出力の処理を切り分けておけば計算のコードをさまざまな形式の入力と
出力で再利用できることに気がつくことが多い。
19.4 　ソフトウェアパイプラインの性能とオーバーヘッド
ソフトウェアによるパイプラインは、結局は1 本のプログラムよりも性能が劣るのではない
かと思われるかもしれない。OS は複数のアプリケーションを同時に実行する必要があり、1 対
のプログラムの間でデータを渡す必要もある。とくに効率が悪いのは、パイプラインの初期段
階で大量のデータを渡しているのに、その大部分が後で捨てられる場合だろう。たとえば次の
ソフトウェアパイプラインを見よう。これには、前の例よりも1 段多いステージが含まれてい
hi.0412.ko.2002@gmail.com
　19.5
ハードウェアによるパイプライン
371
る。つまり、もう1 回sed を呼び出して、
「W」という文字を含む行を削除するのだ。
cat x | sed ’s/friend/partner/g’ | sed ’/W/d’ | more
もし全部の行の99%に「W」という文字が含まれていたら、パイプラインの前半で不必要な
作業を行うことになる（行のテキストを処理しても、パイプラインの後のステージで、その行
が捨てられる）
。この例でパイプラインを最適化するには、もっと前の段階に削除を移すべき
だ。とはいえ、ソフトウェアのパイプラインを使うことのオーバーヘッドは残りそうだ。ある
プログラムから別のプログラムへとデータをコピーするのは、1 個のプログラムの中で全部の
計算を実行するより効率が悪いではないか。
ところが驚くべきことにソフトウェアパイプラインは、根底にあるハードウェアが複数のコ
アを使わない場合でさえも、大きなモノリス（一枚岩）的なプログラムより優れた性能を示す
ことがある。その理由を理解するために、根底にあるアーキテクチャを考えよう。処理もメモ
リも入出力も、独立したハードウェアで構築される。OS は、アプリケーションプログラム（プ
ロセス）の間でプロセッサを自動的に切り替えることによって、その独立性を活用する。アプ
リケーションが入出力を待っているときは、もう1 つのアプリケーションが実行される。した
がって、もしパイプラインが多くの小さなアプリケーションで構成されていたら、パイプライ
ンのアプリケーションの1 つをOS が実行している間、もう1 つのアプリケーションが入出力
を待つことで、全体の性能が高まるかもしれない。
19.5 　ハードウェアによるパイプライン
ソフトウェアによるパイプライン処理と同じように、ハードウェアによるパイプライン処理
も、設計者が複雑さを扱うのに役立つことがある。つまり複雑な仕事を、もっと小さくて扱い
やすい各部に分けるのだ。ただし、アーキテクトがハードウェアパイプラインを選ぶもっとも
重要な理由は、性能の向上だ。ハードウェアパイプラインを使う方法は、次の2 つにわかれる
が、どちらも高性能に貢献する。
•
命令パイプライン
•
データパイプライン
命令パイプライン
プロセッサの「フェッチ‒ 実行」サイクルで、命令のデコードと実行にパイプラインを使え
ることは、第5 章で説明した。厳密に言うと、マシン命令を情報の内容とするパイプラインで、
そのステージが命令のデコードと実行を行うものを「命令パイプライン」と呼ぶ。ただし命令
セットとオペランド型はプロセッサによって異なるので、命令パイプラインで使うステージの
hi.0412.ko.2002@gmail.com
372
第19 章
パイプライン処理　
段数や、所与のステージで実行する処理について、統一的な見解があるわけではない1。
データパイプライン
命令パイプライン以外の、もう1 つのパイプラインが、
「データパイプライン」だ。つまり、
データパイプラインは、命令ではなくデータをステージからステージへと渡すように設計され
る。たとえばコンピュータネットワークから到着するパケットの処理にデータパイプラインを
使うのなら、それぞれのパケットは、パイプラインの格段へと順番に渡されていくことになる。
パイプライン処理のもっとも珍しい、そしてもっとも興味深い使い方は、データパイプライン
で見られる。これから見ていくようにデータパイプラインには、性能の全体的な改善が最大に
なる可能性もある。
19.6 　ハードウェアパイプラインで性能を向上させる方法
なぜパイプラインがハードウェア設計の基本なのだろう。それを理解するには、パイプライ
ンによって性能が飛躍的に向上する可能性を調べる必要がある。そのために、データパイプラ
インとモノリス的設計を比較しよう。たとえばISP（Internet Sevice Provider：インターネッ
トサービスプロバイダー）が使うインターネットルータの設計を考えてみる。ルータは顧客と
Web サイトの間で行う「フォワーディング」によってパケットを中継する。ルータが接続する
複数のネットワークのなかには、顧客に向かうものと、少なくとも1 つはインターネットに向
かうものがある。ネットワークパケットは、どのネットワークからも届く可能性がある。ルー
タの仕事は、それらのパケットを、各自の送信先に向けて「転送」することだ。この例では、
ルータが、それぞれのパケットについて、図19‒3 に示す6 つの基本的な操作だけを行うこと
にしよう。これらの処理を理解することは重要ではない。現実的な例だと思っていただければ、
それで十分だ。
この図のステップを実装するハードウェアの設計を考えよう。これらのステップには複雑な
計算が関わるので、パケットフォワーディングを実行するのにプロセッサを使うのが良いと
思われるかもしれない。けれども高速ネットワークでは、1 個のプロセッサだけでは十分なス
ピードを得られない。したがって、ほとんどの設計では、これまでの章で説明した、スマート
なI/O デバイスと並行処理という2 つの最適化が採用される。スマートI/O デバイスならば、
プロセッサを使わずにパケットをメモリに、あるいはメモリから、高速に転送できる。そして
並列設計としては個々の入力に、それぞれ別のプロセッサを使う。
スマートなI/O インターフェイスで並列処理のルータを設計するのだから、それぞれのプロ
セッサが実装するループで、6 つの基本ステップを繰り返し実行しよう。図19‒4 に、1 つのプ
ロセッサが1 つの入力に接続するようすと、そのプロセッサで実行されるアルゴリズムを示す。
次に、この図の並列アーキテクチャでも、まだ遅すぎると想定しよう。つまりプロセッサは、
1　この章で後に紹介するスーパーパイプラインの定義も、命令パイプラインと関係がある。
hi.0412.ko.2002@gmail.com
　19.6
ハードウェアパイプラインで性能を向上させる方法
373
1
パケットを受信する（つまり、ネットワークデバイスからパケットを読んで、そのバ
イト列をメモリ内のバッファに送る）
。
2
パケットの真正性をチェックする（たとえばチェックサムを使って、送信と受信の間
で何も変更されていないことを確認する）
。
3
フォワーディングループをチェックする（つまり、ヘッダのある値をデクリメントし
て、新しい値でヘッダを作り直す）
。
4
パスを選択する（つまり、パケットの送信先アドレスフィールドを使って、出力ネッ
トワークの1 つと、そのネットワークにある送信先を選択する）
。
5
送信を準備する（つまり、パケットに送るべき情報を計算する。その情報によってパ
ケットの受信側が真正性をチェックする）
。
6
パケットを送信する（つまり、パケットを出力装置に送る）
。
図19‒3：インターネットルータのハードウェアが、パケットフォワーディングのために実行する一連のス
テップ
出力
プロセッサ
1つの
ネッ
トワークからの
入力
永遠に繰り返す {
    次のパケッ
トを受信
    パケッ
トの真正性を確認
    フォワーディ
ングループのチェ
ッ
ク
    出力パスを選択
    送信準備
    パケッ
トを出力キューに入れる
}
（a）
（b）
図19‒4：
（a）は、インターネットルータの並列実装で使われるプロセッサの接続。
（b）は、1 個のプロセッ
サが実行するアルゴリズム。個々のプロセッサが、それぞれ1 つのネットワークからの入力を扱う
次のパケットがインターフェイスに届く前にアルゴリズムの全ステップを実行できず、より高
速なプロセッサも使えないと想定する。どうすれば高性能を達成できるのか。1 つの可能性は、
データパイプラインによる高速化だ。図19‒5 に示すように、1 個のプロセッサの代わりに複
数のプロッサによるパイプラインを使う2。
この図のパイプラインは、図19‒4 で見た1 個のプロセッサよりも高速とは思えないかもし
れない。結局パイプラインアーキテクチャも、個々のパケットに対してシングルプロセッサと
まったく同じ処理を行うのだ。そればかりか、もし図19‒5 のプロセッサが、どれも図19‒4 の
プロセッサと同じスピードならば、所与の演算を実行する時間は同じだろう。たとえば「真正
性を確認」というラベルのステップには、どちらのアーキテクチャでも同じ時間がかかるだろ
うし、
「ループをチェック」というラベルのステップにも、どちらも同じ時間がかかるはずだ
2　このパイプラインは、前章で言及したフリンの分類によるMISD 並列アーキテクチャの一例である。
hi.0412.ko.2002@gmail.com
374
第19 章
パイプライン処理　
パケッ
トが
到着する
真正性を
確認
ループを
チェ
ッ
ク
パスを選択
送信準備
パケッ
トが
出て行く
図19‒5：インターネットルータで、1 個のプロセッサの代わりにパイプラインを使う例
（以下同様）
。だから、パケットをパイプラインのステージ間で渡すことによる遅延を無視すれ
ば、1 個のパケットを処理するのにかかる時間の合計は、シングルプロセッサアーキテクチャ
と、まったく同じになるはずだ。つまり次のことが言える。
データパイプラインは、データを一連のステージに渡し、それぞれのステージがデータ
の検査や書き換えを行う。もしパイプラインを使わないアーキテクチャと同じスピード
のプロセッサを使うのなら、データパイプラインでも、所与のデータ項目を処理するの
に必要な時間の合計は改善されないだろう。
もし1 個の要素に必要な処理時間の合計が、パイプライン処理でも、そうではないアーキテ
クチャと同じだとしたら、いったいデータパイプラインの利点は何なのか? 驚くべきことに、
たとえ図19‒5 の個々のプロセッサが、図19‒4 のプロセッサとまったく同じスピードでも、パ
イプラインアーキテクチャのほうが、毎秒に処理できるパケットの数が多いのだ。その理由を
知るには、まず個々のプロセッサがパケット毎に実行する命令の数が少ないという点に注目し
よう。さらに、1 個のデータ項目を処理した後で、プロセッサは次のデータ項目に進むことが
できる。したがってデータパイプラインアーキテクチャでは、所与のプロセッサが、パイプラ
インを使わないアーキテクチャよりも素早く次のデータ項目に進めるのだ。その結果、データ
は、より高速なレートでパイプラインに入り、そして出て行く。
要約しよう。
たとえパイプラインで、非パイプラインアーキテクチャと同じ速度のプロセッサを使っ
ても、データパイプラインのほうが全体のスループットが高い（つまり、毎秒に処理さ
れるデータの数が多くなる）
。
19.7 　パイプラインを使えるケース
パイプラインは、すべてのケースで高性能を発揮するわけではない。パイプラインがシング
ルプロセッサよりも高い性能を示すための必要条件を、図19‒6 に示す。
hi.0412.ko.2002@gmail.com
　19.7
パイプラインを使えるケース
375
•
問題を分割できる
•
同じスピードのプロセッサ
•
データ移動のオーバーヘッドが低い
図19‒6：データパイプラインが、シングルプロセッサでの同じ計算より高い性能を示すために、満たす必要
がある3 つの主な条件
問題を分割できる
処理を複数のステージに分けて、それぞれ独立して計算させることが可能でなければならな
い。一連のステップで構成される計算はパイプライン化に適しているが、繰り返して行う計算
は不適切なことが多い。
同じスピードのプロセッサ
もしデータパイプラインに使うプロセッサが遅すぎたら、計算に必要な合計時間がシングル
プロセッサの場合より、ずっと長くなることは明らかだ。パイプラインのプロセッサは、シン
グルプロセッサより高速である必要はない。ここではパイプラインの各プロセッサが、シング
ルプロセッサと、ほぼ同じ速さであることが条件となる。つまり、ある計算をパイプラインプ
ロセッサで実行するのに必要な時間が、シングルプロセッサで同じ計算を行うのに必要な時間
を超えてはいけない。
データ移動のオーバーヘッドが低い
計算を実行するのに必要な時間に加えて、データパイプラインには、さらにオーバーヘッド
が加わる。それは、データ項目をパイプラインのステージから次のステージへと移すのに必要
な時間だ。もしデータの移動に極度に大きなレイテンシがかかるのなら、パイプライン化によ
る性能の向上は望めない。
時間の要件に関しては、次の重要な原則がある。
パイプラインのスループットは、もっとも時間がかかるステージによって限定される。
たとえば図19‒5 のデータパイプラインで考えてみよう。このパイプラインの全部のプロセッ
サが同じで、パイプラインプロセッサでも命令の実行時間はシングルプロセッサとまったく同
じだと想定しよう。例を具体化するために、そのプロセッサは1 マイクロ秒毎に10 個の命令
を実行できると仮定する。さらに、この図の4 段のステージが、パケット処理に、それぞれ50
個、100 個、200 個、150 個の命令を実行する必要があると仮定する。もっとも遅いステージ
に200 個の命令が必要なので、そのもっとも遅いステージがパケットを処理する合計時間を求
める。
合計時間=
200 命令
10 命令/μ sec = 20μ sec
(19.1)
別の見方をすれば、毎秒処理できるパケットの最大数は、もっとも遅いステージにおけるパ
hi.0412.ko.2002@gmail.com
376
第19 章
パイプライン処理　
ケット毎の処理時間の逆数である。したがって、このサンプル全体のスループット、Tp を求め
ると次のようになる。
Tp = 1 パケット
20μ sec
= 1 パケット× 106
20 sec
= 毎秒50, 000 パケット
(19.2)
これに対して、
パイプラインではないアーキテクチャでは、
それぞれのパケットについて500
個の命令すべてを実行しなければなない。ということは、1 パケットに必要な合計時間は50 μ
sec である。ゆえに、非パイプラインアーキテクチャのスループットは、次の値に限定される。
Tnp = 1 パケット
50μ sec
= 1 パケット× 106
50 sec
= 毎秒20, 000 パケット
(19.3)
19.8 　処理分割のコンセプト
データパイプラインによって性能が改善される理由は、パイプラインが（特殊な形式だが）
一種の並列処理を提供するからだ。一連のシーケンシャルな処理をグループに分け、それらを
別々のステージで処理することにより、パイプラインでは各ステージの処理が並列に進行する。
もちろんパイプラインのアーキテクチャは、一般的な並列アーキテクチャと大きく異なってい
る。各ステージは並列に動作するが、どのデータ項目も、すべてのステージを通過しなければ
ならない。このコンセプトを、図19‒7 に示す。
（a）
（b）
f()
g()
h()
f()
g()
h()
図19‒7：
（a）一般的なプロセッサでの処理と、
（b）データパイプラインにおける、それと等価な処理。シー
ケンスで実行されていた関数群が、パイプラインでは各ステージに切り分けられる
この図におけるポイントは、3 つのステージが並列に動くことだ。ステージ3 が、あるデー
タ項目に対して関数「h」を実行するとき、同時にステージ2 は第2 のデータ項目に関数「g」
を実行し、同時にステージ1 は第3 のデータ項目に関数「f」を実行している。パイプライン
が満たされている限り（つまり項目の間で遅延がなければ）
、N 個のステージをすべて並列に
実行することのメリットを、システム全体が受ける。
hi.0412.ko.2002@gmail.com
　19.9
パイプラインアーキテクチャ
377
19.9 　パイプラインアーキテクチャ
前章では、単に並行処理を使うだけのハードウェアアーキテクチャと、中心的なパラダイム
として並行処理を使い、アーキテクチャ全体を、それを囲むように設計するものとを区別した。
それと同じく、われわれは、単にパイプライン処理を使うだけのハードウェアアーキテクチャ
と、中心的なパラダイムとしてパイプライン処理を使い、それを囲むようにシステム全体を設
計するアーキテクチャとを区別する。われわれが「パイプラインアーキテクチャ」と呼ぶのは、
後者だけである。したがって、アーキテクトが「このシステムのプロセッサは命令パイプライ
ンを使っている」と言ったとしても、アーキテクトはパイプラインが全体的な設計の中心でな
ければ、そのシステムを「パイプラインアーキテクチャ」とは呼ばないのである。
パイプラインアーキテクチャにしたがうハードウェアシステムのほとんどは、特殊な用途を
持つ専用のシステムである。たとえば先ほど挙げた例は、パケット処理システムの性能を高め
るためにパイプライン処理を使う方法を示していた。パイプライン処理が、とくにネットワー
クシステムで重要なのは、光ファイバーでデータを送信するときに使うデータレートが非常に
高いので、一般的なプロセッサの能力を超えるからだ。
パイプラインアーキテクチャと汎用的なコンピュータとの関連が比較的弱いのには、2 つの
理由がある。第1 に、シーケンシャルに適用可能な、独立した処理の集合へと分割できるアプ
リケーションは少ない。典型的なアプリケーションは、むしろ要素をランダムにアクセスし、
状態を表す情報を大量に持つもののだ。第2 に、たとえデータに適用する関数をパイプライ
ン用に分解できるとしても、パイプラインのステージ数や、各ステージで実装する必要のある
ハードウェアは、事前に確定できないのが普通である。その結果、汎用コンピュータで使える
パイプラインハードウェアは、プロセッサ内部の命令パイプラインか、I/O デバイスの中にあ
る特殊用途のパイプラインに限定される。
19.10 　パイプラインのセットアップとストールとフラッシュ
のタイミング
これまでの記述ではパイプラインの実装に関する詳細の多くを省いていた。たとえば、たい
がいのパイプライン実装には、パイプラインの始動と停止にかかるオーバーヘッドが存在する。
アイドル期間の後でパイプラインを始動するのに要する時間のことを「セットアップタイム」
と呼ぶ。セットアップには、ステージ間で処理を同期させる処理や、各ステージを再開させる
ためにパイプラインを通して特殊な制御トークンを渡す処理が含まれるかもしれない。ソフト
ウェアパイプラインの場合、さまざまなステージを繋ぐ接続を動的に作ることで、とくにセッ
トアップのコストが高くなるかもしれない。
他のアーキテクチャと違って、パイプラインでは処理の停止に、かなり長い時間がかかる可
能性がある。入力が途絶えてからパイプラインが現在の処理を完了するまでに経過する時間を、
hi.0412.ko.2002@gmail.com
378
第19 章
パイプライン処理　
「フラッシュタイム」と呼ぶ。パイプラインを停止するには、その前に現在パイプラインに入っ
ている項目を「フラッシュ」する必要がある。
パイプラインを通じて項目をフラッシュする必要が生じる理由は、2 つある。まず、第1 ス
テージで入力が得られなくなると、パイプラインはアイドル状態になる。そして、あるステー
ジが「ストール」すると（つまり、プロセスを完了できないステージにおいて遅延が生じると）
、
それに続くステージがアイドル状態になる。高速なハードウェアパイプラインにおいては、メ
モリ参照や入出力操作といった平凡な処理でも、ステージがストールする原因になりかねない。
したがって、フラッシュまたはセットアップの時間が長ければ、パイプラインの性能が顕著に
低下するかもしれない。
19.11 　スーパーパイプラインアーキテクチャの定義
このコンセプトを最後に述べて、パイプラインの記述を終える。アーキテクトが「スーパー
パイプライン」という用語を使うのは、パイプラインのアプローチを拡張して、パイプライン
の所与のステージを、さらに細かく一群のサブステージに分けた場合である。スーパーパイプ
ラインがもっとも頻繁に使われるのは命令パイプラインだが、このコンセプトはデータパイプ
ラインにも適用できる。このアイデアは要するに、プロセスをN 段のステージに分けて全体の
スループットを上げられるなら、もっとステージを追加すれば、さらにスループットを上げら
れる、という考えだ。
従来の命令パイプラインでは、たとえば5 段のステージが、命令のフェッチ、命令のデコー
ド、オペランドのフェッチ、ALU 演算、メモリへの書き込みに対応する。スーパーアーキテク
チャでは、これらのステージのうち1 段以上を、複数のサブステージに分ける。たとえばスー
パーパイプラインでは、オペランドをフェッチするステージを、オペランドのデコード、即値ま
たはレジスタ値のフェッチ、メモリからのフェッチ、間接参照オペランド値のフェッチという
4 段に細分化するかもしれない。標準的なパイプラインと同じく、細分化の目標はスループッ
トを上げることだ。細分化された個々のサブステージの処理時間が短いので、スーパーパイプ
ラインのスループットは、標準的なパイプラインのスループットよりも高くなる。
19.12 　まとめ
パイプライン処理は、ハードウェアでもソフトウェアでも使われる、応用範囲の広い基礎的
な概念だ。一連のプログラムにデータを通して処理を進行させるソフトウェアパイプラインは、
パイプラインを提供しないハードウェアで使うこともできる。
ハードウェアパイプラインは、プロセッサの内部でマシン命令を処理するのに使われる命令
パイプラインと、任意のデータがパイプラインを通じて送られるデータパイプラインの、どち
らかに分類される。パイプラインを構成するステージを、さらに細分化してサブステージに分
けるスーパーパイプラインの技法は、しばしば命令パイプラインで使われる。
hi.0412.ko.2002@gmail.com
　19.12
まとめ
379
データパイプラインを採用しても、1 個のデータ項目を処理するのに必要な時間は短縮され
ない。けれども、パイプラインを使えば全体的なスループット（毎秒に処理できる項目数）を
上げることが可能だ。パイプラインのスループットは、そのパイプラインのなかで項目を処理
するのにもっとも長い時間を要するステージによって限定される。
練習問題
19.1
ある科学者がPC のクラスタを使い、それぞれのプロセッサで計算の1 ステップ
を実行するようにしています。そのプロセッサは、そのとき利用できるデータを最大
1MB まで読み、そのデータを処理してから、出力を32 ビットのバスを通じて次のプ
ロセッサに渡します。この構成は、図19‒2 のうち、どの性質を持っていますか。
19.2
あなたのチームに与えられた仕事は、ある古いシングルコアプロセッサから、動
画処理プログラムを取り出して、新しいクアッドコアのプロセッサに移植することで
す（4 つのコアが高速に相互接続されています）
。普通のアプローチによる並列処理で
は、うまくいきません。動画のフレームを順番に処理する必要があるからです。新し
いハードウェアを使って性能を上げられそうなのは、どういうテクニックでしょうか?
19.3
ある技術者が、8 個のプロセッサを使うデータパイプラインを構築しています。そ
の性能を計測するために、1 個のプロセッサでソフトウェアを実行し、1 個のデータ
項目を処理するのに必要な時間を計りました。次に、ソフトウェアを8 段のステージ
に分割し、1 個のデータ項目を処理するのにかかる時間を計りました。これらの計測
値から、何がわかるでしょうか?
19.4
ほとんどのデータパイプラインは、
（たとえばグラフィックス処理など）専門的な
タスクに充てられます。すべてのコンピュータにデータパイプラインをインストール
したら、すべてのプログラムの性能を上げられるでしょうか。答えとともに、その理
由も教えてください。
19.5
会社の経営者が、10 箇所あるデータセンターのそれぞれに、2 つか3 つはアイドル
状態のコンピュータがあることに気がつきました。データセンターは国中に散らばっ
ていて、センター間の通信には低速なインターネット接続が使われています。経営者
は、地元のデータセンターにあるコンピュータを使うよりも、10 箇所のデータセン
サー全部で「巨大データパイプライン」を設置すれば性能が上がると提案しました。
あなたなら、このアイデアについて、経営者にどう言いますか?
19.6
あなたは、1 個のコアで実行されるプログラムを渡されました。そのプログラムを
分割して、最大8 個のコアを使えるデータパイプラインを作って欲しいというので
す。そのプログラムを分割する方法は、2 つありました。片方の分割方法では、それぞ
れのコアが、680、2000、1300、1400、800、1900、1200、200 の命令を実行しま
す。もう1 つの方法では、コアが実行する命令の数が、それぞれ680、1400、1300、
hi.0412.ko.2002@gmail.com
380
第19 章
パイプライン処理　
1400、1400、1000、1200、1100 になります。どちらの分割方法を選びますか? そ
の理由は?
19.7
4 個のプロセッサで、それぞれ毎秒100 万個の命令を実行できる同質的パイプラ
インがあります。個々のステージで1 個のデータ項目を処理するのに、それぞれ50、
60、40、30 の命令が必要だとしたら、最大のスループットは、どれほどですか? ど
の命令も実行時間は一定だとします。
19.8
上の質問の例で、パイプラインのないアーキテクチャと比較した場合の相対的なス
ループットのゲインは、どれほどですか? 最大のスピードアップは、どれほどですか?
19.9
1 つ前の質問の拡張で、それぞれ異なるプロセッサを使う異質的パイプラインにつ
いても考えてみましょう。その場合の命令実行速度は、MIPS 単位で、それぞれ1.0、
1.2、0.9、1.0 だとします（MIPS は100 万命令／秒です）
。
19.10
もしあなたが、既存のパイプラインにあるステージの1 つを細分してスーパーパ
イプラインを作るように頼まれたら、どのステージを選びますか? その理由は?
hi.0412.ko.2002@gmail.com
第20 章
電力とエネルギー
20.1 　はじめに
電力消費と総合的なエネルギー消費という、2 つの関連する話題が、コンピュータシステム
の設計で重要性を増している。携帯機器の設計は、バッテリーを使える時間を最大にすること
と、ユーザーが望む機能を最大限に実現することの間でバランスを取らなければならない。大
きなデータセンターの場合は、膨大な消費電力と、それに応じた冷却が、設計と規模の決定的
なファクターになっている。
この短い章では、あまり詳細にわたることなく、これらの話題を紹介する。この章では用語
を定義し、デジタル回路が消費する電力の種類を説明し、電力とエネルギーの関係を述べるほ
か、重要なポイントとして、電力消費を低減させるためにソフトウェアを使ってシステムを部
分的にシャットダウンする方法を示す。
20.2 　電力の定義
物理学が定義する「力」は、エネルギーの消費率である（移動や変換といった仕事が、エネ
ルギーの消費だ）
。そして電子回路に関わる「電力」は、電圧と電流の積である。電力は「ワッ
ト」を単位として計測され、1 ワットのエネルギーは、毎秒1 ジュール（J/s）と定義されてい
る。電子機器のワット数が高ければ、それだけ多くの電力を消費する。キロワット（103 ワッ
ト）単位の電力を使う機器もある。大規模なデータセンターのクラスタでは、そのクラスタに
属する全部のコンピュータによって消費される総電力が非常に大きいので、メガワット（106
ワット）で測る。携帯電話機のようなハンドヘルド機器では、要求される電力が非常に少ない
ので、ミリワット（10−3 ワット）で測る。
システムが使う電力は、時間によって変化する場合があり、それを認識することが重要だ。
たとえばスマートフォンがOFF 状態で消費する電力は、画面をON にしているときよりも少な
hi.0412.ko.2002@gmail.com
382
第20 章
電力とエネルギー　
い。だから厳密な定義によれば、ある時刻t における「瞬時電力」P(t) は、t における電圧V(t)
と、t における電流I(t) の積である。
P(t) = V (t) × I(t)
(20.1)
システムの電力消費が時間の経過によって変化することは、データセンターの強力なクラス
タコンピュータのように極度に大きなシステムでも、バッテリー駆動の小さなデバイスのよう
に極度に小さなコンピュータシステムでも、これから学ぶように重要な意味を持つ。
システムが使う最大の電力は、とくに大規模なシステムで重要だ。システムが必要とする最
大の電力を指定するのに、われわれは「ピーク瞬時電力」という言葉を使う。大規模なコン
ピュータシステムの構築には、ピーク電力の要件を満たす設計が必要だ。たとえばデータセン
ターを計画する設計者は、ピーク時の要請を満たすのに十分な電力を供給できることを保証し
なければならない。
20.3 　エネルギーの定義
システムが使うエネルギーの合計は、ある時間に消費される電力から計算でき、その単位は
ジュールである。普通、電気エネルギー（電力量）は、ワットの倍数に計時単位を掛ける形式
で報告される。典型的な計時単位は時間であり、典型的なワットの倍数は、キロワット、メガ
ワット、ミリワットだ。したがって、たとえばある週にデータセンターが消費したエネルギー
の報告には、
「kWh」
（キロワット毎時）または「MWh」
（メガワット毎時）が使われ、ある週に
バッテリーが消費したエネルギーの報告には、
「mWh」
（ミリワット毎時）が使われるだろう。
もし電力の使い方が一定ならば、消費されたエネルギーは、使った電力P に、電力を使った
時間を掛けることで簡単に算出できる。たとえば、t0 からt1 に至る時間で使ったエネルギーE
は、次の式で得られる。
E = P × (t1 −t0)
(20.2)
1 時間に6 キロワットの電力を使ったシステムのエネルギー消費は6kWh であり、2 時間に
3 キロワットを使ったシステムのエネルギー消費も、それと同じである。
しかし上述したように、ほとんどのシステムは電力を一定の度合いで消費するのではない。
時間の経過にしたがって、電力消費が変化する。継続的に変化する電力を把握するために、わ
れわれはエネルギーを「瞬時電力を時間で積分したもの」として定義する。
E =
Z t1
t=t0
P(t)dt
(20.3)
このように、電力は「時間の経過で変化する可能性がある瞬間的な計測値」として定義され
るが、電力のシステムによっては「平均電力」という値が指定される。前述したように、電力
はエネルギーの消費率なので、ある期間における平均電力を計算するには、その期間に使われ
hi.0412.ko.2002@gmail.com
　20.4
デジタル回路が消費する電力
383
たエネルギーの量を、その時間で割ればよい。
Pavg =
E
(t1 −t0)
(20.4)
20.4 　デジタル回路が消費する電力
デジタル回路が論理ゲートによって作られることを思い出そう。最も低いレベルで見ると、
すべての論理ゲートはトランジスタで構成され、トランジスタの電力消費には、次の2 種類が
ある1。
•
スイッチング電力または動的電力（Ps またはPd）
•
漏れ電力（Pleak）
スイッチング電力
「スイッチング」という用語は、入力に応じた出力の変化を意味する。ゲートの入力が1 つ
以上変化すると、出力が変化する場合がある。出力が変化するのは、トランジスタに電子が流
れるときだけだ。個々のトランジスタは、スイッチング時に、より多くの電力を消費する。つ
まり、それだけシステムの総電力が増加する。
漏れ電力
デジタル回路はバイナリの値（ON またはOFF）を持つと考えられるが、半導体素子の物理
学によれば、トランジスタは「不完全なスイッチ」である。というのは、たとえトランジスタが
OFF の状態でも、半導体の境界を、わずかな電子が通り抜けるからだ。したがって、デジタル
回路に電力を供給するときは、たとえ出力をスイッチングしていなくても、必ずいくらかの電
流が常に流れている。このように、回路が動作していないときに流れる電流を、
「漏れ」と呼ぶ。
個々のトランジスタにおける漏れ電流は、微々たるものだ。けれども1 個のプロセッサには
10 億ものトランジスタが含まれるかもしれないから、漏れ電流の総計は非常に高いものにな
る。ある種のデジタルシステムでは、漏れ電流が電力消費の半分以上を占めるほどだ。要点を
まとめるておこう。
典型的なコンピュータシステムでは、そのシステムが使う電力の40%から60%が、漏
れ電力である。
1　主な電力消費は、この2 つだが、わずかながら「短絡電力」も消費される。その理由は、CMOS トラン
ジスタのスイッチングで、電源とグランドの間に短い接触が作られるからだ。
hi.0412.ko.2002@gmail.com
384
第20 章
電力とエネルギー　
電力管理を論じるには、さらに重要なポイントがある。基本的な原則として、電力が存在す
るときは、必ず漏れが発生する。
漏れ電流をなくすには、回路から電力をなくす以外に方法がない。
20.5 　CMOS デジタル回路によるスイッチング電力の消費
デジタル回路の電力消費をソフトウェアを使って管理することが、われわれにとって重要
だ。電力管理のテクニックを理解するためには、いくつか基本的な概念が必要である。まず、
スイッチングによって消費されるエネルギーの総量について考えよう。1 個のゲートの1 回の
切り替えに必要なエネルギー、Ed は、次の式で求められる。
Ed = 1
2 C V 2
dd
(20.5)
ここでC は、根底にあるCMOS テクノロジーに依存するキャパシタンス（容量）の値であ
り、Vdd は、その回路を動作させる電圧である2。
式（20.5）から導かれる電力を理解するために、クロックについて考えよう。クロックは固
定の周波数を持つ矩形波を生成する。クロック信号がインバータに接続されていると考えよう。
そのインバータの出力は、1 クロックサイクルの間に2 回変化する。1 回はクロックが0 から
1 に変わるとき、もう1 回はクロックが1 から0 に戻るときだ。したがって、クロックの周期
がTclock ならば、使用される電力の平均値、Pavg は次のようになる。
Pavg = C V 2
dd
Tclock
(20.6)
クロック周波数、Fclock は、周期の逆数なので、
Fclock =
1
Tclock
(20.7)
式（20.6）をクロック周波数を使って書き直すと、
Pavg = C V 2
dd Fclock
(20.8)
平均電力を計算するには、もうひとつ項を使う。それは回路のなかで、出力をスイッチング
している活性（アクティブ）部分の割合だ。それを記述するのにα を使う（0 ≤α ≤1）
。それ
によって式（20.8）から得られる最終的な平均電力の式は次のようになる。
Pavg = α C V 2
dd Fclock
(20.9)
式（20.9）には、これからの議論に関係する電力の主な成分が3 つ含まれている。定数C は、
根底にあるテクノロジーの性質であって、簡単に変えられるものではない。したがって、われ
2　Vdd という記法は、CMOS 回路を駆動する電圧の指定に使われる。文脈の理解が得られるときは、V
（電圧）を使える。
hi.0412.ko.2002@gmail.com
　20.6
冷却と電力密度と電力の壁
385
われが制御できる3 つの成分は次の通り。
•
アクティブな回路の割合、α
•
クロック周波数、Fclock
•
回路の電圧、Vdd
20.6 　冷却と電力密度と電力の壁
前述したように、瞬時の電力消費は、ピーク電力の利用が重視されるデータセンターや、そ
の他の大規模な設備に関連して語られることが多い。電力の消費に関しては、ピークでも十分
な電力を供給できるようにするメガワット単位の給電の問題の他に、設計者が重視すべき側面
として、冷却と電力密度がある。
冷却
デジタルデバイスは動作中に熱を発する。負荷が大きいときは、数多くのデバイスが動作し
ていて、それぞれのデバイスが熱を発している。したがって生成される熱量は、消費電力に関
連する。すべての電子回路には冷却が必要であり、さもなければ回路は過熱して焼き切れてし
まう。ごく小さなデバイスならば、周囲の空気に十分な熱が逃げるので、それ以上の冷却は不
要である。中規模のデバイスではファンによる冷却が必要だ。ファンで回路の全般に冷えた空
気を行き渡らせるためには、
「HVAC」
（Heating, Ventilation, and Air Conditioning）の空調
換気システムが必要である。極端なケースでは、空冷では不十分であり、何らかの液冷が必要
になる。
電力密度
回路によって生成される熱の総量が必要な冷却容量を決定するのだが、
熱に関して、
もうひと
つ重要な側面は、小さな面積に熱が集中することだ。たとえばデータセンターの場合、もし多
くのコンピュータが互いに密接して置かれたら過熱する危険がある。したがって、コンピュー
タとコンピュータの間、ラックとラックの間の空間を広げて冷えた空気を流し、熱を逃がす必
要がある。
電力密度は、個々の集積回路でも重要だ。その場合の電力密度は、あるシリコン領域で発散
される電力である。半導体業界は、長年にわたって「ムーアの法則」にしたがってきた。個々
のトランジスタのサイズは縮小を続け、1 個のチップに搭載されるトランジスタの数は、18 か
月ごとに倍増した。けれども「ムーアの法則」にしたがうことには負の側面があって、電力密
度も増加する。電力密度の増加にしたがって、単位面積あたりで生成される熱量が増加する。
だから現在のプロセッサは、古いプロセッサと比べて、1 平方センチメートルあたりの発熱が
多いのだ。
その結果、トランジスタの過密充填という大問題が生じる。チップから熱を除去できるレー
hi.0412.ko.2002@gmail.com
386
第20 章
電力とエネルギー　
トの限界に達しつつあるのだ。それ以上は電力を増やせないので、技術者たちは、その限界を
「電力の壁」と呼んでいる。現在の冷却技術では、その限界は次の式で近似される。
PowerWall = 100 watts
cm2
(20.10)
20.7 　エネルギーの利用
電流の瞬間的な流れを計測する電力と違って、
エネルギーは、
ある期間に消費された電力の総
量を計測する。エネルギーは、とくに電池を使う携帯機器で重視される。電池を「エネルギー
を入れたバケツ」に例えれば、デバイスは、そこから必要に応じてエネルギーを取り出すのだ
と考えられる。電池がデバイスを駆動できる時間の合計（単位はミリワット毎時）は、電池の
エネルギー量から割り出すことができる。
水を入れるバケツに例えて、電池をエネルギーのバケツと考えるのは、モデル化としては単
純すぎるかもしれないが、電池には水のバケツとの共通点が3 つある。第1 に、バケツの水と
同じように、電池に蓄えられたエネルギーは「蒸発」するかもしれない。電池の場合、化学的、
物理的なプロセスが完全ではなく、内部抵抗が許す限り、ごく微量の電流が電池の内部で流れ
てしまう。その流れは、ほとんど感知できないほどわずかなものだが、電池を長い間（たとえ
ば1 年）放置していると、蓄えたエネルギーが失われる（自己放電）
。第2 に、バケツから注ぐ
ときに水の一部がこぼれやすいのに似て、電池からエネルギーを取り出すときも、一部のエネ
ルギーが失われる。第3 に、バケツから水を取り出す度合いを変えられるように、電池からエ
ネルギーを取り出す度合い（負荷）もさまざまに変更できる。この3 つめの性質の背後には、
電流のレベルが（つまり電力のレベルが）低ければ電池の効率が高くなるという重要な概念が
ある。だから設計者は、電池駆動のデバイスが消費する電力を最小化する方法を探すのだ。
20.8 　電力管理
結論として電力消費の削減は、あらゆるケースで望ましい。大きなデータセンターでは、電
力消費を減らせば発熱量も減らせる。小さな携帯機器では、電力消費を削減すれば電池が長持
ちする。そこで、2 つの疑問が生じる。電力消費を削減するのに、どういう方法が使えるのか。
そして、それらの節電技法のうち、ソフトウェアで制御できるのは、どれなのか。
20.6 節の式（20.9）で見たように、電力消費に関わる主な要素は3 つある。回路のうちア
クティブな部分の割合を示すα と、クロック周波数のFclock と、回路の駆動に使われる電圧の
Vdd だ。電圧と周波数を使って電力消費を削減する方法を、この節で見ていこう。アクティブ
な回路の割合については、その後の節で検討する。
hi.0412.ko.2002@gmail.com
　20.8
電力管理
387
20.8.1
電圧と遅延
電力の消費は電圧の2 乗に依存するのだから、電圧を下げることが電力を削減する最大の手
段である。ただし電圧は独立変数ではない。第1 に、電圧を下げると「ゲート遅延」が長くな
る。つまり、ゲートの入力が変化してから出力を変えるまでにかかる時間だ。プロセッサは、
すべてのハードウェアユニットがクロックにしたがって動作するよう精密に設計される。もし
1 個のゲートの遅延が長すぎれば、そのハードウェアユニット（数多くのゲート）全体の遅延
が設計時の仕様を超過してしまうだろう。
現在のテクノロジーにおいて、遅延は次の式で見積もることができる。
Delay = β
K Vdd
(Vdd −VT H)
(20.11)
ここで、Vdd は使用する電圧、VT H は根底にあるCMOS テクノロジーによって決まる「閾
値電圧」
、K はテクノロジーに依存する定数、そしてβ も定数だ（現在のテクノロジーでは、お
よそ1.3 である）
。
電力において、電圧に関係する第2 の側面は漏れ電流である。漏れ電流は、回路の温度と
CMOS テクノロジーの閾値電圧に依存する。電圧を下げれば漏れ電流も下がるが、注目すべき
副作用がある。遅延が長くなるので、消費エネルギーの合計が増えるのだ。漏れ電流の増加が、
どれほど重要かは、ある回路が使う電力のうち、40%から60%が漏れ電力になるかもしれない
ことを思い出せば理解できるだろう。要点をまとめておく。
電力は電圧の2 乗に依存するが、電圧を下げると遅延が長くなり、それによって全体的
なエネルギー利用が上昇する。
こういう問題はあるが、電圧は省電力で最大の要因となる。このため、半導体物理とシリコ
ンテクノロジーに携わる研究者たちが、わずかな電圧で正確に動作するトランジスタを考案し
てきた。たとえば、初期のデジタル回路は5 ボルトで動作していたが、現在の携帯電話機で
使われているテクノロジーは、もっと低い電圧で動いている。満充電の電池が携帯電話機に提
供するのは、およそ4 ボルトだが、それから電池が放電しても、回路は動作し続ける。実際、
ニッケル水素充電池を使う携帯電話機のひとつは、電池から得られる電圧が1.2 ボルトになっ
ても、まだ電話を受けることができ、電圧が0.8 ボルト未満になって、ようやく「電池がなく
なりました」と宣言するのだ（リチウムをベースとする電池の場合は、およそ3.65 ボルトで
なくなる傾向がある）
。
20.8.2
クロックの周波数を下げる
クロック周波数は電力利用の第2 の要因だ。電力はクロック周波数に比例するから、理論的
にはクロックを遅くすれば電力を節約できるはずだ。しかし実際にクロック周期を下げたら性
能が落ちるのだから、たとえばビデオや音楽の再生のようなリアルタイム要件を持つシステム
では致命的かもしれない。
hi.0412.ko.2002@gmail.com
388
第20 章
電力とエネルギー　
興味深いことに、クロック周波数を、電圧の低下と連係して調整することができる。つまり、
電圧の低下によって遅延が増しても、
クロックを遅くすれば適応できるのだ。したがって、
電圧
の低下に応じてクロック周波数を下げる設計にすれば、性能は落ちるが回路は正しく動作する。
クロック周波数と電圧の両方を低下させると、電力を劇的に削減できるかもしれない。具体
的な例をひとつ挙げると、周波数を1/2 にすることで、電圧を1/1.7 に下げることができた。
式（20.9）で示したように、電力を求める式では電圧を2 乗するから、電圧を下げれば電力は
劇的に低下する。この例では結果として、元の電力の約15%になる。どのくらい節約できるか
は使用するテクノロジーに依存するが、一般的な概念は次のように要約できる。
もし回路のクロック周波数を下げても適切な性能を維持できるのなら、クロック周波数
を下げれば電圧も下げられるので、電力を劇的に削減できる。
インテルはクロック周波数を動的に変える興味深い発明を導入した。そのアイデアは単刀直
入なものだ。プロセッサがビジーなとき、OS はクロック周波数を高くする。もしプロセッサ
が、あらかじめ設定した熱の限界を超えるか（つまり過熱）
、あるいは電力の限界を超えたら
（その場合はバッテリーが急速に放電する）
、OS はクロック周波数を、プロセッサが上記の限界
内で動作するまで下げる。たとえばクロック周波数を100MHz 単位で動的に増減させるのだ。
もしプロセッサがアイドル状態ならば、逆にクロック周波数を落として電力を節約できる。た
だしインテルは動的にスピードを落とせる能力を宣伝する代わりに、話を逆にして、この機能
を「ターボ・ブースト」と呼んで宣伝した。
20.8.3
遅いクロック周波数とマルチコアプロセッサ
2000 年代の初め頃、電力の利用が問題になり始めるのと同時に、チップベンダー各社が「マ
ルチコアプロセッサ」を売り出した。マルチコアアーキテクチャへのシフトは、表面的には逆
効果のように思える。コアが2 つになれば、必要な電力がシングルコアの2 倍になるのでは
ないか。もちろん2 つのコアで回路の一部は共用できるから（たとえばメモリやバスインター
フェイス）
、デュアルコアチップの電力消費がシングルコアチップの電力消費のちょうど2 倍
になるわけではない。しかしコアを追加することで必要な電力が、かなり大きく増加すること
は確かだ。
電力の消費を抑えることが重要なのに、なぜマルチコアが導入されたのだろうか。その理由
を理解するには、
クロック周波数に注目する必要がある。マルチコアチップが出現するまで、
ク
ロック周波数は数年ごとに、新しいプロセッサが現れるたびに増加されていった。すでに学ん
だように、クロック周波数を半分に落とせば、電圧も下げられ、電力消費を大いに削減できる。
そこでデュアルチップだが、シングルコアチップのクロック周波数の半分で、それぞれのコア
を実行すると、どうなるだろうか。デュアルコア版の計算能力は、2 倍の速度で実行されるシン
グルコアと、ほとんど同じままだ。けれども電力消費に関しては、電圧を下げられるので、そ
れぞれのコアが必要とする電力は、シングルコア版が要求する値× F になる。ゆえに、デュア
hi.0412.ko.2002@gmail.com
　20.9
エネルギー利用のソフトウェア制御
389
ルコア版が消費する電力は、およそシングルコア版× 2F となる。F が50%よりも少なければ、
低速デュアルコアチップのほうが電力消費が少ない。上に挙げた例で言えばF は15%なので、
デュアルコアチップは、元のチップのわずか30%の電力で、同等な計算能力を提供するのだ。
マルチコアチップで、それぞれのコアを低い周波数、低い電圧で動かせば、ほとんどシ
ングルコアチップと同じ計算能力を提供しながら、電力の利用を大きく削減できる。
もちろん上記の議論には、マルチコアプロセッサに関する重要な前提がある。つまり、複数
のコアに計算を均等に分配できるという前提だ。残念ながら第18 章で指摘したように、並行
処理に関するわれわれの経験は、それほど楽観的ではない。並列処理のアプローチに適さない
計算では、クロックが遅ければシステムを使えないかもしれない。たとえいくらか並列処理が
可能でも、メモリ衝突などで効率が悪ければ、満足な性能を得られないかもしれない。同時に
複数の入力項目を扱うために並列処理を使うときは、2 つのコアから得られる全体的なスルー
プットを、高速なシングルコアと同程度にできるだろう。ただしレイテンシは（つまり所与の
項目を処理するのに必要な時間は）大きくなる。最後に、スイッチング電力に関する議論も忘
れてはならない。漏れ電力が大きな問題になるかもしれないのだ。
20.9 　エネルギー利用のソフトウェア制御
システムのソフトウェアは、使用する電圧を上げ下げするような能力を、ほとんど、あるい
はまったく持たないのが普通である。むしろソフトウェアによる制御は、次の2 つに限定され
ることが多い。
•
クロックゲーティング
•
パワーゲーティング
クロックゲーティングというのは、クロックの周波数をゼロに落とすことで、つまり実質的
にプロセッサの停止を意味する。ただしプロセッサを停止する前に、プログラマがリスタート
の準備を整えておく必要がある。典型的には、コードのイメージをメモリに残して、メモリの
電力を維持する。それでプロセッサが動作を再開するときには、イメージの準備ができている。
パワーゲーティングは、プロセッサの電力を絶つことを意味する。電源の遮断には、とくに
漏れ電流の低い特殊な半導体デバイスが使われる。クロックゲーティングと同じく、プログラ
マはリスタートの準備を整える必要がある。それには、メモリのイメージを一時的に保存して
おいてリストアするか、あるいはメモリの電力を保持してイメージを維持しておく必要がある。
パワーゲーティングの能力を持つシステムは、システム全体にゲーティングを適用するわけ
ではない。代わりに、システムを複数の「島」
（ブロック）に分けて、いくつかの島にゲーティ
ングを適用し、それ以外の島は通常通りに動かす。電力の孤島で、とくに重要なのがメモリ
キャッシュだ。もしメモリキャッシュの電力を絶ったら、キャッシュしていたデータが全部消
hi.0412.ko.2002@gmail.com
390
第20 章
電力とエネルギー　
えてしまう。第12 章で学んだように、キャッシュは性能にとって重要だ。したがって、プロ
セッサの他の部分から電力を遮断しても、メモリキャッシュはシャットダウンを受けない電力
の孤島に入れておきたい。
プロセッサによっては、このアイデアを拡張して、ソフトウェアが電力消費の削減に使うこ
とができる、一群の「低電力モード」を提供するものがある。これらのモードの名前は、ベン
ダーによってまちまちで、
「スリープ」
、
「ディープスリープ」
、
「ハイバーネーション」などと呼
ばれる。われわれはジェネリックな名称として、LPM0、LPM1、LPM2、LPM3、LPM4 を使
うことにする。一般に、低電力モードは階層的に並べられる。LPM0 は電力を絶つ回路が最も
少なく、回復が最も素早い。最も深いスリープのモードであるLPM4 は、プロセッサのほとん
ど全部の電源を遮断する。その結果、LPM4 からの回復には、他の低電力モードより、ずっと
長い時間がかかる。
20.10 　スリープとスリープ解除のタイミング
ここで2 つの疑問に答えなければならない。システムは、いつスリープモードに入るべきな
のか。そして、いつスリープを解除するべきなのか。スリープモードから脱するタイミングを
選ぶのは、普通は単純明快で、
「オンデマンド」で解除すればよい。つまりハードウェアは、プ
ロセッサを要求するイベントの発生を待って、それからプロセッサをスリープモードから脱す
る。たとえばスクリーンセイバーは、ユーザーがマウスを動かすか、タッチスクリーンに触れ
るか、キーボードのキーを押したら、画面の表示を再開する。
いつ低電力モードに入るかという問題は、もっと複雑だ。その動機は電力利用の削減である。
そのため、あるサブシステムが、かなり長い期間にわたって不要になるとしたら、そのサブシ
ステムへの電力を「遮断」したい（つまり、電源をOFF にする）
。しかし普通は将来の需要を
知ることができないので、多くのシステムは、いつサブシステムが必要になるかをヒューリス
ティックに（発見的手法で）概算する。つまり、十分に長く作動しなかったサブシステムは、
もっと長く作動しないままだろうと推測するのだ。もしプロセッサまたはデバイスがN 秒間作
動していなければ、そのプロセッサまたはデバイスをスリープモードに入れるのが典型的であ
る。この方法が、より深いスリープにも適用される。つまり、プロセッサがK 秒間、浅いス
リープ状態に入ったままなら、ハードウェアは、プロセッサを、より深いスリープ状態に移行
させる（プロセッサのうち、さらに多くの部分をOFF にする）
。
では、スリープモードに入るタイムアウトとして、どんな値をN に使うべきだろうか。ユー
ザーとの対話処理を提供するサブシステムでは、ユーザーがタイムアウトを設定できるように
するのが典型的だ。たとえばスクリーンセイバーでは、どれだけ長く入力デバイスを使わなけ
ればスクリーンセイバーが走るかをユーザーが指定できる。タイムアウトをユーザーに決めて
もらうのなら、どのユーザーも、自分のニーズに合わせてシステムをカスタマイズできる。
ユーザーの好みと関係のないシステムでタイムアウトを設定するには、もっと慎重な分析が
hi.0412.ko.2002@gmail.com
　20.10
スリープとスリープ解除のタイミング
391
必要だ。単純化したモデルで、その計算方法を示そう。このモデルでは、2 つの状態を想定す
る。
「RUN」状態では、プロセッサがフルパワーで実行され、
「OFF」状態では、すべての電力が
遮断される。プロセッサが状態の遷移を行うときは、ある時間が経過する。これを、Tshutdown
およびTwakeup と呼ぶことにしよう。図20‒1 に、この単純なモデルを示す。
RUN
OFF
Tshutdown
Twakeup
図20‒1：低電力モードの遷移を表す単純化されたモデル
それぞれの遷移は電力を必要とする（つまり遷移のために、状態情報の保存や、I/O デバイ
スの準備を行う必要がある）
。計算を簡単にするため、遷移で使われる電力は一定だというこ
とにしよう。したがって、1 回の遷移に必要なエネルギーは、それぞれの電力と経過時間の積
として計算できる。
Eshutdown = Es = Pshutdown × Tshutdown
(20.12)
および
Ewakeup = Ew = Pwakeup × Twakeup
(20.13)
遷移に必要なエネルギーと、システムの実行時およびシャットダウン時に使われるエネル
ギーを理解すれば、どれだけエネルギーを節約できるかを評価できる。基本的にシャットダウ
ンが有益なのは、シャットダウン（あるいはスリープ）と、その後の再起動で消費されるエネ
ルギーが、同じ期間だけ実行を続けているよりも少ない場合である。
いま考慮する時間のインターバルを、t としよう。実行中のシステムが使う電力が一定だと仮
定すれば（Prun）
、システムが実行時間t で消費するエネルギー、Erun は次のように表される。
Erun = Prun × t
(20.14)
もしシステムが時間t の間スリープモードに入るのなら、その間に消費されるエネルギー
（Esleep）は、それぞれの遷移に必要なエネルギーに、Poff、すなわちプロセッサがシャットダ
ウンしている間に消費するエネルギー（もしあれば）を加えたものだ。
Esleep = Es + Ew + Poff(t −Tshutdown −Twakeup)
(20.15)
そして、シャットダウンが有益なのは、次の場合である。
Esleep < Erun
(20.16)
この差は、式（20.12）から式（20.15）までを使って、1 個の自由変数、すなわちタイムイ
hi.0412.ko.2002@gmail.com
392
第20 章
電力とエネルギー　
ンターバルt から求めることができる。したがって、シャットダウンによってエネルギーを節
約できる最小時間t を指定する「損益分岐点」の計算が可能である。
もちろん上記は単純化されたモデルに基づく分析だ。電力の利用は一定のままではないだろ
う。遷移に必要とされる時間と電力も、システムの状態に依存するだろう。さらに重要なポイ
ントとして、この分析はスイッチングによって消費されるエネルギーに焦点を当て、漏れを無
視している。とはいえ、この分析は基本的なポイントをひとつ示している。
ただ1 つの低電力状態しか持たない単純化されたモデルでも、状態遷移の間に使われる
エネルギーのような詳細によって、いつ低電力モードに移行するかの決定が複雑になる。
20.11 　スリープモードとネットワーク機器
電力を節約するために使われる低電力モードは、多くの機器にある。たとえばプリンタは普
通、N 分間作動しなければスリープする。同様にワイヤレスネットワーク機器も、電力消費を
抑えるためにスリープモードに入ることがある。ネットワークアダプタの場合、出力（送信）
の扱いは、ほとんど問題にならない。アプリケーションが送信パケットを生成したら必ずアダ
プタを起動できるのだ。けれども入力（受信）は低電力モードにとって難関である。なぜなら
コンピュータは、他のコンピュータがいつパケットを送ってくるか、知りようがないからだ。
一例として、Wi-Fi の標準規格（802.11）には、
「省電力ポーリング」モードがある。Wi-Fi
を使うノートPC その他のデバイスはシャットダウンと起動を定期的に行うだけだ。デバイス
が実行されシャットダウンされる周期の繰り返しを、われわれは「デューティサイクル」という
用語で表現する。無線部は、アクセスポイントが送信する時に起動しなければならない。Wi-Fi
基地局が周期的に送信するビーコンには、その基地局に未配信のパケットが存在する受信者の
リストが含まれている。ビーコンは十分に頻繁に送られるから、デバイスはデューティサイク
ルの起動期間に、必ずビーコンを受けることが保証される。もし受信者リストにデバイス自身
が含まれていたら、そのデバイスは起動し続けてパケットの受信を行う。
ネットワークアダプタがパケットを無期限に失わずにスリープできる基本的なアプローチと
して、2 種類が使われてきた。ひとつのアプローチでは、それぞれのデバイスが自分のスリー
プサイクルを基地局と同期させる。もうひとつのアプローチでは、基地局が個々のパケットを、
受信側が起動して受け取るまで、何度も繰り返して送信する。
20.12 　まとめ
電力は、エネルギー利用率の瞬間的な計測値である。エネルギーは、所与の時間に使われた
電力の総量である。デジタル回路が使うのは、動的電力あるいはスイッチング電力（つまり、
入力の変化に応じて変化する出力）と、漏れ電力である。漏れは、ある回路が消費する電力の
40%から60%にもおよぶことがある。
hi.0412.ko.2002@gmail.com
　20.12
まとめ
393
電力消費を抑えるには、回路の一部を非活性化するか、クロック周波数を下げるか、電圧を
下げる。そのうち電圧の低下は最も効果的だが、遅延が大きくなる。電力密度は、ある空間へ
の電力の集中を意味する。電力密度は熱に関連する。
「電力の壁」は、現在の冷却技術でシリ
コンチップから熱を取り去ることのできる最大の電力密度を示すもので、およそ1 平方センチ
メートルあたり100 ワットが限界である。
回路（または回路の一部）をOFF にするには、クロックゲーティングとパワーゲーティン
グが使われる。電池電源を使うデバイスでは、電力管理システム全体の目標は、エネルギー利
用の総計を減らすことにある。低電力（スリープ）モードに入り、それから出るのにもエネル
ギーを消費する。だからスリープが正当化されるのは、そのまま実行を続けるよりもスリープ
モードに入る方が、必要なエネルギーが少ない場合に限られる。単純化されたモデルによって、
シャットダウンのコストと起動のコストが計算に関わることを示した。
デバイスも低電力モードを使える。ネットワークインターフェイスが難関になるのは、イン
ターフェイスが必ずパケットを受信する必要があるのに、いつパケットが到着するのかを、必
ずコンピュータが知っているわけではないからだ。W-Fi の標準規格には、省電力ポーリング
モードが含まれている。
練習問題
20.1
18.19 節で説明したスーパーコンピュータの天河二号（Tianhe-2）に必要な電力の
量を見積もってみましょう。
ヒント：まずは、1 個のプロセッサによって使われるワット数の見積もりから始めま
しょう。
20.2
クロック周波数を10%だけ削減し、その他のパラメータは変えないとしたら、電力
はどれくらい削減できますか？
20.3
電圧（Vdd）を10%だけ削減し、その他のパラメータは変えないとしたら、電力は
どれくらい削減できますか？
20.4
式（20.16）を使って、t の損益分岐点を計算しましょう。
20.5
図20‒1 のモデルを拡張して、3 つの状態を持つシステムを表現しましょう。その
プロセッサは、スリープモードとディープスリープモードの両方を持つことにします。
hi.0412.ko.2002@gmail.com
hi.0412.ko.2002@gmail.com
第21 章
性能評価
21.1 　はじめに
本書では、まずコンピュータシステムの構築にアーキテクトが使う3 つの基礎的な機構であ
るプロセッサ、メモリ、I/O デバイスについて、それぞれの性質と機能を説明した。そして第
5 部の最初の2 章では、計算能力を高める2 つのテクニックである、並行処理とパイプライン
処理を考察した。
この章では、広く性能について学ぶ。どのように性能を測れるかを調べ、命令セットをアー
キテクトがどう評価するかを論じる。そして、もっと重要なポイントとして、この章ではアム
ダールの法則を紹介し、コンピュータアーキテクチャに対する影響を説明する。
21.2 　計算能力と性能を測定する
計算能力は、どうすれば測れるのだろう。あるコンピュータシステムの性能が、他のシステ
ムより優れているとしたら、いったい何が違うのだろうか。これらの質問は科学的なコニュニ
ティで研究を触発し、商用コンピュータベンダーの販売およびマーケティング部門の人たちの
間に白熱した論争を起こし、結局はさまざまな答えを生み出している。
性能評価の根本的な問題は、汎用コンピュータシステムの柔軟性から生じた。そもそもコン
ピュータは、さまざまな仕事を実行できるように設計されている。しかも最適化を行うには、
いくつかの選択肢から選ぶ必要があるから、ある仕事のためにアーキテクチャを最適化すれば、
他の仕事には最適ではなくなる。これが重要なポイントだ。コンピュータシステムの性能は、
そのシステムを何に使うかに依存する。
コンピュータは幅広い範囲の仕事を実行できるように設計される。あらゆる仕事に最適
なアーキテクチャは存在しないから、あるシステムの性能は、実行しているタスクに依
存する。
hi.0412.ko.2002@gmail.com
396
第21 章
性能評価　
性能と実行しているタスクとの依存関係がおよぼす重要な影響が2 つある。第1 に、多くの
コンピュータベンダーが「最も強力なコンピュータは我が社の製品です」と、それぞれ主張で
きる。たとえば、あるベンダーは、行列の演算を高速に実行する自社製コンピュータの性能を
計測するのに、行列の乗算を使い、もうひとつのベンダーは、整数演算を高速に実行する自社
製コンピュータの性能を計測するのに、整数を使う。だから、どちらのベンダーも「自社のコ
ンピュータが最高の性能」と主張できるのだ。第2 に、これを科学的な立場から見ると、すべ
てのケースを満足させる計測方法は存在しない。この点は、コンピュータの性能評価を理解す
るための基本だ。
性能を計測する方法がさまざまに存在するのは、
「すべてのケースを満たす唯一の方法」
がないからだ。
21.3 　計算能力の測定方法
初期のコンピュータシステムは、中央のプロセッサと、
（たとえあっても）わずかな入出力機
能で構成されていた。したがって、コンピュータの性能を測る方法は、CPU の実行速度が中心
だった。しかし、たとえ性能の尺度がCPU に限定されても、適用できる尺度はさまざまに存
在する。最も重要な区分は、コンピュータシステムが次のどちらを基準に最適化されるかだ。
•
整数の計算
•
浮動小数点数の計算
科学技術計算は浮動小数点を多用するので、浮動小数点を使うアプリケーションは、しばし
ば「科学的アプリケーション」と呼ばれ、その計算は「科学的計算」と呼ばれる。科学的アプ
リケーションを、コンピュータがどれほど実行できるのかを評価するため、技術者は浮動小数
点演算の性能だけに注目する。彼らは整数演算のスピードを無視して、浮動小数点演算（具体
的には、浮動小数点値の加算、減算、乗算、除算）のスピードを計測するのだ。もちろん加算
や減算は一般に乗算や除算よりも高速だし、プログラムには他の命令も含まれる（たとえば関
数コールや繰り返しの制御など）
。けれども多くのコンピュータでは、典型的な整数演算の命
令と比べて浮動小数点演算の実行に、ずっと長い時間がかかるので、浮動小数点計算がプログ
ラムの全体的な性能を支配することになる。
技術者は、1 個の浮動小数点演算の実行に必要な時間ではなく、単位時間に実行できる浮動
小数点演算の数を報告する。とくに主な目安となるのは、そのハードウェアが1 秒間に実行で
きる浮動小数点演算の平均（FLOPS）である。
もちろんこれは、浮動小数点のスピードは科学的計算との関係が深い、というだけの話であ
る。整数を使うプログラムに、浮動小数点ハードウェアのスピードは関係がない。もっと重要
なポイントとして、FLOPS の計測は、浮動小数点命令を持たないRISC プロセッサには無意味
hi.0412.ko.2002@gmail.com
　21.4
特定アプリケーションの実行命令数
397
である。したがって、浮動小数点の性能を測る代わりに、ベンダーは浮動小数点を省いた命令
について、単位時間にプロセッサが実行できる平均命令数を選んで報告することができる。そ
のようなベンダーが測るのは、
「MIPS」
（100 万命令/秒）になるのが典型的だ。
MIPS やFLOPS のように単純な性能の尺度は、大ざっぱに性能を見積もるだけだ。その理由
を知るために、命令の実行に要する時間に注目しよう。たとえば、あるプロセッサでは浮動小
数点の乗算または除算に、浮動小数点の加算または減算と比べて、2 倍の時間がかかると仮定
しよう。加算または減算の命令にQ ナノ秒が必要だとして、これら4 種類の命令に対等な重
みをかけるなら、このコンピュータが浮動小数点命令1 個の実行に要する平均時間、Tavg は、
次の式で求めることができる。
Tavg = Q + Q + 2 × Q + 2 × Q
4
= 1 命令毎に1.5Q ナノ秒
(21.1)
けれども、このコンピュータが加算と減算を実行するのに必要な時間は、命令毎にQ ナノ秒
にすぎず、これは平均の2/3 である。同様に、乗算か減算を実行しているときのコンピュータ
は、命令毎に2Q ナノ秒を要するから、平均の4/3 である。実際に加算または減算に要する時
間と比べると2 倍の違いがあるのだから、実際の性能の違いには、それだけのばらつきがある
（練習問題で、その他の倍率について考慮する）
。
要点をまとめておこう。
命令の実行に要する時間が、命令の種類によって大きく違うとしたら、1 個の命令の実
行に必要な平均時間は、性能の指標としては粗雑な近似値にすぎない。実際に必要とな
る時間は、どの命令を実行するかに依存する。
21.4 　特定アプリケーションの実行命令数
どうすれば、もっと正確に性能を評価できるのだろうか。ひとつの答えは、ある特定のアプ
リケーションについて性能を評価することだ。たとえば、ある浮動小数点ハードウェアユニッ
トが、2 個のN×N 行列の乗算を計算するときの性能を知りたいとしよう。そのプログラムを
調べると、実行される浮動小数点加算、減算、乗算、除算の回数を表現する一群の式を、N の
関数として導き出せる。たとえばN×N 行列のペアを掛け合わせるには、N3 個の浮動小数点
乗算と、N3−N2 個の浮動小数点加算が必要である。個々の加算にQ ナノ秒が必要で、個々の
乗算に2×Q ナノ秒が必要だとしたら、2 個の行列の乗算に必要な時間の合計は次の通り。
Ttotal = 2 × Q × N 3 + Q × (N 3 −N 2)
(21.2)
精密な分析の代替策として、技術者は「加重平均」を使う。つまり、それぞれの命令が何回
実行されるかを正確に数える代わりに、およそのパーセンテージを使うのだ。たとえば、ある
グラフィックスプログラムを、数多くの入力データ集合について実行するとき、それぞれの浮
動小数点演算をいくつ実行するかを数えると、表21‒1 に示すリストを作ることができる。
hi.0412.ko.2002@gmail.com
398
第21 章
性能評価　
表21‒1：あるグラフィックスアプリケーションを、多くの入力値に対して実行したときの命令数のサンプ
ル。3 列目は、それぞれの命令が占める相対的な割合（パーセンテージ）である
命令の種類
総数
パーセンテージ
Add
8513508
72
Subtract
1537162
13
Multiply
1064188
9
Divide
709458
6
いったん命令数の統計を取得したら、ハードウェアの性能は、加重平均を使って評価できる。
上記のハードウェアで同じグラフィックスアプリケーションを実行するとき、個々の浮動小数
点命令について、次の平均時間を期待できる。
Tavg = .72Q + .13Q + .09 × 2Q + .06 × 2Q = 1 命令毎に1.16Q ナノ秒
(21.3)
この例が示すように、加重平均は均一な平均と比べて、大きく異なる場合がある。この場合
の加重平均は、命令毎に均一な重みを使って取得した前節の式（21.1）の平均を、23%下回っ
ている。
21.5 　命令ミックス
加重平均は、確かに性能を「より正確に」測れるのだが、上記のサンプルは、ただ1 つの科
学的アプリケーションに適用できるだけで、浮動小数点演算の性能しか評価していない。もっ
と汎用的な評価を出せないものだろうか。人気を得たアプローチがひとつある。プログラムの
大きな集合から、それぞれの種類の命令について「相対加重」を求め、その値を使って、所与
のアーキテクチャの性能を評価するのだ。つまり、浮動小数点ばかりに注目するのではなく、
各種の命令をカウントし（たとえば整数の算術命令、ビットシフト命令、サブルーチンコール、
条件分岐など）
、そのカウントと相対加重を使って、性能の加重平均を計算するわけだ。
もちろん加重は、選択した特定のプログラム集合に依存する。だから、可能な限り高い精度
を得るために、典型的な作業負荷（ワークロード）を表現するプログラム集合を選ぶ必要があ
る。アーキテクトは、典型的なプログラム集合を表現する「命令ミックス」のひとつを選ぶ。
命令ミックスは、コンピュータの性能を評価する助けになるだけではない。アーキテクトが
効率の良い命令セットを設計する助けにもなる。アーキテクトは暫定的な命令セットを選んで、
それぞれの命令に予想されるコストを割り当て、命令セットの加重を使って、計画中の命令セッ
トで得られる性能を調べる。要するにアーキテクトは、命令ミックスを使って、典型的なプロ
グラムで命令セットが示す性能を評価するのだ。もし性能に満足が得られなければ、アーキテ
クトは設計を変更できる。
命令ミックスは、サンプルプログラムで命令毎の実行回数を集計して得た「相対加重」
を持たせた命令セットで構成される。アーキテクトは、計画しているアーキテクチャで
hi.0412.ko.2002@gmail.com
　21.6
標準ベンチマーク
399
予想される性能を、命令ミックスを使って評価することができる。
21.6 　標準ベンチマーク
2 つのアーキテクチャの性能を比較するには、どんな命令ミックスを使うべきだろうか。そ
の質問に答えるには、コンピュータがどう使われるのかを知る必要がある。つまり、そのコン
ピュータで実行されるプログラムと、それらのプログラムが入力として受け取る入力の種類が
問題だ。要するに、われわれは典型的なアプリケーション集合を見つける必要がある。技術者
とアーキテクトは、そのようなプログラムを「ベンチマーク」と呼んでいる。ベンチマークは、
コンピュータを評価する標準的な作業負荷を提供する。
もちろんベンチマークを考案するのは難しい。もし各社が独自のベンチマークを作っていた
ら、
コミュニティにとって有益ではない。この問題を解決するために、
ある独立した非営利団体が
1980 年代に設立された。それは「SPEC」
（Standard Performance Evaluation Corporation）
という名前で、
「最新世代のコンピューティングシステムについて、性能とエネルギー効率を評
価できる、標準のベンチマークとツールを制定、整備、奨励するために」作られた1。SPEC は
性能の比較に使える一連の標準ベンチマークを作っている。たとえば「SPEC cint2006」のベ
ンチマークは、整数演算の性能を評価するのに使われ、
「SPEC cfp2006」ベンチマークは浮動
小数点演算の性能を評価するのに使われた。
SPEC によって作られたベンチマークは、
（設計ではなく）主に測定に使われている。つま
り、それぞれのベンチマークは、実行して評価すべきプログラムの集合で構成される。SPEC
ベンチマークを実行した結果として得られるスコアは、
「SPECmark」と呼ばれ、ベンダーに依
存しないコンピュータ性能の目安として業界で引用されることが多い。
興味深いことに、SPEC は、それぞれ性能の一面をテストするベンチマークを数多く作ってい
る。たとえばSPEC は、整数演算に特化した6 種類のベンチマークと、浮動小数点演算のさま
ざまな側面に重点を置いた14 種類のベンチマークを提供した。さらにSPEC は、コンピュー
タが消費する電力や、Java 環境の性能を評価するベンチマークも提供した。さらに、
「NFS」
（Network File System）を実行するUnix システムによるリモートファイルアクセスの性能を
ソフトウェア開発中に評価できるベンチマークも提供している。
1　この記述は、SPEC のトップページ（http://www.spec.org）から引用した。訳注：翻訳の時点で、原
著の記述と少し違っていたので、新しいものを試訳した（last updated Jun 11, 2020）
。最新情報は、上記
のサイトで調べていただきたい。
hi.0412.ko.2002@gmail.com
400
第21 章
性能評価　
21.7 　入出力とメモリのボトルネック
CPU の性能は、あるコンピュータシステムにおける全体的な性能の一部である。パーソナ
ルコンピュータのユーザーならば知っているはずだが、より高速なCPU、より多くのコアが
あっても、すべてのタスクで高速な応答が得られるという保証はない。著者の同僚は、
「CPU
パワーは10 年ごとに1 桁上がってきたというが、アプリの起動に必要な時間は、かえって伸
びているじゃないか」と文句を言っている。
CPU が高速化しても全体的なスピードが上がらない理由は何だろうか。答えのひとつは、す
でに見ている。フォン・ノイマンのボトルネック、つまりメモリアクセスだ。メモリの速度は、
どれだけのレートで命令をフェッチできるかに影響を与えるだけでなく、どれだけのレートで
データをアクセスできるかにも影響を与える。ゆえに、単にCPU 性能を計測するのではなく、
メモリ性能を測るベンチマークも設計されている。メモリのベンチマークは、繰り返しメモリ
をアクセスするプログラムで構成される。ある種のメモリベンチマークは、シーケンシャルア
クセス（つまり連続するバイト列のアクセス）をテストし、他のベンチマークはランダムアク
セスをテストする。さらに重要なポイントとして、メモリベンチマークは、ある場所のメモリ
に対する参照を繰り返すことによってメモリのキャッシングをテストする。
入出力の章で指摘したように、周辺デバイスも、周辺デバイスとの通信を行うバスも、ボト
ルネックになることがある。このため、I/O デバイスの性能をテストするベンチマークも設計
されている。たとえばディスクをテストするベンチマークなら、
「ライト」と「リード」の演算
を繰り返し実行して、データブロックをディスクに転送し、またそのデータを読み返す。メモ
リと同様に、ディスクのベンチマークにも、主として連続するデータブロックをシーケンシャ
ルにアクセスする性能を計測するものと、ランダムなブロックをアクセスする性能を計測する
ものがある。
21.8 　ハードウェアとソフトウェアの境界をずらす
コンピュータ性能の根本的な原則のひとつは、ハードウェアとソフトウェアの相対的な性能
差に起因する。つまり原則としてハードウェア（とくに特殊用途のために設計されたハード
ウェア）は、ソフトウェアよりも高速なのだ。その結果、所与の機能をハードウェアに移すこ
とによって、その機能をソフトウェアで実行するよりも高い性能を得られる。言い換えると、
アーキテクトは特殊用途のハードウェアユニットを追加することによって、全体的な性能を高
めることが可能だ。
同じように重要な原則から、もうひとつの必然的な結果が得られる。ソフトウェアはハード
ウェアより、はるかに柔軟性が高い、というのが原則で、ハードウェアによって実装された機
能は変更できない、というのがその結果である。したがってアーキテクトはソフトウェアに、
より多くの機能を委ねることによって、全体的な柔軟性と汎用性を高めることが可能である。
hi.0412.ko.2002@gmail.com
　21.9
最適化する項目の選択：アムダールの法則
401
最近よく使われているFPGA は、ハードウェア機能をソフトウェアに移す例だ。ゲートの固定
された組み合わせでチップを作る代わりに、FPGA では設計に含まれる機能をプログラミング
することができる。
要するに、ハードウェアとソフトウェアにはトレードオフの関係がある。
機能をソフトウェアからハードウェアに移せば性能を高めることができる。機能をハー
ドウェアからソフトウェアに移せば柔軟性を高めることができる。
21.9 　最適化する項目の選択：アムダールの法則
性能を高める必要があるとき、アーキテクトは最適化すべき項目を選ぶ必要がある。設計に
ハードウェアを追加するにはコストがかかる。特殊用途の高速なハードウェアは、とくに高価
だ。したがってアーキテクトは、高速なハードウェアを使いたいだけ指定するわけにはいかな
い。その代わりに、高速なハードウェアで最適化される機能と、従来のハードウェアで処理で
きる機能とを、注意深く選ぶ必要がある。
その選択は、どのように行うべきだろうか。コンピュータアーキテクトのジーン・アムダー
ル（Gene Amdahl）は観察に基づいて、めったに使わない機能を最適化するのはリソースの無
駄遣いであると述べた。たとえばゼロによる除算を処理するハードウェアや、コンピュータシ
ステムの電源断を行う回路について考えてみよう。めったに使われることのない、こういった
ハードウェアを最適化することには、ほとんど意味がない。
アムダールは、性能を最も向上させるには、最も多くの時間が費やされる機能を最適化すべ
きだと提案した。彼の原則、いわゆる「アムダールの法則」は、集中的な計算を必要とする演
算、または、最も頻繁に実行される演算に重点を置く。彼の原則は高速化の可能性に関わる形
で書かれることが多い2
アムダールの法則
より高速なハードウェア技術によるスピードアップの実現は、その高速テクノロジーが
使われる時間の割合によって制限される。
アムダールの法則を定量的に表現するには、補強されたハードウェアが使われる時間の割合
と、その補強によってもたらされるスピードアップ（高速化）から、全体のスピードアップを
求める。
Speedup全体=
1
1 −割合補強済+
割合補強済
Speedup補強済
(21.4)
この式は、両極端のケースでも有効だ。もし補強されたハードウェアが、まったく使われな
ければ（つまり割合が0）
、スピードアップは発生せず、式（21.4）の結果は1 という割合にな
2　訳注：アムダールの法則についての詳しい記述は、ヘネシー＆パターソン『コンピュータアーキテクチャ
定量的アプローチ第5 版』
（翔泳社、2014 年）のpp.44-48 を参照。
hi.0412.ko.2002@gmail.com
402
第21 章
性能評価　
る。逆に、もし補強されたハードウェアが100%の時間で使われたら（つまり割り合いが1）
、
全体のスピードアップは、補強されたハードウェアのスピードアップと等しくなる。そして割
合の数値が0 と1 の間にあれば、全体のスピードアップは、補強されたハードウェアが使われ
た時間の割合にしたがって加重される。
21.10 　アムダールの法則と並列システム
第18 章では並列アーキテクチャを論じ、その性能の不満を説明した。具体的には、プロセッ
サ間の通信によるオーバーヘッドや、メモリやI/O バスといった共有リソースの衝突によって、
システムの実質的なスピードが制限される。その結果、N 個のプロセッサを含む並列システム
で、シングルプロセッサのN 倍の性能を達成することはできない。
おもしろいことに、アムダールの法則は、そのまま並列システムにも適用でき3、プロセッサ
を追加しても満足な性能を得られない理由が、それによって説明される。プロセッサの処理能
力を最適化することによって（つまりプロセッサの追加によって）達成できる高速化は、追加
したプロセッサが使われる時間の割合によって制限される。並列システムでは多くの時間が、
プロセッサの利用ではなく、通信またはバスアクセスを待つのに費やされるので、いくらプロ
セッサを追加しても性能が十分に向上しないという結果になる。
21.11 　まとめ
性能を計測する方法は、多種多様である。プロセッサの性能を測る単純な手段として、コン
ピュータが1 秒間に実行できる平均の浮動小数点演算命令数や、同じく1 秒間に実行できる平
均命令数の指標がある。より洗練された測定方法では加重平均を使い、使用頻度の高い命令が
多く加重される。その加重は、1 個のプログラムまたはプログラムの集合で実行される命令を
数えることによって求めるので、利用するアプリケーションに特有ものだ。命令セットの評価
には、命令と加重との対応を含む命令ミックスを利用できる。
ベンチマークは、性能の評価に使われる標準化されたプログラムまたはプログラム集合であ
る。それぞれのベンチマークは、典型的な計算を表すために選ばれたものだ。最もよく知られ
たベンチマークとして、SPEC.org のものがあり、それらはSPECmark と呼ばれている。整数
および浮動小数点のさまざまな性能を測定するベンチマークのほかに、たとえばリモートファ
イルアクセスのような機構を計測するベンチマークも入手できる。
アムダールの法則は、アーキテクトが最適化すべき機能を選択するのに役立つ（最適化は、た
とえば機能をソフトウェアからハードウェアに移したり、従来のハードウェアから高速なハー
3　訳注：
「アムダールの法則は並列コンピュータに適用できない」という異論に対しては、パターソン＆ヘ
ネシー『コンピュータの構成と設計第5 版』
（日経BP 社、2014 年）の「6.13 誤信と落とし穴」に解説が
ある。
hi.0412.ko.2002@gmail.com
　21.11
まとめ
403
ドウェアに移すことで行う）
。この法則によれば、最も多くの時間を費やしている機能を最適
化すべきである。並列システムでマルチプロセッサによる恩恵を十分に得られない理由も、ア
ムダールの法則で説明できる。
練習問題
21.1
整数の加算と減算を行う演算子の性能を測るC プログラムを書いてみましょう。少
なくとも10,000 回の演算を実行して、演算毎の平均時間を計算します。
21.2
整数の加算と整数の除算の間で、実行時間の差を測定するプログラムを書きましょ
う。どちらの命令も100,000 回実行し、実行に要した時間を比較します。実験を繰
り返し、そのコンピュータで行われる他の動作が測定に影響を与えないかを確認しま
しょう。
21.3
上の課題の拡張として、16bit、32bit、
（もしあれば）64bit の整数加算について性
能を比較しましょう。つまり、short、int、long、long long の変数を、必要に応
じて使います。結果を説明してください。
21.4
コンピュータのプロは一般に、プロセッサの性能を測る方法として、加算、減算、乗
算、除算の命令を使います。けれども多くのプログラムでは、論理積、論理和、ビッ
ト反転、右シフト、左シフトといった論理演算も使われます。これらの演算も計測し
て、性能を整数加算と比較しましょう。
21.5
もし浮動小数点数の加算と減算に、それぞれQ マイクロ秒かかり、浮動小数点数の
乗算と減算に、それぞれ3Q マイクロ秒かかるとしたら、この4 種類の演算に必要な
時間の平均は？
21.6
上記の演習を拡張して、加算と平均の実行時間の差、乗算と平均の実行時間の差を、
それぞれパーセンテージで計算しましょう。
21.7
上記の演習で、コンパイラの最適化オプションを有効にして測定を繰り返し、相対
的なスピードアップを測りましょう。
21.8
整数の算術演算を実行するのに必要な平均時間と、メモリ参照に必要な平均時間と
を比較するプログラムを書きましょう。メモリのコストと整数演算のコストの比率を
計算します。
21.9
浮動小数点演算と整数演算の実行に必要な平均時間を比較するプログラムを書きま
しょう。たとえば、浮動小数点数の加算を10,000 回実行するのに必要な平均時間と、
整数の加算を10,000 回実行するのに必要な平均時間を比較します。
21.10
あるプログラマが、
メモリシステムの性能を測定しようとしています。DRAM チッ
プのメーカーによれば、物理メモリにある1 個の整数をアクセスするのに必要な時間
は80 ナノ秒です。そこでプログラマは、ある値を、ある場所のメモリに40 億回スト
アして、それに要した時間を計って平均の性能を計算するプログラムを、アセンブリ
hi.0412.ko.2002@gmail.com
404
第21 章
性能評価　
言語で書きました。とことが驚いたことに、ストア演算1 回の平均は、わずか52 ナ
ノ秒でした。どうして、こんな結果があり得るのでしょうか？
21.11
上記の質問に関して、物理メモリの正確な測定が難しい理由を教えてください。
21.12
あるハッシュ関数は、
「ハッシュテーブル」と呼ばれる配列のランダムな場所に値
を置きます。あるプログラマが、その動作を調べたら、たとえメモリのキャッシング
をOFF にしても、極度に大きなハッシュテーブル（16 メガバイト）に50,000 の値
をストアして、それらをルックアップすると、小さなハッシュテーブル（16 キロバイ
ト）で同じデータを使うより、性能が悪くなることがわかりました。その理由を説明
してください。
hi.0412.ko.2002@gmail.com
第22 章
アーキテクチャのサンプルと階層構造
22.1 　はじめに
これまで、コンピュータのアーキテクチャを理解するのに必要な概念と用語を説明してきた。
プロセッサ、メモリ、入出力の基本的な側面を論じ、それぞれの役割を説明した。そして性能
を改善するために並列処理とパイプライン処理を使う方法を論じた。
この章では、アーキテクチャのサンプルを挙げて考察する。ここでは新しいアイデアを紹介
するのではなく、これまでの章で見たアイデアを使って、デジタルシステムのさまざまな側面
を記述し説明する方法を紹介する。サンプルは、幅広い可能性を示すように選んだ。
22.2 　アーキテクチャの3 つのレベル
以前の章で述べたように、アーキテクチャは複数の抽象レベルで表現できる。アーキテク
チャの諸概念をデジタルシステムに幅広く適用できることを認識するために、アーキテクチャ
仕様の階層構造を見ていこう。その階層構造は、それぞれのレベルの範囲が、コンピュータシ
ステム全体から、集積回路に存在する小さな機能ユニットにおよぶ。それぞれの範囲を表現す
るのに、われわれは「システムレベル・アーキテクチャ」
（あるいは巨視的アーキテクチャ）
、
「ボードレベル・アーキテクチャ」
、
「チップレベル・アーキテクチャ」
（あるいは微視的アーキテ
クチャ）という用語を使う。各レベルで基本的なコンポーネントと、それらの相互接続を理解
するのに、これまでに学んだ概念が役立つだろう。どのレベルでも、論理的（概念的）アーキテ
クチャや詳細な実装を指定できる。表22‒1 に、これから見ていく3 つのレベルの概要を示す。
hi.0412.ko.2002@gmail.com
406
第22 章
アーキテクチャのサンプルと階層構造　
表22‒1：アーキテクチャの概念的なレベルと、それぞれの目的
レベル
説明
システム
プロセッサ、メモリ、I/O デバイスを含む完全なコンピュータ。典型的なシス
テム・アーキテクチャは、コンポーネントとバスとの相互接続を記述する。
ボード
コンピュータシステムの一部を構成する、個々の回路基板。典型的なボード・
アーキテクチャは、さまざまなチップの相互接続と、バスとのインターフェイ
スを記述する。
チップ
回路基板で使われる、個々の集積回路（IC）
。典型的なチップ・アーキテクチャ
は、各種の機能ユニットやゲートの相互接続を記述する。
22.3 　システムレベルのアーキテクチャ：PC
パーソナルコンピュータ（PC）は、概念的にはプロセッサと、メモリと、一群のI/O デバイ
スで構成され、それらはすべて1 個のバスに接続される。しかし実際には、PC といえども複雑
なバス構成を持ち、それぞれ特定の役割を果たすべく設計された機構の相互接続を含んでいる。
根底にあるハードウェアの多様性と複雑さは、性能に関する要件とコストに起因する。たと
えばビデオカードは、フロッピーディスクなどと比べれば、ずっと高いデータスループットを
必要とする。そして高解像度スクリーンは低解像度スクリーンよりも高いスループットを必要
とする。残念ながら、デバイスを高速なバスに接続するハードウェアは、デバイスを低速なバ
スに繋げるハードウェアよりも、ずっとコストが高い。だから複数のバスを使うことでシステ
ム全体のコストを下げることがある。
複数の入出力バスを使う第2 の動機は、新しい、より強力なシステムへのグレードアップを
安価に提供したいというベンダーの欲求から生じる。つまりベンダーは、高性能と多彩な能力
を提供するプロセッサを作りたいが、それと同時に、既存の周辺機器をそのまま使えるように
もしたいのだ。既存のハードウェアを利用できる性質は、
「後方互換性」と呼ばれる。
後方互換性が、とりわけ重要なのはバスのアーキテクチャだ。なぜならバスは、I/O デバイ
スとプロセッサの相互接続を形成するのだから。コンピュータベンダーは、新しい高速バスを
作りながら、古い周辺機器を接続できる能力を、どうやって維持するのだろうか。ひとつの可
能性は、複数のバスインターフェイスを持つプロセッサを作ることだ。しかし、それよりずっ
と安価な解決策は、
「ブリッジ」を使うことだ。
22.4 　バスの相互接続とブリッジ
後方互換性のためにブリッジを使うことは、歴史的な例を見ると理解しやすい。過去のあ
る時点では、あらゆるPC で、IBM が開発した「ISA」
（Industry Standard Architecture）バ
スが使われていた。PC 用の周辺機器は。このISA バスとのインターフェイスとともに設計さ
れた。その後、もっと高速なバスアーキテクチャとして開発されたのが、
「PCI」
（Peripheral
hi.0412.ko.2002@gmail.com
　22.5
コントローラチップと物理アーキテクチャ
407
Component Interconnect）バスである。この2 つは、どちらもPC 用の標準バスだが互換性
がなく、ISA バスで使えたインターフェイスが、PCI バスでは使えなかった。このため、ISA
機器を持っているユーザーが、PCI 機器だけを受け付ける新しいコンピュータに買い換えるの
は容易ではなかった。
古いコンピュータを持っている人が、PCI バスを持つコンピュータにアップグレードしやす
くするために、ベンダー各社は、古いISA バスと新しいPCI バスとの相互接続を行う「ブリッ
ジ」を作った。ブリッジは、論理的には図22‒1 に示すような相互接続を提供した。
CPU
メモリ
ブリ
ッ
ジ
PCIバス
ISAバス
PCIインターフェイスを持つ機器
ISAインターフェイスを持つ機器
図22‒1：ISA バスとPCI バスの相互接続をブリッジで行うPC アーキテクチャの概念図。ブリッジによっ
て、ISA 用の古い機器を、もっと新しいコンピュータで使うことが可能になった
この図で、CPU と、PCI インターフェイスを持つI/O デバイスは、PCI バスに直接繋がれ
ている。そして、ISA インターフェイスを持つI/O デバイスを使うために、ISA バスとの相互
接続をブリッジが提供する。最良のケースで、ブリッジが提供する相互接続は「トランスペア
レント」である。つまり、ブリッジのどちら側も相互接続の存在を知らずに、ローカルバスを
使って通信することが可能だ。CPU は、PCI バスに接続されているかのようにISA デバイス
をアドレッシングするし、ISA デバイスは、CPU がISA バスに接続されているかのように、応
答することができる。
22.5 　コントローラチップと物理アーキテクチャ
図22‒1 はPC アーキテクチャの概要を示しているが、その実装は図が示すよりも、はるか
に複雑だ。まずPC には、外部デバイスをそれぞれのバスに接続するためのスロットがあるが、
内部接続にはスロットを使わない。その代わり、PC は普通、すべてのバスとメモリの相互接
hi.0412.ko.2002@gmail.com
408
第22 章
アーキテクチャのサンプルと階層構造　
続を提供するために、特殊用途の「コントローラチップ」を持っている。そしてコントローラ
チップは、まるで複数のバスがあるような錯覚が得られるように設定される。
コントローラチップの必要性を理解するために、PC に要求される機能を考えよう。アーキ
テクトは、プロセッサと、メモリと、
（複数かもしれない）入出力バスを接続する必要がある。
それには物理的に互換性のある相互接続を提供するだけでなく、コンポネント同士が通信でき
る機構を設計する必要がある（たとえばCPU もI/O デバイスも、メモリをアクセスする必要
がある）
。
しかし残念ながら、ハードウェアインターフェイスを複製するのはコストが高い。アーキテ
クトには、それぞれのコンポネントに複数のインターフェイスユニットを持たせ、それで他の
コンポネントとの相互接続を処理させるような、贅沢なシステムを構築する余裕がない。たと
えばプロセッサも、ほとんどのI/O デバイスも、メモリをアクセスする必要があるが、コスト
の制限があるので、個々のデバイスにメモリインターフェイスを持たせることができない。
費用と労力を節約するために、しばしばアーキテクトは、機能を集中させた「コントローラ
チップ」を置くアプローチを採用する。1 個のコントローラチップには、K 個のハードウェア
インターフェイスが含まれ、個々のインターフェイスが、それぞれ特定の種類のハードウェア
を受け持って、要求をそれらに配給する。あるハードウェアユニットが、もうひとつのハード
ウェアユニットをアクセスする必要があるとき、その要求は必ずコントローラに向かう。コン
トローラは、受け取った要求を、それぞれ適切な形式に変換してから、目的のハードウェアユ
ニットに転送する。同じように、それぞれの応答もコントローラが変換する。
要点をまとめておこう。
アーキテクトはコントローラチップを使って、コンピュータ内部のコンポネント間に相
互接続を提供する。そのほうが、個々のユニットに一群のインターフェイスを装備させ
たり、バスの相互接続のために一群のブリッジを個別に構築するよりも、コストを抑え
られるからだ。
22.6 　仮想バス
コントローラチップによって興味深い可能性がもたらされた。バスは通信に使うのだから、
それぞれのバスに2 つ以上のデバイスを（たとえばプロセッサとディスクを）繋げるのが普通
だ。ところがコントローラチップを使うコンピュータでは、デバイスを1 個だけ含むバスを作
るのも合理的だ。たとえば、ISA バスを必要とするデバイスが1 個だけあって、他のデバイス
はどれもPCI バスを使うのであれば、そのISA デバイスとはISA プロトコルを使って通信し、
他のデバイスとの通信にはPCI プロトコルを使うように、コントローラチップを作ることがで
きる。たとえコントローラチップがISA デバイスとの通信にISA プロトコルを使うとしても、
そのコンピュータがISA デバイス用のスロットを持つ必要はなく、通常の意味での物理的な
ISA バスを持つ必要もない。
hi.0412.ko.2002@gmail.com
　22.6
仮想バス
409
コントローラチップによって、直接バスと接続しているような錯覚を得ることが可能だ。
物理的なソケットも、普通はバスに使われる配線も、必要ではない。
コントローラで、直接的なバス接続の感覚が得られるというアイデアのおかげで、アーキテ
クトはバスを汎用的な存在として認識できる。パラレルな配線を持つ実際のバスの代わりに、
シリコンチップを使うことで「バスのようなもの」を作れるのだ。このテクノロジーを、われ
われは「仮想バス」と呼んでいる。たとえば、接続されているデバイスごとに1 つの仮想バス
があるように思わせるコントローラを作ることも可能だ。あるいは、1 つ以上の物理バスとの
接続を持つ1 つ以上の仮想バスを組み合わせたコントーラを作ることもできる。後の節でサン
プルを見よう。
典型的なPC アーキテクチャは、1 つではなく2 つのコントローラチップを使っていた。そ
れらのチップは非公式に「ノースブリッジ」
、
「サウスブリッジ」と呼ばれた。
「システムコン
トローラ」とも呼ばれたノースブリッジには、高速なコンポーネントが接続された。たとえば
CPU、メモリ、ストリーミング通信のコントローラ、そして、高速グラフィックスディスプレ
イの制御に使われる「AGP」
（Advanced Graphics Port）インターフェイスなどだ。ノースブ
リッジに接続されるサウスブリッジは、低速なコンポーネントとの接続に使われた。それらは
PCI バス、Wi-Fi ネットワークインターフェイス1、オーディオデバイス、キーボード、マウス
などのデバイスだ。図22‒2 に、この2 つのコントローラチップを使うPC アーキテクチャの
物理的な相互接続を示す。
コントローラチップは異種混合に対処できなければならない。この図が示すように、コント
ローラには複数のバステクノロジーが接続されるからだ。たとえばこの図のサウスゲートは、
PCI バス、USB バス、ISA バスに接続を提供している。もちろんコントローラは、それぞれの
バスのルールにしたがう必要がある。つまりコントローラは、電子的仕様を守り、全部のアド
レスがバスのアドレス空間にあることを確実にし、デバイスがバスをアクセスし利用する方法
を定義したプロトコルを遵守する必要がある。
CPU を作るベンダーは、そのCPU と標準バスとの相互接続ができるように設計した、一群
のコントローラチップを提供するのが普通だ。たとえばインテルは、ノースブリッジ機能を持
つ「82865PE」チップと、サウスブリッジ機能を持つ「ICH5」チップを提供した。重要なポイ
ントとして、インテルのプロセッサチップとインテルのコントローラチップは、共同作業をす
るように設計されている。それぞれのチップには、これらのチップを直接相互接続するための
インターフェイスが含まれていて、それぞれのチップが、異種混合のデバイス群を接続するの
に必要な変換を実行する。
1　ただしギガビットの速度で運用されるネットワークは、ノースブリッジに接続された。
hi.0412.ko.2002@gmail.com
410
第22 章
アーキテクチャのサンプルと階層構造　
CISC
CPU
（x86）
コン
トローラ
AGPポー
ト
ス
トリーム
ポー
ト
ノースブリ
ッ
ジ
コン
トローラ
USB
サウスブリ
ッ
ジ
ISAバス
デジタル
オーディオ
Wi-Fi
インターフェイス
デュアルポー
トメモリ
QDR
SDRAM
QDR
SDRAM
独自のハブ接続
PCI
図22‒2：2 つのコントローラチップを使うPC の物理的な相互接続を示す、システムレベルのアーキテク
チャの例。高速を必要とするコンポーネントはノースブリッジコントローラに繋がれている
22.7 　接続の速度
図22‒2 で示した接続では、固定のビット幅を持つパラレルなハードウェアインターフェイ
スを使うのが典型的で、それらは指定のスループットを達成できる固定のクロックレートで運
用するように設計される。表22‒2 に、主な接続の典型的なクロックレートと、データ幅と、ス
ループットを示す。
比較できるように、この表にはFCC が「ブロードバンド」として定義したインターネット接
続（ダウンストリームで毎秒25 メガビット、すなわち毎秒3.1 メガバイト）と、当時のプロ
セッサにおけるレジスタファイルの例を入れた。これを見ると、一般にコンピュータ内部の転
送は、ブロードバンドインターネット接続より、ずっと高速になること、そしてレジスタで維
持されるスループットの高さと比べれば、このリストにある他のすべてのスループットが見劣
りすることがわかる。
hi.0412.ko.2002@gmail.com
　22.8
ブリッジ機能と仮想バス
411
表22‒2：図22‒2 に示したアーキテクチャにあった接続のクロックレート、データ幅、スループット2の例
接続
クロックレート
データ幅
スループット
USB 1.0
33MHz
32 ビット
1.5MB/s
FCC 定義のブロードバンド
-
-
3.1MB/s
AGP
100～200MHz
64-128 ビット
2.0GB/s
USB 3.0
最大で500MHz
32 ビット
5.0 GB/s
メモリ
200～800MHz
64-128 ビット
6.4 GB/s
PCI 3.0
33MHz
32 ビット
126.0 GB/s
レジスタ
1000～2000MHz
64-128 ビット
672.0 GB/s
22.8 　ブリッジ機能と仮想バス
「ノースブリッジ」
、
「サウスブリッジ」という名前が示唆するように、これら2 つのコント
ローラはブリッジ機能を提供した。たとえばノースブリッジが提供したのは、メモリ、高速デ
バイス、およびサウスブリッジチップへのブリッジ機能だ。そしてノースブリッジは、以上の
すべてを含む1 個の統一されたアドレス空間を、CPU に提供した。同様に、サウスブリッジ
は、PCI バス、ISA バス、USB バスを組み合わせて1 個の統一されたアドレス空間を作り、そ
の空間が、ノースブリッジがプロセッサに提供するアドレス空間の一部になった。
興味深いことにコントローラは、必ずしも全部のデバイスを1 個のアドレス空間に統合する
ブリッジ機能を提供する必要はない。その代わりに、コントローラはCPU に、複数の仮想バス
という架空の存在を提供できる。たとえばコントローラは、CPU が2 つの別々のPCI バスを
アクセスできるようにする。0 番のバスにはCPU とメモリが含まれ、1 番のバスにはI/O デ
バイスが含まれる、という具合だ。あるいはコントローラは、3 つの仮想バスがあるという錯
覚を提供することも可能だ。ひとつはCPU とメモリを含み、もうひとつは高速グラフィック
ス機器を含み、第3 のバスは任意のデバイスを繋げられる外部PCI スロットに対応する、とい
う具合に。このような分離は、プログラマにとって興味深いものではないけれど、性能を重視
するハードウェア設計者には非常に重要だ。なぜならコントローラチップに並列回路を入れれ
ば、すべての仮想バスを同時に動かすことが可能になるからだ。
22.9 　ボードレベルのアーキテクチャ
図22‒2 に示したアーキテクチャには、パーソナルコンピュータに含まれるユニットとして
Wi-Fi インターフェイスが入っていた。このインターフェイスの役割は単純明快だ。これはPC
とWi-Fi 無線部との間に物理的な接続を提供し、PC がネットークに送るデータとネットワー
クから届いたデータの転送を行う。Wi-Fi インターフェイスは、物理的にラップトップの「マ
2　スループットは、MB/s（メガバイト毎秒）とGB/s（ギガバイト毎秒）で記述した。大文字のB を使う
のは、ビットではなくバイトであることを強調するため。
hi.0412.ko.2002@gmail.com
412
第22 章
アーキテクチャのサンプルと階層構造　
ザーボード」に統合することもできるし、デスクトップシステムなら独立した回路基板（イン
ターフェイスカード）に載せることもできる。どちらも論理的な相互接続は同じだ。
Wi-Fi ネットワークインターフェイスのカードには、膨大な計算能力が搭載される。具体的
に言えば、このインターフェイスには埋め込みプロセッサ、その命令を含むROM、バッファ
メモリ、外部ホストインターフェイス（たとえばPCI バスのインターフェイス）
、無線送受信
部への接続が含まれる。インターフェイスカードには、通常のRISC プロセッサを使うものも、
ネットワークパケットの処理に最適化された特別な「ネットワークプロセッサ」を使うものも
ある。図22‒3 に、ネットワークプロセッサを使うLAN インターフェイスのアーキテクチャ
として可能な一例を示す。
ホス
トインターフェイス
ネッ
トワークインターフェイス
SRAM
SDRAM
ネッ
トワーク
プロセッサ
SRAMバス
SDRAMバス
図22‒3：LAN インターフェイスカードのアーキテクチャを示すサンプル
なぜインターフェイスカードに2 種類のメモリが必要なのか。主な理由はコストだ。SDRAM
と比べてSRAM は高速だが、コストが高い。したがって、大きなSDRAM をパケットの格納
に使い、小さなSRAM は、頻繁にアクセスあるいは更新する必要のある値に使う（たとえば
ネットワークプロセッサが実行する命令）
。このサンプルで、この2 つのメモリ接続を選んだ
理由は、次の節で述べるネットワークプロセッサがSRAM とSDRAM の両方を使うからだ。
hi.0412.ko.2002@gmail.com
　22.10
チップレベルのアーキテクチャ
413
22.10 　チップレベルのアーキテクチャ
前述したように、チップレベルのアーキテクチャは、1 個の集積回路の内部構造を記述するも
のだ。図22‒3 に示したボードレベル・アーキテクチャで、ネットワークプロセッサは単なる
四角い枠だったが、チップレベル・アーキテクチャの一例として、そのチップの内部構造を調
べよう。図22‒4 に示すのは、Netronome ネットワークプロセッサ3の、チップレベル・アー
キテクチャだ。
メディア
アクセスユニッ
ト
PCIバス
アクセスユニッ
ト
SDRAM
アクセス
埋め込み
RISC
プロセッサ
(XScale)
シリアルライン
マイクロエンジン 1
マイクロエンジン 2
マイクロエンジン 3
マイクロエンジン 4
マイクロエンジン 5
マイクロエンジン N
複数の
独立した
内部バス
オンボー
ド
スクラ
ッチ
メモリ
SRAM
アクセス
図22‒4：チップレベル・アーキテクチャの例として、Netronome ネットワークプロセッサの主な内部コン
ポーネントを示す。アクセスユニットは、チップの外部接続を提供する
この図のすべてが1 個の集積回路であることを忘れてはいけない。これが重要なポイントだ。
このネットワークプロセッサには、さまざまな外部インターフェイスがあり、高速ストレージ
を提供するオンボード「スクラッチ」メモリがあり、複数の独立したプロセッサなど数多くの要
素が含まれている。さらに、このチップでは「マイクロエンジン」と呼ばれるプログラマブル
なRISC プロセッサの一群が並列動作するほか4、
「XScale」RISC プロセッサも含まれている。
XScale は汎用プロセッサで、他のプロセッサを管理するインターフェイスを提供する。ネット
ワークプロセッサが動作するとき、このXSCale はLinux のような一般的なOS を実行する。
3　このネットワークプロセッサは、インテルが設計した。その設計が、後にNetronome に売却された。
4　このチップの、より高度なバージョンは、16 個のマイクロエンジンを提供する。
hi.0412.ko.2002@gmail.com
414
第22 章
アーキテクチャのサンプルと階層構造　
このプロセッサが集積回路の一部であることを示すために「埋め込み」と断っている。
ネットワークプロセッサと、その内部プロセッサの詳細は、いまのところ関係がない。理解
すべき重要なポイントは、アーキテクチャのレベルを下げると、より多くの詳細が現れること
だ。この場合で言えば、1 個の集積回路に数多くの機能ユニットが含まれるけれど、その回路
の構造が現れるのはチップレベルの図だけであり、ボードレベルの図では、チップの構造は隠
されている。
アーキテクチャのレベルを下げると、より高いレベルでは隠されていた詳細が現れる。
チップレベル・アーキテクチャは、ボードレベル・アーキテクチャでは隠されていた集
積回路の内部構造を指定する。
22.11 　オンチップ機能ユニットの構造
アーキテクチャのレベルを示す最後の例として、チップに含まれる1 個のコンポネントの
アーキテクチャを、どうすれば記述できるかを見よう。図22‒5 に示すのは、図22‒4 にあった
SRAM アクセスユニットである。このメモリアクセスユニットの内部構造は、きわめて複雑だ。
SRAMアクセスユニッ
ト
SRAM
クロ
ッ
ク
制御信号
ア
ドレス
データ
データ
SRAM
ピン
インター
フェイス
ア
ドレス
コマン
ド
デコーダと
ア
ドレス
ジェネレータ
サービス優先
順位の調停
メモリと
FIFO
AMBA
XScaleから
AMBA
バス
インター
フェイス
AMBAア
ドレス
キュー
マイクロエンジンの
ア
ドレスとコマン
ドの
キュー
マイクロエンジンの
コマン
ド
マイクロエンジンの
データ
図22‒5：SRAM アクセスユニットの内部構造（図22.6 では隠されていた）
。アーキテクチャの階層構造を
下るたびに、さらなる詳細と構造が現れる
hi.0412.ko.2002@gmail.com
　22.12
まとめ
415
22.12 　まとめ
デジタルシステムのアーキテクチャは、いくつもの抽象レベルで見ることができる。システ
ムレベル・アーキテクチャは、コンピュータシステム全体の構造を示し、ボードレベル・アー
キテクチャは、それぞれの基板の構造を示し、チップレベル・アーキテクチャは、集積回路の
内部構造を示す。レベルを下げるのにしたがって、それ以前のレベルでは隠されていた詳細が
現れる。
サンプルとして、
この章では古典的なパーソナルコンピュータと、
そのコンピュータにあった
Wi-Fi ネットワークインターフェイスボードと、そのインターフェイスボードにあったネット
ワークプロセッサの構造を示す、アーキテクチャの階層構造を提供した。そして最後に、チッ
プレベル・アーキテクチャをさらに細かく見る例として、埋め込みユニットのアーキテクチャ
を見た。
練習問題
22.1
ある技術者が、システムアーキテクトとしての仕事をオファーされました。その仕
事の範囲に含まれるのは何でしょうか？
22.2
コンピュータが2 つのバスを提供する理由となるのは。どんな動機でしょうか？
22.3
USB ポートを持つコンピュータには、
「USB ハブ」と呼ばれるハードウェアが含ま
れます。これは普通、PCI バスの外部ポートに接続して使うものです。図22‒1 の図
を、USB ハブを示すように書き換えてください。
22.4
もしコンピュータに、トランスペアレントなブリッジで接続された2 つのバスがあ
り、その片方にはメモリが、もう片方にはデバイスが接続されるとしたら、そのデバ
イスはメモリと通信できるでしょうか。説明してください。
22.5
最近のバスアーキテクチャにあるコントローラチップの目的は何ですか？
22.6
あるコンピュータには、古いバスを使うデバイスが1 つあるのですが、そのバスの
ための通常のソケットも配線も、そのコンピュータにはありません。どういう状況が
考えられますか？
22.7
PC に超高速ビデオシステムを接続するとしたら、そのチップはノースブリッジと
サウスブリッジの、どちらでしょうか？
22.8
ある動画をUSB 3.0 のポートを介して転送するのに40 秒かかるとしたら、毎秒20
メガビットで動作するWi-Fi ネットワークで同じ動画を転送するのに、どのくらいか
かるでしょうか。
22.9
ネットワークプロセッサ（たとえば図22‒5 に示したもの）は、
「SoC」
（System on
Chip）に分類されます。その理由を説明してください。
22.10
ハードウェア設計の図面では、サブシステムを表すのに四角い枠（ボックス）が
hi.0412.ko.2002@gmail.com
416
第22 章
アーキテクチャのサンプルと階層構造　
使われます。その図を見ただけで、ボックスの機能を実装するのに必要なゲート数の
概算がわかるのでしょうか。説明してください。
hi.0412.ko.2002@gmail.com
第23 章
ハードウェアのモジュール化
23.1 　はじめに
これまでの章では、ハードウェアアーキテクチャの概要を示すだけで、設計や実装の詳細に
は触れなかった。この短い章で、設計のモジュール化について考えたい。まずはハードウェア
のモジュールとソフトウェアのモジュールを比較し、ソフトウェアで一般的な抽象がハード
ウェアに適用されない理由を考察する。それからサンプルを使って、基本的なハードウェアモ
ジュールによって設計を柔軟にする方法を明らかにし、基本モジュールの複製によってスケー
ラブルなハードウェア設計が可能になることを示す。
23.2 　モジュールの需要
モジュール式の構築には、知的な動機と経済的な動機がある。知的な面で言えば、モジュー
ル式のアプローチをとる設計者は、大きくて複雑な問題を、もっと小さな部分に分割できる。
全体の解決は困難でも、小さい部品なら理解しやすい。だから設計者は、部品の正しさを容易
に確認でき、最適化も容易になる。
モジュール化を選ぶ経済的な動機は、製品を設計しテストするための費用に関係する。多く
の場合、企業はただ1 つ孤立した製品を作るのではなく、関連した一群の製品を作るだろう。
複数の製品を作る一般的な理由の1 つはサイズである。企業は小規模から大規模に至る広い範
囲で、一連の製品を販売したいはずだ。たとえばネットワーク製品を売る会社は、ネットワー
クスイッチのモデルを4 種類提供したいかもしれない。そうすれば、4 台のコンピュータにも、
24 台のコンピュータにも、48 台のコンピュータにも、96 台のコンピュータにも、適切な接続
を提供できる。あるいは、どれも基本的には同じ機能を提供するが、それぞれ特徴的な機能を
持たせた一連の製品を提供したい場合もあるだろう。たとえばネットワーク機器を販売する会
社は、無線のWi-Fi ネットワークに接続するモデルと、有線のEthernet に接続するモデルの
hi.0412.ko.2002@gmail.com
418
第23 章
ハードウェアのモジュール化　
両方を提供したいかもしれない。
製品の設計には高いコストがかかる。企業は費用を節約するために、ある基本的なモジュー
ルを1 度だけ設計し、あとはそのモジュールを複数の製品で再利用したいだろう。いったん基
本モジュールを徹底的にテストしておけば、それに続く一連の設計ではモジュールが正しく動
作することを前提として、さらに費用を節約できる。
23.3 　ソフトウェアのモジュール化
モジュール化は、初期のコンピュータから、ソフトウェア設計で重要な役割を果たしてきた。
主な抽象として、サブルーチンがある（これはプロシージャとも、サブプログラムとも、関数と
も呼ばれる）
。サブルーチンを使う動機は、最初はメモリサイズの制限によるものだった。同
じコードセクションをプログラム全体に繰り返し配置するのではなく、そのコードのコピーを
ただ1 つメモリに置いて、プログラムのいくつかの場所から、それを使う（呼び出す）ことが
できる。
ソフトウェアが、もっと複雑になると、サブプログラムは複雑さに対処する重要なツールに
なった。具体的には、サブプログラムという抽象を採用することによって、優れた専門家が構
築したソフトウェアの部品を、他のプログラマが詳細を理解する必要なしに使えるようになっ
た。たとえば数値計算を得意とする専門家は、sin(x)、cos(x) など一群の三角関数を作るこ
とができる。それらは効率がよく、正確に動作する。ほかのプログラマは、自分でコーディン
グしないで、それらの関数を呼び出せばよく、その中で使われているアルゴリズムを理解する
必要もない。サブプログラムによって抽象化のレベルを上げ、詳細を隠すことによって、プロ
グラマは、より高いレベルで仕事をすることが可能になる。彼らの生産性は高まり、結果とし
てソフトウェアに含まれるエラーも少なくなることが期待できる。
23.4 　パラメータを持つサブプログラムの呼び出し
基本的なビルディングブロックを複数の目的で使うには、どうすればいいだろうか。ソフト
ウェアの場合、その答えは、よく知られている。サブプログラムを作るとき、プログラマは一
群の「パラメータ」を仮に指定する。そのサブプログラムを呼び出すコードを書くとき、プロ
グラマは、仮のパラメータを置き換える実際の「引数」を指定する。
重要なポイントは次の通り。
モジュール化されたソフトウェアを書くとき、それぞれのサブプログラムのコピーは1
個だけ存在する。呼び出し毎に変更する必要があるのは、サブプログラムの呼び出しで
提供する引数だけだ。
hi.0412.ko.2002@gmail.com
　23.5
ハードウェアのスケーリングと並列性
419
23.5 　ハードウェアのスケーリングと並列性
パラメータ付きの関数を呼び出すというパラダイムは、ソフトウェアには適切だがハード
ウェアには使えない。その理由は、ソフトウェアが関数を繰り返し呼び出すのに対して、ハー
ドウェアの場合は、並列に制御できる実体を複数持つ必要があるからだ。たとえばN 個の要素
を持つ集合を制御する場合を考えてみよう。ソフトウェアなら、それらの要素を1 個の配列に
格納し、1 個の要素に対して演算を実行する関数を書けば、プログラムは配列を巡回しながら、
個々の要素について、その関数を繰り返し呼び出すことができる。プログラムを大きな配列に
スケーリングするには、繰り返しの限度を変更するだけでよい。
ところが要素の集合を制御するハードウェアを作るときは、それぞれの要素に専用のハード
ウェアが必要になる。集合に要素を追加するときは、設計にハードウェアを追加しなければな
らない。言い換えると、ハードウェア設計のスケーリングには、必ずハードウェア部品の追加
が必要である。結果として次のことが言える。
ハードウェア設計者がモジュール式の設計を考えるときは、ハードウェアの部品を繰り
返し呼び出す方法を考えるのではなく、設計にハードウェアを追加する方法を考える。
23.6 　基本ブロックの複製
ハードウェアのスケーリングを実現する基本的なテクニックは、必要に応じて複製が可能な
基本のビルディングブロックを定義することだ。その単純な例は、これまでにも見てきた。た
とえば「ラッチ」の回路をN 回複製すればN ビットの「レジスタ」になるし、
「フルアダー」
をN−1 回コピーして「ハーフアダー」を加えれば、N ビット整数2 つの和を計算する加算回
路を作れる。
上記の単純なケースにおいて、複製に関わるのは小さな回路（数個のゲート）だけであり、
しかも複製の個数が固定されていた。小さな回路の複製も設計の重要な側面ではあるが、この
アプローチを、もっと大きな回路に適用すれば、設計のスケーリングに利用できる。たとえば
チップのメーカーは、マルチコアのアーキテクチャを使って、2 コア、4 コア、8 コアなど一連
の製品を作ることができるだろう。設計で、とくに複製が重要になるのは、ユーザーから見え
る入力または出力の数が、シリーズの製品ごとに異なる場合だ。
23.7 　設計の例：リブータ
この考えは、例を見ると理解しやすくなる。ここでは架空の設計ではなく、著者のラボ1で
使っているハードウェア部品について考えることにしたい。そのラボは、OS とネットワーキ
1　訳注：前書きにあるように、著者のComer 博士は、パデュー大学でコンピュータサイエンスのコース
を持っている。著者のラボ（研究室、実験室）については、本書の付録でも言及されている。
hi.0412.ko.2002@gmail.com
420
第23 章
ハードウェアのモジュール化　
ングの研究に使っていて、研究目的に、そしてクラスの学生たちが使うために、大量のバック
エンドコンピュータを用意している。このラボの設備を使うユーザーは、OS を作成し、バッ
クエンドコンピュータを1 つ割り当て、OS を、そのバックエンドコンピュータのメモリにダ
ウンロードして、コンピュータの実行を開始することができる。そうすればユーザーは、バッ
クエンドコンピュータとのインタラクションを開始できる2。
残念ながら、OS の実験的な作業では、コンピュータがクラッシュしたり、ハードウェアがそ
れ以上の入力に応答しない状態になったりすることが多い。そういう状況では、バックエンド
コンピュータの電源をいったん落として再起動させる「リブート」によって、制御を復旧させ
る必要がある。そこでわれわれは、個々のバックエンドコンピュータを必要に応じてリブート
できる、特殊用途のハードウェアシステムを作成した。このシステムを、
「リブータ」と呼んで
いる。ラボでは何世代かのリブータを使ってきたが、ここで見るのは、その設計の1 つである。
23.8 　高いレベルでのリブータ設計
リブータのハードウェアは、原則的には単刀直入なアプローチにしたがう。リブータには一
群の出力があって、それぞれ1 台のバックエンドコンピュータに電力を供給する。リブータの
入力は、リブートしたい出力の1 つを指定するバイナリ値と、リブータの動作を許可する1 本
のイネーブル入力で構成される。このリブータを使うには、まず入力にバイナリ値を設定して
出力の1 つを指定し、それからイネーブル入力に1 をセットする。これによってリブータは指
定の出力で電源OFF/ON のサイクルを実行する3。図23‒1 に、その入力と出力を示す。
2N台のバッ
クエン
ドコンピュータ
に電力を供給する接続
Nビッ
トの
バイナリ入力値
イネーブル入力
リブータのハー
ドウェアユニッ
ト
図23‒1：リブータの基本的なハードウェア構成
リブータには、いくつ出力を持たせるべきだろうか。この質問が重要なのは、リブータには
個々の出力に物理的な接続が必要だからだ。最初はラボにバックエンドが1 台しかなかった
が、すぐに2 台となり、それから8 台と、サイズが増え続けた。将来性を配慮して設計するた
2　訳注：この場合はラボで作ったOS を実行するコンピュータが「バックエンド」で、フロントエンドに
は別のコンピュータを使うのだろう。このように分けておけば、バックエンドの1 つがクラッシュしても、
その他のコンピュータは無事である。
3　リブータ回路の詳細は、今後の議論には関係ない。基本的な事項を理解するために重要なだけである。
hi.0412.ko.2002@gmail.com
　23.9
広範囲な規模に対応できるビルディングブロック
421
め、私たちは少なくとも40 台、できれば100 台のバックエンドをサポートできるリブータ回
路を必要とした。この状況は、標準的なハードウェアのジレンマを例示している。
•
出力が少なすぎる設計は、将来の需要に対応できない。
•
出力が多すぎる設計は、無駄になる。
23.9 　広範囲な規模に対応できるビルディングブロック
特定のサイズを選ぶ代わりに、われわれはモジュール化のアプローチを使った。つまり、基
本となるビルディングブロックを1 つ選び、複数の基本ブロックを相互接続することで、よ
り大きなリブータを作れるようにした。このモジュール式アプローチによって、まず小さなリ
ブータを構築し、必要に応じて出力を追加できるようになった。
われわれの基本となるビルディングブロックは、図23‒2 に示す16 出力のリブータである。
リブータの
ビルディ
ング
ブロ
ッ
ク
16台のバッ
クエン
ドに
電力を供給する接続
8ビッ
トの
バイナリ入力値
イネーブル入力
図23‒2：リブータに使う基本的なビルディングブロックの例
この図を注意深く見ていただきたい。バイナリの入力値は8 ビットだが、出力は16 しかな
い。したがって、出力を1 つ選ぶのに必要なのは4 ビットだけである。残りのビットは、何の
ためにあるのか? このビルディングブロックの複数のコピーを組み合わせて、もっと大きなリ
ブータを作るためにあるのだ。
23.10 　並列的な相互接続
われわれの設計は、多くのハードウェアシステムで一般に使われている並列的なアプローチ
を利用している。それは、全部のモジュールに入力を並列的に繋ぐことだ。コンセプトとして、
どのビルディングブロックも、その入力のコピーを（イネーブル入力を含めて）次のビルディ
ングブロックに渡す。図23‒3 に、このアイデアを示す。
hi.0412.ko.2002@gmail.com
422
第23 章
ハードウェアのモジュール化　
すべての入力の
コピーを、
次の段に渡す
16台のバッ
クエン
ドに
電力を供給する接続
8ビッ
トの
バイナリ入力値
イネーブル入力
リブータの
ビルディ
ング
ブロ
ッ
ク
図23‒3：基本的なビルディングブロックが、すべての入力を、リブータの次の段に渡す
23.11 　相互接続の例
図23‒4 に、複数のビルディングブロックを接続する例を示す。
64台のバッ
クエン
ドコンピュータに電力を供給する接続
8ビッ
トの
バイナリ入力値
イネーブル入力
モジュール
（ID=0）
モジュール
（ID=１）
モジュール
（ID=２）
モジュール
（ID=３）
必要に応じて、
より多くのモジュールを追加できる
図23‒4：基本的なビルディングブロックの4 つのコピーを相互接続して、64 の出力を提供する
23.12 　モジュール選択
図23‒4 に示したように、入力は4 個のモジュールすべてに並列的に渡される。入力で、リ
ブートをかけるコンピュータの番号として5 を指定したら、どのモジュールも5 番目の出力を
リブートするのだろうか。そうではない。1 番目のモジュールの5 番目の出力だけが変化する。
複数のモジュールが入力値に対応する方法を理解するためには、それぞれのモジュールにユ
ニークなID（この例では0、1、2、3）を割り当てていることを認識する必要がある。モジュー
ルには、入力の上位4 ビットをチェックして、自分に割り当てられているID と一致するかど
うかを判定するハードウェアが含まれる。もし入力がID と一致しなければ、その入力は無視
される。言い換えると、ハードウェアは上位4 ビットを「モジュール選択」と解釈し、下位4
ビットを「出力選択」と解釈する。
一例として図23‒5 は、ハードウェアが5 という入力値を、モジュール選択＝0、出力選択＝
5 と解釈するようすを示している。
hi.0412.ko.2002@gmail.com
　23.13
まとめ
423
入力の値は
バイナリの5
モジュール選択は、
0
出力選択は、
5
0 
0 
0 
0 
0 
1 
0 
1








図23‒5：入力の5 を、図23‒4 のリブータが解釈する
図23‒5 が示すように、5 という入力では、上位4 ビットの値が0000 で、下位4 ビットの
値が0101 である。上位4 ビットはモジュール0 のID に一致し、それ以外のモジュールには
一致しない。したがって、モジュール0 だけが、この入力に応答する。
このように、
入力の上位ビットを使ってモジュールを選択すれば、
ハードウェアの効率が非常
によくなる。モジュール選択のビットは、モジュールID とともに、
「コンパレータ」チップに
渡すことができる。コンパレータは、2 つの入力集合を比較して、両者が等しいときに限って
出力をハイレベル（真）にしてくれる。だから、モジュール選択を実行するのに必要なハード
ウェアの追加は、ごくわずかである。
23.13 　まとめ
ハードウェア技術者もソフトウェア技術者も、モジュール性を利用する。ソフトウェアにお
いて、モジュールの基礎となる抽象は、サブプログラムだ。ハードウェアにおいて、モジュー
ルの基礎となる抽象は、基本的なビルディングブロックである。
広範囲な規模のハードウェアに対応する方法の1 つは、N 本の入力を受け取って、2N 本の
出力を制御するような、モジュール（ビルディングブロック）を構築することだ。ビルディン
グブロックを複製するとき、それぞれにユニークなID を割り振る。この設計には入力線を追
加できる。その場合、入力の高位ビットでモジュールの1 つを選択し、下位ビットで、そのモ
ジュールの出力を選択できる。
練習問題
23.1
モジュール化と再利用には、技術的にはどういう関係がありますか?
23.2
関数に引数を渡せる能力は、プログラマが複雑さを制御するうえで、どのように役
立ちますか?
23.3
ソフトウェア技術者とハードウェア技術者が、128 ビットの整数を処理する暗号化
システムについて、それぞれ独自のアイデアを考えました。ソフトウェア技術者は、
整数を32 ビットずつ繰り返し処理するアルゴリズムを考えました。ハードウェア技
術者は、何を考えたでしょうか。
hi.0412.ko.2002@gmail.com
424
第23 章
ハードウェアのモジュール化　
23.4
数学的には、モジュールに任意の数の出力を持たせ、割り算によってモジュール番
号と、そのモジュールでの出力を計算することができます（たとえばモジュール毎の
出力が7 であれば、入力値を7 で割ればモジュール番号が得られ、そのあまりをモ
ジュール内の出力番号にできます）
。けれどもハードウェア技術者は、常に2 の冪乗
を出力に選びます。その理由を説明してください。
23.5
あるハードウェア部品に、いくつの出力を持たせるかについて、考慮すべきトレー
ドオフは、何と何ですか?
23.6
基本的なビルディングブロックに4 つの出力があり、設計を64 出力までスケーリ
ングする必要があるとしたら、そのビルディングブロックを、いくつ使うことになり
ますか?
23.7
それぞれのビルディングブロックに8 個の出力があり、入力が16 ビットなら、全
部でいくつまでビルディングブロックを制御できますか?
23.8
上記の問題について、図23‒5 と同様の図を描いて、入力ビットの解釈を示してく
ださい。
23.9
コンパレータチップについて調べましょう。1 個のコンパレータに、入力のペアは、
いくつありますか?
23.10
上記の問題で、コンパレータチップがK 対の入力を比較でき、設計はで2K 対を
比較する必要があるのだとしたら、複数のチップを、どうすれば使えますか?
hi.0412.ko.2002@gmail.com
付録A
コンピュータアーキテクチャコースのラボ
A.1 　はじめに
この付録は、学部生用「コンピュータアーキテクチャ」コースのラボ演習である。このラボ
（実験室／研究室）は、ハードウェアではなくソフトウェアの習得を主な目標とする学生のため
に設計した。そのため、デジタル回路入門を数週間行った後、ラボの重点はプログラミングに
移行する。
ラボに必要な機材は最小限である。最初の数週間は、少しハードウェアが必要だ。その後の
ラボでは、Unix 系のOS（たとえばLinux）を実行するコンピュータへのアクセスが必要とな
る。アセンブリ言語のラボには、RISC アーキテクチャが最適だ。インストラクターの所見に
よれば、CISC アーキテクチャではアセンブリ言語の詳細に、クラスの時間がいくらでも費や
されてしまう。
あるラボでは、学生たちにC のプログラムを書かせる。それは、アーキテクチャがビッグエ
ンディアンか、それともリトルエンディアンかを検出するプログラムだ。ほとんどのコーディ
ングとデバッグは、2 つのアーキテクチャの片方で実行されるので、そう多くの追加リソース
は必要ない。もう片方のアーキテクチャにプログラムを移植してテストするのには、たいして
時間はかからない。
A.2 　デジタルロジックの実験に必要なハードウェア
最初の数週間で行うハードウェアラボでは、それぞれの学生に次のものが必要になる。
•
ソルダーレスブレッドボード
•
ブレッドボードで使うワイヤーキット
•
5 ボルト電源
hi.0412.ko.2002@gmail.com
426
付録A
コンピュータアーキテクチャコースのラボ　
•
LED（出力を見るため）
•
NAND とNOR のロジックゲート
どのハードウェアも高価ではない。たとえば70 人のクラスでパデュー大学がハードウェア
に使った費用は1000 ドルに満たなかった。もっと小さなクラスか、ラボで機材を共有するな
ら、さらにコストを削減できる。あるいは、ラボの費用を徴収するか、学生たちに自分のハー
ドウェアを調達してもらうことも考えられる。
A.3 　ソルダーレスブレッドボードとは
ソルダーレスブレッドボードを使うと、接点のハンダ付けを行う必要がないので、素早く電
子回路を組むことができる。ブレッドボードは、物理的にはプラスチック製のブロックで（典
型的には3 インチ×7 インチ）
、表面を小さい穴の列が覆っている。
穴は中央のギャップを挟んで左右に縦に並び、その外側にも縦列が並んでいる1。ブレッド
ボードの穴は、ぴったりワイヤ（導線）が入る大きさのソケットになっている。ワイヤを穴に
挿入するとソケットの金属接点が金属のワイヤと電気的につながる。ブレッドボードのソケッ
トのサイズと間隔は、標準的な集積回路（標準DIP パッケージのIC）のピンと一致する。そ
してブレッドボード中央のギャップもDIP の幅に合わせてあるから、ギャップを挟んでIC を
縦に配置すると、ピンをそのまま穴に差し込めるようになっている。
ブレッドボードの裏側には金属のストライプが張られ、ソケットを相互に接続している。た
とえば中央のギャップを挟む左右のソケットは、いずれも横方向に相互接続されている。図
A‒1 に、ブレッドボードのソケットと、ソケット間の導通を示す。
A.4 　ソルダーレスブレッドボードを使う
実験用にブレッドボードを使うには、IC をブレッドボードの中央部に挿入し、ワイヤを使っ
てIC とIC を繋ぐ。穴に挿入したワイヤは、その行に挿入したIC のピンと繋がっている。配線
を行うには、
「ワイヤーキット」と呼ばれる、さまざまな長さに切りそろえられた導線（ジャン
パー線）のセットを使う。ワイヤーキットの導線は、端だけが剥き出しになってブレッドボー
ドに差し込めるが、それ以外の部分は絶縁されている。ブレッドボードに数多くのワイヤを追
加できるのは、絶縁部分が接触してもショートしないからだ。
図A‒2 に示すブレッドボードには、7400 のIC が1 つ置かれ、このIC のいくつかのゲート
をワイヤで繋いでいる。
1　訳注：ソケットの並びでは、ギャップを挟んで左右に5 列または6 列、その外側（左右または片側）に
2 列という配置が典型的。詳しくはサンハヤトのページ（https://www.sunhayato.co.jp/problem-so
lving/howto SAD-101.html）などを参照。
hi.0412.ko.2002@gmail.com
　A.4
ソルダーレスブレッドボードを使う
427
(a) 
(b)
図A‒1：（a）ブレッドボードのソケットにはワイヤを挿入できる。
（b）濃い線はソケット間の接続を示す
入力 1
入力 2
入力 3
出力
5ボル
トへ
0ボル
トへ
(a) 
(b)
図A‒2：（a）7400 チップの内部接続（b）ブレッドボードの一部。濃い線は7400 チップとの配線に使う
ワイヤを示すほか、電源とグランドのソケットを使って、さらに配線を加えている
hi.0412.ko.2002@gmail.com
428
付録A
コンピュータアーキテクチャコースのラボ　
A.5 　電源とグランドの接続
複数のチップをブレッドボードに挿入するとき、それぞれのチップに電源（5 ボルト）とグ
ランド（0 ボルト）への接続が必要になる。電源とグランドを短く簡便に配線できるよう、ブ
レッドボードの外側の端にあるソケットの縦列2 つを電源とグランド専用にするのが賢明だ。
電源とグランドの配線は、ある意味で固定される。つまり、数多くの実験で再利用できるの
だ。ワイヤの色を分けて配線の用途を明らかにするとき、電源とグランドには、他の配線に使
わない色を選ぶのが良い。電源の配線にはすべて赤いワイヤを使い、グランドの配線にはすべ
て黒いワイヤを使うのが標準で、青いワイヤなどは、その他の用途に使おう。もちろんワイヤ
の中身は、どれも同じである。絶縁部の色は、ワイヤの用途を人間が理解しやすくするための
ものだ。実験を終えてブレッドボードの配線を外すとき、電源とグランドのワイヤだけは、次
回の実験のために残しておくのが賢明だ。
A.6 　回路を組んでテストする
デジタル回路を構築するもっとも簡単な方法は、回路をステージ（段階）ごとに組んではテ
ストして、次の段階に進むというアプローチだ。たとえばチップに電源とグランドを接続した
ら、そのチップにあるゲートをテストすれば、チップが期待通りに動作することを確認できる。
同様に、ある特定のゲートに配線した後は、そのゲートの入力と出力を測ることによって、接
続が正しいことを確認できる。
デジタル回路の出力を測るには、電圧計を使ってもよいが、実験では、もっと手軽で安上が
りな方法も好まれる。それはLED（発光ダイオード）だ。肝心なのは、直接電源を使えるLED
を選ぶことだ2。LED は論理値1（5V）に繋ぐと光り、論理値0（0V）に繋ぐと光らない。た
とえば、図A‒2 の回路をテストするには、LED を出力に繋ぐ（IC の11 番ピン）
。
A.7 　ラボの実験
この後のページではラボの実験を紹介する。それぞれの記事で、ラボで実施すべき手順を指
定している。ただし個々の環境や使用するコンピュータシステムに関する詳細は、ラボのイン
ストラクターが提供すべきである。たとえば最初のLab 1 では、学生たちにコンピュータアカ
ウントを登録してもらうが、これは環境変数を含む。PATH 変数に組み込むべきディレクトリ
はコンピュータシステムによって異なるので、実際のパス名は、それぞれの環境で提供してい
ただきたい。
2　警告：回路に適切な電気的特性を持つLED を選ばなければならない。特性の合わないLED を使うと、
電力を使いすぎて7400 シリーズのIC が焼けてしまうこともある。
hi.0412.ko.2002@gmail.com
　A.7
ラボの実験
429
Lab 1
導入とアカウント設定
目的
ラボの設備について学び、学期中にラボで使うコンピュータのアカウントを設定する。
背景：読書と準備
Linux で利用できる「bash シェル」について読み、Linux の環境変数を設定できるように
する。
概要
ラボのアカウントを書き換えて、自分の環境がログイン時に自動的に設定されるようにする。
手順と詳細（終わったらチェックマークを付ける）
　　　1. アカウントのスタートアップファイル（たとえば.profile や.bash profile）を
書き換えて、自分のPATH に、ラボのインストラクターが指定したディレクトリが入
るようにする。
　　　2. いったんログアウントして、再びログインする。
　　　3. ラボのインストラクターが指定したファイルとコンパイラを使えることを確認する。
hi.0412.ko.2002@gmail.com
430
付録A
コンピュータアーキテクチャコースのラボ　
Lab 2
デジタルロジック：ブレッドボードを使う
目的
ブレッドボードの基本的なワイヤリングを学び、LED を使ってゲートの動作をテストする。
背景：読書と準備
第2 章を読んで基本的な論理ゲートと回路について学び、この付録の冒頭部分でブレッド
ボードについて学ぶ。ブレッドボードと関連機材の使い方についてレクチャーを受ける。
概要
7400 チップを1 つブレッドボードに置き、電源とグランドを5 ボルト電源から供給し、ゲー
トの入力を、0 と1 の4 種類の組み合わせに接続して、その出力をLED で観察する。
手順と詳細（終わったらチェックマークを付ける）
　　　1. ブレッドボード、電源、ワーヤーキット、および必要なロジックゲートを含むパー
ツボックスを受け取る。7400 のピン配置が書かれているデータシートも入手する
（このIC には、2 入力のNAND ゲートが4 つ入っている）
。ピンの配置図は、本書
の図2-13 にもある（2.10 節）
。
　　　2. 7400 を、図A‒2 の（b）に示したように、ブレッドボードに配置する。
　　　3. 5 ボルト電源からの2 本の導線を、ブレッドボードの端に近い2 列のソケットに、
それぞれ繋ぐ。
　　　4. ジャンパー線を追加して、7400 の14 番ピンを5V に繋ぐ。
　　　5. ジャンパー線を追加して、7400 の7 番ピンを0V に繋ぐ。注意：電源との接続を逆
にしたらチップが破損する恐れがある。
　　　6. ジャンパー線を追加して、7400 の1 番ピンを0V に繋ぐ。
　　　7. ジャンパー線を追加して、7400 の2 番ピンを0V に繋ぐ。
　　　8. ラボのキットにあるLED を、7400 の3 番ピンとグランド（0V）の間に接続する。
注意：必ずLED のプラス側を7400 に繋ぐこと3。
　　　9. LED が点灯することを確認する（両方の入力が0 のとき、出力は1 になる）
。
　　　10. 2 番ピンに繋いだジャンパーを、0V から5V に繋ぎ替えて、それでもLED が点灯
することを確認する。
　　　11. 2 番ピンに繋いだジャンパーを、5V から0V に戻し、1 番ピンに繋いだジャンパー
を0V から5V に繋ぎ替える。この場合もLED が点灯することを確認する。
　　　12. 1 番ピンから5V でのジャンパーを繋いだままにして、
2 番ピンに繋いだジャンパー
を5V に繋ぎ替える。このときLED が点灯しないことを確認する。
3　訳注：LED はダイオードなので、プラス側のアノード（A）と、マイナス側のカソード(K) の2 極があ
り、正しく繋ぐと電流が流れて点灯する。砲弾型のLED では、2 本の端子のうち長いほうがアノードである。
hi.0412.ko.2002@gmail.com
　A.7
ラボの実験
431
オプション課題（終わったらチェックマークを付ける）
　　　13. ブレッドボードを、図A1.2b のように配線する（3 番ピンと12 番ピンを繋ぎ、13
番ピンを3 番目の入力とする）
。
　　　14. LED を11 番ピンとグランドの間に接続する。
　　　15. 3 つの入力で可能な全部の組み合わせを試み、それぞれのLED 状態を記録する。
　　　16. この回路が表しているブール関数は何か?
hi.0412.ko.2002@gmail.com
432
付録A
コンピュータアーキテクチャコースのラボ　
Lab 3
デジタルロジック：ゲートを組み合わせてアダーを作る
目的
基本的な論理ゲートの組み合わせで、バイナリ加算のような複雑なタスクを実行できること
を学ぶ。
背景：読書と準備
第2 章で基本の論理ゲートと回路について学び、この付録の導入部でブレッドボードについ
て学ぶ。
概要
基本的な論理ゲートだけを使って、ハーフアダーとフルアダーを作る4。それらの回路を組
み合わせて、キャリー出力を持つ2 ビットのバイナリアダー（2 進加算器）を実装する。
手順と詳細（終わったらチェックマークを付ける）
　　　1. ブレッドボード、電源、ワーヤーキット、および必要なロジックゲートを含むパー
ツボックスを受け取る。アダー回路に使うチップのピン配置とロジックの回路図を
記述したラボの資料も受け取ること。
　　　2. ラボのインストラクターが提供する回路図にしたがって、バイナリハーフアダーを
構築する。
　　　3. 出力をLED に繋ぎ、入力をスイッチに繋いで、LED に現れる結果が1 ビットアダー
の値として正しいことを確認する。
　　　4. ラボのインストラクターが提供する回路図にしたがって、バイナリフルアダーを構
築する。
　　　5. 出力をLED に、入力をスイッチに繋いで、LED に現れる結果がフルアダーの値とし
て正しいことを確認する。
　　　6. ハーフアダー回路をフルアダー回路に連結して、2 ビットのアダーを作る。回路が2
ビット値のペアを正しく加算し、キャリーの出力値も正しいことを確認する。
オプション課題（終わったらチェックマークを付ける）
　　　7. 3 ビットアダーの回路を描く。
　　　8. 4 ビットアダーの回路を描く。
　　　9. N ビットアダーを実装するのに必要なゲート数を求める式を書く。
4　訳注：ハーフアダーとフルアダーの解説は、2.9 節にある。
hi.0412.ko.2002@gmail.com
　A.7
ラボの実験
433
Lab 4
デジタルロジック：クロックとデコーダ
目的
クロックによる回路の制御を理解し、一連のイベントを発生させる。
背景：読書と準備
第2 章で基本の論理ゲートとクロックについて学ぶ。とくにクロックが機能する仕組みを、
よく理解すること。
概要
スイッチを使ってクロックをシミュレートする。そして、クロックによってデコーダ回路を
動かす（これはデマルチプレクサとも呼ばれる回路だ）
。
手順と詳細（終わったらチェックマークを付ける）
　　　1. ブレッドボード、電源、ワーヤーキット、および必要なロジックゲートを含むパー
ツボックスを受け取る。デコーダの回路に使うチップのピン配置と回路図を記述し
たラボの資料も受け取ること。
　　　2. スイッチを1 つ使って、遅いクロックをシミュレートする。
　　　3. スイッチの動作を確認するため、
スイッチの出力をLED に繋ぎ、
スイッチのON/OFF
にしたがってED が点滅することを確認する。
　　　4. シミュレートしたクロックを、4 ビットのバイナリカウンタ（7493 系のチップ）の
入力に繋ぐ。
　　　5. LED を使って、スイッチON/OFF のサイクルを繰り返すたびに、カウンタの出力が
次のバイナリ値（4 の剰余）になることを確認する。
　　　6. バイナリカウンタの4 本の出力を、デコーダチップ（74154 系）の入力に繋ぐ。
　　　7. LED を使って、スイッチがON/OFF で1 サイクルするたびに、デコーダの出力が1
本だけアクティブになることを確認する。注意：直感に反して、74154 のアクティ
ブ出力はローレベル（論理値0）
、その他の出力はハイレベル（論理値1）である。
オプション課題（終わったらチェックマークを付ける）
　　　8. 555 タイマチップを使って1 Hz のクロックを作り、クロックの動作を確認する。
　　　9. スイッチをクロック回路に交換する。
　　　10. 複数のLED を使って、デコーダの出力が順番に変化していくことを確認する。
hi.0412.ko.2002@gmail.com
434
付録A
コンピュータアーキテクチャコースのラボ　
Lab 5
表現：ビッグエンディアンとリトルエンディアン
目的
根底にあるハードウェアによる整数表現が、プログラミングとデータレイアウトにおよぼす
影響を理解する。
背景：読書と準備
第3 章を読んで、整数表現のビッグエンディアンとリトルエンディアン、および整数のサイ
ズについて学ぶ。
概要
メモリに格納されたデータを調べるプログラムをC で書き、
コンピュータが整数表現に、
ビッ
グエンディアンとリトルエンディアンの、どちらを使っているかを判定する。
手順と詳細（終わったらチェックマークを付ける）
　　　1. C のプログラムで、メモリにバイト配列を作り、配列をゼロで初期化する。次に、配
列の中央に0x04030201 整数値を格納する。
　　　2. さらにプログラムで配列のバイト値を調べ、そこに格納されたバイトの並び順によっ
て、ビッグエンディアンかリトルエンディアンかを判定する。
　　　3. このプログラムを（ソースコードを変更せずに）ビッグエンディアンとリトルエン
ディアンの両方のコンピュータでコンパイルし、実行する。そして整数の格納方法
が正しく判定されることを確認する。
　　　4. プログラムに、整数のサイズを判定するコードを追加する。
ヒント：整数値1 に繰り返し左シフト演算を行い、何回のシフトで値がゼロになる
かを調べる。
　　　5. そのプログラムを（ソースコードを変更せずに）32bit と64bt の両方のコンピュー
タでコンパイルし、実行する。そして整数型のサイズが正しく判定されることを確
認する。
オプション課題（終わったらチェックマークを付ける）
　　　6. 整数のサイズを判定できる別の方法を考える。
　　　7. 別の方法による整数サイズの判定を実装して、プログラムが正しく動作することを
確認する。
　　　8. そのプログラムを拡張して、整数のフォーマットを判定する（1 の補数か、それとも
2 の補数か）5。
5　訳注：
「3.13 2 進の符号付き整数」を参照。
hi.0412.ko.2002@gmail.com
　A.7
ラボの実験
435
Lab 6
表現：C 言語の16 進ダンプ関数
目的
メモリの値を16 進形式で表現する方法を学ぶ。
背景：読書と準備
第3 章を読んでデータ表現を学び、自分が使っているコンピュータの整数サイズとアドレス
サイズを知る6。出力フォーマットの詳細はラボのインストラクターに質問する。
概要
C でメモリダンプのプログラムを書き、16 進とASCII で表示する。フォーマットのうち、コ
ンピュータによって異なる詳細は、ラボのインストラクターが決めるが、全般的には次の形式
とする。
ア
ドレス 
16進ワー
ド 
ASCII キャラクタ
aaaaaaaa 
xxxxxxxx 
xxxxxxxx 
xxxxxxxx 
xxxxxxxx 
cccccccccccccccc
この例で、各行は一連のメモリアドレスに対応する。文字列「aaaaaaaa」は、その行に表示
する値の開始アドレスを、16 進表記で示す。
「xxxxxxxx」は、メモリ内のワード値を、やはり
16 表記で示す。
「cccccccccccccccc」は、同じ場所のメモリをASCII キャラクタと解釈した
場合の文字表記とする。
メモ：ASCII 出力は、印字可能なキャラクタだけを表示する。それ以外のキャラクタはブラン
クとする。
手順と詳細（終わったらチェックマークを付ける）
　　　1. mdump という関数を作る。これは、それぞれメモリアドレスを指定する2 つの引数
を取る。第1 引数は、ダンプを開始するアドレスを指定し、第2 引数は、ダンプに
入れる最高位アドレスを指定する。開始アドレスが終了アドレスよりも小さいこと
を確認する。
　　　2. 受け取った引数値を、ワードアドレスとして適切な値に変更する（4 バイト境界に
合わせる）
。開始アドレスの場合は、もっとも近いワードアドレスに切り捨てる。終
了アドレスは、逆に切り上げる。
　　　3. この関数をテストして、アドレスが正しく丸められることを確認する。
　　　4. ヘッダ部と16 進ダンプをプリントするように、
printf を使うコードを追加し、
ヘッ
ダが正しくプリントされることを確認する。
　　　5. アドレスを順に反復して16 進の値を含む行を作るコードを追加する。
6　ほとんどのコンピュータで、アドレスのサイズは整数のサイズと同じである。
hi.0412.ko.2002@gmail.com
436
付録A
コンピュータアーキテクチャコースのラボ　
　　　6. mdump 関数が正しい値を出力することを確認するために、メモリに構造体を定義し、
そのフィールドに値を設定し、mdump 関数を呼び出して、その構造体の項目をダン
プさせる。
　　　7. それぞれの行のメモリ内容を、前記の印字可能なASCII キャラクタで出力するコー
ドを追加する。
　　　8. 出力に、印字可能なキャラクタだけが含まれることを確認する（たとえば0x01 の
ような印字できないキャラクタが、ブランクにマップされること）
。
オプション課題（終わったらチェックマークを付ける）
　　　9. mdump を拡張して、バイトアドレスで開始と終了の位置を指定できるようにする（最
初の出力行では、先行する値を省略し、最後の行では後続の値を省略する）
。
　　　10. mdump を拡張して、バイトをASCII でプリントする代わりに、ワードの値を10 進
数で表示するように変更する。
　　　11. mdump を拡張して、ASCII の値をプリントする代わりに、そのメモリがマシン命令
に対応するものと仮定して、それぞれの命令のオペコードをニーモニックで印字す
る。たとえば、もし行の最初のワードがload 命令に対応していたら、
「load」と出
力する。
　　　12. mdump 関数に引数を1 個追加して、3 種類のフォーマット（ASCII 文字、10 進数、
命令ニーモニック）のどれかを選べるようにする。
hi.0412.ko.2002@gmail.com
　A.7
ラボの実験
437
Lab 7
プロセッサ：RISC のアセンブリ言語を学ぶ
目的
アセンブリ言語を直接経験し、アセンブリ言語の命令とマシン命令との1 対1 のマッピング
を理解する。
背景：読書と準備
第5 章、第7 章、第9 章を読んで、命令セットとオペランドの型についての概念を学ぶ。ラ
ボで利用するコンピュータで使える命令セットについて学習する。アセンブラのリファレンス
マニュアルを参照して、そのアセンブラで必要となる構文規約を学ぶ。また、アセンブラのリ
ファレンスマニュアルを見て、外部関数を呼び出すのに使う規約を知っておく。
概要
アセンブリ言語のプログラムで、まず整数値を右にシフトし、次にC の関数を呼び出して結
果を16 進で表示する。
手順と詳細（終わったらチェックマークを付ける）
　　　1. C の関数、int out を書く。この関数は、整数の引数を1 つ受け取り、printf を
使って、その引数の値を16 進で表示する。
　　　2. この関数が正しく動作することを確認する。
　　　3. アセンブリ言語のプログラムを書く。その処理は、レジスタに整数4 を入れ、その
レジスタの内容を1 ビットだけ右にシフトするだけにする。
　　　4. 上記のプログラムを拡張して、前記のステップの結果を、外部関数int out に引数
として渡すようにする。
　　　5. このプログラムが、0x2 を出力することを確認する。
　　　6. 整数0xBD5A をレジスタにロードし、その結果を出力して、符号拡張が正しく動作
することを確認する。
　　　7. 整数4 を右に1 ビットシフトする代わりに、0xBD5B7DDE を32bit レジスタにロー
ドし、それを右に1 ビットシフトして、結果の出力が正しいことを確認する。
オプション課題（終わったらチェックマークを付ける）
　　　8. 外部関数int out を書き直して、アセンブリ言語プログラムから複数の引数を渡せ
るようにする。
hi.0412.ko.2002@gmail.com
438
付録A
コンピュータアーキテクチャコースのラボ　
Lab 8
プロセッサ：C から呼び出せる関数
目的
C のプログラムから呼び出せるアセンブリ言語関数を書く方法を学ぶ。
背景：読書と準備
第9 章で、アセンブリ言語におけるサブルーチンコールの概念を学ぶ、C コンパイラとアセ
ンブラのリファレンスマニュアルを読んで、C が関数を呼び出す規約が、ラボのコンピュータ
でどうなっているかを調べる。
概要
C から呼び出せるアセンブリ言語関数を書く。この関数は、2 つの整数値を受け取って、そ
の排他的論理（XOR）を返す。
手順と詳細（終わったらチェックマークを付ける）
　　　1. まずは、xor という関数をC で書く。これは整数型の引数を2 つ受け取り、その引
数の排他的論理和を返す。
　　　2. 2 つの整数を引数としてxor 関数を呼び出すC のメインプログラムを書く。このプ
ログラムは、関数から返された結果を表示する。
　　　3. 次に、C のxor 関数のアセンブリ言語バージョンとして、まったく同じように振る
舞うaxor を書く。
（ただし、C コンパイラにアセンブリファイルの生成を指示する
のはダメ。新しいバージョンを最初から書くこと）
　　　4. axor 関数にpfintf の呼び出しを加えて、それを使って、C のプログラムから引数
として渡された2 つの値を、この関数が正しく受け取っていること（引数渡しが正
しく行われていること）を確認する。
　　　5. C のメインプログラムを、axor を呼び出すように書き換えて、そのコードが、適切
な範囲の入力から正しい結果を返すことを確認する。
ヒント：ランダムな値を生成しよう。
オプション課題（終わったらチェックマークを付ける）
　　　6. C のプログラムとaxor 関数を書き換えて、C のプログラムが2 つの整数ではなく、
2 つの整数値を含む1 個の構造体を渡すようにする。
hi.0412.ko.2002@gmail.com
　A.7
ラボの実験
439
Lab 9
メモリ：配列ストレージの行優先と列優先
目的
配列をメモリに格納する順序に、行優先と列優先があることを理解する。
背景：読書と準備
第10 章から第13 章を読んで、メモリの基本的な組織方法を学び、配列を格納する順序が行
優先と列優先でどう違うかを理解する7。
概要
2 次元配列を宣言するのに、言語に組み込まれている機構を使うのではなく、two d store
とtwo d fetch の2 つをC で実装する。これらは連続するストレージを使って2 次元配列を
実装する関数だ。two d fetch 関数は、6 個の引数を受け取る。それらは、2 次元配列として
使うメモリ領域のベースアドレス、配列の要素サイズ（バイト数）
、配列の2 つの寸法、そして
2 つのインデックス値である。それによって、たとえば、次の2 行を書く代わりに、
int d[10,20];
x = d[4,0];
次の2 行を書けるようになる。
char d[200*sizeof(int)];
x = two d fetch(d, sizeof(int), 10, 20, 4, 0);
two d store 関数は、7 個の引数を受け取る。ただし最初の6 個はtwo d fetch の6 個の
引数に対応する。7 番目の引数は、ストアする値だ。たとえば、次のように書く代わりに、
int d[10,20];
d[4,0] = 576;
次のようにコーディングできる。
char d[200*sizeof(int)];
two d store(d, sizeof(int), 10, 20, 4, 0, 576);
手順と詳細（終わったらチェックマークを付ける）
　　　1. 配列の格納に行優先を使って、two d store 関数を実装する。
7　訳注：2 次元配列の行優先と列優先についての説明は、13.24 節にある。
hi.0412.ko.2002@gmail.com
440
付録A
コンピュータアーキテクチャコースのラボ　
　　　2. 配列を格納できる大きさの領域をメモリに確保し、全領域をゼロで初期化してから
two d store を呼び出して、さまざまな値をさまざまな場所にストアする。次に、
Lab 6 で作ったダンププログラムを使って結果を表示し、正しい値が格納されたこ
とを確認する。
　　　3. two d store で使った順序と同じ行優先によって、two d fetch 関数を実装する。
　　　4. 実装したtwo d store とtwo d fetch が正しく動作することを確認する。
　　　5. たとえば配列インデックスの最小値、
最大値を指定して、
two d store とtwo d fetch
の動作を境界条件でテストする。
　　　6. two d store とtwo d fetch を、列優先の順序を使うように書き直す。
　　　7. 列優先のコードが正しく動作することを確認する。
オプション課題（終わったらチェックマークを付ける）
　　　8. two d store とtwo d fetch の2 つの関数が、配列にキャラクタ、整数、倍精度の
浮動小数点数を格納する場合でも、正しく動作するか確認する。
　　　9. two d store とtwo d fetch を、どんな配列インデックスを使っても正常に動作す
るように書き直す。たとえば第1 インデックスの範囲を−5 から+15、第2 イン
デックスの範囲を30 から60 と指定できるようにする8。
8　訳注：安全のため、普通ならば配列の前後に安全地帯を確保し、その範囲を超えないように制限するだ
ろう。配列のインデックスに負の値を使うのは禁じ手だ。
hi.0412.ko.2002@gmail.com
　A.7
ラボの実験
441
Lab 10
入出力：バッファ付きI/O ライブラリ
目的
バッファ付き入出力の動作を学び、バッファ付きI/O とバッファなしI/O で、性能を比較
する。
背景：読書と準備
第14 章から第16 章を読んで入出力一般を学び、第17 章でバッファリングを学ぶ。
概要
バッファ付きI/O を実装するC の関数として、buf in、buf out、buf flush の3 つを実
装する。毎回の呼び出しで、buf in 関数は、ファイルディスクリプタ0（stdin）から次のバ
イトデータを読み出す。そのデバイスから、もっと入力が必要になったとき、buf in は16 キ
ロバイトのデータをバッファに読み込んで、次回以降の呼び出しでバッファから値を返せるよ
うにする。buf out 関数は、毎回の呼び出しで1 バイトのデータをバッファに書く。バッファ
が満杯のとき、あるいはプログラムがbuf flush 関数を呼び出したときは、バッファのデータ
をファイルディスクリプタ1（stdout）に書く9。
手順と詳細（終わったらチェックマークを付ける）
　　　1. buf in 関数を実装する。
　　　2. buf in が、バッファのサイズである16 キロバイトを超えない入力で、正しく動作
することを確認する。
　　　3. 32 キロバイトを超える大きさのファイルから入力を得るようにリダイレクトして、
buf in がバッファを何度か満たす必要が生じても正しく動作することを確認する。
　　　4. buf out 関数とbuf flush 関数を実装する。
　　　5. buf out とbuf flush が、バッファのサイズを超えない16 キロバイト未満の出力
で、正しく動作することを確認する。
　　　6. buf out とbuf flush が、複数のバッファにまたがる出力でも正しく動作すること
を確認する。
オプション課題（終わったらチェックマークを付ける）
　　　7. 関数buf in、buf out、buf flush の性能を、さまざまな大きさのファイルを使っ
て、バッファのない（読み書きを1 バイトずつ行う）入出力と比較し、その結果を
プロットする10。
9　訳注：ファイルディスクリプタ（ファイル記述子）のstdin とstdout は、シェルがオープンするスト
リームで、普通はコンソール入出力。リダイレクトはコマンドラインで行う。
10　訳注：プロッティングソフトには、たとえばgnuplot がある。紹介記事は、Web で検索していただき
たい。
hi.0412.ko.2002@gmail.com
442
付録A
コンピュータアーキテクチャコースのラボ　
　　　8. 大きなファイルをコピーする場合のbuf in、buf out、buf flush の性能を、バッ
ファのサイズをさまざまに変えて計測し、比較する。4 バイトから100K バイトま
での範囲でバッファのサイズを変化させ、結果をプロットする。
hi.0412.ko.2002@gmail.com
　A.7
ラボの実験
443
Lab 11
アセンブリ言語の16 進ダンププログラム
目的
アセンブリ言語でのコーディング経験を積む。
背景：読書と準備
第5 章、第7 章、第9 章の復習。このラボで書いたアセンブリ言語プログラム。
概要
Lab 6 の16 進ダンププログラムをアセンブリ言語で書き直す。
手順と詳細（終わったらチェックマークを付ける）
　　　1. Lab 6 で作った基本的な16 進ダンプ関数をアセンブリ言語で書き直す。
　　　2. アセンブリ言語のバージョンでも、C のバージョンと同じ出力が得られることを確
認する。
オプション課題（終わったらチェックマークを付ける）
　　　3. アセンブリ言語のダンプ関数を拡張して、バイトアドレスで開始と終了の位置を指
定できるようにする（最初の出力行では、先行する値を省略し、最後の行では後続
の値を省略する）
。
　　　4. ダンプ関数を書き換えて、値をASCII 文字で出力する代わりに、10 進数で表示する。
　　　5. ダンプ関数を書き換えて、ASCII の値を出力する代わりに、そのメモリがマシン命
令に対応するものとみなして、それぞれの命令のオペコードをニーモニックで印字
する。たとえば、もし行の最初のワードがload 命令に対応していたら、
「load」と
出力する。
　　　6. ダンプ関数に引数を1 個追加して、3 種類のフォーマット（ASCII 文字、10 進数、
命令ニーモニック）のどれかを選べるようにする。
hi.0412.ko.2002@gmail.com
hi.0412.ko.2002@gmail.com
付録B
ブール代数を単純化する規則
B.1 　はじめに
ブール式は、ブール代数の規則を適用して単純化できるかもしれない。具体的には、
「結合
的」
、
「反射的」
、
「分配的」な性質を使う。エンジニアリングの視点から見ると、単純化を行う
動機は、実装に必要なゲートを少なくするためだ。たとえば論理和（OR）を考えてみよう。も
し2 つの式がtrue（真）であれば、その論理和もtrue になることを、われわれは知ってい
る。だから、X or true という式は、true で置き換えることができる。
B.2 　使用する記法
次に見る表で、ドット（·）は論理積（AND）を、プラス記号（+）は論理和（OR）を、アポ
ストロフ（′）は論理否定（NOT）を、0 は偽（false）を、1 は真（true）を、それぞれ表現す
る。この記法による次の式、
(X + Y ) · Z′
は、次の意味を持つ。
(X or Y ) and (not Z)
B.3 　ブール代数の規則
図B‒1 に、ブール代数の19 の規則を示す。多くの規則は一見すると当然と思われるかもし
れないが、リストを完全にするために入れてある。
hi.0412.ko.2002@gmail.com
446
付録B
ブール代数を単純化する規則　
x + 0
=
x
x + 1
=
1
x · 0
=
0
x · 1
=
x
x + x
=
x
x + x′
=
1
x · x
=
x
x · x′
=
0
(x′)′
=
x
x · y
=
y · x
x + y
=
y + x
x · (y · z)
=
(x · y) · z
x + (y + z)
=
(x + y) + z
x · (y + z)
=
(x · y) + (x · z)
x + (y · z)
=
(x + y) · (x + z)
x · (x + y)
=
x
x + (x · y)
=
x
(x · y)′
=
x′ + y′
(x + y)′
=
x′ · y′
図B‒1：ブール式の単純化に使えるブール代数の規則
hi.0412.ko.2002@gmail.com
付録C
x86アセンブリ言語の基本
C.1 　はじめに
技術者が言う「x86」は、インテルが作ったアーキテクチャを使う一連のプロセッサを意味
する1。インテルによる、このシリーズのプロセッサは、どれも1 つ前のモデルより強化され
ている。その過程で、設計が16bit アーキテクチャから32-bit アーキテクチャに変わったが、
そんな遷移があっても、同じシリーズであれば新しいチップでも前のチップのために書かれた
コードをそのまま実行できるように、インテルは後方互換性を維持した。したがって、基本は
同じままである。
x86 は、もう1 つの遷移を経ている。こんどは32bit アーキテクチャから64bit アーキテク
チャに変わったのだ（この変化は、インテルと競合するAMD によって先導された）
。このとき
も、遷移の鍵となる要件は後方互換性だった。この短い章では、まず32bit バージョンを論じ、
それから64bit の拡張機能を述べる。
x86 プロセッサは、CISC アプローチにしたがうので、その命令セットは大きく、複雑であ
る。実際、その命令セットは巨大なものだ。ベンダーが命令を記述したマニュアルは、合計
3000 ページに近い。x86 の命令セットは、高速なグラフィック演算、三角関数、そしてOS が
プロセッサのモードを制御し、プロテクションを設定し、入出力を処理するのに使う大量の命
令を含むことがある。最近のプロセッサで実行されるアプリケーションが使う32bit 命令に加
えて、インテルのx86 プロセッサは、以前のバージョンをサポートするハードウェアを残して
いる。このため、命令セットの全貌を、この短い章で述べることは不可能だ。代わりに、基本
事項を紹介する概要を述べる。いくつかの基本をマスターしたプログラマは、新しい命令を学
習しやすくなるだろう。
1　この名前は、それらのインテル製品に、8086、80286、80386、80486 といった番号が使われたからだ。
hi.0412.ko.2002@gmail.com
448
付録C
x86 アセンブリ言語の基本　
C.2 　x86 の汎用レジスタ
拡張が行われてきた結果、x86 アーキテクチャには、紛らわしくて予期できない不整合（一
貫性のなさ）がある。たとえば、このアーキテクチャには8 個の「汎用レジスタ」があるのだ
が、とくに不整合が目立つのは、それらの汎用レジスタの命名と参照の方法だ。具体的に言う
と、最初の設計では4 個の汎用16bit レジスタが使われ、アセンブリ言語は、それらのレジス
タに、バイト毎の名前を提供した。それらのレジスタが32bit に拡張されたとき、それぞれの
「拡張レジスタ」に名前が付けられ、新しいアーキテクチャでは元の16bit レジスタが、それ
に対応する拡張レジスタの下位16 ビットにマップされた。このため、アセンブリ言語が提供
するレジスタ名の集合を使って、プログラマは32bit レジスタの全体でも、そのレジスタの下
位16bit 領域でも、その16bit 領域を構成する個々のバイトでも参照できるようになった。し
かし残念ながら、それらの名前は紛らわしいものである。初期のレジスタには、それぞれ特有
な用途が割り当てられていたので、レジスタ名は、そういう歴史的な用途を継承している。図
C‒1 は、8 個の汎用レジスタを列記し、その歴史的な用途と、各レジスタおよび、その部分を
歴史的な用途 
レジスタ名
Source Index 
ESI
Destination Index 
EDI
Stack Pointer 
ESP
Base Pointer 
EBP
Accumulator 
EAX 
AH 
AL
Base 
EBX 
BH 
BL
Count 
ECX 
CH 
CL
Data 
EDX 
DH 
DL
AX (16ビッ
ト)
BX (16ビッ
ト)
CX (16ビッ
ト)
DX (16ビッ
ト)
（アキュムレータ）
（ベース）
（カウン
ト）
（データ）
（ソース
・
インデッ
クス）
（デスティネーシ
ョ
ン
・
インデッ
クス）
（スタ
ッ
ク
・
ポインタ）
（ベース
・
ポインタ）
図C‒1：x86 の8 本の汎用レジスタ。歴史的な用途と、レジスタの全体と部分を参照する名前を示す
hi.0412.ko.2002@gmail.com
　C.3
許容されるオペランド
449
参照する名前を示している2。
ほとんどのレジスタは、元の用途に縛られなくなっているが、スタックポインタ（ESP）と
ベースポインタ（EBP）は、いまだに特別な意味を持っている。プロシージャコールにおける
ベースポインタとスタックポインタの役割は、後で説明しよう。
C.3 　許容されるオペランド
オペランドでは、ある演算で使う値や、結果を置く場所を指定する。1 つのオペランドで、レ
ジスタの1 つか、メモリの場所1 つか、定数1 つを指定できる。許容できるオペランドの組み
合わせは、命令ごとに決まっている。たとえば、ある場所から別の場所へとデータをコピーす
るmov 命令では、ある定数をレジスタまたはメモリにコピーすることも、レジスタの値をメモ
リにコピーすることも、メモリの値をレジスタにコピーすることも、あるレジスタから別のレ
ジスタにコピーすることもできる。ただしmov は、メモリのある場所から別の場所へとデータ
をコピーすることができない。したがって、2 つの場所のメモリの間でデータをコピーするに
は、この命令を2 回使うことになる。つまり1 回目のmov で、ある場所のメモリからレジス
タにデータをコピーし、2 回目のmov で、そのレジスタからメモリの新しい場所にデータをコ
ピーする。
表C‒1 は、所与の命令で許されるオペランド集合の記述で使う総称のリストだ。
表C‒1：許容されるオペランドを指定する総称
名前
意味
<reg32>
任意の32bit レジスタ（EAX、EBX など）
<reg16>
任意の16bit レジスタ（AX、BX など）
<reg8>
任意の8bit レジスタ（AH、AL、BH、BL など）
<reg>
任意のレジスタ（32bit か、16bit か、8bit）
<con32>
任意の32bit 定数
<con16>
任意の16bit 定数
<con8>
任意の8bit 定数
<con>
任意の定数（32bit か、16bit か、8bit）
<mem>
任意のメモリアドレス
メモリアドレスを算出する方法は、後の節で示そう。これから命令を説明するのに表C‒1 の
総称を使うということを理解していただければ十分だ。たとえばmov 命令の場合、
「ソース」オ
ペランドで指定した場所から、
「ターゲット」オペランドで指定した場所に、データ項目をコ
ピーする。表C‒2 は、表C‒1 で示した総称を使って、mov に許さていれる、ソースオペラン
ドとターゲットオペランドの組み合わせを示している。
2　ほとんどのアセンブラは大文字と小文字を区別しないので、eax とEAX は同じレジスタを意味する。概
してプログラマは小文字を使う傾向があり、ドキュメントは大文字を使う傾向がある。
hi.0412.ko.2002@gmail.com
450
付録C
x86 アセンブリ言語の基本　
表C‒2：mov 命令で許容されるソースオペランドとターゲットオペランドの組み合わせ
ソース
ターゲット
<reg>
<reg>
<mem>
<reg>
<reg>
<mem>
<con>
<reg>
<con>
<mem>
C.4 　Intel 方式とAT&T 方式のx86 アセンブリ言語
個々の命令の解説を読む前に、いくつかアセンブリ言語の基本を理解しておく必要がある。
たとえばアセンブリ言語では、1 行に1 ステートメントすつ、次のような形式でコーディング
する。
<ラベル> <オペコード> <オペランド> ...
ステートメントの「ラベル」はオプションで、そのステートメントを識別する名前である。
もしステートメントがデータ項目を定義していたら、ラベルは、その項目の名前を指定する。
もしステートメントがコードを含んでいたら、そのステートメントに制御を渡す分岐の目的で
使われる。この場合はラベルの最後にコロン（:）を付ける必要がある。
「オペコード」フィー
ルドは、データ項目または命令の型を指定する。その後に続くゼロ個以上の「オペランド」は、
データまたは演算の詳細を指定する。
多くのx86 アセンブラが作られたが、残念ながら、それぞれ特有の書き方があって紛らわし
い。ここでは個々のアセンブラを調べるのではなく、2 つの主要なカテゴリーに話を絞ろう。
第1 のカテゴリーは、もともとIntel が定義し、それからMicrosoft が採用した構文を使う。
これは非公式に「Intel アセンブリ言語」あるいは「Microsoft-Intel アセンブリ言語」と呼ば
れている。第2 のカテゴリーは、もともとAT&T のBell 研究所がUnix のために定義した構
文を採用するもので、オープンソースコミュニティによってLinux で使うために採用されてい
る。こちらは「AT&T アセンブリ言語」または「GNU アセンブリ言語」と呼ばれる3。
どちらのカテゴリーに属するアセンブラも、機能的には等価である。というのは、プログラ
マがx86 の命令で、任意のシーケンスをコーディングすることができ、メモリに任意のデータ
項目を宣言できるという意味だ。このように全般的には似てはいるが、この2 種類のアセンブ
ラは、多くの詳細が異なっている4。たとえばオペランドを並べる順序も、レジスタを参照する
3　訳注：GAS と呼ばれるGNU アセンブラは、広範囲なプロセッサをサポートしている。x86 の場合はオ
プションの指定で、Intel 記法を使うこともできる。
4　訳注：詳しくは、Wikibooks（https://ja.wikibooks.org/wiki/）の「X86 アセンブラ/GAS での
文法」などを参照。
hi.0412.ko.2002@gmail.com
　C.4
Intel 方式とAT&T 方式のx86 アセンブリ言語
451
方法も、コメントの書き方も違うのだ。どちらの形式も使えるわけだが、プログラマは、どち
らか一方の形式が直感的に理解しやすく、便利で、エラーを見つけやすいと感じるかもしれな
い。しかし、どちらの形式のアセンブラも、広く業界で使われているので、それぞれの形式で
例を見ていくことにする。
C.4.1
Intel アセンブリ言語の特徴
Intel アセンブラには、次の特徴がある。
•
オペランドの順序は、
「右から左」で、ソースオペランドを右に、ターゲットオペラン
ドを左に置く。
•
コメントはセミコロン（;）で始める。
•
レジスタ名を、記号なしで、そのまま書く（たとえば、eax）
•
即値定数も、記号なしで、そのまま書く
•
アセンブラが、オペランドから演算コードを推定する
オペランドの順序を覚えるために、プログラマは「高水準言語の代入文と同じ」と考えるこ
とができる。つまり、等号の右側に書いた式の値を、左側の変数に代入する。だからIntel ア
センブル言語では、データ移動の演算を次のように書く。
mov
<ターゲット>, <ソース>
たとえば次のコードは、EBX レジスタの値に2 を加え、その結果をEAX レジスタに代入する。
mov
eax, ebx+2
Intel のハードウェアには「暗黙の」オペランド型があると言われる。それはプロセッサの実
行時に具体的な演算コードによって、オペランドの型が厳密に指定されるという意味だ。つま
りx86 のハードウェアには、ただ1 つのmov 命令があるのではなく、mov というニーモニック
で表現される命令が複数あり、オペランドの型によって、それぞれ別のオペコードが割り当て
られる（16 進で88、89、8A、8B、9C など）
。x86 の「mov」には、1 バイトをコピーする演算、
1 ワードをコピーする演算などがあり、それぞれ別のオペコードが割り当てられるが、Intel ア
センブラは、バイナリコードを生成するとき、正しいオペコードをオペランドの型から推定す
る。もしターゲットが1 バイトならば、アセンブラは1 バイトを転送するコードを選び、ター
ゲットが16 ビットレジスタならば、アセンブラは16 ビットの値を転送するコードを選ぶ（以
下同様）
。
hi.0412.ko.2002@gmail.com
452
付録C
x86 アセンブリ言語の基本　
他の命令も、これと同じパターンにしたがう。プログラマがコーディングに使うニーモニッ
クは1 種類でも（たとえば加算ならadd、減算ならsub）
、プロセッサには、それぞれの演算に
対応する一群の演算コードがある。そしてIntel アセンブラは、プログラマが指定したオペラ
ンドに適した演算コードを選ぶのだ。
C.4.2
AT&T アセンブリ言語の特徴
AT&T アセンブラには、次の特徴がある。
•
オペランドの順序は、
「左から右」で、ソースを左に、ターゲットを右に置く。
•
コメントは、/*...
*/で囲むか、あるいはハッシュ記号（#）で始める。
•
レジスタ名の先頭にパーセント記号を置く（たとえば、%eax）
•
措置定数の先頭にドル記号（$）を置く。
•
プログラマが、オペランドの型を含む演算の種類を、ニーモニックで指定する（たと
えば、movl）
。
オペランドの順序は、Intel アセンブラの方式と、正反対である。つまりAT&T アセンブリ
言語では、データを移動する演算を、次のように書く。
<mov 命令>
<ターゲット>, <ソース>
たとえば次のコードは、EBX レジスタの内容に2 を足した32bit の結果を、EAX レジスタに
代入する。
movl
%ebx+2, %eax
C.5 　算術命令
加算と減算
x86 の算術演算と論理演算の多くは、
「ソース」と「ターゲット」の2 つをオペランドとし
て受け取る。ターゲットは場所（たとえばレジスタ）を指定し、ソースは場所または定数を指
定する。プロセッサは、指定された2 つのオペランドを使って演算を実行し、その結果をター
ゲットオペランドに置く。たとえば、次の加算命令で、
Intel 版
add eax, ebx
AT&T 版
add %ebx, %eax
hi.0412.ko.2002@gmail.com
　C.5
算術命令
453
プロセッサは、レジスタEAX とEBX にある2 つの値を加算して、その結果をEAX レジスタ
に置く。言い換えるとプロセッサは、EBX の値を加算することによってEAX の値を変更する。
表C‒3 に、加算と減算の命令（add とsub）で利用できるオペランドの組み合わせを示す。
表C‒3：add またはsub で許されるオペランドの組み合わせ
ソース
ターゲット
<reg>
<reg>
<mem>
<reg>
<reg>
<mem>
<con>
<reg>
<con>
<mem>
インクリメントとデクリメント
x86 は、add とsub の他に、1 を足すインクリメントと、1 を引くデクリメントの命令を提
供する。これらのオペコードは、それぞれinc とdec であり（これはIntel アセンブラ式）
、そ
れぞれ1 個のオペランドを取るが、それには任意のレジスタまたは任意のメモリの場所が許さ
れる。たとえば次の命令は、
Intel 版
inc
ecx
AT&T 版
incl
%ecx
ECX レジスタの値を1 だけ増やす。そのためにインクリメント命令を使うか、それとも1 と
の加算命令を使うかは、プログラマが決めることだ。
命令セットにインクリメントとデクリメントを含めているのは、このアーキテクチャの重要
な原則の現れだ。
（たとえばx86 で使われているような）CISC アーキテクチャでは、しばしば所与の計
算を実行できる命令が複数存在する。
乗算と除算
整数の乗算と除算には、コンピュータアーキテクトにとって興味深い課題がある。2 つのレ
ジスタを掛け合わせた結果、その積が1 個のレジスタに入りきらないことが多いのだ。実際、
積はレジスタの2 倍の長さになるかもしれない。また、多くのコンピュータでは、整数の除算
を行う被除数を、1 個のレジスタより大きくすることが許されている。
x86 には、整数の乗算と除算に多くのバリエーションがある。そのうちいくつかの演算では、
プログラマが結果のサイズに制限を指定できる（たとえば積を32bit に限定できる）
。積が1 個
のレジスタに入りきらない場合を扱うために、x86 では2 つのレジスタの組み合わせに結果を
入れることができる。たとえば32 ビットの値を2 つ掛け合わせるとき、x86 は64 ビットの
結果を、EDX レジスタとEAX レジスタに入れる。EDX には上位の32 ビットが入り、EAX には
hi.0412.ko.2002@gmail.com
454
付録C
x86 アセンブリ言語の基本　
下位の32 ビットが入る。
x86 では、整数除算のオペランドを64 ビットにして、レジスタのペアに格納することもで
きる。もちろん整数除算は、もっと小さな項目に使うことも可能だ。たとえ被除数に64 ビッ
トを要さないときでも、x86 は2 つのレジスタに整数除算の結果を入れることができ、片方に
は商が、もう片方には剰余が格納される。除算で「剰余」
（モジュロ）を得られるから、ハッシ
ングのような計算の効率が良くなる。
x86 は、乗算に2 つの基本形式を提供する。第1 の形式は、加算や減算と同じパラダイムに
したがう。つまり乗算命令には2 つのオペランドがあり、第1 オペランドの値は結果で上書き
される。第2 の形式では、オペランドが3 つあり、第3 オペランドは定数だ。プロセッサは第
2 オペランドと第3 オペランドを掛け合わせた後、第1 オペランドで指定された場所に結果を
入れる。たとえば次の命令は、
Intel 版
imul eax, edi, 42
AT&T 版
imul %edi, 42, %eax
EDI レジスタの内容に42 を掛けて、その結果をEAX レジスタに入れる。
C.6 　論理演算
x86 プロセッサが提供する論理演算は、データ項目をビット列として扱い、各ビットに対す
る演算を行う。2 つのオペランドを使ってビット演算を行う論理演算は、論理積（OR）
、論理和
（AND）
、排他的論理和（XOR）の3 種類だ。4 つめの論理演算である否定（NOT）は、1 個の
オペランドに対してビット演算を行う。表C‒4 に、論理演算で使えるオペランドの型を示す。
表C‒4：論理積、論理和、排他的論理和、否定の演算に許されるオペランドの組み合わせ
AND、OR、XOR
NOT
ソース
ターゲット
ターゲット
<reg>
<reg>
<reg>
<mem>
<reg>
<mem>
<reg>
<mem>
<con>
<reg>
<con>
<mem>
ビットごとの論理演算に加えて、x86 は「シフト」演算もサポートする。シフトはレジスタ
またはメモリの場所を対象とする。シフト演算は、レジスタまたはメモリの現在の値を取り出
し、指定のビット数だけ左または右にビット列をずらして、その結果を元の場所に書き戻す。
シフトでは、空いたビットがハードウェアによって充填される。たとえばshl 命令でK ビッ
ト左にシフトするときは、結果の下位K ビットにゼロが充填される。shr 命令でK ビット右
hi.0412.ko.2002@gmail.com
　C.7
基本データ型
455
にシフトするときは、結果の上位K ビットにゼロが充填される5。表C‒5 に、左シフトと右シ
フトの演算で使えるオペランドを示す。
表C‒5：シフト命令で許容されるオペランドの組み合わせ。<cl>は、8bit のCL レジスタを意味する
左シフトと右シフト
ソース
ターゲット
<con8>
<reg>
<con8>
<mem>
<cl>
<reg>
<cl>
<mem>
C.7 　基本データ型
x86 のアセンブリ言語では、プログラマが、初期値のあるデータ項目と初期化されないデー
タ項目を定義できる。データ宣言の前に、.data というアセンブラのディレクティブを置く必
要がある。これがアセンブラに、以下の項目をデータとして扱うように指示する。プログラマ
は、個々のデータ項目を定義することも、連続するメモリでデータのシーケンスを、いちいち
名前を付けずに定義することもできる。表C‒6 に、利用できる基本データ型を示す（AT&T で
の名前は、32bit プロセッサ用コードを生成する場合）
。
表C‒6：基本データ型（Intel とAT&T のアセンブラで使う方法）
Intel での名前
AT&T での名前
サイズ（バイト数）
DB
.byte
1
DW
.hword
2
DD
.long
4
DQ
.quad
8
どちらの形式のアセンブラでも、プログラマがデータ項目に初期値を設定できる。Intel アセ
ンブリのプログラムでは、行の最初にラベルを置き、その次にデータの型を指定し、その後に、
その項目の初期値を書く。Intel アセンブラでは、初期値の代わりにクエスチョンマーク（?）
を書くことで、初期化しない項目を示す。AT&T のアセンブリプログラムでは、ラベルの末尾
に1 個のコロン（:）を置き、その後にデータの型と初期値を書くが、もし初期値を略せばゼ
ロになる。リストC‒1 とC‒2 に、この2 種類のアセンブラでのデータ宣言を示す。
5　訳注：元の値の最上位ビットで充填される右シフト命令もある（sar）
。また、ビット列を左右に回転さ
せるローテート命令もある。
hi.0412.ko.2002@gmail.com
456
付録C
x86 アセンブリ言語の基本　
リストC‒1：Intel アセンブラを使うときのデータ宣言の例
.DATA
; データ宣言の開始（Intel アセンブラ）
z
DD
?
; 初期化しない4 バイト
y
DD
0
; ゼロで初期化する4 バイト
x
DW
-54
; -54 で初期化する2 バイト
w
DW
?
; 初期化しない2 バイト
v
DB
?
; 初期化しない1 バイト
u
DB
6
; 6 で初期化する1 バイト
アセンブラは、連続するデータを、メモリ上で隣接するバイトに置く。2 つの表で、
「u」と
いう項目は、
「v」という項目に続くバイトに置かれる、同様に、
「y」は「z」の直後に置かれ
る。
「z」は4 バイトあるので、
「y」は、
「z」が始まる場所の4 バイト先から始まる。
リストC‒2：AT&T アセンブラを使うときのデータ宣言の例
.data
; データ宣言の開始（AT&T アセンブラ）
z:
.long
; ゼロで初期化される4 バイト
y:
.long
0
; ゼロで初期化される4 バイト
x:
.hword
-54
; -54 で初期化される2 バイト
w:
.hword
; ゼロで初期化される2 バイト
v:
.byte
; ゼロで初期化される1 バイト
u:
.byte
6
; 6 で初期化される1 バイト
C.8 　データブロックと配列と文字列
x86 アセンブリ言語は、構造体のようなデータ集合体は提供しないけれど、メモリで連続す
る場所を占める複数のデータ項目を、プログラマがまとめて宣言することはできる。たとえば
16bit の項目を3 つ、初期値を1、2、3 として宣言するには、3 行に分けて1 個ずつ項目を宣
言することもできるが、1 行で複数の項目を列記することも可能だ。
Intel 版
q
DW
1, 2, 3
AT&T 版
q:
.hword
1, 2, 3
Intel アセンブラでは、K DUP (<値>) と書くことで、1 個のデータ項目をK 回繰り返すこと
ができる。AT&T アセンブラでは、.space と指定することで、指定サイズのメモリを、ある
値で満たすことができる。たとえば、220 を初期値とするデータバイトを1000 回繰り返して
宣言するには、次のように書く。
Intel 版
s
DB
1000 DUP(220)
AT&T 版
s:
.space
1000, 220
hi.0412.ko.2002@gmail.com
　C.9
メモリ参照
457
AT&T アセンブラでは、大きな項目を繰り返し宣言するために、.rept マクロを使える。た
とえば4 バイトのゼロが12 回続くのを宣言するには：
Intel 版
DD
12 DUP(0)
AT&T 版
.rept
12
.long
0
.endr
x86 アセンブリ言語では、初期値として数値だけでなくASCII キャラクタも使うことができ
る。Intel アセンブラでは、文字定数をシングルクオート（’）で囲み、複数の文字を並べて文
字列にすることもできる。ただし、このアセンブラは文字列の末尾に「終端を示すゼロ」を付
加してくれない。AT&T アセンブラでは、文字定数をダブルクオート（"）で囲み、文字列を宣
言するにはディレクティブの.ascii または.asciz を使う。.ascii は末尾にゼロのバイトを
付加しないが、.asciz は、それを付加してくれる。プログラマは、たとえば文字「Q」で初期
化されるバイトをメモリに宣言することも、
「hello world」というキャラクタの並びを含む文
字列を終端のゼロを付けずに、あるいはゼロを付けて宣言することもできる。
Intel 版
c
DB
’Q’
d
DB
’hello world’
e
DB
’hello world’, 0
AT&T 版
c:
.ascii
"Q"
d:
.ascii
"hello world"
e:
.asciz
"hello world"
C.9 　メモリ参照
これまで見てきたように、多くのx86 命令では、演算でメモリを参照できる。それには、命
令で使う値をメモリからフェッチすることも、結果をメモリにストアすることも含まれる。x86
が提供する複雑な機構を使って、プログラマはメモリアドレスを計算できる。たとえば、2 つ
の汎用レジスタの内容を加算し、さらに定数を加えてアドレスを作ることも可能だ。さらに、
レジスタの値1 つを2 倍、4 倍、8 倍することもできる。サンプルによって、いくつかの可能
性を示そう。
データの名前で参照する
Intel 版
mov
dx, [T]
AT&T 版
movw
$T,%dx
hi.0412.ko.2002@gmail.com
458
付録C
x86 アセンブリ言語の基本　
レジスタを介した間接参照
プログラマは、ある数値を算出し、その値をレジスタに入れ、そのレジスタをメモリアドレ
スとして使うように指定できる。たとえば、
Intel 版
mov
eax, [ebx]
AT&T 版
movl
(%ebx), %eax
この命令は、EBX レジスタの内容をメモリアドレスとして、そのアドレスから始まる4 バイ
トをEAX レジスタにコピーする。
アドレスを計算する式も、許される。ただし「最大で2 個のレジスタと1 個の定数」という
ルールにしたがう必要がある。ただしオプションとして、レジスタの1 つを2 倍か4 倍か8 倍
にする乗算が可能だ。たとえばメモリアドレスを、EAX レジスタの内容にECX レジスタの値を
加え、さらに16 という定数を足して計算し、そのアドレスにEDI レジスタの値をストアする
ことができる。Intel の記法では、その演算を次のように書く。
mov
[eax+exb+16], edi
任意の式を書けそうな感じがするから、最初はアドレス計算のルールを覚えるのが難しいか
もしれない。表C‒7 に、メモリ参照の有効な例と無効な例を示しておく。
表C‒7：Intel 記法を使ったメモリ参照の、有効な例と無効な例
有効な参照
mov
eax, [lab1]
; lab1 というラベルのメモリから4 バイトをEAX に読む
mov
[lab2], ebx
; EBX の4 バイトを、lab2 というラベルのメモリに書く
and
eax, [esi-4]
; EAX と、ESI-4 のアドレスにある4 バイトのand を取る
not
[edi+8]
; EDI+8 のアドレスにある32 ビットを反転する
mov
[eax+2*ebx],0
; EAX+2*EBX のアドレスにある4 バイトに0 を書く
mov
cl, [esi+4*ebx]
; ESI+4*EBX のアドレスから1 バイトをCL レジスタに読む
無効な参照
mov
eax, [esi-ebx]
; 2 つのレジスタの引き算は使えない
mov
[eax+ebx+cl], 0
; 3 個以上のレジスタを指定できない
C.10 　データサイズの推定と明示的なサイズディレクティブ
メモリアドレスを実行時に計算することが可能なのだから、アドレスは単なる「32 ビットの
符号なし整数値」にすぎない。つまりメモリにある項目のサイズを指定する情報は、そのアド
レスに含まれないのだ。x86 アセンブラはヒューリスティックに（発見的手法で）
、可能な限り
データサイズを「推定」する。たとえば次の命令（Intel 記法）は、メモリの値をEAX レジスタ
にコピーするが、コピー先のレジスタのサイズが4 バイトなので、アセンブラは推定により、
hi.0412.ko.2002@gmail.com
　C.11
アドレス計算
459
そのメモリアドレスから4 バイトの値を参照するコードを生成する。
mov
eax, [ebx+esi+12]
同様に、ある名前が1 バイトとして宣言されているデータ項目に割り当てられていれば、ア
センブラは、その名前へのメモリ参照が1 バイトの参照だと推定してくれる。けれども、プロ
グラマ自身がデータ項目のサイズを明示的に指定しなければならない場合もある。そのときに
使うのが「サイズディレクティブ」だ。たとえばプログラマが、メモリの16bit ワードに-1 を
格納するために、そのメモリのアドレスを計算してEAX レジスタに入れたとしよう。アセンブ
ラには、プログラマがそのアドレスを「16 ビットの（つまり2 バイトの）データ項目へのポイ
ンタ」と考えていることがわからないから、4 バイト項目の参照と推定してしまうだろう。だ
からプログラマは、メモリ参照の前に、次のようなサイズディレクティブを加える必要がある
（この例は、Intel 記法を使っている）
。
mov
WORD PTR [eax], -1
疑いの余地があれば、意図を明白にするためにサイズディレクティブを使う習慣を付けるの
が賢明だ。たとえアセンブラが推定のルールによって正しい結果を出す場合でも、やはりそう
すべきだ。利用できる3 種類のサイズディレクティブを、表C‒8 に示す。
表C‒8：Intel アセンブラでメモリ参照の前に置けるサイズディレクティブ
ディレクティブ
意味
BYTE PTR
このアドレスで、メモリの1 バイトを参照する
WORD PTR
このアドレスで、メモリの16 ビット値を参照する
DWORD PTR
このアドレスで、メモリの32 ビット値を参照する
C.11 　アドレス計算
前述したように、ある整数を計算し、その値をレジスタに入れ、メモリアドレスとして使う
ことが可能だ。けれども、ほとんどのアドレス計算は、たとえば配列が始まる場所など、メモ
リの既知の場所から始まる。たとえば4 バイト整数の配列をiarray という名前で宣言し、ゼ
ロで初期化したとしよう（Intel アセンブラの場合）
。
iarray
DB
1000 DUP(0)
この配列でi をインデックスとする要素のアドレスを求めるには、
（要素サイズが4 バイト
なので）i を4 倍した結果を、配列の最初のバイトのアドレスに加算する。
hi.0412.ko.2002@gmail.com
460
付録C
x86 アセンブリ言語の基本　
実行中のプログラムで、配列の最初のアドレスを取得するには、どうするのだろうか。いや、
もっと広く言えば、プログラムが任意の変数のメモリアドレスを取得するには、どうすればいい
のか。値ではなくアドレスをレジスタにロードする特別な命令を使うのだ。その命令には「有
効アドレスをロードせよ」という意味の「lea」
（load eﬀective address）というニーモニック
があり、1 個のレジスタとメモリの場所とをオペランドとして取る。メモリの内容をアクセス
するmov 命令と違って、lea は、メモリアドレスを計算したら、そのアドレスを指定されたレ
ジスタに入れる。たとえば、
lea
eax, [iarray]
という命令は、メモリにあるiarray という項目の先頭アドレスを、EAX レジスタに入れる。
4 バイト整数の配列で、i をインデックスとする要素のオフセットを計算するのは簡単だ。
まずi を、レジスタに入れる（たとえばEBX）
。いったんインデックスをレジスタに入れたら、
配列のその要素に対応するメモリのアドレスは、1 個のlea 命令で計算できる。
mov
ebx, [i]
; メモリの変数i からインデックスを読み出す
lea
eax, [4*ebx+iarray] ; iaraay[i] のアドレスを取得し、EAX に入れる
C.12 　スタック演算：プッシュとポップ
x86 のハードウェアには、メモリ上のスタックを操作する命令がある。スタックは「LIFO」
（後入れ先出し：Last-In-First-Out）方式のデータ構造で、最後に追加された項目が、最初に取
り出される。他のプロセッサのスタックと同じように、x86 のスタックも下向きに（アドレス
0 に向けて）成長するので、新たに追加される項目は、その前よりも低位のメモリアドレスに置
かれる。このように成長は「下向き」だが、われわれは最後に追加した項目がスタックの「トッ
プ」にある、と表現する6。
新しい項目をスタックに追加することを、スタックに「プッシュする」と表現する。そうす
ると、スタックのトップが、その新しい項目になる。トップの項目をスタックから取り出すこ
とを、スタックから「ポップする」と表現する。
われわれが使うx86 のスタックでは、必ず4 バイトの項目が使われる。1 個の項目をスタッ
クにプッシュすると、さらに4 バイトのメモリが使用される。逆にスタックから項目を1 個
ポップするとき、その項目は4 バイトであり、スタックがメモリに占める大きさが4 バイト
減る。
6　訳注：食器の皿を下向きに積み重ねたようすを想像するとわかりやすいだろう。最後に乗せた皿が「トッ
プ」であり、それを最初に取り出す。
hi.0412.ko.2002@gmail.com
　C.13
制御の流れと無条件分岐
461
x86 のスタックポインタはESP レジスタで、これにはスタックの現在のトップを指すアドレ
スが含まれる。したがって、ESP の名前を出さないけれど、スタック操作は必ずESP の値を変
化させる。スタックを操作する命令の名前は、以上の説明で使った一般的な呼び名、すなわち
push とpop である。表C‒9 に、引数として使える型をあげる。
表C‒9：push とpop の命令で使えるオペランド
push
<reg32>
pop
<reg32>
push
<mem>
pop
<mem>
push
<con32>
いったんESP を設定したら、スタックに項目を追加するのは簡単だ。たとえば次の命令は、
push
eax
EAX レジスタの値をスタックにプッシュし、次の命令は、
pop
[qqqq]
スタックのトップからポップした値を、qqqq という名前のメモリに格納する。同様に、次
の命令は、
push
-1
‒1 という定数をスタックにプッシュする。x86 のハードウェアにはスタック境界が存在しな
いので、プログラマはスタックの使い方を事前に注意深く計画しておく必要がある。さもない
と、スタックが下向きに成長しすぎて、他の変数に使われているメモリ領域に侵入する危険が
ある。
C.13 　制御の流れと無条件分岐
通常は、あるステートメントを実行したらプロセッサは次のステートメントに進む。x86 に
は、制御の流れを変える3 種類の命令がある。
•
無条件分岐
•
条件分岐
•
プロシージャのコールとリターン
hi.0412.ko.2002@gmail.com
462
付録C
x86 アセンブリ言語の基本　
無条件分岐命令は、もっとも理解しやすい。オペコードはjmp、唯一のオペランドはステー
トメントのラベルだ。プロセッサはjmp 命令に遭遇したら、即座に指定されたラベルの位置に
ジャンプして、そこから実行を進める。たとえば次の命令は、
jmp
prntname
次にプロセッサが実行すべき命令が、prtname というラベルを持つ命令だという意味である。
プログラマは、飛び先の命令に、このラベルを付けておかなければならない（たぶん名前をプ
リントするシーケンスの最初の命令だ）
。Intel 記法では、たとえば次のように書く。
prntname:
mov
eax, [nam]
...
C.14 　条件分岐と条件コード
どの数値演算命令も、
「条件コード」と呼ばれるプロセッサ内部の値をセットする。
「条件分
岐」命令は、条件コードの値を使って、実行の流れを変える分岐を行うか、それとも次の命令に
進むかを決定する。一群の条件分岐命令が存在し、それぞれ条件コードの一部をテストする。
表C‒10 に、その概要を示す。
表C‒10：条件分岐命令と、それぞれの意味
オペコード
ニーモニックの意味
日本語に訳した意味
jeq
Jump if Equal
等しければジャンプ
jne
Jump if Not Equal
等しくなければジャンプ
jz
Jump if Zero
ゼロならジャンプ
jnz
Jump if Not Zero
ゼロでなければジャンプ
jg
Jump if Greater than
より大ならジャンプ
jge
Jump if Greater than or Equal
より大か等しければジャンプ
jl
Jump if Less than
より小ならジャンプ
jle
Jump if Less than or Equal
より小か等しければジャンプ
たとえば次のコード（Intel 記法）は、EBX レジスタをデクリメントし、その結果がゼロなら
atzero というラベルにジャンプする。
dec
ebx
; EBX から1 を引く
jz
atzero
; もし（EBX が）ゼロになったらatzero にジャンプする
表C‒10 に示した条件分岐命令の一部は、使う前にプログラマが2 つの項目を比較する必要
hi.0412.ko.2002@gmail.com
　C.15
サブプログラムのコールとリターン
463
がある。たとえば「より大か、それとも等しいか」をテストするjge が、そうだ。けれども、
条件分岐命令そのものは比較を実行しない。命令のオペランドは1 個だけで、それは分岐先を
示すラベルである。数値演算の結果をテストする場合と同じく、比較を含む条件分岐は、条件
コードに依存する。条件コードは、さまざまな命令によって設定される。だから条件分岐命令
は、
条件コードを設定したら即座に実行すべきだ。もし条件コードを設定した命令の直後に条件
分岐を置かなければ、間に挟まれた命令によって、条件コードが変更されてしまう危険がある。
x86 アーキテクチャには、
条件コードの設定に使われる命令が2 つある。それはtest とcmp
だ。どちらの命令も、レジスタやメモリの内容を変更しない。これらは単に、2 つの値を比較
して条件コードをセットするだけだ。cmp 命令は、等しいかどうかをチェックする。要するに
cmp は引き算を行うが、その答えを捨てて、条件コードだけを残すのだ。たとえば次のコード
（Intel 記法）は、var1 という場所のメモリにある4 バイトの値を定数の123 と比較し、もし
両者が等しければbb というラベルにジャンプする。
cmp
DWORD PTR [var1], 123
; メモリ項目var1 を123 と比較して、
jeq
bb
; 等しければ、ラベルbbb に分岐
test 命令は、もう少し複雑だ。この命令は2 つのオペランドの、ビット毎の「OR」を取り、
その結果にしたがって、条件コードのさまざまなビット（各種のフラグ値）を設定する。たと
えばtest 命令は、データの値が偶数パリティか奇数パリティか、といった条件も設定する。
C.15 　サブプログラムのコールとリターン
x86 のハードウェアは、
「サブルーチン呼び出し」をサポートする（これは、サブプログラム
を呼び出し、そのサブプログラムから呼び出し側に戻ることができる、という意味だ）
。サブ
ルーチン呼び出しは、高いレベルの「手続き型言語」に必要な実時間サポートの、決定的に重
要な部分を提供する。
図C‒2 は、サブプログラムを可能にするx86 命令を2 つ示している。片方call 命令は、サ
ブプログラムを呼び出すコールに使い、もう片方のret 命令は、呼び出し側に戻るリターンに
使う。
call <label>
ret
図C‒2：サブプログラムの呼び出しで使われる2 つの命令。call はサブプログラムを呼び出し、ret はサブ
プログラムを呼び出した側に戻る
サブプログラムのコールとリターンは、ランタイムスタックを使用する。たとえばcall 命
令は、リターンアドレスをスタックにプッシュする。次の節で、その詳細を論じる。
hi.0412.ko.2002@gmail.com
464
付録C
x86 アセンブリ言語の基本　
C.16 　C の呼び出し規約と引数渡し
「呼び出し規約」は、呼び出し側と呼び出される側の両方のプログラムが、引数の置き場所
などの詳細について、確実に合意するためのルールだ。呼び出し規約は、呼び出すプログラム
と呼び出されるプログラムに責任を分担させる。たとえば規約は、呼び出し側のプログラムが
引数をスタックにプッシュする方法を厳密に指定して、サブプログラムが引数を使えるように
する。また、規約はサブプログラムが値を返す方法を厳密に指定して、呼び出し側のプログラ
ムが戻り値を使えるようにする。
どの高水準言語にも、呼び出し規約が定義される。ここでは馴染み深いC の呼び出し規約を
例としよう。その呼び出し規約は、C またはC++のプログラムからアセンブリ言語のプログラ
ムを呼び出せるように、そして、アセンブリ言語のプログラムからC の関数を呼び出せるよう
にするのを目的としているが、C の呼び出し規約はアセンブリ言語のプログラムからアセンブ
リ言語のサブプログラムを呼び出すのにも使える。だから、われわれは一般的な例を示すこと
になる。
呼び出し規約を理解するもっとも簡単な方法は、サブプログラムが呼び出されるときのリア
ルタイムスタックの内容を視覚化することだ。この例では、1 回の呼び出しで3 つの整数型引
数（引数1 個につき4 バイト）を、100、200、300 という値でサブプログラムに渡す。その
サブプログラムは4 個のローカル変数を持ち、それらはどれも32 ビットである。呼び出し規
約の指定にしたがって、1 回の呼び出しで、下記のアクションが行われる。
呼び出す側のアクション
呼び出し側は、レジスタEAX、ECX、EDX の値をスタックにプッシュして保存する。次に呼
び出し側は、引数を逆順でスタックにプッシュする。引数の並び順が100、200、300 ならば、
まず300 を、次に200 を、そして100 をプッシュするのだ。そして最後にcall 命令を実行す
るが、その呼び出しによってリターンアドレス、つまりcall 命令の直後のアドレスがスタッ
クにプッシュされ、サブプログラムへのジャンプが行われる。
呼び出されたサブプログラムのアクション
call で呼び出されたサブプログラムは、まずEBP レジスタをスタックにプッシュしてから、
EBP にスタックの現在のトップを設定する。サブプログラムは、次にレジスタEBX、EDI、ESI
をスタックにプッシュし、それから各ローカル変数をスタックにプッシュする（あるいは、もし
ローカル変数に初期値がなければ、単にスタックポインタを更新して、その場所を確保する）
。
図C‒3 に示すスタックは、サブプログラムの呼び出しが行われた後、すなわち、呼び出し側
とサブプログラムの両方が、規約にしたがって記のアクションを行った直後の状態である。こ
の図を理解するには、スタックがメモリで下向きに成長することを思い出そう。つまりpush 演
算はスタックポインタをデクリメントし、pop 演算はスタックポインタをインクリメントする。
hi.0412.ko.2002@gmail.com
　C.16
C の呼び出し規約と引数渡し
465
保存された EAX
保存された ECX
保存された EDX
引数 3 (300)
引数 2 (200)
引数 1 (100)
リターンア
ドレス
保存された EBP
保存された EBX
保存された EDI
保存された ESI
ローカル変数 1
ローカル変数 2
ローカル変数 3
ローカル変数 4
EBP
サブプログラムが
設定した
ESP
スタ
ッ
クは低位メモリア
ドレスに向けて成長する
呼び出し側が
プッ
シュ
した
callでプッ
シュされ、
retで削除される
呼び出された
サブプログラムが
プッ
シュ
した
図C‒3：サブプログラムが3 つの引数とともに呼び出され、4 個のローカル変数に使う空間を予約した後
の、ランタイムスタックの状態
呼び出されて処理を終えたサブプログラムは、呼び出し時のアクションを取り消してから、
呼び出し側に戻らなければならない。下記は、そのリターン時にサブプログラムと呼び出した
プログラムが実行するステップである。
呼び出されたサブプログラムがリターンするアクション
呼び出されたサブプログラムは、スタックに置いたローカル変数の割り当てを解除する。そ
のために、サブプログラムはスタックポインタに4N バイトを加算する（ここでN はローカル
変数の個数。どのローカル変数も4 バイト長と仮定している）
。次にサブプログラムは、ESI、
EDI、EBX、EBP のレジスタを元に戻すため、スタックに保存した値を、それぞれのpop で取得
する。最後にサブプログラムはret 命令を実行する。これによってリターンアドレスがスタッ
クからポップされ、呼び出し側に戻る。
リターンされた側のアクション
呼び出したサブプログラムがリターンしたら、呼び出し側は引数の割り当てを解除する（引
数の個数に4 を掛けた値に等しい定数をスタックポインタに加算する）
。最後に呼び出し側は、
EDX、ECX、EAX の値を復旧する。
hi.0412.ko.2002@gmail.com
466
付録C
x86 アセンブリ言語の基本　
C.17 　関数コールと戻り値
上記の呼び出し規約が適用されるのは、厳密に言えば「プロシージャコール」である。
「関数
コール」の場合、サブプログラムは呼び出し側に値を返さなければならない。規約により、そ
の「戻り値」はEAX レジスタに入れて渡される。したがって、関数を呼び出すときの呼び出し
規約は、呼び出し側がEAX の値を上書きしないように変更される。
では、関数を呼び出す前に呼び出し側がEAX をスタックに保存する意味は、あるのだろう
か。関数からリターンしたら、EAX には戻り値が入っているのだから。しかし、EAX を保存す
べき理由が2 つある。第1 にシンボリックデバッガは、呼び出されたのがプロシージャでも関
数でも、スタックのレイアウトが同じであることを期待する第2 に、呼び出し側は関数呼び出
しの結果を保存した後も、計算を続行したいかもしれない。たとえば、コンパイラがループに
使うインデックス変数を入れるのにEAX を使ったと仮定しよう。もしそのループに次のような
ステートメントが含まれていたら、
r = f(t);
コンパイラは、関数呼び出しの前にEAX を保存するコードを生成するだろう。そして関数f
からリターンした直後に、その戻り値をr の場所のメモリにストアし、それからEAX をリスト
アして、ループを続行できるだろう。
C.18 　64 ビットへの拡張（x64）
x86 アーキテクチャは、64bit 版への拡張が行われている。興味深いことに、エクステン
ションの枠組みを定義したのはAMD であり、それがIntel その他のベンダーに採用された。
「x86-64」という名で、しばしば短く「x64」とも呼ばれる、そのアーキテクチャには、多くの
変更点が含まれている。たとえば算術命令と論理命令、2 つのレジスタが関わる命令、1 個のレ
ジスタとある場所のメモリが関わる命令、そして2 つの場所のメモリが関わる命令は、すべて
64bit 演算で処理するように拡張された。スタック演算も変更され、一度に64 ビット（8 バイ
ト）をプッシュ／ポップすることになったし、ポインタも64bit 幅になった。われわれの議論
にもっとも関係が深いのは、汎用レジスタに関する、次の2 つの変更だ。
•
どの汎用レジスタも、それぞれ64 ビットに拡張された。
•
汎用レジスタとして、新たに8 個のレジスタが追加され、合計16 個の汎用レジスタ
となった。
x86 がそうしたように、x64 アーキテクチャも後方互換性を保とうとしている。たとえば全
部の64-bit レジスタは、その下半分を32bit レジスタとして参照することができる。そればか
hi.0412.ko.2002@gmail.com
　C.18
64 ビットへの拡張（x64）
467
りか、最初の4 本のレジスタはx86 とまったく同じように、16bit の部分、8bit の部分を参照
できる。図C‒4 に、x64 で利用できる汎用レジスタを示す。この章で最初に見た図C‒1 と、比
べていただきたい。
RSI 
ESI
RDI 
EDI
RSP 
ESP
RBP 
EBP
R8
R9
R10
R11
R12
R13
R14
R15
RAX 
AH 
AL 
EAX
RBX 
BH 
BL 
EBX
RCX 
CH 
CL 
ECX
RDX 
DH 
DL 
EDX
AX (16ビッ
ト)
BX (16ビッ
ト)
CX (16ビッ
ト)
DX (16ビッ
ト)
新規に
追加された
レジスタ
図C‒4：x64 アーキテクチャの汎用レジスタ
hi.0412.ko.2002@gmail.com
468
付録C
x86 アセンブリ言語の基本　
C.19 　まとめ
この章で見てきたx86 の基本事項には、データ宣言、レジスタ、オペランドの型、基本的な
命令、算術と論理演算の命令、メモリ参照、スタック操作、無条件分岐と条件分岐、サブプログ
ラムの呼び出しが含まれる。x86 アーキテクチャは膨大な数の命令を提供しているから、プロ
グラマは所与のタスクを実行するのに、複数の機構ののなかから選べるかもしれない。64 ビッ
トに拡張された設計は、
「x64」と呼ばれている。
hi.0412.ko.2002@gmail.com
付録D
ARMのレジスタ定義と
コーリングシーケンス
D.1 　はじめに
1 つ前の付録では、x86 とx64 のアーキテクチャについて概説した。そこで見たように、x86
の命令セットは典型的なCISC である。続いて、この付録ではARM アーキテクチャに関する
情報を提供する。ARM はRISC アーキテクチャの典型的な例である。
ARM は一群のプロセッサ（コア）を定義してきたが、この付録では、そのうち多くの32bit
製品に共通する機能に焦点を絞る。個々のモデルに特有な詳細は、ARM のドキュメンテーショ
ンを参照していただきたい1。
D.2 　ARM プロセッサのレジスタ
ARM プロセッサには汎用レジスタが16 本あり、0 から15 までの番号が振られている。こ
れらは一般に、r0 からr15 という名前で呼ばれる。r0 からr3 までのレジスタは、引数をサブ
ルーチンに渡し、結果を呼び出し側に返すのに使われる。r4 からr11 までのレジスタは、現
在実行されているサブルーチンのローカル変数に使われる。r12 は、プロシージャ間コール用
のスクラッチレジスタである。r13 はスタックポインタだ。r14 はサブルーチンコールに使わ
れる「リンクレジスタ」である。最後のr15 はプログラムカウンタである。これは命令ポイン
タなので、r15 にアドレスをロードすると、プロセッサは、そのアドレスに分岐する。表D‒1
に、これらのレジスタの用途をまとめ、gcc のアセンブラで使われているレジスタ名を示す。
1　訳注：
「Documentation - Arm Developer」
（https://developer.arm.com/documentation）が窓
口である。技術資料は「Processor Tehnical Reference Manual」
、
「Architecture Reference Manual」と
いった名前で見つかるが、英文で非常に大きな文書だ。概要を知るには、パターソン&ヘネシー『コンピュー
タの構成と設計第5 版』や、Upton 他『Raspberry Pi で学ぶコンピュータアーキテクチャ』などが参考に
なるだろう。
hi.0412.ko.2002@gmail.com
470
付録C
x86 アセンブリ言語の基本　
表D‒1：ARM アーキテクチャの汎用レジスタと、アセンブリ言語で使われる別名と、それぞれのレジスタ
に割り当てられた意味を示す
レジスタ
名前
用途
r15
pc
プログラムカウンタ
r14
lr
リンクレジスタ
r13
sp
スタックポインタ
r12
ip
プロシージャ間のスクラッチ
r11
fp
フレームポインタ（あるいは引数ポインタ）
r10
sl
スタックリミット
r9
v6
ローカル変数6 （あるいは実際のフレームポインタ）
r8
v5
ローカル変数5
r7
v4
ローカル変数4
r6
v3
ローカル変数3
r5
v2
ローカル変数2
r4
v1
ローカル変数1
r3
a4
引数4 （関数呼び出しの間）
r2
a3
引数3（関数呼び出しの間）
r1
a2
引数2（関数呼び出しの間）
r0
a1
引数1（関数呼び出しの間）
これらの汎用レジスタのほか、どのARM プロセッサにも32bit の「CPSR」
（カレントプロ
グラムステータスレジスタ）がある。CPSR は、多くのフィールドにわかれていて、それにはプ
ロセッサのモードや演算を制御するフィールド、割り込みを制御するフィールド、演算実行後
の条件コードを知らせるフィールド、ハードウェアエラーを知らせるフィールド、システムの
エンディアンを制御するフィールドがある。表D‒2 に、CPSR のフィールドをまとめておく。
表D‒2：ARM のCPSR のビット構成と、それぞれの意味
名前
ビット
用途
N
31
ネガティブ条件（結果が負／小さい）
Z
30
ゼロ条件（結果が0/等しい）
C
29
キャリー／ボロー／桁あふれ条件
V
28
符号付きオーバーフロー条件
Q
27
スティッキーオーバーフロー（特殊な演算の結果）
J
24
Java ステート（命令セット選択）
DNM
20-23
書き換え禁止
GE
16-19
Greater-than-or-equal-to 実行状態
IT
10-15 と25-26
If-then 実行状態
E
9
データのエンディアン
A
8
不正データアボート無効フラグ
I
7
IRQ 無効フラグ
F
6
FIQ 無効フラグ
T
5
Thumb ステート（命令セット選択）
M
0-4
プロセッサモード
hi.0412.ko.2002@gmail.com
　D.3 　ARM の呼び出し規約
471
D.3 　ARM の呼び出し規約
プログラミング言語がサポートする呼び出し機構では、あるコードがサブルーチンを呼び出
し、そのサブルーチンが実行を終えると、その呼び出しを行った所に制御が戻される。ランタ
イム環境に注目すると、サブルーチンコールでは、ランタイムスタックへのプッシュが行われ
る。コードはサブルーチンを呼び出すことで「呼び出した側」になり、サブルーチンとして呼
び出されると「呼び出された側」になる。プログラミング言語C では、サブルーチンを「関数」
と呼ぶ。これらの用語を今後、この付録で使うことにしたい。
関数コールにはハードウェアによる制約があるが、いくつかの詳細はプログラマあるいはコ
ンパイラが自由に選べる。この章の記述は、広く受け入れられている「gcc」の呼び出し規約に
基づいている。
ARM における引数渡しの規約には、次の特徴がある。
•
呼び出し側は、0 個以上の引数を、呼び出される側に渡すことができる。
•
最初の4 個の引数はアクセスが最適化される。
•
呼び出される側は、一群の結果を呼び出した側に返すことができる。
•
呼び出される側が変更できるレジスタ、変更したままのリターンが許されないレジス
タが、指定される。
•
関数のコールとリターンでランタイムスタックをどう使うかが指定される。
多くの関数はパラメータが4 個以下である。そこで最初の4 つの引数についてアクセスを最
適化するため、それらの値をa1 からa4 までの汎用レジスタ（つまり、レジスタr0 からr3
まで）に入れて渡す。その他の引数はスタックメモリに置かれる。呼び出された側は最初の4
個の引数を、単なるレジスタ参照でアクセスできるから、そのアクセスは極めて高速である。
呼び出された側は、結果を呼び出し側に返すのに、レジスタa1 からa4 までを使うことがで
きる。多くのプログラム言語では、関数が返す結果は1 個だけであり、それはa1 に入る。も
し引数または結果が32 ビットよりも大きければ、その値はメモリに置かれ、そのアドレスが
引数レジスタで渡される。
図D‒1 に、関数コールを行った直後のスタックレイアウトを例示する。この例を見れば、呼
び出し規約が明らかになり、関数コールの間にレジスタの値を保存する方法も、理解できるだ
ろう。
この図は、実行されていた関数A が、引数を6 個渡して関数B を呼び出したところだ。前述
したように最初の4 個の引数はレジスタ渡しなので、スタックに現れない。しかし最初の4 個
を超えた引数はスタックで渡す必要がある。このため関数A は、関数B を呼び出す前に、引数
5 と引数6 を逆順でランタイムスタックにプッシュする。この図が示すように、これらの追加
引数は、呼び出しが発生するとき、最後にスタックに入る項目である。
hi.0412.ko.2002@gmail.com
472
付録D 　ARM のレジスタ定義とコーリングシーケンス　
関数A
（呼び出し側）
の
スタ
ッ
ク領域
関数B
（呼び出された側）
の
スタ
ッ
ク領域
Aからのリターンア
ドレス
関数Aの開始時に
保存された値
関数Aが、
Bを呼び出すまでに
使ったスタ
ッ
ク領域
最初の4個を超えて
Bに渡された2つの引数
Bからのリターンア
ドレス
関数Bの開始時に
保存された値
保存した lr 
（r14）
保存した fp 
（r7）
保存したレジスタ
r4 - r6
と
r8 - r11
関数Aの
ローカル変数群
Bへの引数 6
Bへの引数 5
保存した lr 
（r14）
保存した fp 
（r7）
保存したレジスタ
r4 - r6
と
r8 - r11
関数Bの
ローカル変数群
スタ
ッ
クは下向きに成長する
図D‒1：関数A が関数B を、6 個の引数とともに呼び出した直後のランタイムスタックと項目のレイアウト
呼び出し側は、関数呼び出しの間、ほとんどの汎用レジスタの値が「保存される」ことを期待
する。つまり呼び出し側は、呼び出された関数がレジスタの値を変えないことを期待するのだ。
もちろん、ほとんどの関数はレジスタを使う必要がある。このため、呼び出された関数は入り
口で、それらのレジスタの内容をセーブし、リターンする前に、それらをリストアする。図が示
すように、関数B のプレリュード（入り口のコード）は、リンクポインタ（r14）
、フレームポ
インタ（r7）
、レジスタr4 からr6 まで、およびレジスタr8 からr11 までを、スタックに保存
する。次に関数B のプレリュードは（必要に応じて）ローカル変数のための空間をスタックに
hi.0412.ko.2002@gmail.com
　D.3
ARM の呼び出し規約
473
確保する。ローカルストレージの割り当てを終えたら、関数B を実行できる。実行を終えた関
数B は、その関数のポストリュード（出口のコード）を実行する。ポストリュードのコードは、
レジスタ群をスタックに保存した値で復旧し、スタックを自分が呼び出される前の状態に戻す。
hi.0412.ko.2002@gmail.com
索　引
■記号・数字
$ ···
···
···
···
···
···
···
···
···
···
···
···
···
···
···
···
··· 162
.long
···
···
···
···
···
···
···
···
···
···
···
···
···
···
··· 170
.word ···
···
···
···
···
···
···
···
···
···
···
···
···
···
···170
0アドレスアーキテクチャ···
···
···
···
···
··· 120
14ピンDIP
···
···
···
···
···
···
···
···
···
···
···
···
··· 18
1アドレス···
···
···
···
···
···
···
···
···
···
···
···
··· 121
1次記憶···
···
···
···
···
···
···
···
···
···
···
···188, 190
1対1写像
···
···
···
···
···
···
···
···
···
···
···
···
··· 296
1の補数···
···
···
···
···
···
···
···
···
···
···
···
···
···
···49
1ビットのバス···
···
···
···
···
···
···
···
···
···
··· 284
2アドレス···
···
···
···
···
···
···
···
···
···
···
···
··· 122
2次記憶···
···
···
···
···
···
···
···
···
···
···
···188, 190
2進化10進数
···
···
···
···
···
···
···
···
···
···
···
··· 55
2進法の桁···
···
···
···
···
···
···
···
···
···
···
···
···
···40
2の冪乗···
···
···
···
···
···
···
···
···
···
···
···
···
··· 203
2の補数···
···
···
···
···
···
···
···
···
···
···
···
···
···
···49
2パスのアルゴリズム···
···
···
···
···
···
···
··· 177
3アドレス···
···
···
···
···
···
···
···
···
···
···
···
··· 122
3値CAM ···
···
···
···
···
···
···
···
···
···
···
···
···
···213
■A
A（アンペア）···
···
···
···
···
···
···
···
···
···
···
··· 8
Advanced Graphics Portインターフェイス
···
···
···
···
···
···
···
···
···
···
···
···
···
··· 409
AGPインターフェイス···
···
···
···
···
···
···
···409
Alan Perlis ···
···
···
···
···
···
···
···
···
···
···
···
···157
ALU ···
···
···
···
···
···
···
···
···
···
···
···
···
···69, 144
American National Standards Institute
45
American Standard Code for Information
Interchange ···
···
···
···
···
···
···
···
···45
AND ···
···
···
···
···
···
···
···
···
···
···
···
···
···
···
···10
ANSI ···
···
···
···
···
···
···
···
···
···
···
···
···
···
···
···45
Application Speciﬁc Integrated Circuits 35
argument ···
···
···
···
···
···
···
···
···
···
···
···
···
···94
Arithmetic Logic Unit ···
···
···
···
···
···
···
··· 69
ASCII ···
···
···
···
···
···
···
···
···
···
···
···
···
···
···
···45
ASIC ···
···
···
···
···
···
···
···
···
···
···
···
···
···
···
···35
Asymmetric Multiprocessor ···
···
···
···
···353
AT&Tアセンブリ言語···
···
···
···
···
···
···
···450
■B
BCD ···
···
···
···
···
···
···
···
···
···
···
···
···
···
···
··· 55
Bell Labs
···
···
···
···
···
···
···
···
···
···
···
···
··· 161
Binary Coded Decimal ···
···
···
···
···
···
···
···55
bit ···
···
···
···
···
···
···
···
···
···
···
···
···
···
···
···
··· 40
byte
···
···
···
···
···
···
···
···
···
···
···
···
···
···
···
··· 40
■C
C.mmp
···
···
···
···
···
···
···
···
···
···
···
···
···
··· 353
CAM ···
···
···
···
···
···
···
··· 212, 237, 260, 262
Carnegie Multi-Mini-Processor
···
···
··· 353
carry ···
···
···
···
···
···
···
···
···
···
···
···
···
···
···
···16
carryビット···
···
···
···
···
···
···
···
···
···
···
···
···16
CDC ···
···
···
···
···
···
···
···
···
···
···
···
···
···33, 354
Central Processing Unit ···
···
···
···
···
···2, 65
CISC ···
···
···
···
···
···
···
···
···
···
···
···
···
···
···
···86
CISCプロセッサ···
···
···
···
···
···
···
···
···
···
···86
close関数
···
···
···
···
···
···
···
···
···
···
···
···
··· 334
CMOS ···
···
···
···
···
···
···
···
···
···
···
···
···
··· 9, 34
Complementary Metal Oxide
Semiconductor ···
···
···
···
···
···
···
···9
Content Addressable Memory ···
···
···
···212
Control and Status Registers
···
···
···
··· 308
Control Data Corporation ···
···
···
···
···
···354
CPSR ···
···
···
···
···
···
···
···
···
···
···
···
···
···
··· 470
CPU
···
···
···
···
···
···
···
···
···
···
···
··· 2, 65, 133
CSR ···
···
···
···
···
···
···
···
···
···
···
···
···
···
···
···308
■D
DDR
···
···
···
···
···
···
···
···
···
···
···
···
···
···
··· 198
DDR-DRAM ···
···
···
···
···
···
···
···
···
···
···
··· 198
DDR-SDRAM
···
···
···
···
···
···
···
···
···
···
··· 198
demultiplexor ···
···
···
···
···
···
···
···
···
···
···
···25
demux ···
···
···
···
···
···
···
···
···
···
···
···
···
···
··· 25
DIMM ···
···
···
···
···
···
···
···
···
···
···
···
···
···
···195
Direct Memory Access ···
···
···
···
···
···
··· 318
DMA
···
···
···
···
···
···
···
···
···
···
···
···
···
···
··· 318
Double Data Rate Dynamic RAM ···
··· 198
Double Data Rate Synchronous Dynamic
RAM
···
···
···
···
···
···
···
···
···
···
··· 198
DRAM ···
···
···
···
···
···
···
···
···
···
···
···
···35, 259
Dual In-line Package
···
···
···
···
···
···
···
··· 18
Dynamic Ram ···
···
···
···
···
···
···
···
···
···
···
···35
■E
EBCDIC
···
···
···
···
···
···
···
···
···
···
···
···
···
··· 45
Extended Binary Coded Decimal
Interchange Code ···
···
···
···
···
···45
■F
Fast Cycle RAM ···
···
···
···
···
···
···
···
···
··· 198
Fast Page Mode Dynamic RAM ···
···
··· 198
FCRAM ···
···
···
···
···
···
···
···
···
···
···
···
···
··· 198
FET ···
···
···
···
···
···
···
···
···
···
···
···
···
···
···
···
··· 8
Field Eﬀect Transistor
···
···
···
···
···
···
···
··· 8
FIFO
···
···
···
···
···
···
···
···
···
···
···
···
···
···
··· 187
ﬂoating point ···
···
···
···
···
···
···
···
···
···
···
··· 51
FLOPS ···
···
···
···
···
···
···
···
···
···
···
··· 363, 396
ﬂush
···
···
···
···
···
···
···
···
···
···
···
···
···
···
··· 338
ﬂush関数
···
···
···
···
···
···
···
···
···
···
···
···
··· 338
Flynn classiﬁcation ···
···
···
···
···
···
···
···
···349
forステートメント
···
···
···
···
···
···
···
···
··· 165
forループ
···
···
···
···
···
···
···
···
···
···
···
···
··· 165
FPGA ···
···
···
···
···
···
···
···
···
···
···
···
···
···
···141
FPM-DRAM ···
···
···
···
···
···
···
···
···
···
···
··· 198
■G
GAS ···
···
···
···
···
···
···
···
···
···
···
···
···
···
···
···450
Gene Amdahl ···
···
···
···
···
···
···
···
···
···
··· 401
GND
···
···
···
···
···
···
···
···
···
···
···
···
···
···
···
··· 8
GNUアセンブリ言語
···
···
···
···
···
···
···
··· 450
Gordon Moore
···
···
···
···
···
···
···
···
···
···
··· 35
■H
h ···
···
···
···
···
···
···
···
···
···
···
···
···
···
···
···
···
···43
H
···
···
···
···
···
···
···
···
···
···
···
···
···
···
···
···
··· 43
Heating, Ventilation, and Air Conditioning
···
···
···
···
···
···
···
···
···
···
···
···
···
··· 385
hex ···
···
···
···
···
···
···
···
···
···
···
···
···
···
···
···
···43
HVAC ···
···
···
···
···
···
···
···
···
···
···
···
···
···
···385
■I
I/O ···
···
···
···
···
···
···
···
···
···
···
···
···
···
···
··· 133
I/Oバス···
···
···
···
···
···
···
···
···
···
···
···
···
··· 279
IC ···
···
···
···
···
···
···
···
···
···
···
···
···
···
···
···
··· 34
IEEE ···
···
···
···
···
···
···
···
···
···
···
···
···
···
···
··· 52
if-then-elseステートメント
···
···
···
···
··· 165
if文···
···
···
···
···
···
···
···
···
···
···
···
···
···
···
··· 164
Industry Standard Architecture ···
···
··· 406
Instruction Set Architecture ···
···
···
···
··· 80
Integrated Circuit ···
···
···
···
···
···
···
···
···
···34
Intelアセンブリ言語
···
···
···
···
···
···
···
··· 450
Internet Sevice Provider
···
···
···
···
···
··· 372
ioctl関数···
···
···
···
···
···
···
···
···
···
···
···
···
···334
ISA ···
···
···
···
···
···
···
···
···
···
···
···
···
···
···
···
···80
ISAバス···
···
···
···
···
···
···
···
···
···
···
···
···
··· 406
ISO符号···
···
···
···
···
···
···
···
···
···
···
···
···
···
···45
ISP ···
···
···
···
···
···
···
···
···
···
···
···
···
···
···
··· 372
■J
JIS符号···
···
···
···
···
···
···
···
···
···
···
···
···
···
···45
John von Neumann ···
···
···
···
···
···
···
···
···64
jsr ···
···
···
···
···
···
···
···
···
···
···
···
···
···
···
···
··· 94
jsr命令
···
···
···
···
···
···
···
···
···
···
···
···
···
··· 166
jump subroutine
···
···
···
···
···
···
···
···
···
··· 94
■L
L1キャッシュ
···
···
···
···
···
···
···
···
···
···
··· 228
L2キャッシュ
···
···
···
···
···
···
···
···
···
···
··· 228
L3キャッシュ
···
···
···
···
···
···
···
···
···
···
··· 228
LAN ···
···
···
···
···
···
···
···
···
···
···
···
···
···
···
···363
Last-In-First-Out ···
···
···
···
···
···
···
···
···
··· 460
lea
···
···
···
···
···
···
···
···
···
···
···
···
···
···
···
··· 460
Least Recently Used ···
···
···
···
···
···
···
··· 222
Least Recently Used置換···
···
···
···
···
··· 262
Least Signiﬁcant Bit ···
···
···
···
···
···
···
···
···43
LIFO
···
···
···
···
···
···
···
···
···
···
···
···
···
···
··· 460
load eﬀective address
···
···
···
···
···
···
··· 460
load命令···
···
···
···
···
···
···
···
···
···
···
···
···
···160
Local Area Network
···
···
···
···
···
···
···
··· 363
LPM0 ···
···
···
···
···
···
···
···
···
···
···
···
···
···
···390
LPM1 ···
···
···
···
···
···
···
···
···
···
···
···
···
···
···390
LPM2 ···
···
···
···
···
···
···
···
···
···
···
···
···
···
···390
LPM3 ···
···
···
···
···
···
···
···
···
···
···
···
···
···
···390
LPM4 ···
···
···
···
···
···
···
···
···
···
···
···
···
···
···390
LRU ···
···
···
···
···
···
···
···
···
···
···
···
···
···
···
···222
LRU置換···
···
···
···
···
···
···
···
···
···
···
···
···
···262
LSB
···
···
···
···
···
···
···
···
···
···
···
···
···
···
···
··· 43
■M
M.J.Flynn ···
···
···
···
···
···
···
···
···
···
···
···
··· 346
Maurice Wilkes
···
···
···
···
···
···
···
···
···
··· 224
MBps ···
···
···
···
···
···
···
···
···
···
···
···
···
···
··· 273
Mbps ···
···
···
···
···
···
···
···
···
···
···
···
···
···
··· 273
Metal Oxide Semiconductor ···
···
···
···
···
···8
Microsoft-Intelアセンブリ言語···
···
···
···450
MIMD
···
···
···
···
···
···
···
···
···
···
···
··· 350, 352
MIPS ···
···
···
···
···
···
···
···
···
···
···
···
···
···
··· 397
MISD ···
···
···
···
···
···
···
···
···
···
···
···
···
···
··· 350
MMU ···
···
···
···
···
···
···
···
···
···
···
···
···209, 242
MOSFET ···
···
···
···
···
···
···
···
···
···
···
···
···
···
···8
Most Signiﬁcant Bit ···
···
···
···
···
···
···
···
··· 43
MSB ···
···
···
···
···
···
···
···
···
···
···
···
···
···
···
··· 43
MSI
···
···
···
···
···
···
···
···
···
···
···
···
···
···
···
··· 35
Multiple Instruction streams Multiple Data
streams ···
···
···
···
···
···
···
···
···
··· 350
Multiple Instruction streams Single Data
stream
···
···
···
···
···
···
···
···
···
··· 350
■N
NAND ···
···
···
···
···
···
···
···
···
···
···
···
···
···
··· 11
Network File System ···
···
···
···
···
···
···
···399
NFS ···
···
···
···
···
···
···
···
···
···
···
···
···
···
···
···399
no operation
···
···
···
···
···
···
···
···
···
···
···
··· 91
No-Op ···
···
···
···
···
···
···
···
···
···
···
···
···
···
··· 91
NOR ···
···
···
···
···
···
···
···
···
···
···
···
···
···
···
··· 11
NOT ···
···
···
···
···
···
···
···
···
···
···
···
···
···
···
··· 10
ns ···
···
···
···
···
···
···
···
···
···
···
···
···
···
···
···
···273
NVRAM ···
···
···
···
···
···
···
···
···
···
···
···
···
···187
N型シリコン
···
···
···
···
···
···
···
···
···
···
···
··· 34
N重インターリーブ···
···
···
···
···
···
···
···
···211
hi.0412.ko.2002@gmail.com
　索　引
475
■O
OFF状態···
···
···
···
···
···
···
···
···
···
···
···
···
···391
open/read/write/closeのパラダイム
··· 334
open関数
···
···
···
···
···
···
···
···
···
···
···
···
··· 334
operation code ···
···
···
···
···
···
···
···
···
···
··· 81
OR ···
···
···
···
···
···
···
···
···
···
···
···
···
···
···
···
···10
out of order ···
···
···
···
···
···
···
···
···
···
···
··· 150
■P
PCB ···
···
···
···
···
···
···
···
···
···
···
···
···
···36, 282
PCI ···
···
···
···
···
···
···
···
···
···
···
···
···
···
···
··· 296
PCIバス···
···
···
···
···
···
···
···
···
···
···
···
···
··· 407
Peripheral Component Interconnect
296,
407
Printed Circuit Board ···
···
···
···
···
···36, 282
PROM ···
···
···
···
···
···
···
···
···
···
···
···
···
···
···187
P型シリコン···
···
···
···
···
···
···
···
···
···
···
···
···34
■Q
QDR
···
···
···
···
···
···
···
···
···
···
···
···
···
···
··· 198
QDR-SRAM ···
···
···
···
···
···
···
···
···
···
···
··· 198
Quad Data Rate Dynamic RAM ···
···
···198
Quad Data Rate Static RAM ···
···
···
···
···198
■R
r
···
···
···
···
···
···
···
···
···
···
···
···
···
···
···
···
··· 162
RAM
···
···
···
···
···
···
···
···
···
··· 186, 187, 193
Rambus Dynamic RAM ···
···
···
···
···
···
···198
RDRAM ···
···
···
···
···
···
···
···
···
···
···
···
···
···198
Read Only Memory ···
···
···
···
···
···
···
···
··· 72
read関数···
···
···
···
···
···
···
···
···
···
···
···
···
···334
Reduced Latency Dynamic RAM
···
··· 198
reg A ···
···
···
···
···
···
···
···
···
···
···
···
···
···
··· 108
register ﬁle
···
···
···
···
···
···
···
···
···
···
···
··· 104
REPEAT ···
···
···
···
···
···
···
···
···
···
···
···
···
···182
repeat ···
···
···
···
···
···
···
···
···
···
···
···
···
···
···182
REPプリフィクス···
···
···
···
···
···
···
···
···
···182
ret命令···
···
···
···
···
···
···
···
···
···
···
··· 166, 169
RISC ···
···
···
···
···
···
···
···
···
···
···
···
···
···
···
···86
RISCプロセッサ···
···
···
···
···
···
···
···
···
···
···86
RLDRAM
···
···
···
···
···
···
···
···
···
···
···
···
··· 198
ROM ···
···
···
···
···
···
···
···
···
···
···
···
···
··· 72, 75
RUN状態
···
···
···
···
···
···
···
···
···
···
···
···
··· 391
■S
SDRAM ···
···
···
···
···
···
···
···
···
···
···
···197, 198
seek関数···
···
···
···
···
···
···
···
···
···
···
···
···
···334
setup関数···
···
···
···
···
···
···
···
···
···
···
···
··· 337
SIMD ···
···
···
···
···
···
···
···
···
···
···
···
···350, 351
Single Instruction stream Multiple Data
streams ···
···
···
···
···
···
···
···
···
··· 350
Single Instruction stream Single Data
stream
···
···
···
···
···
···
···
···
···
··· 350
SISD
···
···
···
···
···
···
···
···
···
···
···
···
···
···
··· 350
SMP ···
···
···
···
···
···
···
···
···
···
···
···
···
···
···
···352
SoC ···
···
···
···
···
···
···
···
···
···
···
···
···
···
···35, 76
SPEC ···
···
···
···
···
···
···
···
···
···
···
···
···
···
··· 399
SPECmark ···
···
···
···
···
···
···
···
···
···
···
···
···399
SRAM
···
···
···
···
···
···
···
···
···
···
···
··· 193, 259
SSD
···
···
···
···
···
···
···
···
···
···
···
···
··· 187, 188
SSI ···
···
···
···
···
···
···
···
···
···
···
···
···
···
···
···
···35
SSRAM ···
···
···
···
···
···
···
···
···
···
···
···197, 198
Standard Performance Evaluation
Corporation ···
···
···
···
···
···
···
··· 399
stdio
···
···
···
···
···
···
···
···
···
···
···
···
···
···
··· 341
sumビット
···
···
···
···
···
···
···
···
···
···
···
···
··· 16
Symmetric Multiprocessor
···
···
···
···
··· 352
Synchronous Dynamic RAM
···
···
···
··· 198
Synchronous Dynamic Random Access
Memory ···
···
···
···
···
···
···
···
···
···197
Synchronous Static RAM ···
···
···
···
···
···198
Synchronous Static Random Access
Memory ···
···
···
···
···
···
···
···
···
···197
System on Chip ···
···
···
···
···
···
···
···
···
···
···35
■T
TCAM ···
···
···
···
···
···
···
···
···
···
···
···
···
···
···213
terminate ···
···
···
···
···
···
···
···
···
···
···
···
··· 338
terminate関数···
···
···
···
···
···
···
···
···
···
··· 337
Tianhe-2
···
···
···
···
···
···
···
···
···
···
···
···
··· 363
TLB
···
···
···
···
···
···
···
···
···
···
···
···
··· 260, 262
Transistor-Transistor Logic ···
···
···
···
···
···13
Translation Lookaside Buﬀer ···
···
···
··· 260
tRC ···
···
···
···
···
···
···
···
···
···
···
···
···
···
···
···197
TTL
···
···
···
···
···
···
···
···
···
···
···
···
···
···
···
··· 13
tWC ···
···
···
···
···
···
···
···
···
···
···
···
···
···
···
···197
■U
Unicode
···
···
···
···
···
···
···
···
···
···
···
···
···
··· 46
Universal Serial Bus ···
···
···
···
···
···296, 316
unsigned integer
···
···
···
···
···
···
···
···
···
··· 47
unsigned short integer ···
···
···
···
···
···
···
···67
USB
···
···
···
···
···
···
···
···
···
···
···
···
··· 296, 316
■V
V（ボルト）···
···
···
···
···
···
···
···
···
···
···
···
··· 8
VLSI ···
···
···
···
···
···
···
···
···
···
···
···
···
···
···
··· 35
VM ···
···
···
···
···
···
···
···
···
···
···
···
···
···
···
··· 241
■W
Webロードバランサ···
···
···
···
···
···
···
···
···362
while ···
···
···
···
···
···
···
···
···
···
···
···
···
···
··· 166
whileループ···
···
···
···
···
···
···
···
···
···
···
··· 171
write関数
···
···
···
···
···
···
···
···
···
···
···
···
··· 334
■X
x64 ···
···
···
···
···
···
···
···
···
···
···
···
···
···466, 468
x86-64
···
···
···
···
···
···
···
···
···
···
···
···
···
··· 466
XOR ···
···
···
···
···
···
···
···
···
···
···
···
···
···
···
··· 11
XScale
···
···
···
···
···
···
···
···
···
···
···
···
···
··· 413
■Z
ZBT-SRAM
···
···
···
···
···
···
···
···
···
···
···
··· 198
Zero Bus Turnaround Static RAM ···
···198
■あ
アーキテクチャ···
···
···
···
···
···
···
···
···
···
···
···3
アキュミュレータ···
···
···
···
···
···
···
···
···
···121
アクセス···
···
···
···
···
···
···
···
···
···
···
···
···
···199
アクセスプロトコル
···
···
···
···
···
··· 280, 282
アクティブな機構···
···
···
···
···
···
···
···
···
···219
アセンブラ
···
···
···
···
···
···
···
··· 73, 158, 176
アセンブリ···
···
···
···
···
···
···
···
···
···
···
···
···158
アセンブリ言語···
···
···
···
···
···
···
···
···
···
···158
後入れ先出し···
···
···
···
···
···
···
···
···
···
···
···460
アドレス空間
···
···
···
···
···
···
···
···
··· 205, 288
アドレス衝突···
···
···
···
···
···
···
···
···
···
···
···289
アドレスとデータの多重化···
···
···
···
···
···285
アドレス変換キャッシュ···
···
···
···
···
···
···260
アドレスマップ···
···
···
···
···
···
···
···
···
···
···294
穴···
···
···
···
···
···
···
···
···
···
···
···246, 293, 300
アナログコンピュータ···
···
···
···
···
···
···
···
···7
アムダールの法則···
···
···
···
···
···
···
···
···
···401
アライン···
···
···
···
···
···
···
···
···
···
···
···
···
···204
アラインメント···
···
···
···
···
···
···
···
···
···
···204
アラン・パリス···
···
···
···
···
···
···
···
···
···
···157
アレイプロセッサ···
···
···
···
···
···
···
···
···
···351
アンダーフロー
···
···
···
···
···
···
···
···
···
···
··· 47
アンペア···
···
···
···
···
···
···
···
···
···
···
···
···
···
···8
暗黙···
···
···
···
···
···
···
···
···
···
···
···
···
···
···
···124
暗黙的並列性
···
···
···
···
···
···
···
···
··· 349, 360
暗黙の1ビット···
···
···
···
···
···
···
···
···
···
···
···54
暗黙のオペランド符号化···
···
···
···
···
···
···124
■い
閾値電圧···
···
···
···
···
···
···
···
···
···
···
···
···
···387
維持···
···
···
···
···
···
···
···
···
···
···
···
···
···
···
···197
一枚岩的なプログラム···
···
···
···
···
···
···
···371
イディオム···
···
···
···
···
···
···
···
···
···
···
···
···164
イネーブル
···
···
···
···
···
···
···
···
···
···
···
···
··· 19
イベント···
···
···
···
···
···
···
···
···
···
···
···
···
···312
イミディエート値···
···
···
···
···
···
···
···
···
···123
入り口のコード···
···
···
···
···
···
···
···
···
···
···472
インクリメント···
···
···
···
···
···106, 206, 453
インクリメントステートメント···
···
···
···207
インターセプト···
···
···
···
···
···
···
···
···
···
···218
インターネットサービスプロバイダー···372
インターフェイスコントローラ···
···
···
···271
インターフェイス幅···
···
···
···
···
···
···
···
···272
インターリーブ···
···
···
···
···
···
···
···
···
···
···211
インテリジェンス···
···
···
···
···
···
···
···
···
···304
インバータ
···
···
···
···
···
···
···
···
···
···
···
···
··· 13
インプットとアウトプット···
···
···
···
···
···
···2
隠蔽する···
···
···
···
···
···
···
···
···
···
···
···
···
···324
■う
ウィンドウ···
···
···
···
···
···
···
···
···
···
···95, 332
埋め込みシステム
···
···
···
···
···
···
···
···
···
··· 71
■え
永続···
···
···
···
···
···
···
···
···
···
···
···
···
···
···
···190
エネルギー···
···
···
···
···
···
···
···
···
···
···
···
···382
エブシディク
···
···
···
···
···
···
···
···
···
···
···
··· 45
エレガンス
···
···
···
···
···
···
···
···
···
···
···
···
··· 99
エンコード
···
···
···
···
···
···
···
···
···
···
··· 39, 45
演算···
···
···
···
···
···
···
···
···
···
···
···
···
···57, 107
演算コード···
···
···
···
···
···
···
···
···
···
···81, 159
演算の連鎖···
···
···
···
···
···
···
···
···
···
···
···
···320
■お
オーバーフロー
···
···
···
···
···
···
···
···
··· 16, 47
オプコード
···
···
···
···
···
···
···
···
···
···
···
···
··· 81
オフセット
···
···
···
···
···
···
···
···
···
··· 105, 114
オペコード
···
···
···
···
···
···
···
··· 81, 119, 159
オペランド···
···
···
···
···
···
···
···
···
···
···81, 119
オンデマンド···
···
···
···
···
···
···
···
···
···
···
···390
オンボードスクラッチメモリ···
···
···
···
···413
■か
外部インターフェイス
···
···
···
···
···
···
···
··· 69
回路基板···
···
···
···
···
···
···
···
···
···
···
···
···
···406
回路図
···
···
···
···
···
···
···
···
···
···
···
···
···
···
··· 10
カウンタ
···
···
···
···
···
···
···
···
···
···
···
···
···
··· 23
科学的アプリケーション···
···
···
···
···
···
···396
科学的計算···
···
···
···
···
···
···
···
···
···
···
···
···396
科学的表記法
···
···
···
···
···
···
···
···
···
···
···
··· 52
書き込み···
···
···
···
···
···
···
···
···
···
···
···
···
···196
書き込み可能···
···
···
···
···
···
···
···
···
···
···
···187
拡張値
···
···
···
···
···
···
···
···
···
···
···
···
···
···
··· 84
拡張レジスタ···
···
···
···
···
···
···
···
···
···
···
···448
確定反復···
···
···
···
···
···
···
···
···
···
···
···
···
···165
加重平均···
···
···
···
···
···
···
···
···
···
···
···
···
···397
下層···
···
···
···
···
···
···
···
···
···
···
···
···
···
···
···325
仮想アドレス···
···
···
···
···
···
···
···
···
···
···
···242
仮想アドレス空間···
···
···
···
···
···
···
···
···
···242
仮想バス···
···
···
···
···
···
···
···
···
···
···
···
···
···409
仮想メモリ···
···
···
···
···
···
···
···
···
···
···
···
···241
仮想メモリシステム···
···
···
···
···
···
···
···
···248
型···
···
···
···
···
···
···
···
···
···
···
···
···
···
···
···
···163
カプセル化する···
···
···
···
···
···
···
···
···
···
···324
可変長
···
···
···
···
···
···
···
···
···
···
···
···
···
···
··· 82
空の値···
···
···
···
···
···
···
···
···
···
···
···
···
···
···255
仮数
···
···
···
···
···
···
···
···
···
···
···
···
···
···
···
··· 51
仮パラメータ···
···
···
···
···
···
···
···
···
···
···
···179
カレントプログラムステータスレジスタ470
完結
···
···
···
···
···
···
···
···
···
···
···
···
···
···
···
··· 87
関数
···
···
···
···
···
···
···
···
···
···
···
···
··· 168, 471
関数コール
···
···
···
···
···
···
···
···
···
··· 466, 471
hi.0412.ko.2002@gmail.com
476
　
間接オペランド···
···
···
···
···
···
···
···
···
···
···209
間接参照
···
···
···
···
···
···
···
···
···
···
··· 128, 209
完全一致···
···
···
···
···
···
···
···
···
···
···
···
···
···212
■き
記憶階層
···
···
···
···
···
···
···
···
···
···
··· 188, 189
ギガバイト···
···
···
···
···
···
···
···
···
···
···
···
···206
木構造···
···
···
···
···
···
···
···
···
···
···
···
···
···
···206
疑似命令···
···
···
···
···
···
···
···
···
···
···
···
···
···170
基数
···
···
···
···
···
···
···
···
···
···
···
···
···
···
···
··· 52
機能ユニット
···
···
···
···
···
···
···
···
··· 113, 135
揮発性
···
···
···
···
···
···
···
···
···
···
···
··· 186, 190
ギャザーライト···
···
···
···
···
···
···
···
···
···
···320
キャッシュ···
···
···
···
···
···
···
···
···
···
···
···
···188
キャッシュ一貫性プロトコル···
···
···
···
···227
キャッシュ行···
···
···
···
···
···
···
···
···
···
···
···231
キャッシュヒット···
···
···
···
···
···
···
···
···
···219
キャッシュミス···
···
···
···
···
···
···
···
···
···
···219
キャッシング···
···
···
···
···
···
···
···
···
···
···
···218
キャパシタンス···
···
···
···
···
···
···
···
···
···
···384
キャラクタ
···
···
···
···
···
···
···
···
···
···
···
···
··· 45
キャリー
···
···
···
···
···
···
···
···
···
···
···
···
···
··· 47
キュー···
···
···
···
···
···
···
···
···
···187, 206, 328
境界···
···
···
···
···
···
···
···
···
···
···
···
···
···
···
···250
境界レジスタ···
···
···
···
···
···
···
···
···
···
···
···250
競合···
···
···
···
···
···
···
···
···
···
···
···
···
···
···
···356
競合する···
···
···
···
···
···
···
···
···
···
···
···
···
···356
協調···
···
···
···
···
···
···
···
···
···
···
···
···
···
···
···356
共有···
···
···
···
···
···
···
···
···
···
···
···
···
···
···
···280
行優先の順序···
···
···
···
···
···
···
···
···
···
···
···261
共有変数群···
···
···
···
···
···
···
···
···
···
···
···
···325
局所性···
···
···
···
···
···
···
···
···
···
···
···
···
···
···219
巨視的アーキテクチャ···
···
···
···
···
···
···
···405
巨視的並列性···
···
···
···
···
···
···
···
···
···
···
···348
キロバイト···
···
···
···
···
···
···
···
···
···
···
···
···206
銀行丸めアルゴリズム
···
···
···
···
···
···
···
··· 59
金属酸化物半導体···
···
···
···
···
···
···
···
···
···
···8
■く
クアッドコア···
···
···
···
···
···
···
···
···
···
···
···349
クエリーエンジン
···
···
···
···
···
···
···
···
···
··· 67
矩形波
···
···
···
···
···
···
···
···
···
···
···
···
··· 20, 24
組み合わせ回路
···
···
···
···
···
···
···
···
···
···
··· 18
クラスタコンピュータ···
···
···
···
···
···
···
···362
グラフィックスアクセラレータ
···
···
···
··· 67
グラフィックスエンジン
···
···
···
···
···
···
··· 67
グランド···
···
···
···
···
···
···
···
···
···
···
···
···
···
···8
繰り上げ
···
···
···
···
···
···
···
···
···
···
···
···
···
··· 16
繰り返しブロック機能···
···
···
···
···
···
···
···182
グリッドコンピューティング···
···
···
···
···362
クロスバースイッチ···
···
···
···
···
···
···
···
···298
クロック···
···
···
···
···
···
···
···
···
··· 18, 24, 384
クロックゲーティング···
···
···
···
···
···
···
···389
クロック周波数···
···
···
···
···
···
···
···
···
···
···387
クロック信号のタイミングのずれ
···
···
··· 32
クロックスキュー
···
···
···
···
···
···
···
···
···
··· 32
クロック同期
···
···
···
···
···
···
···
···
···
···
···
··· 33
クロックドメインクロッシング
···
···
···
··· 33
クロック領域
···
···
···
···
···
···
···
···
···
···
···
··· 33
クロックレスロジック
···
···
···
···
···
···
···
··· 33
■け
計算エンジン
···
···
···
···
···
···
···
···
···
···
···
··· 67
経路···
···
···
···
···
···
···
···
···
···
···
···
···
···
···
···8, 9
ゲート···
···
···
···
···
···
···
···
···
···
···
···
···
···
···
···9
ゲート遅延···
···
···
···
···
···
···
···
···
···
···
···
···387
桁あふれ
···
···
···
···
···
···
···
···
···
···
···
···
···
··· 16
ゲタをはかせる
···
···
···
···
···
···
···
···
···
···
··· 53
検索キー···
···
···
···
···
···
···
···
···
···
···
···
···
···212
■こ
コア
···
···
···
···
···
···
···
···
···
···
···
···
··· 134, 469
高水準言語···
···
···
···
···
···
···
···
··· 73, 94, 156
構成···
···
···
···
···
···
···
···
···
···
···
···
···
···
···
···186
構成要素
···
···
···
···
···
···
···
···
···
···
···
···
···
··· 36
構造体···
···
···
···
···
···
···
···
···
···
···
···
···
···
···309
構造体宣言···
···
···
···
···
···
···
···
···
···
···
···
···208
高速化···
···
···
···
···
···
···
···
···
···
···
···
···
···
···357
高速データレート···
···
···
···
···
···
···
···
···
···198
恒等写像
···
···
···
···
···
···
···
···
···
···
···
···
···
··· 30
構文形式···
···
···
···
···
···
···
···
···
···
···
···
···
···163
後方互換性···
···
···
···
···
···
···
···136, 152, 406
ゴードン・ムーア
···
···
···
···
···
···
···
···
···
··· 35
固定長
···
···
···
···
···
···
···
···
···
···
···
···
···
···
··· 82
固定長命令
···
···
···
···
···
···
···
···
···
···
···
···
··· 82
固定ロジックのプロセッサ
···
···
···
···
···
··· 66
コプロセッサ
···
···
···
···
···
···
···
···
···
···
···
··· 70
コマンド···
···
···
···
···
···
···
···
···
···
···
···
···
···144
混成物···
···
···
···
···
···
···
···
···
···
···
···
···
···
···349
コンデンサ···
···
···
···
···
···
···
···
···
···
···
···
···194
コントローラ···
···
···
···
···
···
···
···
···
···69, 113
コントローラチップ···
···
···
···
···
···
···
···
···408
コントロールレジスタ···
···
···
···
···
···
···
···308
コンパイラ
···
···
···
···
···
···
···
···
···
···
···
···
··· 73
コンパレータチップ···
···
···
···
···
···
···
···
···423
コンパレータ回路···
···
···
···
···
···
···
···
···
···235
コンピュータ性能···
···
···
···
···
···
···
···
···
···400
コンフリクト
···
···
···
···
···
···
···
···
···
···
···
··· 85
■さ
再開···
···
···
···
···
···
···
···
···
···
···
···
···
···
···
···311
最下位ビット
···
···
···
···
···
···
···
···
···
···
···
··· 43
最高性能メモリ···
···
···
···
···
···
···
···
···
···
···188
最上位ビット
···
···
···
···
···
···
···
···
···
···
···
··· 43
サイズディレクティブ···
···
···
···
···
···
···
···459
再配置可能
···
···
···
···
···
···
···
···
···
···
···
···
··· 73
細粒度の並列性···
···
···
···
···
···
···
···
···
···
···349
サインと絶対値
···
···
···
···
···
···
···
···
···
···
··· 49
サイン波
···
···
···
···
···
···
···
···
···
···
···
···
···
··· 24
サインビット
···
···
···
···
···
···
···
···
···
···
···
··· 49
サウスブリッジ···
···
···
···
···
···
···
···
···
···
···409
作業負荷···
···
···
···
···
···
···
···
···
···
···
···
···
···398
先読み···
···
···
···
···
···
···
···
···
···
···
···
···
···
···148
サスペンド···
···
···
···
···
···
···
···
···
···
···
···
···311
サブルーチン···
···
···
···
···
···
···
···
···
···94, 166
サブルーチンコール···
···
···
···
···
···
···
···
···166
サブルーチン呼び出し···
···
···
···
···
···
···
···463
サブルーチン呼び出し命令···
···
···
···
···
···166
算術オーバーフロー
···
···
···
···
···
···
···
···
··· 54
算術コプロセッサ···
···
···
···
···
···
···
···
···
···354
算術論理演算装置
···
···
···
···
···
···
···
···
···
··· 69
■し
シーケンシャルアクセス
···
···
···
··· 187, 190
シーケンシャルサーキット
···
···
···
···
···
··· 19
シーケンシャルな実行···
···
···
···
···
···
···
···149
シーケンス
···
···
···
···
···
···
···
···
···
···
···
···
··· 24
ジーン・アムダール···
···
···
···
···
···
···
···
···401
自己放電···
···
···
···
···
···
···
···
···
···
···
···
···
···386
指数
···
···
···
···
···
···
···
···
···
···
···
···
···
···
···
··· 51
シスク
···
···
···
···
···
···
···
···
···
···
···
···
···
···
··· 86
システムコール···
···
···
···
···
···
···
···
···
···
···335
システムコントローラ···
···
···
···
···
···
···
···409
システムレベル・アーキテクチャ···
···
···405
実行コンテクスト···
···
···
···
···
···
···
···
···
···313
実行する
···
···
···
···
···
···
···
···
···
···
···
···
···
··· 80
実行パイプライン
···
···
···
···
···
···
···
···
···
··· 87
実行モード
···
···
···
···
···
···
···
···
···
··· 135, 248
実装···
···
···
···
···
···
···
···
···
···
···
···
···
···
···
···
···3
自動運転
···
···
···
···
···
···
···
···
···
···
···
···
···
··· 24
自動的な最適化
···
···
···
···
···
···
···
···
···
···
··· 91
遮断···
···
···
···
···
···
···
···
···
···
···
···
···
···
···
···390
シャットダウン···
···
···
···
···
···
···
···
···
···
···391
主···
···
···
···
···
···
···
···
···
···
···
···
···
···
···
···
···353
従···
···
···
···
···
···
···
···
···
···
···
···
···
···
···
···
···353
集合体
···
···
···
···
···
···
···
···
···
···
···
···
···
···
··· 56
集積回路···
···
···
···
···
···
···
···
···
··· 17, 34, 406
終端を示すゼロ···
···
···
···
···
···
···
···
···
···
···457
集中···
···
···
···
···
···
···
···
···
···
···
···
···
···
···
···133
周辺プロセッサ···
···
···
···
···
···
···
···
···
···
···354
ジュール···
···
···
···
···
···
···
···
···
···
···
···
···
···382
主記憶···
···
···
···
···
···
···
···
···
···
···
···
···
···
···185
主従関係···
···
···
···
···
···
···
···
···
···
···
···
···
···353
出力選択···
···
···
···
···
···
···
···
···
···
···
···
···
···422
受動的···
···
···
···
···
···
···
···
···
···
···
···
···
···
···281
瞬時電力···
···
···
···
···
···
···
···
···
···
···
···
···
···382
順序回路
···
···
···
···
···
···
···
···
···
···
···
···
···
··· 19
条件コード
···
···
···
···
···
···
···
··· 99, 164, 462
条件実行···
···
···
···
···
···
···
···
···
···
···
···
···
···164
条件分岐···
···
···
···
···
···
···
···
···
···
···
···99, 462
上層···
···
···
···
···
···
···
···
···
···
···
···
···
···
···
···325
状態
···
···
···
···
···
···
···
···
···
···
···
···
···
··· 19, 99
状態レジスタ···
···
···
···
···
···
···
···
···
···
···
···308
冗長ハードウェア···
···
···
···
···
···
···
···
···
···361
省電力ポーリング···
···
···
···
···
···
···
···
···
···392
衝突
···
···
···
···
···
···
···
···
···
···
···
···
···
···
···
··· 85
蒸発···
···
···
···
···
···
···
···
···
···
···
···
···
···
···
···386
剰余···
···
···
···
···
···
···
···
···
···
···
···
···
···
···
···454
シリアル
···
···
···
···
···
···
···
···
···
···
··· 272, 281
シリアルバス···
···
···
···
···
···
···
···
···
···
···
···284
シングルコア···
···
···
···
···
···
···
···
···
···
···
···134
シングルプロセッサ···
···
···
···
···
···
···
···
···375
シンボルテーブル···
···
···
···
···
···
···
···
···
···177
真理値表
···
···
···
···
···
···
···
···
···
···
···
··· 11, 15
■す
垂直アーキテクチャ···
···
···
···
···
···
···
···
···142
垂直マイクロコード···
···
···
···
···
···
···
···
···142
スイッチング···
···
···
···
···
···
···
···
···
···
···
···383
スイッチングファブリック···
···
···
···
···
···298
水平マイクロコード···
···
···
···
···
···
···
···
···143
数値演算コプロセッサ
···
···
···
···
···
···
···
··· 70
スーパーコンピュータ···
···
···
···
···
···
···
···363
スーパーパイプライン···
···
···
···
···
···
···
···378
スキャッターリード···
···
···
···
···
···
···
···
···320
スケジューリング···
···
···
···
···
···
···
···
···
···149
スコアボード···
···
···
···
···
···
···
···
···
···
···
···150
少しだけ遅いメモリ···
···
···
···
···
···
···
···
···188
スタックアーキテクチャ···
···
···
···
···
···
···120
スタティックRAM ···
···
···
···
···
···
···193, 194
ステージ···
···
···
···
···
···
···
···
···
···
···
···
···
···367
ステータス
···
···
···
···
···
···
···
···
···
···
···
···
··· 99
ステータスレジスタ···
···
···
···
···
···
···
···
···308
ステートメント···
···
···
···
···
···
···
···
···
···
···156
ストア
···
···
···
··· 2, 83, 137, 189, 284, 347
ストア演算
···
···
···
···
···
···
···
···
···
··· 190, 225
ストアドプログラム型
···
···
···
···
···
···
···
··· 57
ストール···
···
···
···
···
···
···
···
···
··· 89, 91, 378
ストレージ···
···
···
···
···
···
···
···
···
···
···
···
···185
ストレージの階層構造···
···
···
···
···
···
···
···185
スマートデバイス···
···
···
···
···
···
···
···
···
···317
スリープ
···
···
···
···
···
···
···
···
···
···
··· 390, 391
スリープモード···
···
···
···
···
···
···
···
···
···
···390
スループット···
···
···
···
···
···
···
···
···
···
···
···273
スロット···
···
···
···
···
···
···
···
···
···
···
···
···
···212
■せ
正規化
···
···
···
···
···
···
···
···
···
···
···
···
···
···
··· 52
制御ビット···
···
···
···
···
···
···
···
···
···
···
···
···258
制御レジスタ···
···
···
···
···
···
···
···
···
···
···
···308
制限付きのパラレル···
···
···
···
···
···
···
···
···274
正弦波
···
···
···
···
···
···
···
···
···
···
···
···
···
···
··· 24
hi.0412.ko.2002@gmail.com
　索　引
477
性能の線形な向上···
···
···
···
···
···
···
···
···
···357
整列アクセス···
···
···
···
···
···
···
···
···
···
···
···204
セカンダリメモリ···
···
···
···
···
···
···
···
···
···188
セグメンテーション···
···
···
···
···
···
···
···
···252
セグメント···
···
···
···
···
···
···
···
···
···
···
···
···252
設計···
···
···
···
···
···
···
···
···
···
···
···
···
···
···
···
···3
絶対分岐
···
···
···
···
···
···
···
···
···
···
···
···
···
··· 93
セットアソシアティブ式メモリキャッシュ236
セットアップタイム···
···
···
···
···
···
···
···
···377
接頭辞
···
···
···
···
···
···
···
···
···
···
···
···
···
···
··· 44
セトリング
···
···
···
···
···
···
···
···
···
···
···
···
··· 32
セルフクロッキング···
···
···
···
···
···
···
···
···272
線···
···
···
···
···
···
···
···
···
···
···
···
···
···
···
···
···283
遷移図
···
···
···
···
···
···
···
···
···
···
···
···
···
···
··· 21
全加算器
···
···
···
···
···
···
···
···
···
···
···
···
···
··· 17
宣言···
···
···
···
···
···
···
···
···
···
···
···
···
···
···
···162
先行ゼロ
···
···
···
···
···
···
···
···
···
···
···
···
···
··· 52
選択可能なロジックのプロセッサ
···
···
··· 66
全二重インターフェイス···
···
···
···
···
···
···273
前方参照···
···
···
···
···
···
···
···
···
···
···
···
···
···177
■そ
相互排他···
···
···
···
···
···
···
···
···
···
···
···
···
···359
相互配置···
···
···
···
···
···
···
···
···
···
···
···
···
···211
走査···
···
···
···
···
···
···
···
···
···
···
···
···
···
···
···177
相対加重···
···
···
···
···
···
···
···
···
···
···
···
···
···398
相対分岐命令
···
···
···
···
···
···
···
···
···
···
···
··· 93
挿抜可能な···
···
···
···
···
···
···
···
···
···
···
···
···316
双方向転送···
···
···
···
···
···
···
···
···
···
···
···
···273
相補型···
···
···
···
···
···
···
···
···
···
···
···
···
···
···
···9
相補型金属酸化膜半導体
···
···
···
···
···
···
··· 34
ソース···
···
···
···
···
···
···
···
···
···
···
···
···
···
···
···9
ソースコード
···
···
···
···
···
···
···
···
···
···
···
··· 73
ソースレジスタ···
···
···
···
···
···
···
···
···
···
···161
ソースレジスタ群···
···
···
···
···
···
···
···
···
···105
即値
···
···
···
···
···
···
···
···
···
···
···
···
··· 123, 163
疎結合···
···
···
···
···
···
···
···
···
···
···
···
···
···
···362
ソフトウェアパイプライン
···
···
··· 370, 371
ソフトエラー···
···
···
···
···
···
···
···
···
···
···
···318
ソフトパワースイッチ
···
···
···
···
···
···
···
··· 76
粗粒度の並列性···
···
···
···
···
···
···
···
···
···
···349
損益分岐点···
···
···
···
···
···
···
···
···
···
···
···
···392
存在ビット···
···
···
···
···
···
···
···
···
···
···
···
···258
■た
ターゲットレジスタ···
···
···
···
···
···
···
···
···161
ダーティビット···
···
···
···
···
···
···
···
···
···
···226
ターボ・ブースト···
···
···
···
···
···
···
···
···
···388
ダイオード
···
···
···
···
···
···
···
···
···
···
···
···
··· 12
対称性···
···
···
···
···
···
···
···
···
···
···
···
···
···
···361
対称的並列性···
···
···
···
···
···
···
···
···
···
···
···348
対称的マルチプロセッサ···
···
···
···
···
···
···361
ダイナミックRAM
···
···
···
···
···
···
···
···
··· 194
タイミング
···
···
···
···
···
···
···
···
···
···
···
···
··· 32
タイムアウト機構···
···
···
···
···
···
···
···
···
···289
ダイレクトマップ式メモリキャッシュ···231
高い参照局所性···
···
···
···
···
···
···
···
···
···
···219
タグ···
···
···
···
···
···
···
···
···
···
···
···
···
···
···
···232
多重化
···
···
···
···
···
···
···
···
···
···
···
··· 274, 285
多重化の長所···
···
···
···
···
···
···
···
···
···
···
···286
多重キャッシュ···
···
···
···
···
···
···
···
···
···
···228
多層
···
···
···
···
···
···
···
···
···
···
···
···
···
···
···
··· 36
多段キャッシュの階層構造···
···
···
···
···
···223
立ち上がりエッジ
···
···
···
···
···
···
···
···
···
··· 22
立ち上がる
···
···
···
···
···
···
···
···
···
···
···
···
··· 22
立ち下がりエッジ
···
···
···
···
···
···
···
···
···
··· 22
ダムデバイス···
···
···
···
···
···
···
···
···
···
···
···317
端子···
···
···
···
···
···
···
···
···
···
···
···
···
···
···
···
···9
単精度
···
···
···
···
···
···
···
···
···
···
···
···
···
···
··· 52
短絡電力···
···
···
···
···
···
···
···
···
···
···
···
···
···383
■ち
遅延···
···
···
···
···
···
···
···
···
···
···
···
···
···
···
···320
力···
···
···
···
···
···
···
···
···
···
···
···
···
···
···
···
···381
置換ポリシー
···
···
···
···
···
···
···
···
··· 222, 262
チップレベル・アーキテクチャ···
···
···
···405
チャネル
···
···
···
···
···
···
···
···
···
···
···
··· 9, 355
チャンク···
···
···
···
···
···
···
···
···
···
···
···
···
···275
中央処理装置···
···
···
···
···
···
···
···
···
···
···
···133
駐在している···
···
···
···
···
···
···
···
···
···
···
···255
抽象···
···
···
···
···
···
···
···
···
···
···
···
···
···39, 332
直列アーキテクチャ···
···
···
···
···
···
···
···
···350
直交性
···
···
···
···
···
···
···
···
···
···
···
···
···
···
··· 99
直交的
···
···
···
···
···
···
···
···
···
···
···
···
···
···
··· 99
■つ
通信···
···
···
···
···
···
···
···
···
···
···
···
···
···
···
···355
使っていないビット
···
···
···
···
···
···
···
···
··· 82
ツリー···
···
···
···
···
···
···
···
···
···
···
···
···
···
···206
■て
ディープスリープ···
···
···
···
···
···
···
···
···
···390
定義···
···
···
···
···
···
···
···
···
···
···
···
···
···
···
···178
抵抗
···
···
···
···
···
···
···
···
···
···
···
···
···
···
···
··· 12
低水準言語···
···
···
···
···
···
···
···
···
···
···
···
···157
定数···
···
···
···
···
···
···
···
···
···
···
···
···
···
···
···163
ディスクのブロック···
···
···
···
···
···
···
···
···320
低電力モード···
···
···
···
···
···
···
···
···
···
···
···390
ディレクティブ···
···
···
···
···
···
···
···
···
···
···170
ディレクトリテーブル···
···
···
···
···
···
···
···266
データキャッシュ···
···
···
···
···
···
···
···
···
···230
データストア···
···
···
···
···
···
···
···
···
···
···
···189
データ転送···
···
···
···
···
···
···
···
···
···
···
···
···271
データ転送機構···
···
···
···
···
···
···
···
···
···
···144
データの経路
···
···
···
···
···
···
···
···
···
···
···
··· 72
データの多重化···
···
···
···
···
···
···
···
···
···
···285
データのローカルストレージ
···
···
···
···
··· 69
データパイプライン···
···
···
···
···
···
···
···
···372
データパス69, 72, 104, 110, 143, 144, 204
データパス図···
···
···
···
···
···
···
···
···
···
···
···104
出口のコード···
···
···
···
···
···
···
···
···
···
···
···473
テクノロジー···
···
···
···
···
···
···
···
···
···
···
···186
デクリメント···
···
···
···
···
···
···
···
···
···
···
···453
デコーダ
···
···
···
···
···
···
···
···
···
···
···
···
···
··· 25
デジタル回路···
···
···
···
···
···
···
···
···
···
···
···347
デジタルコンピュータ···
···
···
···
···
···
···
···
···7
デジタルロジック
···
···
···
···
···
···
···
···
···
··· 37
デジタル論理
···
···
···
···
···
···
···
···
···
···
···
··· 24
デスティネーションレジスタ···
···
···
···
···105
テスト&セット命令···
···
···
···
···
···
···
···
···331
手続き型言語···
···
···
···
···
···
···
···
···
···
···
···463
デバイス独立···
···
···
···
···
···
···
···
···
···
···
···324
デバイスドライバ···
···
···
···
···137, 323, 324
デバイスに依存しないインターフェイス324
デマルチプレククサ
···
···
···
···
···
···
···
···
··· 25
デマルチプレクサ···
···
···
···
···
···
···
···
···
···274
デマンド···
···
···
···
···
···
···
···
···
···
···
···
···
···253
デマンドページの置換···
···
···
···
···
···
···
···262
デマンドページング···
···
···
···
···
···
···
···
···253
デマンドページングシステム···
···
···
···
···260
デュアルプロセッサ···
···
···
···
···
···
···
···
···349
デューティサイクル···
···
···
···
···
···
···
···
···392
デリファレンス···
···
···
···
···
···
···
···
···
···
···206
電圧···
···
···
···
···
···
···
···
···
···
···
···
···
···
···
···
···8
電圧計···
···
···
···
···
···
···
···
···
···
···
···
···
···
···
···8
展開···
···
···
···
···
···
···
···
···
···
···
···
···
···
···
···178
電界効果トランジスタ···
···
···
···
···
···
···
···
···8
天河二号···
···
···
···
···
···
···
···
···
···
···
···
···
···363
電気エネルギー···
···
···
···
···
···
···
···
···
···
···382
転送···
···
···
···
···
···
···
···
···
···
···
···
···
···
···
···372
転送能力···
···
···
···
···
···
···
···
···
···
···
···
···
···273
伝搬遅延
···
···
···
···
···
···
···
···
···
···
···
···
···
··· 19
電流···
···
···
···
···
···
···
···
···
···
···
···
···
···
···
···
···8
電力
···
···
···
···
···
···
···
···
···
···
···
···
··· 381, 382
電力の壁···
···
···
···
···
···
···
···
···
···
···
···
···
···386
電力密度···
···
···
···
···
···
···
···
···
···
···
···
···
···385
電力量···
···
···
···
···
···
···
···
···
···
···
···
···
···
···382
■と
同期···
···
···
···
···
···
···
···
···
···
···
···
···
···
···
···304
同期式
···
···
···
···
···
···
···
···
···
···
···
··· 311, 331
同期式DRAM ···
···
···
···
···
···
···
···
···
···
···
···197
同期式SRAM ···
···
···
···
···
···
···
···
···
···
···
···197
同期式クロックシステム···
···
···
···
···
···
···197
同期式プログラミング···
···
···
···
···
···
···
···331
同期的なパイプライン···
···
···
···
···
···
···
···368
透明
···
···
···
···
···
···
···
···
···
···
···
···
··· 219, 312
独自設計···
···
···
···
···
···
···
···
···
···
···
···
···
···280
特別なソケット···
···
···
···
···
···
···
···
···
···
···289
特権
···
···
···
···
···
···
···
···
···
···
···
···
··· 134, 137
トラップ···
···
···
···
···
···
···
···
···
···
···
···
···
···335
トランジスタ···
···
···
···
···
···
···
···
···
···
···
···
···8
トランスペアレント
70, 88, 219, 296, 407
トランスレーションルックアサイドバッファ
···
···
···
···
···
···
···
···
···
···
···
···
···
··· 260
ドレイン···
···
···
···
···
···
···
···
···
···
···
···
···
···
···9
■な
内部の相互接続
···
···
···
···
···
···
···
···
···
···
··· 69
内部バス···
···
···
···
···
···
···
···
···
···
···
···
···
···281
ナノセカンド···
···
···
···
···
···
···
···
···
···
···
···273
名前···
···
···
···
···
···
···
···
···
···
···
···
···
···
···
···170
■に
ニーモニック
···
···
···
···
···
···
···
···
··· 105, 159
二重間接参照···
···
···
···
···
···
···
···
···
···
···
···128
ニブル
···
···
···
···
···
···
···
···
···
···
···
···
···
···
··· 56
入出力
···
···
···
···
···
···
···
···
···
···
···
···
··· 2, 133
入出力に束縛される···
···
···
···
···
···
···
···
···357
■ね
ネットワーククラスタ···
···
···
···
···
···
···
···362
■の
ノイマン型
···
···
···
···
···
···
···
···
···
···
···
···
··· 64
能動的な機構···
···
···
···
···
···
···
···
···
···
···
···219
ノースブリッジ···
···
···
···
···
···
···
···
···
···
···409
■は
バースト···
···
···
···
···
···
···
···
···
···
···
···
···
···319
パーティション···
···
···
···
···
···
···
···
···
···
···248
ハードウェアリセット
···
···
···
···
···
···
···
··· 75
ハードウェアロック···
···
···
···
···
···
···
···
···359
ハードワイヤド
···
···
···
···
···
···
···
···
···
···
··· 66
ハーバード・アーキテクチャ··· 63‒65, 189
ハーフアダー···
···
···
···
···
···
···
···
···
···16, 419
バイアス
···
···
···
···
···
···
···
···
···
···
···
···
···
··· 52
バイアス定数
···
···
···
···
···
···
···
···
···
···
···
··· 53
倍精度
···
···
···
···
···
···
···
···
···
···
···
···
··· 52, 84
排他使用権···
···
···
···
···
···
···
···
···
···
···
···
···359
排他制御
···
···
···
···
···
···
···
···
···
···
··· 331, 359
排他的論理和
···
···
···
···
···
···
···
···
···
··· 11, 29
配電回路
···
···
···
···
···
···
···
···
···
···
···
···
···
··· 31
バイト
···
···
···
···
···
···
···
···
···
···
···
···
···
···
··· 40
バイトアドレッシング···
···
···
···
···
···
···
···201
バイト整列···
···
···
···
···
···
···
···
···
···
···
···
···204
バイトの配列···
···
···
···
···
···
···
···
···
···
···
···201
ハイバーネーション···
···
···
···
···
···
···
···
···390
ハイパーバイザ···
···
···
···
···
···
···
···
···
···
···152
パイプ···
···
···
···
···
···
···
···
···
···
···
···
···
···
···368
パイプライン···
···
···
···
···
···
···
···
··· 2, 87, 91
パイプラインアーキテクチャ···
···
···
···
···377
パイプライン式コンピュータ···
···
···
···
···345
パイプライン処理
···
···
···
···
···
···
··· 367, 368
hi.0412.ko.2002@gmail.com
478
　
パイプラインの実装···
···
···
···
···
···
···
···
···369
パイプラインを通過···
···
···
···
···
···
···
···
···369
ハイブリッド···
···
···
···
···
···
···
···
···
···
···
···349
配列···
···
···
···
···
···
···
···
···
···
···
···
···
···48, 351
配列の巡回処理···
···
···
···
···
···
···
···
···
···
···106
バス···
···
···
···
···
···
···
···
···
···
···144, 199, 279
パス···
···
···
···
···
···
···
···
···
···
···
···
···
···
···
···
···8
バスアービタ···
···
···
···
···
···
···
···
···
···
···
···281
バスインターフェイス···
···
···
···
···
···
···
···282
バスエラー···
···
···
···
···
···
···
···
···
···
···
···
···288
バスコントローラ···
···
···
···
···
···
···
···
···
···282
パターンエンジン
···
···
···
···
···
···
···
···
···
··· 67
パッシブ···
···
···
···
···
···
···
···
···
···
···
···
···
···281
発振
···
···
···
···
···
···
···
···
···
···
···
···
···
···
···
··· 20
バッファ
···
···
···
···
···
···
···
···
···
···
··· 336, 369
バッファ付きI/Oライブラリ···
···
···
···
··· 337
バッファ付き出力関数···
···
···
···
···
···
···
···337
バッファの連鎖···
···
···
···
···
···
···
···
···
···
···319
バッファリング···
···
···
···
···
···
···
···
···
···
···336
バッファをフラッシュする···
···
···
···
···
···338
幅···
···
···
···
···
···
···
···
···
···
···
···
···
···
···
···
···284
バブル
···
···
···
···
···
···
···
···
···
···
···
···
···
···
··· 89
パラメータ···
···
···
···
···
···
···
···
···
···
···
···
···418
パラメータ化されたロジックのプロセッサ66
パラメータ付きマクロ···
···
···
···
···
···
···
···178
パラレル
···
···
···
···
···
···
···
···
···
···
··· 272, 281
パラレル接続···
···
···
···
···
···
···
···
···
···
···
···199
パラレルハードウェア···
···
···
···
···
···
···
···345
パワーゲーティング···
···
···
···
···
···
···
···
···389
半加算器
···
···
···
···
···
···
···
···
···
···
···
···
···
··· 16
バンク···
···
···
···
···
···
···
···
···
···
···
···
···84, 210
半二重インターフェイス···
···
···
···
···
···
···273
反復
···
···
···
···
···
···
···
···
···
···
···
···
···
···
···
··· 29
汎用プロセッサ
···
···
···
···
···
···
···
···
···
···
··· 71
汎用レジスタ···
···
···
···
···
···
···
···
···
···83, 448
汎用ロジックIC ···
···
···
···
···
···
···
···
···
···
··· 17
■ひ
ピーク瞬時電力···
···
···
···
···
···
···
···
···
···
···382
非永続···
···
···
···
···
···
···
···
···
···
···
···
···
···
···190
引数
···
···
···
···
···
···
···
···
···
···
··· 94, 167, 418
低い参照局所性···
···
···
···
···
···
···
···
···
···
···219
低いレベルのコード···
···
···
···
···
···
···
···
···324
微視的···
···
···
···
···
···
···
···
···
···
···
···
···
···
···347
微視的アーキテクチャ···
···
···
···
···
···
···
···405
微視的並列性···
···
···
···
···
···
···
···
···
···
···
···346
非整列アドレス···
···
···
···
···
···
···
···
···
···
···204
非対称
···
···
···
···
···
···
···
···
···
···
···
··· 292, 348
ビッグエンディアン
···
···
···
···
···
···
···
···
··· 48
ヒット···
···
···
···
···
···
···
···
···
···
···
···
···
···
···219
ビット
···
···
···
···
···
···
···
···
···
···
···
···
··· 40, 57
ビット直列処理···
···
···
···
···
···
···
···
···
···
···347
ビットの終わり
···
···
···
···
···
···
···
···
···
···
··· 33
ビットパターン
···
···
···
···
···
···
···
···
···
···
··· 40
ビット番号
···
···
···
···
···
···
···
···
···
···
···
···
··· 52
ビットビッグエンディアン
···
···
···
···
···
··· 48
ヒット率···
···
···
···
···
···
···
···
···
···
···
···
···
···221
ビットリトルエンディアン
···
···
···
···
···
··· 48
非同期式
···
···
···
···
···
···
···
···
···
···
··· 311, 331
非同期式プログラミング···
···
···
···
···
···
···331
標準I/Oライブラリ···
···
···
···
···
···
···
···
··· 341
標準化されたバス···
···
···
···
···
···
···
···
···
···280
ビルディングブロック···
···
···
···
···
···
···
···103
ピン配置図
···
···
···
···
···
···
···
···
···
···
···
···
··· 35
■ふ
ファイル···
···
···
···
···
···
···
···
···
···
···
···
···
···332
ファンアウト
···
···
···
···
···
···
···
···
···
···
···
··· 13
フィードバック
···
···
···
···
···
···
···
···
···
···
··· 27
フィードバックループ
···
···
···
···
···
···
···
··· 27
フィボナッチ数列···
···
···
···
···
···
···
···
···
···170
ブートストラップ
···
···
···
···
···
···
···
···
···
··· 75
ブール式の最小化
···
···
···
···
···
···
···
···
···
··· 15
ブール代数
···
···
···
···
···
···
···
···
···
···
···
···
··· 10
フェッチ···
···
···
···
···
···
··· 83, 189, 284, 347
フェッチ‒ 実行サイクル···
···
···
···
···
···
··· 72
フェッチ演算···
···
···
···
···
···
···
···
···
···
···
···308
フェッチとストア
···
···
···
···
···
···
··· 189, 284
フォワーディング···
···
···
···
···
···
···
···92, 372
フォン・ノイマン・アーキテクチャ
63, 64,
124, 189
フォン・ノイマンのボトルネック···
···
···218
負荷···
···
···
···
···
···
···
···
···
···
···
···
···
···
···
···386
不確定反復···
···
···
···
···
···
···
···
···
···
···
···
···166
不揮発性
···
···
···
···
···
···
···
···
···
···
··· 187, 190
不揮発性RAM
···
···
···
···
···
···
···
···
···
···
··· 187
複数の命令セット···
···
···
···
···
···
···
···
···
···134
複数の割り込み優先順位···
···
···
···
···
···
···315
複数レベルの割り込み機構···
···
···
···
···
···315
複製
···
···
···
···
···
···
···
···
···
···
···
···
···
···
···
··· 29
符号化
···
···
···
···
···
···
···
···
···
···
···
···
···
···
··· 39
符号なし整数
···
···
···
···
···
···
···
···
···
···
···
··· 47
符号なしの短い整数型
···
···
···
···
···
···
···
··· 67
プッシュ···
···
···
···
···
···
···
···
···
···
···
···
···
···460
物理メモリアドレス···
···
···
···
···
···
···
···
···200
物理メモリシステム···
···
···
···
···
···
···
···
···347
浮動小数点···
···
···
···
···
···
···
···
···
···
···51, 396
浮動小数点演算アクセラレータ
···
···
···
··· 70
浮動小数点演算の平均···
···
···
···
···
···
···
···396
浮動小数点レジスタ
···
···
···
···
···
···
···
···
··· 83
負のゼロ
···
···
···
···
···
···
···
···
···
···
···
···
···
··· 49
部分一致検索···
···
···
···
···
···
···
···
···
···
···
···213
プライマリメモリ···
···
···
···
···
···
···
···
···
···188
フラグメンテーション···
···
···
···
···
···
···
···252
フラッシュ
···
···
···
···
···
···
···
···
···
··· 263, 378
フラッシュする必要···
···
···
···
···
···
···
···
···378
フラッシュタイム···
···
···
···
···
···
···
···
···
···378
ブリッジ···
···
···
···
···
···
···
···
···296, 406, 407
フリップフロップ
···
···
···
···
···
···
···
···
···
··· 21
プリフィクス
···
···
···
···
···
···
···
···
···
···
···
··· 44
プリフェッチ···
···
···
···
···
···
···
···
···
···
···
···224
プリプロセッサ
···
···
···
···
···
···
···
···
···
···
··· 73
プリロード
···
···
···
···
···
···
···
···
···
··· 224, 341
プリント回路基板···
···
···
···
···
···
···
···36, 282
フリンの分類···
···
···
···
···
···
···
···
···
···
···
···349
フルアソシアティブ···
···
···
···
···
···
···
···
···237
フルアダー···
···
···
···
···
···
···
···
···
···
···17, 419
フレーム···
···
···
···
···
···
···
···
···
···
···
···
···
···255
プレリュード···
···
···
···
···
···
···
···
···
···
···
···472
ブロードバンド···
···
···
···
···
···
···
···
···
···
···410
プログラマビリティ
···
···
···
···
···
···
···
···
··· 29
プログラマブル
···
···
···
···
···
···
···
···
··· 71, 72
プログラミング
···
···
···
···
···
···
···
···
···
···
··· 71
プログラミングインターフェイス···
···
···275
プログラミングできるロジックのプロセッサ67
プログラミングの重荷
···
···
···
···
···
···
···
··· 91
プログラムカウンタ
···
···
···
···
···
···
··· 83, 93
プログラム駆動の入出力···
···
···
···
···
···
···304
プログラム内蔵式
···
···
···
···
···
···
···
···
···
··· 65
プロシージャ···
···
···
···
···
···
···
···
···
···
···
···166
プロシージャ間コール···
···
···
···
···
···
···
···469
プロシージャコール
···
···
···
···
···
··· 166, 466
プロセッサ
···
···
···
···
···
···
···
···
···
···
··· 63, 65
プロセッサのモード···
···
···
···
···
···
···
···
···314
プロセッサモード···
···
···
···
···
···
···
···
···
···249
プロテクション
···
···
···
···
···
···
···
··· 137, 251
文···
···
···
···
···
···
···
···
···
···
···
···
···
···
···
···
···156
分岐予測···
···
···
···
···
···
···
···
···
···
···
···
···
···150
分散···
···
···
···
···
···
···
···
···
···
···
···
···
···
···
···133
■へ
平均電力···
···
···
···
···
···
···
···
···
···
···
···
···
···382
並行性
···
···
···
···
···
···
···
···
···
···
···
··· 346, 360
米国国家規格協会
···
···
···
···
···
···
···
···
···
··· 45
並列アーキテクチャ···
···
···
···
···
···
···
···
···349
並列コンピュータ···
···
···
···
···
···
···
···
···
···345
並列処理
···
···
···
···
···
···
···
···
···
···
···
··· 2, 345
並列性
···
···
···
···
···
···
···
···
···
···
···
··· 147, 346
並列ハードウェア···
···
···
···
···
···
···
···
···
···345
ページ
···
···
···
···
···
···
···
···
···
···
···
··· 253, 255
ページ置換···
···
···
···
···
···
···
···
···
···
···
···
···254
ページテーブル···
···
···
···
···
···
···
···
···
···
···255
ページフォールト···
···
···
···
···
···
···
···
···
···253
ベース···
···
···
···
···
···
···
···
···
···
···
···
···
···
···250
ベースと境界···
···
···
···
···
···
···
···
···
···
···
···250
ベースレジスタ···
···
···
···
···
···
···
···
···
···
···250
ヘキサ
···
···
···
···
···
···
···
···
···
···
···
···
···
···
··· 43
冪指数
···
···
···
···
···
···
···
···
···
···
···
···
···
···
··· 53
ベクトル···
···
···
···
···
···
···
···
···
···
···
···
···
···351
ベル研···
···
···
···
···
···
···
···
···
···
···
···
···
···
···161
変換···
···
···
···
···
···
···
···
···
···
···
···
···
···
···
···243
変形ハーバードアーキテクチャ···
···
···
···230
変更ビット···
···
···
···
···
···
···
···
···
···
···
···
···258
ベンチマーク···
···
···
···
···
···
···
···
···
···
···
···399
■ほ
ポインタ···
···
···
···
···
···
···
···
···
···
···
···
···
···206
ポインタ演算···
···
···
···
···
···
···
···
···
···
···
···307
方形波
···
···
···
···
···
···
···
···
···
···
···
···
···
···
··· 24
ボードレベル・アーキテクチャ···
···
···
···405
ポーリング
···
···
···
···
···
···
···
···
···
··· 305, 310
保護···
···
···
···
···
···
···
···
···
···
···134, 137, 251
保護境界レジスタ···
···
···
···
···
···
···
···
···
···251
補助バス···
···
···
···
···
···
···
···
···
···
···
···
···
···296
ポストリュード···
···
···
···
···
···
···
···
···
···
···473
保存される···
···
···
···
···
···
···
···
···
···
···
···
···472
保存装置
···
···
···
···
···
···
···
···
···
···
···
···
···
··· 69
ポップ···
···
···
···
···
···
···
···
···
···
···
···
···
···
···460
保留···
···
···
···
···
···
···
···
···
···
···
···
···
···
···
···311
ボルト···
···
···
···
···
···
···
···
···
···
···
···
···
···
···
···8
■ま
マイクロエンジン···
···
···
···
···
···
···
···
···
···413
マイクロコード···
···
···
···
···
···
···
···
···
···
···138
マイクロコントローラ···
···
···
···
···
···70, 138
マイクロプロセッサ···
···
···
···
···
···
···
···
···138
マイケル・J・フリン···
···
···
···
···
···
···
··· 346
毎秒メガバイト···
···
···
···
···
···
···
···
···
···
···273
毎秒メガビット···
···
···
···
···
···
···
···
···
···
···273
マクロ命令セット···
···
···
···
···
···
···
···
···
···138
マザーボード
···
···
···
···
···
···
···
···
··· 281, 412
待ち行列
···
···
···
···
···
···
···
···
···
···
··· 206, 328
待ち時間···
···
···
···
···
···
···
···
···
···
···
···
···
···196
マップ···
···
···
···
···
···
···
···
···
···
···
···
···
···
···243
マルチクロックドメイン設計
···
···
···
···
··· 33
マルチコア···
···
···
···
···
···
···
···
···
···
···
···
···134
マルチコアCPU ···
···
···
···
···
···
···
···
···
···
··· 35
マルチコアプロセッサ···
···
···
···
···
···
···
···388
マルチプレクサ
···
···
···
···
···
···
···
··· 114, 274
マルチプログラミング···
···
···
···
···
···
···
···248
マルチプロセシング···
···
···
···
···
···
···
···
···248
マルチプロセッサ···
···
···
···
···
···
···
···
···
···353
満杯···
···
···
···
···
···
···
···
···
···
···
···
···
···
···
···338
■み
ミクロ···
···
···
···
···
···
···
···
···
···
···
···
···
···
···347
未使用···
···
···
···
···
···
···
···
···
···
···
···
···26, 107
ミス···
···
···
···
···
···
···
···
···
···
···
···
···
···
···
···219
ミス率···
···
···
···
···
···
···
···
···
···
···
···
···
···
···221
密結合···
···
···
···
···
···
···
···
···
···
···
···
···
···
···362
密度···
···
···
···
···
···
···
···
···
···
···
···
···
···
···
···195
hi.0412.ko.2002@gmail.com
　索　引
479
■む
ムーアの法則···
···
···
···
···
···
···
···
···
···35, 385
■め
明示···
···
···
···
···
···
···
···
···
···
···
···
···
···
···
···124
明示的なオペランド符号化···
···
···
···
···
···125
明示的並列性
···
···
···
···
···
···
···
···
··· 349, 360
命令
···
···
···
···
···
···
···
···
···
···
···
···
···
··· 39, 80
命令キャッシュ···
···
···
···
···
···
···
···
···
···
···230
命令コード
···
···
···
···
···
···
···
···
···
···
···
···
··· 81
命令ストア···
···
···
···
···
···
···
···
···
···
···
···
···189
命令セット
···
···
···
···
···
···
···
···
···
···
···
···
··· 80
命令セットアーキテクチャ
···
···
···
···
···
··· 80
命令デコーディング···
···
···
···
···
···
···
···
···111
命令の直列処理···
···
···
···
···
···
···
···
···
···
···149
命令パイプライン···
···
···
···
···
···
···
···87, 371
命令表現
···
···
···
···
···
···
···
···
···
···
···
···
···
··· 80
命令フォーマット
···
···
···
···
···
···
···
···
···
··· 80
命令ポインタ···
···
···
···
···
··· 72, 83, 93, 108
命令ミックス···
···
···
···
···
···
···
···
···
···
···
···398
命令名···
···
···
···
···
···
···
···
···
···
···
···
···
···
···105
命令メモリ···
···
···
···
···
···
···
···
···
···
···
···
···110
命令レジスタ···
···
···
···
···
···
···
···
···
···
···
···128
メインメモリ
···
···
···
···
···
···
···
···
··· 185, 186
メガバイト···
···
···
···
···
···
···
···
···
···
···
···
···206
メモリ···
···
···
···
···
···
···
···
···
···
···
···
···
···
···185
メモリアクセス···
···
···
···
···
···
···
···
···
···
···400
メモリ管理ユニット···
···
···
···
···
···
···
···
···242
メモリキャッシュ···
···
···
···
···
···
···
···
···
···389
メモリ構成
···
···
···
···
···
···
···
···
···
··· 186, 199
メモリコントローラ
···
···
···
···
···
··· 196, 199
メモリサイクル時間···
···
···
···
···
···
···
···
···197
メモリテクノロジー···
···
···
···
···
···
···
···
···186
メモリ転送サイズ···
···
···
···
···
···
···
···
···
···200
メモリの階層構造···
···
···
···
···
···
···
···
···
···188
メモリの番地···
···
···
···
···
···
···
···
···
···
···
···163
メモリバス···
···
···
···
···
···
···
···199, 279, 287
メモリバンク···
···
···
···
···
···
···
···
···
···
···
···210
メモリマップトアーキテクチャ···
···
···
···295
■も
モードレジスタ···
···
···
···
···
···
···
···
···
···
···137
モーリス・ウィルクス···
···
···
···
···
···
···
···224
文字
···
···
···
···
···
···
···
···
···
···
···
···
···
···
···
··· 45
文字集合
···
···
···
···
···
···
···
···
···
···
···
···
···
··· 45
モジュール···
···
···
···
···
···
···
···
···
···
···
···
···417
モジュール選択···
···
···
···
···
···
···
···
···
···
···422
文字列
···
···
···
···
···
···
···
···
···
···
···
···
···
···
··· 55
戻り値
···
···
···
···
···
···
···
···
···
···
···
··· 169, 466
モノリス的なプログラム···
···
···
···
···
···
···371
漏れ···
···
···
···
···
···
···
···
···
···
···
···
···
···
···
···383
■ゆ
有効出力···
···
···
···
···
···
···
···
···
···
···
···
···
···235
有効ビット···
···
···
···
···
···
···
···
···
···
···
···
···234
優先度···
···
···
···
···
···
···
···
···
···
···
···
···
···
···134
ユニコード
···
···
···
···
···
···
···
···
···
···
···
···
··· 46
ユニプロセッサアーキテクチャ···
···
···
···350
■よ
要求の待ち行列···
···
···
···
···
···
···
···
···
···
···328
要請···
···
···
···
···
···
···
···
···
···
···
···
···
···
···
···253
容量···
···
···
···
···
···
···
···
···
···
···
···
···
···
···
···384
横取り···
···
···
···
···
···
···
···
···
···
···
···
···
···
···218
呼び出された側···
···
···
···
···
···
···
···
···
···
···471
呼び出し···
···
···
···
···
···
···
···
···
···
···
···
···
···166
呼び出し規約···
···
···
···
···
···
···169, 173, 464
呼び出した側···
···
···
···
···
···
···
···
···
···
···
···471
読み出し···
···
···
···
···
···
···
···
···
···
···
···
···
···196
読み出し可能···
···
···
···
···
···
···
···
···
···
···
···187
読み出し専用メモリ
···
···
···
···
···
···
···
···
··· 72
■ら
ライト···
···
···
···
···
···
···
···
···
···196, 200, 320
ライトイネーブル···
···
···
···
···
···
···
···
···
···194
ライト演算
···
···
···
···
··· 190, 200, 225, 259
ライトサイクル時間···
···
···
···
···
···
···
···
···197
ライトスルーキャッシュ···
···
···
···
···
···
···226
ライトバックキャッシュ···
···
···
···
···
···
···226
ラッチ
···
···
···
···
···
···
···
···
···
··· 19, 347, 419
ラップアラウンド
···
···
···
···
···
···
···
···
···
··· 47
ラベル···
···
···
···
···
···
···
···
···
···
···
···
···
···
···170
ランタイムライブラリ···
···
···
···
···
···
···
···332
ランダムアクセス···
···
···
···
···187, 190, 193
ランダムアクセスメモリ
···
···
···
··· 187, 193
■り
リアルモード···
···
···
···
···
···
···
···
···
···
···
···249
リード
···
···
···
···
···
···
··· 189, 196, 200, 320
リード演算
···
···
···
···
···
···
···
···
···
··· 200, 320
リードオンリー···
···
···
···
···
···
···
···
···
···
···190
リードオンリーメモリ···
···
···
···
···
···
···
···187
リードサイクル時間···
···
···
···
···
···
···
···
···197
リード操作···
···
···
···
···
···
···
···
···
···
···
···
···204
リードライト···
···
···
···
···
···
···
···
···
···
···
···190
リクエストキュー···
···
···
···
···
···
···
···
···
···328
離散的···
···
···
···
···
···
···
···
···
···
···
···
···
···
···
···7
リスク
···
···
···
···
···
···
···
···
···
···
···
···
···
···
··· 86
リセット
···
···
···
···
···
···
···
···
···
···
···
··· 22, 28
リターンアドレス···
···
···
···
···
···
···
···
···
···167
リターン命令···
···
···
···
···
···
···
···
···
···
···
···166
リトルエンディアン
···
···
···
···
···
···
···
···
··· 48
リブータ···
···
···
···
···
···
···
···
···
···
···
···
···
···420
リフレッシュ回路···
···
···
···
···
···
···
···
···
···194
粒度の粗いマッピング···
···
···
···
···
···
···
···251
粒度の細かいマッピング···
···
···
···
···
···
···252
利用ビット···
···
···
···
···
···
···
···
···
···
···
···
···258
リロケータブル
···
···
···
···
···
···
···
···
···
···
··· 73
リンカ
···
···
···
···
···
···
···
···
···
···
···
···
···
···
··· 73
リンクレジスタ···
···
···
···
···
···
···
···
···
···
···469
■れ
例外···
···
···
···
···
···
···
···
···
···
···
···
···
···
···
···253
例外ベクトル···
···
···
···
···
···
···
···
···
···
···
···253
冷却···
···
···
···
···
···
···
···
···
···
···
···
···
···
···
···385
レイテンシ
···
···
···
···
···
···
···
···
···
··· 196, 273
レジスタ
···
···
··· 20, 69, 83, 107, 163, 419
レジスタ＋オフセット···
···
···
···
···
···
···
···126
レジスタインターフェイス···
···
···
···
···
···144
レジスタウィンドウ
···
···
···
···
···
···
···
···
··· 94
レジスタコンフリクト
···
···
···
···
···
···
···
··· 85
レジスタスピル
···
···
···
···
···
···
···
···
···
···
··· 84
レジスタファイル···
···
···
···
···
···
···
···
···
···104
レジスタユニット···
···
···
···
···
···
···
···
···
···112
レジスタ割り当て
···
···
···
···
···
···
···
···
···
··· 84
レジデントセット···
···
···
···
···
···
···
···
···
···255
レジューム···
···
···
···
···
···
···
···
···
···
···
···
···311
列優先の順序···
···
···
···
···
···
···
···
···
···
···
···261
レディ
···
···
···
···
···
···
···
···
···
···
···
··· 197, 328
レディ状態···
···
···
···
···
···
···
···
···
···
···
···
···304
連結リスト···
···
··· 128, 206, 207, 319, 320
連続的···
···
···
···
···
···
···
···
···
···
···
···
···
···
···293
連続的仮想アドレス空間···
···
···
···
···
···
···245
■ろ
ロード···
···
···
···
···
···
···
···
···
···
···
···
···
···
···189
ロード命令···
···
···
···
···
···
···
···
···
···
···
···
···160
論理ゲート
···
···
···
···
···
···
···
···
···
···
···
···
··· 12
論理積···
···
···
···
···
···
···
···
···
···
···
···
···
···
···205
論理の逆
···
···
···
···
···
···
···
···
···
···
···
···
···
··· 11
論理和···
···
···
···
···
···
···
···
···
···
···
···
···
···
···257
■わ
ワークロード···
···
···
···
···
···
···
···
···
···
···
···398
ワード
···
···
···
···
···
···
···
···
···
···
···
··· 200, 201
ワードアドレッシング···
···
···
···
···
···
···
···200
ワードサイズ
···
···
···
···
···
···
···
···
··· 200, 201
ワードの配列···
···
···
···
···
···
···
···
···
···
···
···201
ワード幅···
···
···
···
···
···
···
···
···
···
···
···
···
···200
ワット···
···
···
···
···
···
···
···
···
···
···
···
···
···
···381
割り当てのないアドレス···
···
···
···
···
···
···289
割り込み···
···
···
···
···
···
···
···
···
···
···
···
···
···310
割り込みからのリターン···
···
···
···
···
···
···312
割り込み駆動の入出力···
···
···
···
···
···
···
···311
割り込みハンドラ···
···
···
···
···
···
···
···
···
···313
割り込みベクトル···
···
···
···
···
···
···
···
···
···313
割り込みを許可···
···
···
···
···
···
···
···
···
···
···314
割り込みを禁止···
···
···
···
···
···
···
···
···
···
···314
hi.0412.ko.2002@gmail.com
装丁
山口了児（zuniga）
コンピュータアーキテクチャのエッセンス［第2 版］
2020 年10 月14 日
初版第1 刷発行
著　者
Douglas E.Comer（ダグラス・E・カマー）
翻訳
吉川邦夫
発行人
佐々木幹夫
発行所
株式会社翔泳社（https://www.shoeisha.co.jp/）
印刷・製本
株式会社廣済堂
本書は著作権法上の保護を受けています。本書の一部または全部について（ソフトウェ
アおよびプログラムを含む）
、株式会社翔泳社から文書による許諾を得ずに、いかなる
方法においても無断で複写、複製することは禁じられています。
本書へのお問い合わせについては、ii ページに記載の内容をお読みください。
落丁・乱丁はお取り替えいたします。03‒5362‒3705 までご連絡ください。
ISBN978‒4‒7981‒6793‒0
Printed in Japan
hi.0412.ko.2002@gmail.com
この電子書籍の全部または一部について、著作権者ならびに株式会社翔泳社に無断で
複製（コピー）、転載、公衆送信をすること、改変・改ざんすることを禁じます。
また、有償・無償にかかわらずこのデータを第三者に譲渡することを禁じます。
2020年10月06日　電子書籍版発行
※印刷出版とは異なる表記・表現の場合があります。予めご了承ください。
※印刷出版再現のため電子書籍としては不要な情報を含んでいる場合があります。
※本電子書籍は同名出版物を底本として作成しました。
hi.0412.ko.2002@gmail.com
